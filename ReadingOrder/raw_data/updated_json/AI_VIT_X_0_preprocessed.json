{
    "id": "32b78362-0f94-11ef-8828-426932df3dcf",
    "pdf_path": "/root/data/pdf/2110.14168v2.pdf",
    "elements": [
        {
            "bounding_box": [
                {
                    "x": 647,
                    "y": 685
                },
                {
                    "x": 1903,
                    "y": 685
                },
                {
                    "x": 1903,
                    "y": 755
                },
                {
                    "x": 647,
                    "y": 755
                }
            ],
            "category": "paragraph",
            "html": "<p id='0' style='font-size:22px'>Training Verifiers to Solve Math Word Problems</p>",
            "id": 0,
            "page": 1,
            "text": "Training Verifiers to Solve Math Word Problems"
        },
        {
            "bounding_box": [
                {
                    "x": 618,
                    "y": 824
                },
                {
                    "x": 1932,
                    "y": 824
                },
                {
                    "x": 1932,
                    "y": 989
                },
                {
                    "x": 618,
                    "y": 989
                }
            ],
            "category": "figure",
            "html": "<figure><img id='1' style='font-size:14px' alt=\"Karl Cobbe* Vineet Kosaraju* Mohammad Bavarian Mark Chen\nHeewoo Jun Lukasz Kaiser Matthias Plappert Jerry Tworek\nJacob Hilton Reiichiro Nakano Christopher Hesse John Schulman\" data-coord=\"top-left:(618,824); bottom-right:(1932,989)\" /></figure>",
            "id": 1,
            "page": 1,
            "text": "Karl Cobbe* Vineet Kosaraju* Mohammad Bavarian Mark Chen Heewoo Jun Lukasz Kaiser Matthias Plappert Jerry Tworek Jacob Hilton Reiichiro Nakano Christopher Hesse John Schulman"
        },
        {
            "bounding_box": [
                {
                    "x": 1201,
                    "y": 1027
                },
                {
                    "x": 1345,
                    "y": 1027
                },
                {
                    "x": 1345,
                    "y": 1070
                },
                {
                    "x": 1201,
                    "y": 1070
                }
            ],
            "category": "paragraph",
            "html": "<p id='2' style='font-size:20px'>OpenAI</p>",
            "id": 2,
            "page": 1,
            "text": "OpenAI"
        },
        {
            "bounding_box": [
                {
                    "x": 1182,
                    "y": 1199
                },
                {
                    "x": 1361,
                    "y": 1199
                },
                {
                    "x": 1361,
                    "y": 1242
                },
                {
                    "x": 1182,
                    "y": 1242
                }
            ],
            "category": "paragraph",
            "html": "<p id='3' style='font-size:18px'>Abstract</p>",
            "id": 3,
            "page": 1,
            "text": "Abstract"
        },
        {
            "bounding_box": [
                {
                    "x": 655,
                    "y": 1263
                },
                {
                    "x": 1892,
                    "y": 1263
                },
                {
                    "x": 1892,
                    "y": 1859
                },
                {
                    "x": 655,
                    "y": 1859
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='4' style='font-size:18px'>State-of-the-art language models can match human performance on<br>many tasks, but they still struggle to robustly perform multi-step mathe-<br>matical reasoning. To diagnose the failures of current models and support<br>research, we introduce GSM8K, a dataset of 8.5K high quality linguisti-<br>cally diverse grade school math word problems. We find that even the<br>largest transformer models fail to achieve high test performance, despite<br>the conceptual simplicity of this problem distribution. To increase per-<br>formance, we propose training verifiers to judge the correctness of model<br>completions. At test time, we generate many candidate solutions and<br>select the one ranked highest by the verifier. We demonstrate that ver-<br>ification significantly improves performance on GSM8K, and we provide<br>strong empirical evidence that verification scales more effectively with<br>increased data than a finetuning baseline.</p>",
            "id": 4,
            "page": 1,
            "text": "State-of-the-art language models can match human performance on many tasks, but they still struggle to robustly perform multi-step mathematical reasoning. To diagnose the failures of current models and support research, we introduce GSM8K, a dataset of 8.5K high quality linguistically diverse grade school math word problems. We find that even the largest transformer models fail to achieve high test performance, despite the conceptual simplicity of this problem distribution. To increase performance, we propose training verifiers to judge the correctness of model completions. At test time, we generate many candidate solutions and select the one ranked highest by the verifier. We demonstrate that verification significantly improves performance on GSM8K, and we provide strong empirical evidence that verification scales more effectively with increased data than a finetuning baseline."
        },
        {
            "bounding_box": [
                {
                    "x": 555,
                    "y": 1935
                },
                {
                    "x": 1033,
                    "y": 1935
                },
                {
                    "x": 1033,
                    "y": 1997
                },
                {
                    "x": 555,
                    "y": 1997
                }
            ],
            "category": "paragraph",
            "html": "<p id='5' style='font-size:22px'>1 Introduction</p>",
            "id": 5,
            "page": 1,
            "text": "1 Introduction"
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 2036
                },
                {
                    "x": 1998,
                    "y": 2036
                },
                {
                    "x": 1998,
                    "y": 2435
                },
                {
                    "x": 548,
                    "y": 2435
                }
            ],
            "category": "paragraph",
            "html": "<p id='6' style='font-size:20px'>In recent years, large language models have demonstrated impressive skills<br>across many diverse tasks (Wang et al., 2019; Brown et al., 2020). Kaplan<br>et al. (2020) describe the consistent benefits of increasing model size, character-<br>izing scaling trends that hold across many orders of magnitude. However, even<br>the largest models falter when required to perform multi-step mathematical rea-<br>soning (Hendrycks et al., 2021). Model samples frequently contain catastrophic<br>mistakes, even after the model has been appropriately finetuned. Mathematical<br>reasoning thus reveals a critical weakness in modern language models.</p>",
            "id": 6,
            "page": 1,
            "text": "In recent years, large language models have demonstrated impressive skills across many diverse tasks (Wang , 2019; Brown , 2020). Kaplan  (2020) describe the consistent benefits of increasing model size, characterizing scaling trends that hold across many orders of magnitude. However, even the largest models falter when required to perform multi-step mathematical reasoning (Hendrycks , 2021). Model samples frequently contain catastrophic mistakes, even after the model has been appropriately finetuned. Mathematical reasoning thus reveals a critical weakness in modern language models."
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 2439
                },
                {
                    "x": 1998,
                    "y": 2439
                },
                {
                    "x": 1998,
                    "y": 2685
                },
                {
                    "x": 550,
                    "y": 2685
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='7' style='font-size:18px'>One significant challenge in mathematical reasoning is the high sensitivity<br>to individual mistakes (Shen et al., 2021a). When generating a solution, au-<br>toregressive models have no mechanism to correct their own errors. Solutions<br>that veer off-course quickly become unrecoverable. If we rely purely on genera-<br>tive methods and extrapolate from current trends, we will require an exorbitant</p>",
            "id": 7,
            "page": 1,
            "text": "One significant challenge in mathematical reasoning is the high sensitivity to individual mistakes (Shen , 2021a). When generating a solution, autoregressive models have no mechanism to correct their own errors. Solutions that veer off-course quickly become unrecoverable. If we rely purely on generative methods and extrapolate from current trends, we will require an exorbitant"
        },
        {
            "bounding_box": [
                {
                    "x": 551,
                    "y": 2714
                },
                {
                    "x": 1993,
                    "y": 2714
                },
                {
                    "x": 1993,
                    "y": 2795
                },
                {
                    "x": 551,
                    "y": 2795
                }
            ],
            "category": "paragraph",
            "html": "<p id='8' style='font-size:16px'>* Equal contribution. Correspondence to: Karl Cobbe <karl@openai.com>, Vineet<br>Kosaraju <vineet@openai.com></p>",
            "id": 8,
            "page": 1,
            "text": "* Equal contribution. Correspondence to: Karl Cobbe <karl@openai.com>, Vineet Kosaraju <vineet@openai.com>"
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2933
                },
                {
                    "x": 1259,
                    "y": 2933
                }
            ],
            "category": "footer",
            "html": "<footer id='9' style='font-size:16px'>1</footer>",
            "id": 9,
            "page": 1,
            "text": "1"
        },
        {
            "bounding_box": [
                {
                    "x": 64,
                    "y": 870
                },
                {
                    "x": 149,
                    "y": 870
                },
                {
                    "x": 149,
                    "y": 2336
                },
                {
                    "x": 64,
                    "y": 2336
                }
            ],
            "category": "footer",
            "html": "<br><footer id='10' style='font-size:14px'>2021<br>Nov<br>18<br>[cs.LG]<br>arXiv:2110.14168v2</footer>",
            "id": 10,
            "page": 1,
            "text": "2021 Nov 18 [cs.LG] arXiv:2110.14168v2"
        },
        {
            "bounding_box": [
                {
                    "x": 571,
                    "y": 531
                },
                {
                    "x": 1950,
                    "y": 531
                },
                {
                    "x": 1950,
                    "y": 707
                },
                {
                    "x": 571,
                    "y": 707
                }
            ],
            "category": "paragraph",
            "html": "<p id='11' style='font-size:14px'>Problem: Beth bakes 4, 2 dozen batches of cookies in a week. If these cookies are shared amongst 16 people equally, how many cookies does<br>each person consume?<br>Solution: Beth bakes 4 2 dozen batches of cookies for a total of 4*2 = <<4*2=8>>8 dozen cookies<br>There are 12 cookies in a dozen and she makes 8 dozen cookies for a total of 12*8 = <<12*8=96>>96 cookies<br>She splits the 96 cookies equally amongst 16 people so they each eat 96/16 = <<96/16=6>>6 cookies<br>Final Answer: 6</p>",
            "id": 11,
            "page": 2,
            "text": "Problem: Beth bakes 4, 2 dozen batches of cookies in a week. If these cookies are shared amongst 16 people equally, how many cookies does each person consume? Solution: Beth bakes 4 2 dozen batches of cookies for a total of 4*2 = <<4*2=8>>8 dozen cookies There are 12 cookies in a dozen and she makes 8 dozen cookies for a total of 12*8 = <<12*8=96>>96 cookies She splits the 96 cookies equally amongst 16 people so they each eat 96/16 = <<96/16=6>>6 cookies Final Answer: 6"
        },
        {
            "bounding_box": [
                {
                    "x": 571,
                    "y": 739
                },
                {
                    "x": 1973,
                    "y": 739
                },
                {
                    "x": 1973,
                    "y": 965
                },
                {
                    "x": 571,
                    "y": 965
                }
            ],
            "category": "paragraph",
            "html": "<p id='12' style='font-size:14px'>Problem: Mrs. Lim milks her COWS twice a day. Yesterday morning, she got 68 gallons of milk and in the evening, she got 82 gallons. This morning,<br>she got 18 gallons fewer than she had yesterday morning. After selling some gallons of milk in the afternoon, Mrs. Lim has only 24 gallons left. How<br>much was her revenue for the milk if each gallon costs $3.50?<br>Mrs. Lim got 68 gallons - 18 gallons = <<68-18=50>>50 gallons this morning.<br>So she was able to get a total of 68 gallons + 82 gallons + 50 gallons = <<68+82+50=200>>200 gallons.<br>She was able to sell 200 gallons - 24 gallons = <<200-24=176>> 176 gallons.<br>Thus, her total revenue for the milk is $3.50/gallon x 176 gallons = $<<3.50*176=616>>616.<br>Final Answer: 616</p>",
            "id": 12,
            "page": 2,
            "text": "Problem: Mrs. Lim milks her COWS twice a day. Yesterday morning, she got 68 gallons of milk and in the evening, she got 82 gallons. This morning, she got 18 gallons fewer than she had yesterday morning. After selling some gallons of milk in the afternoon, Mrs. Lim has only 24 gallons left. How much was her revenue for the milk if each gallon costs $3.50? Mrs. Lim got 68 gallons - 18 gallons = <<68-18=50>>50 gallons this morning. So she was able to get a total of 68 gallons + 82 gallons + 50 gallons = <<68+82+50=200>>200 gallons. She was able to sell 200 gallons - 24 gallons = <<200-24=176>> 176 gallons. Thus, her total revenue for the milk is $3.50/gallon x 176 gallons = $<<3.50*176=616>>616. Final Answer: 616"
        },
        {
            "bounding_box": [
                {
                    "x": 571,
                    "y": 1001
                },
                {
                    "x": 1962,
                    "y": 1001
                },
                {
                    "x": 1962,
                    "y": 1255
                },
                {
                    "x": 571,
                    "y": 1255
                }
            ],
            "category": "paragraph",
            "html": "<p id='13' style='font-size:14px'>Problem: Tina buys 3 12-packs of soda for a party. Including Tina, 6 people are at the party. Half of the people at the party have 3 sodas each, 2<br>of the people have 4, and 1 person has 5. How many sodas are left over when the party is over?<br>Solution: Tina buys 3 12-packs of soda, for 3*12= <<3*12=36>>36 sodas<br>6 people attend the party, so half of them is 6/2= <<6/2=3>>3 people<br>Each of those people drinks 3 sodas, so they drink 3*3=<<3*3=9>>9 sodas<br>Two people drink 4 sodas, which means they drink 2*4=<<4*2=8>>8 sodas<br>With one person drinking 5, that brings the total drank to 5+9+8+3= <<5+9+8+3=25>>25 sodas<br>As Tina started off with 36 sodas, that means there are 36-25=<<36-25=11>>11 sodas left<br>Final Answer: 11</p>",
            "id": 13,
            "page": 2,
            "text": "Problem: Tina buys 3 12-packs of soda for a party. Including Tina, 6 people are at the party. Half of the people at the party have 3 sodas each, 2 of the people have 4, and 1 person has 5. How many sodas are left over when the party is over? Solution: Tina buys 3 12-packs of soda, for 3*12= <<3*12=36>>36 sodas 6 people attend the party, so half of them is 6/2= <<6/2=3>>3 people Each of those people drinks 3 sodas, so they drink 3*3=<<3*3=9>>9 sodas Two people drink 4 sodas, which means they drink 2*4=<<4*2=8>>8 sodas With one person drinking 5, that brings the total drank to 5+9+8+3= <<5+9+8+3=25>>25 sodas As Tina started off with 36 sodas, that means there are 36-25=<<36-25=11>>11 sodas left Final Answer: 11"
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 1320
                },
                {
                    "x": 1993,
                    "y": 1320
                },
                {
                    "x": 1993,
                    "y": 1419
                },
                {
                    "x": 552,
                    "y": 1419
                }
            ],
            "category": "paragraph",
            "html": "<p id='14' style='font-size:20px'>Figure 1: Three example problems from GSM8K. Calculation annotations are<br>highlighted in red.</p>",
            "id": 14,
            "page": 2,
            "text": "Figure 1: Three example problems from GSM8K. Calculation annotations are highlighted in red."
        },
        {
            "bounding_box": [
                {
                    "x": 551,
                    "y": 1511
                },
                {
                    "x": 1993,
                    "y": 1511
                },
                {
                    "x": 1993,
                    "y": 1656
                },
                {
                    "x": 551,
                    "y": 1656
                }
            ],
            "category": "paragraph",
            "html": "<p id='15' style='font-size:18px'>parameter count to achieve even moderate performance on distributions as chal-<br>lenging as the MATH dataset (Hendrycks et al., 2021). This evidence strongly<br>motivates the search for methods with more favorable scaling laws.</p>",
            "id": 15,
            "page": 2,
            "text": "parameter count to achieve even moderate performance on distributions as challenging as the MATH dataset (Hendrycks , 2021). This evidence strongly motivates the search for methods with more favorable scaling laws."
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 1663
                },
                {
                    "x": 1996,
                    "y": 1663
                },
                {
                    "x": 1996,
                    "y": 1907
                },
                {
                    "x": 550,
                    "y": 1907
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='16' style='font-size:20px'>We propose training verifiers to evaluate the correctness of model generated<br>solutions, similar to concurrent work by Shen et al. (2021a). At test time, we<br>sample a fixed number of candidate solutions and select the solution ranked<br>highest by the verifier. Verifiers benefit both from their inherent optionality<br>and from verification being a simpler task than generation in general.</p>",
            "id": 16,
            "page": 2,
            "text": "We propose training verifiers to evaluate the correctness of model generated solutions, similar to concurrent work by Shen  (2021a). At test time, we sample a fixed number of candidate solutions and select the solution ranked highest by the verifier. Verifiers benefit both from their inherent optionality and from verification being a simpler task than generation in general."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1910
                },
                {
                    "x": 1997,
                    "y": 1910
                },
                {
                    "x": 1997,
                    "y": 2257
                },
                {
                    "x": 549,
                    "y": 2257
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='17' style='font-size:22px'>To facilitate research, we are releasing GSM8K, a dataset of 8.5K high quality<br>problems at the grade school math level. We designed this dataset to have high<br>linguistic diversity while relying on relatively simple grade school math concepts.<br>State-of-the-art language models struggle to achieve high performance on this<br>dataset, primarily due to the high diversity among problems. At the same time,<br>GSM8K solutions depend only on elementary concepts, SO achieving high test<br>performance is a tractable goal.</p>",
            "id": 17,
            "page": 2,
            "text": "To facilitate research, we are releasing GSM8K, a dataset of 8.5K high quality problems at the grade school math level. We designed this dataset to have high linguistic diversity while relying on relatively simple grade school math concepts. State-of-the-art language models struggle to achieve high performance on this dataset, primarily due to the high diversity among problems. At the same time, GSM8K solutions depend only on elementary concepts, SO achieving high test performance is a tractable goal."
        },
        {
            "bounding_box": [
                {
                    "x": 615,
                    "y": 2258
                },
                {
                    "x": 1320,
                    "y": 2258
                },
                {
                    "x": 1320,
                    "y": 2303
                },
                {
                    "x": 615,
                    "y": 2303
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='18' style='font-size:16px'>Our main contributions are as follows:</p>",
            "id": 18,
            "page": 2,
            "text": "Our main contributions are as follows:"
        },
        {
            "bounding_box": [
                {
                    "x": 600,
                    "y": 2343
                },
                {
                    "x": 2000,
                    "y": 2343
                },
                {
                    "x": 2000,
                    "y": 2815
                },
                {
                    "x": 600,
                    "y": 2815
                }
            ],
            "category": "paragraph",
            "html": "<p id='19' style='font-size:20px'>1. We present a curated dataset of 8.5K grade school math questions and nat-<br>ural language solutions, useful for probing the informal reasoning ability<br>of large language models.<br>2. We show that, compared to a finetuning baseline, the use of verifiers results<br>in approximately the same performance boost as a 30x model size increase,<br>and that verifiers scale significantly better with increased data.<br>3. We show that dropout acts as a strong regularizer, significantly improving<br>performance for both finetuning and verification.</p>",
            "id": 19,
            "page": 2,
            "text": "1. We present a curated dataset of 8.5K grade school math questions and natural language solutions, useful for probing the informal reasoning ability of large language models. 2. We show that, compared to a finetuning baseline, the use of verifiers results in approximately the same performance boost as a 30x model size increase, and that verifiers scale significantly better with increased data. 3. We show that dropout acts as a strong regularizer, significantly improving performance for both finetuning and verification."
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2932
                },
                {
                    "x": 1259,
                    "y": 2932
                }
            ],
            "category": "footer",
            "html": "<footer id='20' style='font-size:16px'>2</footer>",
            "id": 20,
            "page": 2,
            "text": "2"
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 515
                },
                {
                    "x": 889,
                    "y": 515
                },
                {
                    "x": 889,
                    "y": 574
                },
                {
                    "x": 552,
                    "y": 574
                }
            ],
            "category": "paragraph",
            "html": "<p id='21' style='font-size:22px'>2 Dataset</p>",
            "id": 21,
            "page": 3,
            "text": "2 Dataset"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 615
                },
                {
                    "x": 1997,
                    "y": 615
                },
                {
                    "x": 1997,
                    "y": 912
                },
                {
                    "x": 549,
                    "y": 912
                }
            ],
            "category": "paragraph",
            "html": "<p id='22' style='font-size:16px'>GSM8K consists of 8.5K high quality grade school math problems created by<br>human problem writers. We segmented these into 7.5K training problems and<br>1K test problems. These problems take between 2 and 8 steps to solve, and<br>solutions primarily involve performing a sequence of elementary calculations<br>using basic arithmetic operations (+ - x÷) to reach the final answer. A bright<br>middle school student should be able to solve every problem.</p>",
            "id": 22,
            "page": 3,
            "text": "GSM8K consists of 8.5K high quality grade school math problems created by human problem writers. We segmented these into 7.5K training problems and 1K test problems. These problems take between 2 and 8 steps to solve, and solutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ - x÷) to reach the final answer. A bright middle school student should be able to solve every problem."
        },
        {
            "bounding_box": [
                {
                    "x": 614,
                    "y": 916
                },
                {
                    "x": 1734,
                    "y": 916
                },
                {
                    "x": 1734,
                    "y": 964
                },
                {
                    "x": 614,
                    "y": 964
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='23' style='font-size:18px'>We created GSM8K based on the following design principles.</p>",
            "id": 23,
            "page": 3,
            "text": "We created GSM8K based on the following design principles."
        },
        {
            "bounding_box": [
                {
                    "x": 608,
                    "y": 1007
                },
                {
                    "x": 2002,
                    "y": 1007
                },
                {
                    "x": 2002,
                    "y": 2201
                },
                {
                    "x": 608,
                    "y": 2201
                }
            ],
            "category": "paragraph",
            "html": "<p id='24' style='font-size:16px'>● High Quality We avoid error-prone scraping procedures and instead rely<br>on human workers to create problems. After performing extensive quality<br>control based on workers' answer agreement, we estimate that less than 2<br>percent of problems contain breaking errors.<br>● High Diversity We strive for high diversity among problems. We ac-<br>tively avoid designing problems that are drawn from the same linguistic<br>template or differ only in superficial details, an issue that is prevalent<br>among many other datasets. By creating each individual problem to be<br>relatively unique, held-out test performance becomes a far more relevant<br>metric.<br>● Moderate Difficulty We choose a problem distribution that is challeng-<br>ing for large state-of-the-art language models, without being completely<br>intractable. GSM8K will help us better understand the data scaling trends<br>of different models and methods in this difficulty sweet spot. Problems re-<br>quire no concepts beyond the level of early Algebra, and the vast majority<br>of problems can be solved without explicitly defining a variable.<br>● Natural Language Solutions We collect solutions in natural language<br>rather than as pure math expressions. We believe this is the most generally<br>useful data format, and we expect it to shed light on the properties of large<br>language models' internal monologues. We instructed problem writers to<br>explain their work as much as possible, but we allowed them to write<br>solutions in their own diverse linguistic styles.</p>",
            "id": 24,
            "page": 3,
            "text": "● High Quality We avoid error-prone scraping procedures and instead rely on human workers to create problems. After performing extensive quality control based on workers' answer agreement, we estimate that less than 2 percent of problems contain breaking errors. ● High Diversity We strive for high diversity among problems. We actively avoid designing problems that are drawn from the same linguistic template or differ only in superficial details, an issue that is prevalent among many other datasets. By creating each individual problem to be relatively unique, held-out test performance becomes a far more relevant metric. ● Moderate Difficulty We choose a problem distribution that is challenging for large state-of-the-art language models, without being completely intractable. GSM8K will help us better understand the data scaling trends of different models and methods in this difficulty sweet spot. Problems require no concepts beyond the level of early Algebra, and the vast majority of problems can be solved without explicitly defining a variable. ● Natural Language Solutions We collect solutions in natural language rather than as pure math expressions. We believe this is the most generally useful data format, and we expect it to shed light on the properties of large language models' internal monologues. We instructed problem writers to explain their work as much as possible, but we allowed them to write solutions in their own diverse linguistic styles."
        },
        {
            "bounding_box": [
                {
                    "x": 547,
                    "y": 2242
                },
                {
                    "x": 1997,
                    "y": 2242
                },
                {
                    "x": 1997,
                    "y": 2392
                },
                {
                    "x": 547,
                    "y": 2392
                }
            ],
            "category": "paragraph",
            "html": "<p id='25' style='font-size:18px'>The full GSM8K dataset can be found at https: //github.com / openai/ grade-<br>school-math. Example problems are shown in Figure 1, and we discuss addi-<br>tional dataset details in Appendix A.</p>",
            "id": 25,
            "page": 3,
            "text": "The full GSM8K dataset can be found at https: //github.com / openai/ gradeschool-math. Example problems are shown in Figure 1, and we discuss additional dataset details in Appendix A."
        },
        {
            "bounding_box": [
                {
                    "x": 553,
                    "y": 2470
                },
                {
                    "x": 1070,
                    "y": 2470
                },
                {
                    "x": 1070,
                    "y": 2527
                },
                {
                    "x": 553,
                    "y": 2527
                }
            ],
            "category": "paragraph",
            "html": "<p id='26' style='font-size:22px'>3 Related Work</p>",
            "id": 26,
            "page": 3,
            "text": "3 Related Work"
        },
        {
            "bounding_box": [
                {
                    "x": 553,
                    "y": 2576
                },
                {
                    "x": 1106,
                    "y": 2576
                },
                {
                    "x": 1106,
                    "y": 2627
                },
                {
                    "x": 553,
                    "y": 2627
                }
            ],
            "category": "paragraph",
            "html": "<p id='27' style='font-size:20px'>3.1 Related Datasets</p>",
            "id": 27,
            "page": 3,
            "text": "3.1 Related Datasets"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 2656
                },
                {
                    "x": 1998,
                    "y": 2656
                },
                {
                    "x": 1998,
                    "y": 2806
                },
                {
                    "x": 549,
                    "y": 2806
                }
            ],
            "category": "paragraph",
            "html": "<p id='28' style='font-size:18px'>Early math word problem datasets (Kushman et al., 2014; Roy and Roth, 2015)<br>are relatively small and are not well suited for testing the limits of modern lan-<br>guage models. Dolphin18K (Huang et al., 2016) is a larger dataset containing</p>",
            "id": 28,
            "page": 3,
            "text": "Early math word problem datasets (Kushman , 2014; Roy and Roth, 2015) are relatively small and are not well suited for testing the limits of modern language models. Dolphin18K (Huang , 2016) is a larger dataset containing"
        },
        {
            "bounding_box": [
                {
                    "x": 1258,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2933
                },
                {
                    "x": 1258,
                    "y": 2933
                }
            ],
            "category": "footer",
            "html": "<footer id='29' style='font-size:14px'>3</footer>",
            "id": 29,
            "page": 3,
            "text": "3"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 523
                },
                {
                    "x": 1998,
                    "y": 523
                },
                {
                    "x": 1998,
                    "y": 1071
                },
                {
                    "x": 549,
                    "y": 1071
                }
            ],
            "category": "paragraph",
            "html": "<p id='30' style='font-size:18px'>18K problems, but solutions are provided only in the form of equations or fi-<br>nal answers. AQuA-RAT (Ling et al., 2017) contains 100K problems, but this<br>dataset unfortunately suffers from both a high degree of problem templatiza-<br>tion and poor quality control of the natural language solutions. MathQA is<br>a recently released subset of AQuA-RAT focused on correcting these mistakes<br>(Amini et al., 2019), but even the corrected dataset has data quality issues, with<br>around 30% of the data having inconsistencies (Miao et al., 2021). Ape210K<br>(Zhao et al., 2020) is the largest publicly available dataset, consisting of 210K<br>Chinese elementary school-level math problems. However, due to the language<br>barrier and the lack of natural language solutions, we're unable to evaluate our<br>methods on this dataset.</p>",
            "id": 30,
            "page": 4,
            "text": "18K problems, but solutions are provided only in the form of equations or final answers. AQuA-RAT (Ling , 2017) contains 100K problems, but this dataset unfortunately suffers from both a high degree of problem templatization and poor quality control of the natural language solutions. MathQA is a recently released subset of AQuA-RAT focused on correcting these mistakes (Amini , 2019), but even the corrected dataset has data quality issues, with around 30% of the data having inconsistencies (Miao , 2021). Ape210K (Zhao , 2020) is the largest publicly available dataset, consisting of 210K Chinese elementary school-level math problems. However, due to the language barrier and the lack of natural language solutions, we're unable to evaluate our methods on this dataset."
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 1074
                },
                {
                    "x": 1997,
                    "y": 1074
                },
                {
                    "x": 1997,
                    "y": 1519
                },
                {
                    "x": 550,
                    "y": 1519
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='31' style='font-size:20px'>The recently developed ASDiv dataset (Miao et al., 2021), which contains<br>2.3K math word problems, addresses common flaws in prior datasets by ensuring<br>problems have both high diversity and high quality. We share those design<br>principles in the creation of GSM8K. However, we note that GSM8K is larger,<br>provides natural language solutions, and consists of problems that on average<br>require more steps to solve. The MATH dataset (Hendrycks et al., 2021) is larger<br>and significantly more complex than GSM8K, but the high difficulty makes<br>it challenging to accurately measure progress given the current capabilities of<br>state-of-the-art language models.</p>",
            "id": 31,
            "page": 4,
            "text": "The recently developed ASDiv dataset (Miao , 2021), which contains 2.3K math word problems, addresses common flaws in prior datasets by ensuring problems have both high diversity and high quality. We share those design principles in the creation of GSM8K. However, we note that GSM8K is larger, provides natural language solutions, and consists of problems that on average require more steps to solve. The MATH dataset (Hendrycks , 2021) is larger and significantly more complex than GSM8K, but the high difficulty makes it challenging to accurately measure progress given the current capabilities of state-of-the-art language models."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1524
                },
                {
                    "x": 1997,
                    "y": 1524
                },
                {
                    "x": 1997,
                    "y": 1919
                },
                {
                    "x": 549,
                    "y": 1919
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='32' style='font-size:20px'>Other recent reasoning-related datasets have focused on mathematical rea-<br>soning on symbolic math (Lample and Charton, 2019), reading comprehension<br>(LogiQA) (Liu et al., 2020), and commonsense question answering (Common-<br>senseQA) (Talmor et al., 2018). Similar to CommonsenseQA, GSM8K includes<br>questions that require basic background knowledge, like the number of days in<br>a week. Similar to LogiQA, which requires a mix of reading comprehension and<br>logical reasoning, GSM8K's main difficulty lies in both properly interpreting a<br>question and reasoning through the steps to solve it.</p>",
            "id": 32,
            "page": 4,
            "text": "Other recent reasoning-related datasets have focused on mathematical reasoning on symbolic math (Lample and Charton, 2019), reading comprehension (LogiQA) (Liu , 2020), and commonsense question answering (CommonsenseQA) (Talmor , 2018). Similar to CommonsenseQA, GSM8K includes questions that require basic background knowledge, like the number of days in a week. Similar to LogiQA, which requires a mix of reading comprehension and logical reasoning, GSM8K's main difficulty lies in both properly interpreting a question and reasoning through the steps to solve it."
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 1982
                },
                {
                    "x": 1109,
                    "y": 1982
                },
                {
                    "x": 1109,
                    "y": 2034
                },
                {
                    "x": 552,
                    "y": 2034
                }
            ],
            "category": "paragraph",
            "html": "<p id='33' style='font-size:22px'>3.2 Related Methods</p>",
            "id": 33,
            "page": 4,
            "text": "3.2 Related Methods"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 2063
                },
                {
                    "x": 1997,
                    "y": 2063
                },
                {
                    "x": 1997,
                    "y": 2409
                },
                {
                    "x": 549,
                    "y": 2409
                }
            ],
            "category": "paragraph",
            "html": "<p id='34' style='font-size:20px'>Previous work has attempted to solve classic math word problem benchmarks<br>with recurrent seq2seq models (Sutskever et al., 2014) and closely related vari-<br>ants (Wang et al., 2017; Huang et al., 2018). More recent work has improved per-<br>formance by designing specialized encoder-decoder architectures (Amini et al.,<br>2019; Chiang and Chen, 2018; Xie and Sun, 2019; Chen et al., 2020; Li et al.,<br>2020), with the strongest results often relying on large pretrained encoders from<br>the BERT family (Chen et al., 2019; Kim et al., 2020; Liang et al., 2021).</p>",
            "id": 34,
            "page": 4,
            "text": "Previous work has attempted to solve classic math word problem benchmarks with recurrent seq2seq models (Sutskever , 2014) and closely related variants (Wang , 2017; Huang , 2018). More recent work has improved performance by designing specialized encoder-decoder architectures (Amini , 2019; Chiang and Chen, 2018; Xie and Sun, 2019; Chen , 2020; Li , 2020), with the strongest results often relying on large pretrained encoders from the BERT family (Chen , 2019; Kim , 2020; Liang , 2021)."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 2413
                },
                {
                    "x": 2000,
                    "y": 2413
                },
                {
                    "x": 2000,
                    "y": 2758
                },
                {
                    "x": 549,
                    "y": 2758
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='35' style='font-size:18px'>Other recent work has recommended additional pretraining tasks to further<br>improve the math reasoning skills of large transformer-based models. Hendrycks<br>et al. (2021) propose pretraining models on a new AMPS corpus, derived from<br>Khan Academy problems and Mathematica scripts. Similarly, Shen et al. (2021b)<br>propose a pretrained a corpus of pre-K to college level curricula extracted from<br>the internet, and Peng et al. (2021) propose pretraining by predicting masked<br>subexpressions from expression trees.</p>",
            "id": 35,
            "page": 4,
            "text": "Other recent work has recommended additional pretraining tasks to further improve the math reasoning skills of large transformer-based models. Hendrycks  (2021) propose pretraining models on a new AMPS corpus, derived from Khan Academy problems and Mathematica scripts. Similarly, Shen  (2021b) propose a pretrained a corpus of pre-K to college level curricula extracted from the internet, and Peng  (2021) propose pretraining by predicting masked subexpressions from expression trees."
        },
        {
            "bounding_box": [
                {
                    "x": 613,
                    "y": 2762
                },
                {
                    "x": 1995,
                    "y": 2762
                },
                {
                    "x": 1995,
                    "y": 2807
                },
                {
                    "x": 613,
                    "y": 2807
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='36' style='font-size:16px'>Similar to verification, other methods have finetuned a language model to</p>",
            "id": 36,
            "page": 4,
            "text": "Similar to verification, other methods have finetuned a language model to"
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 2898
                },
                {
                    "x": 1286,
                    "y": 2898
                },
                {
                    "x": 1286,
                    "y": 2931
                },
                {
                    "x": 1260,
                    "y": 2931
                }
            ],
            "category": "footer",
            "html": "<footer id='37' style='font-size:14px'>4</footer>",
            "id": 37,
            "page": 4,
            "text": "4"
        },
        {
            "bounding_box": [
                {
                    "x": 584,
                    "y": 517
                },
                {
                    "x": 1957,
                    "y": 517
                },
                {
                    "x": 1957,
                    "y": 1198
                },
                {
                    "x": 584,
                    "y": 1198
                }
            ],
            "category": "figure",
            "html": "<figure><img id='38' style='font-size:14px' alt=\"35 35\n30 30\n25 25\n(%)\n(%)\nRate\nRate\n20 20\nSolve\n15 Solve\n15\nTest\nTest\n10 10\n500 problems\n3B model 1K problems\n6B model 2K problems\n5 5\n12B model 4K problems\n175B model 7.5K problems\n0 0\n500 1000 2000 4000 8000 3 6 12 175\nTraining Set Size # Model Parameters (B)\" data-coord=\"top-left:(584,517); bottom-right:(1957,1198)\" /></figure>",
            "id": 38,
            "page": 5,
            "text": "35 35 30 30 25 25 (%) (%) Rate Rate 20 20 Solve 15 Solve 15 Test Test 10 10 500 problems 3B model 1K problems 6B model 2K problems 5 5 12B model 4K problems 175B model 7.5K problems 0 0 500 1000 2000 4000 8000 3 6 12 175 Training Set Size # Model Parameters (B)"
        },
        {
            "bounding_box": [
                {
                    "x": 547,
                    "y": 1239
                },
                {
                    "x": 1997,
                    "y": 1239
                },
                {
                    "x": 1997,
                    "y": 1388
                },
                {
                    "x": 547,
                    "y": 1388
                }
            ],
            "category": "caption",
            "html": "<caption id='39' style='font-size:16px'>Figure 2: Final test performance for various GPT-3 model sizes after finetuning<br>on training sets of different sizes. Mean and standard deviation is shown across<br>3 runs.</caption>",
            "id": 39,
            "page": 5,
            "text": "Figure 2: Final test performance for various GPT-3 model sizes after finetuning on training sets of different sizes. Mean and standard deviation is shown across 3 runs."
        },
        {
            "bounding_box": [
                {
                    "x": 547,
                    "y": 1481
                },
                {
                    "x": 1999,
                    "y": 1481
                },
                {
                    "x": 1999,
                    "y": 2177
                },
                {
                    "x": 547,
                    "y": 2177
                }
            ],
            "category": "paragraph",
            "html": "<p id='40' style='font-size:18px'>select among many model completions. Nichols et al. (2020) proposed a sample-<br>and-rank approach to improve the collaborative storytelling ability of large lan-<br>guage models, with the training signal coming from the preferences of human<br>workers. In concurrent work closely related to our own, Shen et al. (2021a)<br>applied a similar approach to solving math word problems, jointly training a<br>model to both generate and rank solutions. Our work shares many fundamen-<br>tal similarities with their approach, though we differ in several key respects.<br>First, we focus attention on the space of natural language solutions, as this is<br>a richer and more general solution format than pure mathematical expressions.<br>Moreover, this choice enables our models to develop verbal analytical skills and<br>to produce solutions that are more readily interpretable by humans. Second,<br>we provide evidence that verifiers scale far more favorably with additional data<br>than baseline methods. Finally, we use separate generator and verifier networks,<br>in order to prevent the generator from overfitting.</p>",
            "id": 40,
            "page": 5,
            "text": "select among many model completions. Nichols  (2020) proposed a sampleand-rank approach to improve the collaborative storytelling ability of large language models, with the training signal coming from the preferences of human workers. In concurrent work closely related to our own, Shen  (2021a) applied a similar approach to solving math word problems, jointly training a model to both generate and rank solutions. Our work shares many fundamental similarities with their approach, though we differ in several key respects. First, we focus attention on the space of natural language solutions, as this is a richer and more general solution format than pure mathematical expressions. Moreover, this choice enables our models to develop verbal analytical skills and to produce solutions that are more readily interpretable by humans. Second, we provide evidence that verifiers scale far more favorably with additional data than baseline methods. Finally, we use separate generator and verifier networks, in order to prevent the generator from overfitting."
        },
        {
            "bounding_box": [
                {
                    "x": 551,
                    "y": 2254
                },
                {
                    "x": 919,
                    "y": 2254
                },
                {
                    "x": 919,
                    "y": 2312
                },
                {
                    "x": 551,
                    "y": 2312
                }
            ],
            "category": "paragraph",
            "html": "<p id='41' style='font-size:22px'>4 Methods</p>",
            "id": 41,
            "page": 5,
            "text": "4 Methods"
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 2354
                },
                {
                    "x": 1998,
                    "y": 2354
                },
                {
                    "x": 1998,
                    "y": 2806
                },
                {
                    "x": 548,
                    "y": 2806
                }
            ],
            "category": "paragraph",
            "html": "<p id='42' style='font-size:20px'>We investigate two methods to solve problems in GSM8K: finetuning and ver-<br>ification. Finetuning, our baseline method, uses the same language modeling<br>objective as the generative pretraining in GPT-3 (Brown et al., 2020). At test<br>time, we judge performance by autoregressively sampling a single low temper-<br>ature solution and checking whether the final answer is correct. In contrast,<br>verification consists of sampling multiple high temperature solutions, assigning<br>each solution a score, and outputting the highest ranked solution. Verifiers are<br>trained to judge the correctness of solutions, with the training signal determined<br>solely by whether or not the solution reached the correct final answer.</p>",
            "id": 42,
            "page": 5,
            "text": "We investigate two methods to solve problems in GSM8K: finetuning and verification. Finetuning, our baseline method, uses the same language modeling objective as the generative pretraining in GPT-3 (Brown , 2020). At test time, we judge performance by autoregressively sampling a single low temperature solution and checking whether the final answer is correct. In contrast, verification consists of sampling multiple high temperature solutions, assigning each solution a score, and outputting the highest ranked solution. Verifiers are trained to judge the correctness of solutions, with the training signal determined solely by whether or not the solution reached the correct final answer."
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 2896
                },
                {
                    "x": 1286,
                    "y": 2896
                },
                {
                    "x": 1286,
                    "y": 2932
                },
                {
                    "x": 1259,
                    "y": 2932
                }
            ],
            "category": "footer",
            "html": "<footer id='43' style='font-size:14px'>5</footer>",
            "id": 43,
            "page": 5,
            "text": "5"
        },
        {
            "bounding_box": [
                {
                    "x": 565,
                    "y": 513
                },
                {
                    "x": 1962,
                    "y": 513
                },
                {
                    "x": 1962,
                    "y": 1206
                },
                {
                    "x": 565,
                    "y": 1206
                }
            ],
            "category": "figure",
            "html": "<figure><img id='44' style='font-size:14px' alt=\"22 84\n82\n20\n(%) 99 80-\nRate\nRate\n18\n78\nSolve\n76\n16 Solve\nTest@1\n74\n14 Test@100\n72\n12\n70\n6B 6B\n0 10 20 30 40 50 0 10 20 30 40 50\nEpoch Epoch\" data-coord=\"top-left:(565,513); bottom-right:(1962,1206)\" /></figure>",
            "id": 44,
            "page": 6,
            "text": "22 84 82 20 (%) 99 80Rate Rate 18 78 Solve 76 16 Solve Test@1 74 14 Test@100 72 12 70 6B 6B 0 10 20 30 40 50 0 10 20 30 40 50 Epoch Epoch"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1239
                },
                {
                    "x": 1996,
                    "y": 1239
                },
                {
                    "x": 1996,
                    "y": 1341
                },
                {
                    "x": 549,
                    "y": 1341
                }
            ],
            "category": "caption",
            "html": "<caption id='45' style='font-size:18px'>Figure 3: Test solve rate after finetuning a 6B model on the full GSM8K training<br>set, when the model is allowed to make 1 guess (left) or 100 guesses (right).</caption>",
            "id": 45,
            "page": 6,
            "text": "Figure 3: Test solve rate after finetuning a 6B model on the full GSM8K training set, when the model is allowed to make 1 guess (left) or 100 guesses (right)."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1427
                },
                {
                    "x": 1997,
                    "y": 1427
                },
                {
                    "x": 1997,
                    "y": 1674
                },
                {
                    "x": 549,
                    "y": 1674
                }
            ],
            "category": "paragraph",
            "html": "<p id='46' style='font-size:20px'>For both methods, we use models from the GPT-3 family as our initializa-<br>tion, primarily focusing on the 175B and 6B model sizes. The 175B model is<br>the largest and produces the most impressive results, while the 6B model is sig-<br>nificantly more convenient for research purposes. We discuss hyperparameter<br>choices in Appendix B.</p>",
            "id": 46,
            "page": 6,
            "text": "For both methods, we use models from the GPT-3 family as our initialization, primarily focusing on the 175B and 6B model sizes. The 175B model is the largest and produces the most impressive results, while the 6B model is significantly more convenient for research purposes. We discuss hyperparameter choices in Appendix B."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1679
                },
                {
                    "x": 1998,
                    "y": 1679
                },
                {
                    "x": 1998,
                    "y": 1977
                },
                {
                    "x": 549,
                    "y": 1977
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='47' style='font-size:20px'>Our models frequently fail to accurately perform calculations. Although<br>larger models make fewer arithmetic mistakes than smaller models, this remains<br>a common source of errors. To mitigate this issue, we train all models to use<br>a calculator by injecting calculation annotations into the training set. At test<br>time, a calculator will override sampling when the model chooses to use these<br>annotations. Details can be found in Appendix C.</p>",
            "id": 47,
            "page": 6,
            "text": "Our models frequently fail to accurately perform calculations. Although larger models make fewer arithmetic mistakes than smaller models, this remains a common source of errors. To mitigate this issue, we train all models to use a calculator by injecting calculation annotations into the training set. At test time, a calculator will override sampling when the model chooses to use these annotations. Details can be found in Appendix C."
        },
        {
            "bounding_box": [
                {
                    "x": 551,
                    "y": 2038
                },
                {
                    "x": 957,
                    "y": 2038
                },
                {
                    "x": 957,
                    "y": 2093
                },
                {
                    "x": 551,
                    "y": 2093
                }
            ],
            "category": "paragraph",
            "html": "<p id='48' style='font-size:22px'>4.1 Finetuning</p>",
            "id": 48,
            "page": 6,
            "text": "4.1 Finetuning"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 2119
                },
                {
                    "x": 1996,
                    "y": 2119
                },
                {
                    "x": 1996,
                    "y": 2766
                },
                {
                    "x": 549,
                    "y": 2766
                }
            ],
            "category": "paragraph",
            "html": "<p id='49' style='font-size:20px'>We perform finetuning by updating model parameters to minimize the cross-<br>entropy loss over all training tokens. Figure 2 shows test performance after<br>finetuning on training sets of varying sizes for 20 epochs. We visualize the same<br>data both as a function of training set size and as a function of model size.<br>Test performance is determined by a single low temperature (T = 0) sample<br>for each test problem. Unsurprisingly, we see that the 175B model significantly<br>outperforms the smaller models. Assuming a log-linear trend, we can naively<br>extrapolate these results to estimate that a model with 1016 parameters would<br>be required to reach an 80% solve rate, when using the full GSM8K training<br>set. It is even harder to extrapolate along the data dimension, since performance<br>does not appear to follow a log-linear trend. Nevertheless, it appears likely that<br>the 175B model would require at least two additional orders of magnitude of<br>training data to reach an 80% solve rate.</p>",
            "id": 49,
            "page": 6,
            "text": "We perform finetuning by updating model parameters to minimize the crossentropy loss over all training tokens. Figure 2 shows test performance after finetuning on training sets of varying sizes for 20 epochs. We visualize the same data both as a function of training set size and as a function of model size. Test performance is determined by a single low temperature (T = 0) sample for each test problem. Unsurprisingly, we see that the 175B model significantly outperforms the smaller models. Assuming a log-linear trend, we can naively extrapolate these results to estimate that a model with 1016 parameters would be required to reach an 80% solve rate, when using the full GSM8K training set. It is even harder to extrapolate along the data dimension, since performance does not appear to follow a log-linear trend. Nevertheless, it appears likely that the 175B model would require at least two additional orders of magnitude of training data to reach an 80% solve rate."
        },
        {
            "bounding_box": [
                {
                    "x": 613,
                    "y": 2767
                },
                {
                    "x": 1994,
                    "y": 2767
                },
                {
                    "x": 1994,
                    "y": 2815
                },
                {
                    "x": 613,
                    "y": 2815
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='50' style='font-size:18px'>In Figure 3, we show how 6B test performance varies over the course of 100</p>",
            "id": 50,
            "page": 6,
            "text": "In Figure 3, we show how 6B test performance varies over the course of 100"
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2933
                },
                {
                    "x": 1259,
                    "y": 2933
                }
            ],
            "category": "footer",
            "html": "<footer id='51' style='font-size:16px'>6</footer>",
            "id": 51,
            "page": 6,
            "text": "6"
        },
        {
            "bounding_box": [
                {
                    "x": 558,
                    "y": 512
                },
                {
                    "x": 1983,
                    "y": 512
                },
                {
                    "x": 1983,
                    "y": 1129
                },
                {
                    "x": 558,
                    "y": 1129
                }
            ],
            "category": "figure",
            "html": "<figure><img id='52' style='font-size:14px' alt=\"Generate and label\nTrain generator Train Verifier\n100 solutions/problem\nGenerator Generator Verifier\nQi questions\nSi solutions Si S1 Y.1 S3 Y?\nYi labels S2 Y2\nQi\nS100 Y,100\" data-coord=\"top-left:(558,512); bottom-right:(1983,1129)\" /></figure>",
            "id": 52,
            "page": 7,
            "text": "Generate and label Train generator Train Verifier 100 solutions/problem Generator Generator Verifier Qi questions Si solutions Si S1 Y.1 S3 Y? Yi labels S2 Y2 Qi S100 Y,100"
        },
        {
            "bounding_box": [
                {
                    "x": 751,
                    "y": 1163
                },
                {
                    "x": 1793,
                    "y": 1163
                },
                {
                    "x": 1793,
                    "y": 1216
                },
                {
                    "x": 751,
                    "y": 1216
                }
            ],
            "category": "caption",
            "html": "<caption id='53' style='font-size:20px'>Figure 4: A diagram of the verification training pipeline.</caption>",
            "id": 53,
            "page": 7,
            "text": "Figure 4: A diagram of the verification training pipeline."
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 1304
                },
                {
                    "x": 1998,
                    "y": 1304
                },
                {
                    "x": 1998,
                    "y": 1900
                },
                {
                    "x": 550,
                    "y": 1900
                }
            ],
            "category": "paragraph",
            "html": "<p id='54' style='font-size:18px'>training epochs. We use test@N to denote the percentage of problems solved<br>correctly at least once when allowing the model to make N separate guesses for<br>each problem. We use a low temperature (T = 0) to generate test@1 samples<br>and we use a higher temperature (T = 0.7) to generate test@100 samples. Both<br>temperature values were chosen empirically to produce the best results. Test@1<br>performance improves approximately monotonically, even though we quickly<br>begin overfitting on test loss. Unfortunately, test@100 performance degrades<br>much more sharply than test@1 as we increase the number of epochs. This is<br>to be expected: as the model repeatedly encounters the same data, it becomes<br>increasingly uncalibrated and overconfident in its predictions. At test time, this<br>overconfidence leads to poor coverage of the solution space, an effect which only<br>becomes noticeable when we are considering multiple samples at test time.</p>",
            "id": 54,
            "page": 7,
            "text": "training epochs. We use test@N to denote the percentage of problems solved correctly at least once when allowing the model to make N separate guesses for each problem. We use a low temperature (T = 0) to generate test@1 samples and we use a higher temperature (T = 0.7) to generate test@100 samples. Both temperature values were chosen empirically to produce the best results. Test@1 performance improves approximately monotonically, even though we quickly begin overfitting on test loss. Unfortunately, test@100 performance degrades much more sharply than test@1 as we increase the number of epochs. This is to be expected: as the model repeatedly encounters the same data, it becomes increasingly uncalibrated and overconfident in its predictions. At test time, this overconfidence leads to poor coverage of the solution space, an effect which only becomes noticeable when we are considering multiple samples at test time."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1903
                },
                {
                    "x": 1998,
                    "y": 1903
                },
                {
                    "x": 1998,
                    "y": 2301
                },
                {
                    "x": 549,
                    "y": 2301
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='55' style='font-size:18px'>Choosing a model with good coverage is critical to successfully train verifiers.<br>Empirically, we see that test@100 performance peaks within the first few epochs.<br>For this reason, we use models trained for 2 epochs to generate samples for<br>training verifiers. We provide several example solutions from 6B and 175B<br>models in Appendix D. We also note that it is important to allow the model to<br>generate the full natural language solution before outputting a final answer. If<br>we instead finetune a 6B model to directly output the final answer without any<br>intermediate steps, performance drops drastically from 20.6% to 5.2%.</p>",
            "id": 55,
            "page": 7,
            "text": "Choosing a model with good coverage is critical to successfully train verifiers. Empirically, we see that test@100 performance peaks within the first few epochs. For this reason, we use models trained for 2 epochs to generate samples for training verifiers. We provide several example solutions from 6B and 175B models in Appendix D. We also note that it is important to allow the model to generate the full natural language solution before outputting a final answer. If we instead finetune a 6B model to directly output the final answer without any intermediate steps, performance drops drastically from 20.6% to 5.2%."
        },
        {
            "bounding_box": [
                {
                    "x": 551,
                    "y": 2360
                },
                {
                    "x": 971,
                    "y": 2360
                },
                {
                    "x": 971,
                    "y": 2415
                },
                {
                    "x": 551,
                    "y": 2415
                }
            ],
            "category": "paragraph",
            "html": "<p id='56' style='font-size:22px'>4.2 Verification</p>",
            "id": 56,
            "page": 7,
            "text": "4.2 Verification"
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 2442
                },
                {
                    "x": 1999,
                    "y": 2442
                },
                {
                    "x": 1999,
                    "y": 2793
                },
                {
                    "x": 550,
                    "y": 2793
                }
            ],
            "category": "paragraph",
            "html": "<p id='57' style='font-size:16px'>To improve upon the finetuning baseline, we train verifiers to judge the correct-<br>ness of model-generated solutions and search against these verifiers at test time.<br>Conditioned on the problem and a candidate solution, the verifier outputs the<br>probability that the solution is correct. Training solutions are labeled as correct<br>or incorrect based solely on whether they reach the correct final answer. In prac-<br>tice, some solutions will reach the correct final answer using flawed reasoning,<br>leading to false positives.</p>",
            "id": 57,
            "page": 7,
            "text": "To improve upon the finetuning baseline, we train verifiers to judge the correctness of model-generated solutions and search against these verifiers at test time. Conditioned on the problem and a candidate solution, the verifier outputs the probability that the solution is correct. Training solutions are labeled as correct or incorrect based solely on whether they reach the correct final answer. In practice, some solutions will reach the correct final answer using flawed reasoning, leading to false positives."
        },
        {
            "bounding_box": [
                {
                    "x": 555,
                    "y": 514
                },
                {
                    "x": 1984,
                    "y": 514
                },
                {
                    "x": 1984,
                    "y": 1199
                },
                {
                    "x": 555,
                    "y": 1199
                }
            ],
            "category": "figure",
            "html": "<figure><img id='58' style='font-size:14px' alt=\"60 60\n50 50\n40 40\n(%)\n(%)\nRate\nRate\n30 30\nSolve\nSolve\nTest\n20 Test\n20\n10 10\n6B Finetuning 175B Finetuning\n6B Verification 175B Verification\n0 0\n500 1000 2000 4000 8000 500 1000 2000 4000 8000\nTraining Set Size Training Set Size\" data-coord=\"top-left:(555,514); bottom-right:(1984,1199)\" /></figure>",
            "id": 58,
            "page": 8,
            "text": "60 60 50 50 40 40 (%) (%) Rate Rate 30 30 Solve Solve Test 20 Test 20 10 10 6B Finetuning 175B Finetuning 6B Verification 175B Verification 0 0 500 1000 2000 4000 8000 500 1000 2000 4000 8000 Training Set Size Training Set Size"
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 1238
                },
                {
                    "x": 1997,
                    "y": 1238
                },
                {
                    "x": 1997,
                    "y": 1440
                },
                {
                    "x": 548,
                    "y": 1440
                }
            ],
            "category": "caption",
            "html": "<caption id='59' style='font-size:20px'>Figure 5: A comparison between finetuning and verification using 6B and 175B<br>model sizes. Verification considers 100 solutions per problem. Mean and stan-<br>dard deviation is shown across 3 runs, except for 175B verification which shows<br>only a single run.</caption>",
            "id": 59,
            "page": 8,
            "text": "Figure 5: A comparison between finetuning and verification using 6B and 175B model sizes. Verification considers 100 solutions per problem. Mean and standard deviation is shown across 3 runs, except for 175B verification which shows only a single run."
        },
        {
            "bounding_box": [
                {
                    "x": 615,
                    "y": 1528
                },
                {
                    "x": 1594,
                    "y": 1528
                },
                {
                    "x": 1594,
                    "y": 1576
                },
                {
                    "x": 615,
                    "y": 1576
                }
            ],
            "category": "caption",
            "html": "<caption id='60' style='font-size:18px'>As shown in Figure 4, we train the verifier as follows:</caption>",
            "id": 60,
            "page": 8,
            "text": "As shown in Figure 4, we train the verifier as follows:"
        },
        {
            "bounding_box": [
                {
                    "x": 601,
                    "y": 1614
                },
                {
                    "x": 1996,
                    "y": 1614
                },
                {
                    "x": 1996,
                    "y": 1880
                },
                {
                    "x": 601,
                    "y": 1880
                }
            ],
            "category": "paragraph",
            "html": "<p id='61' style='font-size:18px'>1. Finetune a model (the \"generator\" ) for 2 epochs on the training set.<br>2. Sample 100 completions from the generator for each training problem and<br>label each solution as correct or incorrect.<br>3. Train a verifier for a single epoch on this dataset.</p>",
            "id": 61,
            "page": 8,
            "text": "1. Finetune a model (the \"generator\" ) for 2 epochs on the training set. 2. Sample 100 completions from the generator for each training problem and label each solution as correct or incorrect. 3. Train a verifier for a single epoch on this dataset."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1918
                },
                {
                    "x": 1995,
                    "y": 1918
                },
                {
                    "x": 1995,
                    "y": 2417
                },
                {
                    "x": 549,
                    "y": 2417
                }
            ],
            "category": "paragraph",
            "html": "<p id='62' style='font-size:20px'>Training for 2 epochs is enough for the generator to learn basic skills in this<br>domain. We choose not to train for longer, since the diversity of generated<br>solutions begins to collapse after this point, as shown in Figure 3. We train<br>separate generator and verifier models to limit the generator's training and<br>prevent overfitting, but in principle, it should be possible to combine these<br>models. Unless otherwise specified, we use the same model size for the generator<br>and the verifier. In addition to predicting solution correctness, we also train the<br>verifier with the same language modeling objective as the generator. This serves<br>as a valuable auxiliary objective for the verifier. We discuss additional verifier<br>training details in Appendix E.</p>",
            "id": 62,
            "page": 8,
            "text": "Training for 2 epochs is enough for the generator to learn basic skills in this domain. We choose not to train for longer, since the diversity of generated solutions begins to collapse after this point, as shown in Figure 3. We train separate generator and verifier models to limit the generator's training and prevent overfitting, but in principle, it should be possible to combine these models. Unless otherwise specified, we use the same model size for the generator and the verifier. In addition to predicting solution correctness, we also train the verifier with the same language modeling objective as the generator. This serves as a valuable auxiliary objective for the verifier. We discuss additional verifier training details in Appendix E."
        },
        {
            "bounding_box": [
                {
                    "x": 547,
                    "y": 2419
                },
                {
                    "x": 1997,
                    "y": 2419
                },
                {
                    "x": 1997,
                    "y": 2818
                },
                {
                    "x": 547,
                    "y": 2818
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='63' style='font-size:18px'>At test time, we sample 100 completions to each test problem, rank them<br>with the verifier, and then return the one with the highest verifier score. A<br>comparison between verification and finetuning is shown in Figure 5 for both<br>the 6B and 175B model sizes. We find that it is not beneficial to use verification<br>at low dataset sizes. We believe this is due to the pressure to overfit to the<br>correct answer: with small datasets, overfitting to the correct answer happens<br>faster than learning more generalizable properties of correct reasoning. However,<br>once we use a sufficiently large dataset, we see a strong boost from verifiers.</p>",
            "id": 63,
            "page": 8,
            "text": "At test time, we sample 100 completions to each test problem, rank them with the verifier, and then return the one with the highest verifier score. A comparison between verification and finetuning is shown in Figure 5 for both the 6B and 175B model sizes. We find that it is not beneficial to use verification at low dataset sizes. We believe this is due to the pressure to overfit to the correct answer: with small datasets, overfitting to the correct answer happens faster than learning more generalizable properties of correct reasoning. However, once we use a sufficiently large dataset, we see a strong boost from verifiers."
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2932
                },
                {
                    "x": 1259,
                    "y": 2932
                }
            ],
            "category": "footer",
            "html": "<footer id='64' style='font-size:16px'>8</footer>",
            "id": 64,
            "page": 8,
            "text": "8"
        },
        {
            "bounding_box": [
                {
                    "x": 544,
                    "y": 512
                },
                {
                    "x": 1984,
                    "y": 512
                },
                {
                    "x": 1984,
                    "y": 981
                },
                {
                    "x": 544,
                    "y": 981
                }
            ],
            "category": "figure",
            "html": "<figure><img id='65' style='font-size:14px' alt=\"40 40 60\n6B Gen, 6B Verifier\n6B Gen, 175B Verifier\n35 35 175B Gen, 6B Verifier\n50\n175B Gen, 175B Verifier\n30 30\n(%)\n(%) Tyo 40\nRate\n25 Rate 25 Rate\nSolve\n20 Solve 20 Solve 30\nTest\nTest Test 20\n15 15\n10\n10 10\ntoken-level token-level, joint\nsolution-level token-level, verification-only\n5 5\n0\n500 1000 2000 4000 8000\n0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0\nTraining Set Size\nepoch epoch\" data-coord=\"top-left:(544,512); bottom-right:(1984,981)\" /></figure>",
            "id": 65,
            "page": 9,
            "text": "40 40 60 6B Gen, 6B Verifier 6B Gen, 175B Verifier 35 35 175B Gen, 6B Verifier 50 175B Gen, 175B Verifier 30 30 (%) (%) Tyo 40 Rate 25 Rate 25 Rate Solve 20 Solve 20 Solve 30 Test Test Test 20 15 15 10 10 10 token-level token-level, joint solution-level token-level, verification-only 5 5 0 500 1000 2000 4000 8000 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 Training Set Size epoch epoch"
        },
        {
            "bounding_box": [
                {
                    "x": 547,
                    "y": 999
                },
                {
                    "x": 1999,
                    "y": 999
                },
                {
                    "x": 1999,
                    "y": 1323
                },
                {
                    "x": 547,
                    "y": 1323
                }
            ],
            "category": "caption",
            "html": "<br><caption id='66' style='font-size:16px'>(a) Comparison between a (b) Comparison between (c) Performance when vary-<br>verifier trained to predict a verifier trained jointly ing the size of the genera-<br>correctness after every to- to predict correctness and tor and the verifier in isola-<br>ken (token-level) and one perform language model- tion. Increasing the size of<br>trained to predict correct- ing (joint) and one trained the generator has a larger<br>ness after only the final to- only to predict correctness impact than increasing the<br>ken (solution-level) (verification-only) size of the verifier.</caption>",
            "id": 66,
            "page": 9,
            "text": "(a) Comparison between a (b) Comparison between (c) Performance when varyverifier trained to predict a verifier trained jointly ing the size of the generacorrectness after every to- to predict correctness and tor and the verifier in isolaken (token-level) and one perform language model- tion. Increasing the size of trained to predict correct- ing (joint) and one trained the generator has a larger ness after only the final to- only to predict correctness impact than increasing the ken (solution-level) (verification-only) size of the verifier."
        },
        {
            "bounding_box": [
                {
                    "x": 986,
                    "y": 1363
                },
                {
                    "x": 1563,
                    "y": 1363
                },
                {
                    "x": 1563,
                    "y": 1410
                },
                {
                    "x": 986,
                    "y": 1410
                }
            ],
            "category": "paragraph",
            "html": "<p id='67' style='font-size:20px'>Figure 6: Verification ablations</p>",
            "id": 67,
            "page": 9,
            "text": "Figure 6: Verification ablations"
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 1501
                },
                {
                    "x": 1997,
                    "y": 1501
                },
                {
                    "x": 1997,
                    "y": 1700
                },
                {
                    "x": 550,
                    "y": 1700
                }
            ],
            "category": "paragraph",
            "html": "<p id='68' style='font-size:18px'>It's interesting to note that the 175B verifiers \"take off\" earlier than the 6B<br>verifiers, requiring fewer training problems to surpass the finetuning baseline.<br>See Appendix D for example solutions found by verifiers and Appendix F for a<br>visualization of verifier confidence.</p>",
            "id": 68,
            "page": 9,
            "text": "It's interesting to note that the 175B verifiers \"take off\" earlier than the 6B verifiers, requiring fewer training problems to surpass the finetuning baseline. See Appendix D for example solutions found by verifiers and Appendix F for a visualization of verifier confidence."
        },
        {
            "bounding_box": [
                {
                    "x": 553,
                    "y": 1763
                },
                {
                    "x": 1225,
                    "y": 1763
                },
                {
                    "x": 1225,
                    "y": 1816
                },
                {
                    "x": 553,
                    "y": 1816
                }
            ],
            "category": "paragraph",
            "html": "<p id='69' style='font-size:22px'>4.3 Verification Ablations</p>",
            "id": 69,
            "page": 9,
            "text": "4.3 Verification Ablations"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1844
                },
                {
                    "x": 1998,
                    "y": 1844
                },
                {
                    "x": 1998,
                    "y": 2140
                },
                {
                    "x": 549,
                    "y": 2140
                }
            ],
            "category": "paragraph",
            "html": "<p id='70' style='font-size:18px'>We can either train verifiers to make a single scalar prediction conditioned on<br>the entire generated solution, or to make a scalar prediction after each token<br>in the solution. By default, we choose the latter, training verifiers to make<br>predictions after each token. This can be viewed as a token-level value function.<br>We compare these two methods in Figure 6a, respectively labeled \"solution-<br>level\" and \"token-level\"</p>",
            "id": 70,
            "page": 9,
            "text": "We can either train verifiers to make a single scalar prediction conditioned on the entire generated solution, or to make a scalar prediction after each token in the solution. By default, we choose the latter, training verifiers to make predictions after each token. This can be viewed as a token-level value function. We compare these two methods in Figure 6a, respectively labeled \"solutionlevel\" and \"token-level\""
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 2145
                },
                {
                    "x": 1995,
                    "y": 2145
                },
                {
                    "x": 1995,
                    "y": 2542
                },
                {
                    "x": 548,
                    "y": 2542
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='71' style='font-size:20px'>Predicting the value function at every token is a more challenging and nois-<br>ier task than judging only the full completion. However, despite the initially<br>slower training, the token-level verifier ultimately outperforms the solution-level<br>verifier. Moreover, the token-level verifier is still improving late in training,<br>whereas the solution-level verifier quickly shows signs of overfitting. We hy-<br>pothesize that the full value function provides a useful auxiliary signal that<br>encourages the model to judge the reasoning throughout solutions, rather than<br>merely memorizing the correct final answer.</p>",
            "id": 71,
            "page": 9,
            "text": "Predicting the value function at every token is a more challenging and noisier task than judging only the full completion. However, despite the initially slower training, the token-level verifier ultimately outperforms the solution-level verifier. Moreover, the token-level verifier is still improving late in training, whereas the solution-level verifier quickly shows signs of overfitting. We hypothesize that the full value function provides a useful auxiliary signal that encourages the model to judge the reasoning throughout solutions, rather than merely memorizing the correct final answer."
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 2543
                },
                {
                    "x": 1998,
                    "y": 2543
                },
                {
                    "x": 1998,
                    "y": 2793
                },
                {
                    "x": 548,
                    "y": 2793
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='72' style='font-size:20px'>In Figure 6b, we ablate the objective used when training verifiers. As dis-<br>cussed in Section 4.2, we can optionally include a language modeling objective<br>alongside the verification objective. We compare using both objectives to using<br>only the verification objective. Although both are reasonable choices, including<br>the language modeling objective is a strict improvement. This makes intuitive</p>",
            "id": 72,
            "page": 9,
            "text": "In Figure 6b, we ablate the objective used when training verifiers. As discussed in Section 4.2, we can optionally include a language modeling objective alongside the verification objective. We compare using both objectives to using only the verification objective. Although both are reasonable choices, including the language modeling objective is a strict improvement. This makes intuitive"
        },
        {
            "bounding_box": [
                {
                    "x": 1258,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2896
                },
                {
                    "x": 1287,
                    "y": 2932
                },
                {
                    "x": 1258,
                    "y": 2932
                }
            ],
            "category": "footer",
            "html": "<footer id='73' style='font-size:14px'>9</footer>",
            "id": 73,
            "page": 9,
            "text": "9"
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 520
                },
                {
                    "x": 1234,
                    "y": 520
                },
                {
                    "x": 1234,
                    "y": 1196
                },
                {
                    "x": 552,
                    "y": 1196
                }
            ],
            "category": "figure",
            "html": "<figure><img id='74' style='font-size:14px' alt=\"42\n40\n(%)\nRate\n38\nSolve\nTest\n36\n34\n25 50 100 200 400 800 1600 3200\nNumber of completions per test problem\" data-coord=\"top-left:(552,520); bottom-right:(1234,1196)\" /></figure>",
            "id": 74,
            "page": 10,
            "text": "42 40 (%) Rate 38 Solve Test 36 34 25 50 100 200 400 800 1600 3200 Number of completions per test problem"
        },
        {
            "bounding_box": [
                {
                    "x": 551,
                    "y": 1223
                },
                {
                    "x": 1247,
                    "y": 1223
                },
                {
                    "x": 1247,
                    "y": 1360
                },
                {
                    "x": 551,
                    "y": 1360
                }
            ],
            "category": "caption",
            "html": "<br><caption id='75' style='font-size:16px'>(a) 6B verification test performance<br>when given varying numbers of comple-<br>tions per problem to rank.</caption>",
            "id": 75,
            "page": 10,
            "text": "(a) 6B verification test performance when given varying numbers of completions per problem to rank."
        },
        {
            "bounding_box": [
                {
                    "x": 1307,
                    "y": 524
                },
                {
                    "x": 1988,
                    "y": 524
                },
                {
                    "x": 1988,
                    "y": 1196
                },
                {
                    "x": 1307,
                    "y": 1196
                }
            ],
            "category": "figure",
            "html": "<br><figure><img id='76' style='font-size:14px' alt=\"44\n42\n40\n(%)\n38\nRate\n36\nSolve\n34\nTest\n100 completions\n32\n200 completions\n400 completions\n30 completions\n800\n1600 completions\n28 3200 completions\n1 10 100\nNumber of top samples used for voting\" data-coord=\"top-left:(1307,524); bottom-right:(1988,1196)\" /></figure>",
            "id": 76,
            "page": 10,
            "text": "44 42 40 (%) 38 Rate 36 Solve 34 Test 100 completions 32 200 completions 400 completions 30 completions 800 1600 completions 28 3200 completions 1 10 100 Number of top samples used for voting"
        },
        {
            "bounding_box": [
                {
                    "x": 1304,
                    "y": 1224
                },
                {
                    "x": 1996,
                    "y": 1224
                },
                {
                    "x": 1996,
                    "y": 1360
                },
                {
                    "x": 1304,
                    "y": 1360
                }
            ],
            "category": "caption",
            "html": "<caption id='77' style='font-size:16px'>(b) 6B verification test performance<br>when varying the number of top ranked<br>samples allowed to vote on the answer.</caption>",
            "id": 77,
            "page": 10,
            "text": "(b) 6B verification test performance when varying the number of top ranked samples allowed to vote on the answer."
        },
        {
            "bounding_box": [
                {
                    "x": 666,
                    "y": 1402
                },
                {
                    "x": 1875,
                    "y": 1402
                },
                {
                    "x": 1875,
                    "y": 1452
                },
                {
                    "x": 666,
                    "y": 1452
                }
            ],
            "category": "paragraph",
            "html": "<p id='78' style='font-size:16px'>Figure 7: Performance as the amount of test time compute varies.</p>",
            "id": 78,
            "page": 10,
            "text": "Figure 7: Performance as the amount of test time compute varies."
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 1544
                },
                {
                    "x": 1994,
                    "y": 1544
                },
                {
                    "x": 1994,
                    "y": 1638
                },
                {
                    "x": 548,
                    "y": 1638
                }
            ],
            "category": "paragraph",
            "html": "<p id='79' style='font-size:20px'>sense: better understanding this language distribution should only aid the ver-<br>ifier in discriminating between samples.</p>",
            "id": 79,
            "page": 10,
            "text": "sense: better understanding this language distribution should only aid the verifier in discriminating between samples."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1645
                },
                {
                    "x": 1998,
                    "y": 1645
                },
                {
                    "x": 1998,
                    "y": 1991
                },
                {
                    "x": 549,
                    "y": 1991
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='80' style='font-size:18px'>In Figure 6c, we separately ablate the model size of the generator and the<br>verifier. We find that using a large generator with a small verifier performs sig-<br>nificantly better than using a small generator with a large verifier. Verification<br>is still remarkably effective, even when the verifier is much smaller than the gen-<br>erator. This suggests that the verifier may often be relying on relatively coarse<br>heuristics to discriminate between solutions from a given generator, rather than<br>attempting a more thorough form of verification.</p>",
            "id": 80,
            "page": 10,
            "text": "In Figure 6c, we separately ablate the model size of the generator and the verifier. We find that using a large generator with a small verifier performs significantly better than using a small generator with a large verifier. Verification is still remarkably effective, even when the verifier is much smaller than the generator. This suggests that the verifier may often be relying on relatively coarse heuristics to discriminate between solutions from a given generator, rather than attempting a more thorough form of verification."
        },
        {
            "bounding_box": [
                {
                    "x": 553,
                    "y": 2066
                },
                {
                    "x": 1367,
                    "y": 2066
                },
                {
                    "x": 1367,
                    "y": 2126
                },
                {
                    "x": 553,
                    "y": 2126
                }
            ],
            "category": "paragraph",
            "html": "<p id='81' style='font-size:22px'>5 Additional Experiments</p>",
            "id": 81,
            "page": 10,
            "text": "5 Additional Experiments"
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 2172
                },
                {
                    "x": 1183,
                    "y": 2172
                },
                {
                    "x": 1183,
                    "y": 2226
                },
                {
                    "x": 552,
                    "y": 2226
                }
            ],
            "category": "paragraph",
            "html": "<p id='82' style='font-size:20px'>5.1 Test Time Compute</p>",
            "id": 82,
            "page": 10,
            "text": "5.1 Test Time Compute"
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 2255
                },
                {
                    "x": 1998,
                    "y": 2255
                },
                {
                    "x": 1998,
                    "y": 2701
                },
                {
                    "x": 550,
                    "y": 2701
                }
            ],
            "category": "paragraph",
            "html": "<p id='83' style='font-size:18px'>At test time, we can choose to generate arbitrarily many solutions to be judged<br>by the verifier before selecting the highest ranked completion. Figure 7a shows<br>how 6B verifier performance varies with the number of completions per test<br>problem. At this scale, performance improves as we increase the number of<br>completions up to 400. Beyond this point, performance start to decrease. This<br>suggests that the benefits of search are eventually outweighed by the risk of<br>finding adversarial solutions that fool the verifier. In general, we evaluate verifier<br>test performance using 100 completions, since this captures most of the benefits<br>of verification with a relatively modest compute cost.</p>",
            "id": 83,
            "page": 10,
            "text": "At test time, we can choose to generate arbitrarily many solutions to be judged by the verifier before selecting the highest ranked completion. Figure 7a shows how 6B verifier performance varies with the number of completions per test problem. At this scale, performance improves as we increase the number of completions up to 400. Beyond this point, performance start to decrease. This suggests that the benefits of search are eventually outweighed by the risk of finding adversarial solutions that fool the verifier. In general, we evaluate verifier test performance using 100 completions, since this captures most of the benefits of verification with a relatively modest compute cost."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 2704
                },
                {
                    "x": 1998,
                    "y": 2704
                },
                {
                    "x": 1998,
                    "y": 2801
                },
                {
                    "x": 549,
                    "y": 2801
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='84' style='font-size:18px'>To further increase performance, we can take a majority vote among the<br>top verifier-ranked solutions instead of selecting only the single top solution.</p>",
            "id": 84,
            "page": 10,
            "text": "To further increase performance, we can take a majority vote among the top verifier-ranked solutions instead of selecting only the single top solution."
        },
        {
            "bounding_box": [
                {
                    "x": 1250,
                    "y": 2895
                },
                {
                    "x": 1298,
                    "y": 2895
                },
                {
                    "x": 1298,
                    "y": 2934
                },
                {
                    "x": 1250,
                    "y": 2934
                }
            ],
            "category": "footer",
            "html": "<footer id='85' style='font-size:16px'>10</footer>",
            "id": 85,
            "page": 10,
            "text": "10"
        },
        {
            "bounding_box": [
                {
                    "x": 553,
                    "y": 506
                },
                {
                    "x": 1989,
                    "y": 506
                },
                {
                    "x": 1989,
                    "y": 1054
                },
                {
                    "x": 553,
                    "y": 1054
                }
            ],
            "category": "figure",
            "html": "<figure><img id='86' style='font-size:14px' alt=\"40\n25.0\n40\n35\n22.5\n30\n(%) 20.0 (%) (%) 30\nRate\nRate\n17.5 Rate 25\nSolve\nSolve\n15.0 20\n20 Solve\nTest Test\n12.5 Test\n15\n10\n10.0\n10\n6B Finetuning, dropout = 0 solution-level, dropout = 0\ntoken-level, dropout = 0\n7.5\n6B Finetuning, dropout = 0.2 solution-level, dropout = 0.2\ntoken-level, dropout = 0.2\n0\n500 1000 2000 4000 8000 0.0 0.2 0.4 0.6 0.8 1.0\n0.0 0.2 0.4 0.6 0.8 1.0\nTraining Set Size epoch\nepoch\n(a) Finetuning (b) Solution-level verifiers (c) Token-level verifiers\" data-coord=\"top-left:(553,506); bottom-right:(1989,1054)\" /></figure>",
            "id": 86,
            "page": 11,
            "text": "40 25.0 40 35 22.5 30 (%) 20.0 (%) (%) 30 Rate Rate 17.5 Rate 25 Solve Solve 15.0 20 20 Solve Test Test 12.5 Test 15 10 10.0 10 6B Finetuning, dropout = 0 solution-level, dropout = 0 token-level, dropout = 0 7.5 6B Finetuning, dropout = 0.2 solution-level, dropout = 0.2 token-level, dropout = 0.2 0 500 1000 2000 4000 8000 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 Training Set Size epoch epoch (a) Finetuning (b) Solution-level verifiers (c) Token-level verifiers"
        },
        {
            "bounding_box": [
                {
                    "x": 734,
                    "y": 1089
                },
                {
                    "x": 1809,
                    "y": 1089
                },
                {
                    "x": 1809,
                    "y": 1137
                },
                {
                    "x": 734,
                    "y": 1137
                }
            ],
            "category": "caption",
            "html": "<caption id='87' style='font-size:20px'>Figure 8: 6B finetuning and verification dropout ablations.</caption>",
            "id": 87,
            "page": 11,
            "text": "Figure 8: 6B finetuning and verification dropout ablations."
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 1225
                },
                {
                    "x": 1997,
                    "y": 1225
                },
                {
                    "x": 1997,
                    "y": 1628
                },
                {
                    "x": 548,
                    "y": 1628
                }
            ],
            "category": "paragraph",
            "html": "<p id='88' style='font-size:16px'>This voting process considers only the final answer reached by the individual<br>solutions: the final answer selected is the one with the most votes. Figure 7b<br>shows how performance varies as we allow a greater number of top samples to<br>cast a vote. Unsurprisingly, when starting with a greater number of samples,<br>we can afford to allow a greater number of samples to cast a vote. When we<br>have only 100 samples, it is optimal to allow only the top 3-5 samples to cast a<br>vote. When we have 3200 samples, it is approximately optimal to allow the top<br>30 to cast a vote.</p>",
            "id": 88,
            "page": 11,
            "text": "This voting process considers only the final answer reached by the individual solutions: the final answer selected is the one with the most votes. Figure 7b shows how performance varies as we allow a greater number of top samples to cast a vote. Unsurprisingly, when starting with a greater number of samples, we can afford to allow a greater number of samples to cast a vote. When we have only 100 samples, it is optimal to allow only the top 3-5 samples to cast a vote. When we have 3200 samples, it is approximately optimal to allow the top 30 to cast a vote."
        },
        {
            "bounding_box": [
                {
                    "x": 553,
                    "y": 1689
                },
                {
                    "x": 1045,
                    "y": 1689
                },
                {
                    "x": 1045,
                    "y": 1743
                },
                {
                    "x": 553,
                    "y": 1743
                }
            ],
            "category": "paragraph",
            "html": "<p id='89' style='font-size:22px'>5.2 Regularization</p>",
            "id": 89,
            "page": 11,
            "text": "5.2 Regularization"
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 1767
                },
                {
                    "x": 1996,
                    "y": 1767
                },
                {
                    "x": 1996,
                    "y": 2166
                },
                {
                    "x": 550,
                    "y": 2166
                }
            ],
            "category": "paragraph",
            "html": "<p id='90' style='font-size:18px'>We find that both finetuning and verification strongly benefit from the use of<br>dropout as a regularizer. Specifically, we apply residual dropout (Vaswani et al.,<br>2017) along the residual paths of each layer in the network. We use 20% dropout<br>for all dropout experiments, chosen based on the results of a hyperparameters<br>sweep. We note that GPT-3 models are not pretrained with dropout. For ex-<br>periments involving dropout, we therefore perform additional pretraining with<br>dropout before subsequently finetuning the models. This mitigates the distri-<br>bution shift the model experiences during finetuning.</p>",
            "id": 90,
            "page": 11,
            "text": "We find that both finetuning and verification strongly benefit from the use of dropout as a regularizer. Specifically, we apply residual dropout (Vaswani , 2017) along the residual paths of each layer in the network. We use 20% dropout for all dropout experiments, chosen based on the results of a hyperparameters sweep. We note that GPT-3 models are not pretrained with dropout. For experiments involving dropout, we therefore perform additional pretraining with dropout before subsequently finetuning the models. This mitigates the distribution shift the model experiences during finetuning."
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 2171
                },
                {
                    "x": 1997,
                    "y": 2171
                },
                {
                    "x": 1997,
                    "y": 2817
                },
                {
                    "x": 548,
                    "y": 2817
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='91' style='font-size:18px'>We first investigate the effect of dropout on finetuning across various train-<br>ing set sizes. Figure 8a shows that dropout leads to a significant improvement<br>over baseline. We next investigate the effect of dropout on verifiers, consider-<br>ing both the solution-level and token-level variants. In Figure 8b, we see that<br>dropout significantly improves solution-level verifiers, mitigating the overfitting<br>that occurs in the unregularized baseline. Notably, using dropout with solution-<br>level verifiers reaches a similar level of performance as token-level verifiers. In<br>Figure 8c, we apply dropout to token-level verifiers. Since token-level verifiers<br>are already less susceptible to overfitting, it is no surprise that the impact of<br>dropout is less significant. Nevertheless, we do still see a slight gain from train-<br>ing token-level verifiers with dropout. Note that we increase the batch size for<br>token-level verifiers by a factor of 4, to better handle the more difficult objective<br>and the noise from dropout.</p>",
            "id": 91,
            "page": 11,
            "text": "We first investigate the effect of dropout on finetuning across various training set sizes. Figure 8a shows that dropout leads to a significant improvement over baseline. We next investigate the effect of dropout on verifiers, considering both the solution-level and token-level variants. In Figure 8b, we see that dropout significantly improves solution-level verifiers, mitigating the overfitting that occurs in the unregularized baseline. Notably, using dropout with solutionlevel verifiers reaches a similar level of performance as token-level verifiers. In Figure 8c, we apply dropout to token-level verifiers. Since token-level verifiers are already less susceptible to overfitting, it is no surprise that the impact of dropout is less significant. Nevertheless, we do still see a slight gain from training token-level verifiers with dropout. Note that we increase the batch size for token-level verifiers by a factor of 4, to better handle the more difficult objective and the noise from dropout."
        },
        {
            "bounding_box": [
                {
                    "x": 1250,
                    "y": 2893
                },
                {
                    "x": 1295,
                    "y": 2893
                },
                {
                    "x": 1295,
                    "y": 2935
                },
                {
                    "x": 1250,
                    "y": 2935
                }
            ],
            "category": "footer",
            "html": "<footer id='92' style='font-size:14px'>11</footer>",
            "id": 92,
            "page": 11,
            "text": "11"
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 516
                },
                {
                    "x": 984,
                    "y": 516
                },
                {
                    "x": 984,
                    "y": 573
                },
                {
                    "x": 552,
                    "y": 573
                }
            ],
            "category": "paragraph",
            "html": "<p id='93' style='font-size:18px'>6 Conclusion</p>",
            "id": 93,
            "page": 12,
            "text": "6 Conclusion"
        },
        {
            "bounding_box": [
                {
                    "x": 551,
                    "y": 613
                },
                {
                    "x": 1998,
                    "y": 613
                },
                {
                    "x": 1998,
                    "y": 1065
                },
                {
                    "x": 551,
                    "y": 1065
                }
            ],
            "category": "paragraph",
            "html": "<p id='94' style='font-size:14px'>We have seen that verification provides a significant performance boost relative<br>to a finetuning baseline. On the full dataset, 6B verification slightly outperforms<br>a finetuned 175B model, thereby offering a boost approximately equivalent to<br>a 30x model size increase. We have also seen that token-level verifiers are less<br>prone to overfitting than solution-level verifiers, and that all methods benefit<br>from regularization with residual dropout. We expect verification to scale well<br>to problem distributions that require more complex mathematical reasoning,<br>and we hope GSM8K supports the development of new methods that scale even<br>better.</p>",
            "id": 94,
            "page": 12,
            "text": "We have seen that verification provides a significant performance boost relative to a finetuning baseline. On the full dataset, 6B verification slightly outperforms a finetuned 175B model, thereby offering a boost approximately equivalent to a 30x model size increase. We have also seen that token-level verifiers are less prone to overfitting than solution-level verifiers, and that all methods benefit from regularization with residual dropout. We expect verification to scale well to problem distributions that require more complex mathematical reasoning, and we hope GSM8K supports the development of new methods that scale even better."
        },
        {
            "bounding_box": [
                {
                    "x": 553,
                    "y": 1141
                },
                {
                    "x": 1119,
                    "y": 1141
                },
                {
                    "x": 1119,
                    "y": 1201
                },
                {
                    "x": 553,
                    "y": 1201
                }
            ],
            "category": "paragraph",
            "html": "<p id='95' style='font-size:22px'>Acknowledgements</p>",
            "id": 95,
            "page": 12,
            "text": "Acknowledgements"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1240
                },
                {
                    "x": 1996,
                    "y": 1240
                },
                {
                    "x": 1996,
                    "y": 1542
                },
                {
                    "x": 549,
                    "y": 1542
                }
            ],
            "category": "paragraph",
            "html": "<p id='96' style='font-size:16px'>We thank Dan Hendrycks, Leo Gao, Alec Radford, and Giambattista Paras-<br>candolo for their valuable feedback on this paper; Harri Edwards, Yura Burda,<br>Michael Wu, and Nick Ryder for many insightful conversations; Michael Petrov,<br>Alethea Power, and Jacob Jackson for their technical assistance; the OpenAI<br>Supercomputing team for the infrastructure that made these experiments pos-<br>sible; and the team at Surge AI for performing the GSM8K data collection.</p>",
            "id": 96,
            "page": 12,
            "text": "We thank Dan Hendrycks, Leo Gao, Alec Radford, and Giambattista Parascandolo for their valuable feedback on this paper; Harri Edwards, Yura Burda, Michael Wu, and Nick Ryder for many insightful conversations; Michael Petrov, Alethea Power, and Jacob Jackson for their technical assistance; the OpenAI Supercomputing team for the infrastructure that made these experiments possible; and the team at Surge AI for performing the GSM8K data collection."
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 1617
                },
                {
                    "x": 876,
                    "y": 1617
                },
                {
                    "x": 876,
                    "y": 1675
                },
                {
                    "x": 552,
                    "y": 1675
                }
            ],
            "category": "paragraph",
            "html": "<p id='97' style='font-size:20px'>References</p>",
            "id": 97,
            "page": 12,
            "text": "References"
        },
        {
            "bounding_box": [
                {
                    "x": 546,
                    "y": 1706
                },
                {
                    "x": 1999,
                    "y": 1706
                },
                {
                    "x": 1999,
                    "y": 2822
                },
                {
                    "x": 546,
                    "y": 2822
                }
            ],
            "category": "paragraph",
            "html": "<p id='98' style='font-size:18px'>A. Amini, S. Gabriel, P. Lin, R. Koncel-Kedziorski, Y. Choi, and H. Hajishirzi.<br>Mathqa: Towards interpretable math word problem solving with operation-<br>based formalisms. arXiv preprint arXiv:1905.13319, 2019.<br>T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Nee-<br>lakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot<br>learners. arXiv preprint arXiv:2005.14165, 2020.<br>K. Chen, Q. Huang, H. Palangi, P. Smolensky, K. D. Forbus, and J. Gao. Map-<br>ping natural-language problems to formal-language solutions using structured<br>neural representations. In ICML, 2020.<br>X. Chen, C. Liang, A. W. Yu, D. Zhou, D. Song, and Q. V. Le. Neural symbolic<br>reader: Scalable integration of distributed and symbolic representations for<br>reading comprehension. In International Conference on Learning Represen-<br>tations, 2019.<br>T.-R. Chiang and Y.-N. Chen. Semantically-aligned equation generation for<br>solving and reasoning math word problems. arXiv preprint arXiv:1811.00720,<br>2018.<br>D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song,<br>and J. Steinhardt. Measuring mathematical problem solving with the math<br>dataset. arXiv preprint arXiv:2103.03874, 2021.</p>",
            "id": 98,
            "page": 12,
            "text": "A. Amini, S. Gabriel, P. Lin, R. Koncel-Kedziorski, Y. Choi, and H. Hajishirzi. Mathqa: Towards interpretable math word problem solving with operationbased formalisms. arXiv preprint arXiv:1905.13319, 2019. T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell,  Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020. K. Chen, Q. Huang, H. Palangi, P. Smolensky, K. D. Forbus, and J. Gao. Mapping natural-language problems to formal-language solutions using structured neural representations. In ICML, 2020. X. Chen, C. Liang, A. W. Yu, D. Zhou, D. Song, and Q. V. Le. Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension. In International Conference on Learning Representations, 2019. T.-R. Chiang and Y.-N. Chen. Semantically-aligned equation generation for solving and reasoning math word problems. arXiv preprint arXiv:1811.00720, 2018. D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt. Measuring mathematical problem solving with the math dataset. arXiv preprint arXiv:2103.03874, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 1250,
                    "y": 2896
                },
                {
                    "x": 1298,
                    "y": 2896
                },
                {
                    "x": 1298,
                    "y": 2933
                },
                {
                    "x": 1250,
                    "y": 2933
                }
            ],
            "category": "footer",
            "html": "<footer id='99' style='font-size:14px'>12</footer>",
            "id": 99,
            "page": 12,
            "text": "12"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 521
                },
                {
                    "x": 2003,
                    "y": 521
                },
                {
                    "x": 2003,
                    "y": 2834
                },
                {
                    "x": 549,
                    "y": 2834
                }
            ],
            "category": "paragraph",
            "html": "<p id='100' style='font-size:18px'>D. Huang, S. Shi, C.-Y. Lin, J. Yin, and W.-Y. Ma. How well do computers solve<br>math word problems? large-scale dataset construction and evaluation. In<br>Proceedings of the 54th Annual Meeting of the Association for Computational<br>Linguistics (Volume 1: Long Papers), pages 887-896, 2016.<br>D. Huang, J. Liu, C.-Y. Lin, and J. Yin. Neural math word problem solver with<br>reinforcement learning. In Proceedings of the 27th International Conference<br>on Computational Linguistics, pages 213-223, 2018.<br>J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,<br>S. Gray, A. Radford, J. Wu, and D. Amodei. Scaling laws for neural language<br>models. arXiv preprint arXiv:2001.08361, 2020.<br>B. Kim, K. S. Ki, D. Lee, and G. Gweon. Point to the expression: Solving<br>algebraic word problems using the expression-pointer transformer model. In<br>Proceedings of the 2020 Conference on Empirical Methods in Natural Lan-<br>guage Processing (EMNLP), pages 3768-3779, 2020.<br>N. Kushman, Y. Artzi, L. Zettlemoyer, and R. Barzilay. Learning to automati-<br>cally solve algebra word problems. In Proceedings of the 52nd Annual Meeting<br>of the Association for Computational Linguistics (Volume 1: Long Papers),<br>pages 271-281, 2014.<br>G. Lample and F. Charton. Deep learning for symbolic mathematics. arXiv<br>preprint arXiv:1912.01412, 2019.<br>S. Li, L. Wu, S. Feng, F. Xu, F. Xu, and S. Zhong. Graph-to-tree neural<br>networks for learning structured input-output translation with applications<br>to semantic parsing and math word problem. EMNLP, 2020.<br>Z. Liang, J. Zhang, J. Shao, and X. Zhang. Mwp-bert: A strong baseline for<br>math word problems, 07 2021.<br>W. Ling, D. Yogatama, C. Dyer, and P. Blunsom. Program induction by ra-<br>tionale generation: Learning to solve and explain algebraic word problems.<br>arXiv preprint arXiv:1705.04146, 2017.<br>J. Liu, L. Cui, H. Liu, D. Huang, Y. Wang, and Y. Zhang. Logiqa: A challenge<br>dataset for machine reading comprehension with logical reasoning. In IJCAI,<br>2020.<br>S.-Y. Miao, C.-C. Liang, and K.-Y. Su. A diverse corpus for evaluat-<br>ing and developing english math word problem solvers. arXiv preprint<br>arXiv:2106.15772, 2021.<br>E. Nichols, L. Gao, and R. Gomez. Collaborative storytelling with large-scale<br>neural language models. arXiv preprint arXiv:2011.10208, 2020.<br>S. Peng, K. Yuan, L. Gao, and Z. Tang. Mathbert: A pre-trained model for<br>mathematical formula understanding. ArXiv, abs /2105.00377, 2021.</p>",
            "id": 100,
            "page": 13,
            "text": "D. Huang, S. Shi, C.-Y. Lin, J. Yin, and W.-Y. Ma. How well do computers solve math word problems? large-scale dataset construction and evaluation. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 887-896, 2016. D. Huang, J. Liu, C.-Y. Lin, and J. Yin. Neural math word problem solver with reinforcement learning. In Proceedings of the 27th International Conference on Computational Linguistics, pages 213-223, 2018. J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, and D. Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020. B. Kim, K. S. Ki, D. Lee, and G. Gweon. Point to the expression: Solving algebraic word problems using the expression-pointer transformer model. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3768-3779, 2020. N. Kushman, Y. Artzi, L. Zettlemoyer, and R. Barzilay. Learning to automatically solve algebra word problems. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 271-281, 2014. G. Lample and F. Charton. Deep learning for symbolic mathematics. arXiv preprint arXiv:1912.01412, 2019. S. Li, L. Wu, S. Feng, F. Xu, F. Xu, and S. Zhong. Graph-to-tree neural networks for learning structured input-output translation with applications to semantic parsing and math word problem. EMNLP, 2020. Z. Liang, J. Zhang, J. Shao, and X. Zhang. Mwp-bert: A strong baseline for math word problems, 07 2021. W. Ling, D. Yogatama, C. Dyer, and P. Blunsom. Program induction by rationale generation: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146, 2017. J. Liu, L. Cui, H. Liu, D. Huang, Y. Wang, and Y. Zhang. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. In IJCAI, 2020. S.-Y. Miao, C.-C. Liang, and K.-Y. Su. A diverse corpus for evaluating and developing english math word problem solvers. arXiv preprint arXiv:2106.15772, 2021. E. Nichols, L. Gao, and R. Gomez. Collaborative storytelling with large-scale neural language models. arXiv preprint arXiv:2011.10208, 2020. S. Peng, K. Yuan, L. Gao, and Z. Tang. Mathbert: A pre-trained model for mathematical formula understanding. ArXiv, abs /2105.00377, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 1250,
                    "y": 2895
                },
                {
                    "x": 1298,
                    "y": 2895
                },
                {
                    "x": 1298,
                    "y": 2934
                },
                {
                    "x": 1250,
                    "y": 2934
                }
            ],
            "category": "footer",
            "html": "<footer id='101' style='font-size:14px'>13</footer>",
            "id": 101,
            "page": 13,
            "text": "13"
        },
        {
            "bounding_box": [
                {
                    "x": 547,
                    "y": 514
                },
                {
                    "x": 2003,
                    "y": 514
                },
                {
                    "x": 2003,
                    "y": 2467
                },
                {
                    "x": 547,
                    "y": 2467
                }
            ],
            "category": "paragraph",
            "html": "<p id='102' style='font-size:18px'>S. Roy and D. Roth. Solving general arithmetic word problems. In Pro-<br>ceedings of the 2015 Conference on Empirical Methods in Natural Lan-<br>guage Processing, pages 1743-1752, Lisbon, Portugal, Sept. 2015. Associ-<br>ation for Computational Linguistics. doi: 10.18653/v1 /D15-1202. URL<br>https : / /aclanthology · org/D15-1202.<br>J. Shen, Y. Yin, L. Li, L. Shang, X. Jiang, M. Zhang, and Q. Liu. Generate<br>& rank: A multi-task framework for math word problems. arXiv preprint<br>arXiv:2109.03034, 2021a.<br>J. T. Shen, M. Yamashita, E. Prihar, N. Heffernan, X. Wu, B. Graff, and D. Lee.<br>Mathbert: A pre-trained language model for general nlp tasks in mathematics<br>education, 08 2021b.<br>I. Sutskever, 0. Vinyals, and Q. V. Le. Sequence to sequence learning with<br>neural networks. In Advances in neural information processing systems, pages<br>3104-3112, 2014.<br>A. Talmor, J. Herzig, N. Lourie, and J. Berant. Commonsenseqa: A ques-<br>tion answering challenge targeting commonsense knowledge. arXiv preprint<br>arXiv:1811.00937, 2018.<br>A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,<br>L. Kaiser, and I. Polosukhin. Attention is all you need. In Advances in<br>neural information processing systems, pages 5998-6008, 2017.<br>A. Wang, Y. Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, 0. Levy,<br>and S. R. Bowman. Superglue: A stickier benchmark for general-purpose<br>language understanding systems. arXiv preprint arXiv:1905.00537, 2019.<br>Y. Wang, X. Liu, and S. Shi. Deep neural solver for math word problems. In<br>Proceedings of the 2017 Conference on Empirical Methods in Natural Lan-<br>guage Processing, pages 845-854, Copenhagen, Denmark, Sept. 2017. Asso-<br>ciation for Computational Linguistics. doi: 10.18653 /v1/D17-1088. URL<br>https : / /aclanthology · org/D17-1088.<br>Z. Xie and S. Sun. A goal-driven tree-structured neural model for math word<br>problems. In IJCAI, 2019.<br>W. Zhao, M. Shang, Y. Liu, L. Wang, and J. Liu. Ape210k: A large-<br>scale and template-rich dataset of math word problems. arXiv preprint<br>arXiv:2009.11506, 2020.</p>",
            "id": 102,
            "page": 14,
            "text": "S. Roy and D. Roth. Solving general arithmetic word problems. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1743-1752, Lisbon, Portugal, Sept. 2015. Association for Computational Linguistics. doi: 10.18653/v1 /D15-1202. URL https : / /aclanthology · org/D15-1202. J. Shen, Y. Yin, L. Li, L. Shang, X. Jiang, M. Zhang, and Q. Liu. Generate & rank: A multi-task framework for math word problems. arXiv preprint arXiv:2109.03034, 2021a. J. T. Shen, M. Yamashita, E. Prihar, N. Heffernan, X. Wu, B. Graff, and D. Lee. Mathbert: A pre-trained language model for general nlp tasks in mathematics education, 08 2021b. I. Sutskever, 0. Vinyals, and Q. V. Le. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104-3112, 2014. A. Talmor, J. Herzig, N. Lourie, and J. Berant. Commonsenseqa: A question answering challenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937, 2018. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages 5998-6008, 2017. A. Wang, Y. Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, 0. Levy, and S. R. Bowman. Superglue: A stickier benchmark for general-purpose language understanding systems. arXiv preprint arXiv:1905.00537, 2019. Y. Wang, X. Liu, and S. Shi. Deep neural solver for math word problems. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 845-854, Copenhagen, Denmark, Sept. 2017. Association for Computational Linguistics. doi: 10.18653 /v1/D17-1088. URL https : / /aclanthology · org/D17-1088. Z. Xie and S. Sun. A goal-driven tree-structured neural model for math word problems. In IJCAI, 2019. W. Zhao, M. Shang, Y. Liu, L. Wang, and J. Liu. Ape210k: A largescale and template-rich dataset of math word problems. arXiv preprint arXiv:2009.11506, 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 1249,
                    "y": 2895
                },
                {
                    "x": 1298,
                    "y": 2895
                },
                {
                    "x": 1298,
                    "y": 2935
                },
                {
                    "x": 1249,
                    "y": 2935
                }
            ],
            "category": "footer",
            "html": "<footer id='103' style='font-size:14px'>14</footer>",
            "id": 103,
            "page": 14,
            "text": "14"
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 514
                },
                {
                    "x": 1135,
                    "y": 514
                },
                {
                    "x": 1135,
                    "y": 575
                },
                {
                    "x": 552,
                    "y": 575
                }
            ],
            "category": "paragraph",
            "html": "<p id='104' style='font-size:20px'>A Dataset Details</p>",
            "id": 104,
            "page": 15,
            "text": "A Dataset Details"
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 613
                },
                {
                    "x": 1999,
                    "y": 613
                },
                {
                    "x": 1999,
                    "y": 1213
                },
                {
                    "x": 548,
                    "y": 1213
                }
            ],
            "category": "paragraph",
            "html": "<p id='105' style='font-size:16px'>We initially collected a starting set of a thousand problems and natural lan-<br>guage solutions by hiring freelance contractors on Upwork (upwork. com). We<br>then worked with Surge AI (surgehq. ai), an NLP data labeling platform, to<br>scale up our data collection. After collecting the full dataset, we asked workers<br>to re-solve all problems, with no workers re-solving problems they originally<br>wrote. We checked whether their final answers agreed with the original solu-<br>tions, and any problems that produced disagreements were either repaired or<br>discarded. We then performed another round of agreement checks on a smaller<br>subset of problems, finding that 1.7% of problems still produce disagreements<br>among contractors. We estimate this to be the fraction of problems that con-<br>tain breaking errors or ambiguities. It is possible that a larger percentage of<br>problems contain subtle errors.</p>",
            "id": 105,
            "page": 15,
            "text": "We initially collected a starting set of a thousand problems and natural language solutions by hiring freelance contractors on Upwork (upwork. com). We then worked with Surge AI (surgehq. ai), an NLP data labeling platform, to scale up our data collection. After collecting the full dataset, we asked workers to re-solve all problems, with no workers re-solving problems they originally wrote. We checked whether their final answers agreed with the original solutions, and any problems that produced disagreements were either repaired or discarded. We then performed another round of agreement checks on a smaller subset of problems, finding that 1.7% of problems still produce disagreements among contractors. We estimate this to be the fraction of problems that contain breaking errors or ambiguities. It is possible that a larger percentage of problems contain subtle errors."
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 1215
                },
                {
                    "x": 1999,
                    "y": 1215
                },
                {
                    "x": 1999,
                    "y": 1613
                },
                {
                    "x": 548,
                    "y": 1613
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='106' style='font-size:14px'>To assist contractors with writing questions, we provided seed questions au-<br>tomatically generated from a few-shot prompted 175B GPT-3 model. Contrac-<br>tors were allowed to use those seed questions directly, to use them as inspiration<br>and make modifications, or to come up with their own questions entirely. We<br>instructed contractors to be as descriptive as possible in their solutions, and to<br>not re-use problem settings or templates between different questions. To ensure<br>contractors were not re-using problem templates, we computed pairwise simi-<br>larity scores between problems and used this to provide feedback to contractors.</p>",
            "id": 106,
            "page": 15,
            "text": "To assist contractors with writing questions, we provided seed questions automatically generated from a few-shot prompted 175B GPT-3 model. Contractors were allowed to use those seed questions directly, to use them as inspiration and make modifications, or to come up with their own questions entirely. We instructed contractors to be as descriptive as possible in their solutions, and to not re-use problem settings or templates between different questions. To ensure contractors were not re-using problem templates, we computed pairwise similarity scores between problems and used this to provide feedback to contractors."
        },
        {
            "bounding_box": [
                {
                    "x": 1249,
                    "y": 2894
                },
                {
                    "x": 1298,
                    "y": 2894
                },
                {
                    "x": 1298,
                    "y": 2934
                },
                {
                    "x": 1249,
                    "y": 2934
                }
            ],
            "category": "footer",
            "html": "<footer id='107' style='font-size:14px'>15</footer>",
            "id": 107,
            "page": 15,
            "text": "15"
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 513
                },
                {
                    "x": 1190,
                    "y": 513
                },
                {
                    "x": 1190,
                    "y": 580
                },
                {
                    "x": 552,
                    "y": 580
                }
            ],
            "category": "paragraph",
            "html": "<p id='108' style='font-size:20px'>B Hyperparameters</p>",
            "id": 108,
            "page": 16,
            "text": "B Hyperparameters"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 614
                },
                {
                    "x": 2001,
                    "y": 614
                },
                {
                    "x": 2001,
                    "y": 915
                },
                {
                    "x": 549,
                    "y": 915
                }
            ],
            "category": "paragraph",
            "html": "<p id='109' style='font-size:18px'>We include a table of important hyperparameters below. We performed sweeps<br>of the learning rate and batch size by an order of magnitude in both directions<br>from the values in the table and were unable to find any significant improve-<br>ments. Other reasonable choices for both the verifier temperature (eg: 1.0<br>instead of 0.7) and objective (cross-entropy instead of mean squared error) also<br>had negligible effect in our ablations.</p>",
            "id": 109,
            "page": 16,
            "text": "We include a table of important hyperparameters below. We performed sweeps of the learning rate and batch size by an order of magnitude in both directions from the values in the table and were unable to find any significant improvements. Other reasonable choices for both the verifier temperature (eg: 1.0 instead of 0.7) and objective (cross-entropy instead of mean squared error) also had negligible effect in our ablations."
        },
        {
            "bounding_box": [
                {
                    "x": 753,
                    "y": 961
                },
                {
                    "x": 1793,
                    "y": 961
                },
                {
                    "x": 1793,
                    "y": 2267
                },
                {
                    "x": 753,
                    "y": 2267
                }
            ],
            "category": "table",
            "html": "<table id='110' style='font-size:14px'><tr><td>General Hyperparameters</td><td>Value</td></tr><tr><td>Batch Size</td><td>3.2 x 104 tokens</td></tr><tr><td>Max Sample Length</td><td>400 tokens</td></tr><tr><td>Tokenization</td><td>reversible_50000</td></tr><tr><td>Optimizer</td><td>Adam, B1 = 0.9, B2 = 0.95</td></tr><tr><td>Dropout</td><td>0.0</td></tr><tr><td>Learning Rate Schedule</td><td>Linear decay to 0</td></tr><tr><td>Finetuning Hyperparameters</td><td>Value</td></tr><tr><td>Epochs</td><td>20</td></tr><tr><td>Sampling Temperature</td><td>0 (argmax)</td></tr><tr><td>Base Learning Rate (a)</td><td>1.6 x 10-5 (3B)</td></tr><tr><td></td><td>1.2 x 10-5 (6B)</td></tr><tr><td></td><td>1.0 x 10-5 (12B)</td></tr><tr><td></td><td>6.0 x 10-6 (175B)</td></tr><tr><td>Learning Rate</td><td>0.1 x a</td></tr><tr><td>Verification Hyperparameters</td><td>Value</td></tr><tr><td>Epochs</td><td>2 for generator, 1 for verifier</td></tr><tr><td>Sampling Temperature</td><td>0.7</td></tr><tr><td>Learning Rate</td><td>1.0 x 10-5</td></tr><tr><td>Loss weight</td><td>1.0</td></tr><tr><td>Verifier loss</td><td>MSE</td></tr><tr><td>Completions per train problem</td><td>100</td></tr><tr><td>Completions per test problem</td><td>100</td></tr></table>",
            "id": 110,
            "page": 16,
            "text": "General Hyperparameters Value  Batch Size 3.2 x 104 tokens  Max Sample Length 400 tokens  Tokenization reversible_50000  Optimizer Adam, B1 = 0.9, B2 = 0.95  Dropout 0.0  Learning Rate Schedule Linear decay to 0  Finetuning Hyperparameters Value  Epochs 20  Sampling Temperature 0 (argmax)  Base Learning Rate (a) 1.6 x 10-5 (3B)   1.2 x 10-5 (6B)   1.0 x 10-5 (12B)   6.0 x 10-6 (175B)  Learning Rate 0.1 x a  Verification Hyperparameters Value  Epochs 2 for generator, 1 for verifier  Sampling Temperature 0.7  Learning Rate 1.0 x 10-5  Loss weight 1.0  Verifier loss MSE  Completions per train problem 100  Completions per test problem"
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 2305
                },
                {
                    "x": 2000,
                    "y": 2305
                },
                {
                    "x": 2000,
                    "y": 2559
                },
                {
                    "x": 548,
                    "y": 2559
                }
            ],
            "category": "caption",
            "html": "<caption id='111' style='font-size:18px'>Table 1: Hyperparameters used for all experiments, unless explicitly said oth-<br>erwise. Notable exceptions include Figure 8c, which uses 4x more tokens per<br>batch and 300 completions at both training and test time. All dropout exper-<br>iments in Figure 8 use 20% dropout. Figure 7a uses verifiers trained on 100<br>completions, but searching over more completions at test time.</caption>",
            "id": 111,
            "page": 16,
            "text": "Table 1: Hyperparameters used for all experiments, unless explicitly said otherwise. Notable exceptions include Figure 8c, which uses 4x more tokens per batch and 300 completions at both training and test time. All dropout experiments in Figure 8 use 20% dropout. Figure 7a uses verifiers trained on 100 completions, but searching over more completions at test time."
        },
        {
            "bounding_box": [
                {
                    "x": 1250,
                    "y": 2896
                },
                {
                    "x": 1298,
                    "y": 2896
                },
                {
                    "x": 1298,
                    "y": 2934
                },
                {
                    "x": 1250,
                    "y": 2934
                }
            ],
            "category": "footer",
            "html": "<footer id='112' style='font-size:16px'>16</footer>",
            "id": 112,
            "page": 16,
            "text": "16"
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 513
                },
                {
                    "x": 1366,
                    "y": 513
                },
                {
                    "x": 1366,
                    "y": 573
                },
                {
                    "x": 552,
                    "y": 573
                }
            ],
            "category": "paragraph",
            "html": "<p id='113' style='font-size:22px'>C Calculator Annotations</p>",
            "id": 113,
            "page": 17,
            "text": "C Calculator Annotations"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 613
                },
                {
                    "x": 1998,
                    "y": 613
                },
                {
                    "x": 1998,
                    "y": 862
                },
                {
                    "x": 549,
                    "y": 862
                }
            ],
            "category": "paragraph",
            "html": "<p id='114' style='font-size:16px'>The calculator annotations were not provided by human contractors: they were<br>generated by a combination of hard-coded logic and a finetuned language model.<br>The logic for auto-generating calculator annotations is imperfect. It is highly<br>unlikely to generate any incorrect annotations, but it is not uncommon for it to<br>ignore some lines that could be annotated.</p>",
            "id": 114,
            "page": 17,
            "text": "The calculator annotations were not provided by human contractors: they were generated by a combination of hard-coded logic and a finetuned language model. The logic for auto-generating calculator annotations is imperfect. It is highly unlikely to generate any incorrect annotations, but it is not uncommon for it to ignore some lines that could be annotated."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 868
                },
                {
                    "x": 1997,
                    "y": 868
                },
                {
                    "x": 1997,
                    "y": 1061
                },
                {
                    "x": 549,
                    "y": 1061
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='115' style='font-size:16px'>During training, there is no special distinction between the annotated to-<br>kens and the rest of the solution: they are all just tokens. During testing, we<br>override model sampling when a well-formatted annotation exists, specifically<br>overwriting the token(s) directly following \"=\" and within <<. · >>.</p>",
            "id": 115,
            "page": 17,
            "text": "During training, there is no special distinction between the annotated tokens and the rest of the solution: they are all just tokens. During testing, we override model sampling when a well-formatted annotation exists, specifically overwriting the token(s) directly following \"=\" and within <<. · >>."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1067
                },
                {
                    "x": 1998,
                    "y": 1067
                },
                {
                    "x": 1998,
                    "y": 1259
                },
                {
                    "x": 549,
                    "y": 1259
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='116' style='font-size:16px'>To simulate the calculator, we simply use the python eval function to evalu-<br>ate the tokens in the expression (Figure 9). Evaluations that time out or throw<br>an error result in the annotations being skipped and the model being sampled<br>from as usual.</p>",
            "id": 116,
            "page": 17,
            "text": "To simulate the calculator, we simply use the python eval function to evaluate the tokens in the expression (Figure 9). Evaluations that time out or throw an error result in the annotations being skipped and the model being sampled from as usual."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1265
                },
                {
                    "x": 1998,
                    "y": 1265
                },
                {
                    "x": 1998,
                    "y": 1512
                },
                {
                    "x": 549,
                    "y": 1512
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='117' style='font-size:18px'>We note that the original version of our calculator, used for all results in this<br>paper, had some minor implementation bugs. Our reported test performance<br>is therefore a slight underestimate, though the magnitude of this discrepancy is<br>less than 1% in most experiments. Fixing the calculator improves verification<br>test performance by about 1% when using the full GSM8K training set.</p>",
            "id": 117,
            "page": 17,
            "text": "We note that the original version of our calculator, used for all results in this paper, had some minor implementation bugs. Our reported test performance is therefore a slight underestimate, though the magnitude of this discrepancy is less than 1% in most experiments. Fixing the calculator improves verification test performance by about 1% when using the full GSM8K training set."
        },
        {
            "bounding_box": [
                {
                    "x": 782,
                    "y": 1563
                },
                {
                    "x": 1780,
                    "y": 1563
                },
                {
                    "x": 1780,
                    "y": 2049
                },
                {
                    "x": 782,
                    "y": 2049
                }
            ],
            "category": "figure",
            "html": "<figure><img id='118' style='font-size:14px' alt=\"Her sister gave her 20 + 10 = <<20 Generator +\nHer sister gave her 20 + 10 = <<20+ Generator 10\nTrigger\nHer sister gave her 20 + 10 = <<20+10 Generator =\nCalculator\nCalculator\nHer sister gave her 20 + 10 = <<20+10= 30>>\neval('20+10')\nHer sister gave her 20 + 10 = <<20+10=30>> Generator books\" data-coord=\"top-left:(782,1563); bottom-right:(1780,2049)\" /></figure>",
            "id": 118,
            "page": 17,
            "text": "Her sister gave her 20 + 10 = <<20 Generator + Her sister gave her 20 + 10 = <<20+ Generator 10 Trigger Her sister gave her 20 + 10 = <<20+10 Generator = Calculator Calculator Her sister gave her 20 + 10 = <<20+10= 30>> eval(\"20+10\") Her sister gave her 20 + 10 = <<20+10=30>> Generator books"
        },
        {
            "bounding_box": [
                {
                    "x": 735,
                    "y": 2089
                },
                {
                    "x": 1809,
                    "y": 2089
                },
                {
                    "x": 1809,
                    "y": 2140
                },
                {
                    "x": 735,
                    "y": 2140
                }
            ],
            "category": "caption",
            "html": "<caption id='119' style='font-size:20px'>Figure 9: A diagram of the calculator sampling procedure.</caption>",
            "id": 119,
            "page": 17,
            "text": "Figure 9: A diagram of the calculator sampling procedure."
        },
        {
            "bounding_box": [
                {
                    "x": 1249,
                    "y": 2893
                },
                {
                    "x": 1296,
                    "y": 2893
                },
                {
                    "x": 1296,
                    "y": 2935
                },
                {
                    "x": 1249,
                    "y": 2935
                }
            ],
            "category": "footer",
            "html": "<footer id='120' style='font-size:14px'>17</footer>",
            "id": 120,
            "page": 17,
            "text": "17"
        },
        {
            "bounding_box": [
                {
                    "x": 554,
                    "y": 515
                },
                {
                    "x": 1436,
                    "y": 515
                },
                {
                    "x": 1436,
                    "y": 573
                },
                {
                    "x": 554,
                    "y": 573
                }
            ],
            "category": "paragraph",
            "html": "<p id='121' style='font-size:22px'>D Example Model Solutions</p>",
            "id": 121,
            "page": 18,
            "text": "D Example Model Solutions"
        },
        {
            "bounding_box": [
                {
                    "x": 551,
                    "y": 617
                },
                {
                    "x": 1995,
                    "y": 617
                },
                {
                    "x": 1995,
                    "y": 715
                },
                {
                    "x": 551,
                    "y": 715
                }
            ],
            "category": "paragraph",
            "html": "<p id='122' style='font-size:20px'>We showcase a handful of samples comparing finetuning and verification at both<br>6B and 175B scale. Samples were slightly cherry-picked for diversity.</p>",
            "id": 122,
            "page": 18,
            "text": "We showcase a handful of samples comparing finetuning and verification at both 6B and 175B scale. Samples were slightly cherry-picked for diversity."
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 776
                },
                {
                    "x": 1244,
                    "y": 776
                },
                {
                    "x": 1244,
                    "y": 835
                },
                {
                    "x": 603,
                    "y": 835
                }
            ],
            "category": "paragraph",
            "html": "<p id='123' style='font-size:16px'>Dean's mother gave him $28 to go to the toy store. Dean bought 6 toy cars and 5 teddy bears. Each<br>toy car cost $2 and each teddy bear cost $1. His mother then feels generous and decides to give him<br>an extra $10. How much money does Dean have left?</p>",
            "id": 123,
            "page": 18,
            "text": "Dean's mother gave him $28 to go to the toy store. Dean bought 6 toy cars and 5 teddy bears. Each toy car cost $2 and each teddy bear cost $1. His mother then feels generous and decides to give him an extra $10. How much money does Dean have left?"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 864
                },
                {
                    "x": 699,
                    "y": 864
                },
                {
                    "x": 699,
                    "y": 885
                },
                {
                    "x": 603,
                    "y": 885
                }
            ],
            "category": "paragraph",
            "html": "<p id='124' style='font-size:16px'>Ground Truth:</p>",
            "id": 124,
            "page": 18,
            "text": "Ground Truth:"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 888
                },
                {
                    "x": 1185,
                    "y": 888
                },
                {
                    "x": 1185,
                    "y": 980
                },
                {
                    "x": 603,
                    "y": 980
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='125' style='font-size:14px'>The cost of the toy cars is 6 cars x $2/car = $<<6*2=12>>12.<br>The cost of the teddy bears is 5 bears x $1/bear = $<<5*1=5>>5.<br>The total cost of the toys is $12 + $5 = $<<12+5=17>>17.<br>Adding the two amounts of money his mother gave him, we find that Dean has $28 + $10 =<br>$<<28+10=38>>38 to spend.</p>",
            "id": 125,
            "page": 18,
            "text": "The cost of the toy cars is 6 cars x $2/car = $<<6*2=12>>12. The cost of the teddy bears is 5 bears x $1/bear = $<<5*1=5>>5. The total cost of the toys is $12 + $5 = $<<12+5=17>>17. Adding the two amounts of money his mother gave him, we find that Dean has $28 + $10 = $<<28+10=38>>38 to spend."
        },
        {
            "bounding_box": [
                {
                    "x": 600,
                    "y": 979
                },
                {
                    "x": 802,
                    "y": 979
                },
                {
                    "x": 802,
                    "y": 997
                },
                {
                    "x": 600,
                    "y": 997
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='126' style='font-size:14px'>Dean has $38 - $17 = $21 left.</p>",
            "id": 126,
            "page": 18,
            "text": "Dean has $38 - $17 = $21 left."
        },
        {
            "bounding_box": [
                {
                    "x": 604,
                    "y": 996
                },
                {
                    "x": 641,
                    "y": 996
                },
                {
                    "x": 641,
                    "y": 1021
                },
                {
                    "x": 604,
                    "y": 1021
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='127' style='font-size:16px'>A: 21</p>",
            "id": 127,
            "page": 18,
            "text": "A: 21"
        },
        {
            "bounding_box": [
                {
                    "x": 602,
                    "y": 1049
                },
                {
                    "x": 785,
                    "y": 1049
                },
                {
                    "x": 785,
                    "y": 1071
                },
                {
                    "x": 602,
                    "y": 1071
                }
            ],
            "category": "paragraph",
            "html": "<p id='128' style='font-size:18px'>6B Finetuning: [incorrect]</p>",
            "id": 128,
            "page": 18,
            "text": "6B Finetuning: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 1068
                },
                {
                    "x": 966,
                    "y": 1068
                },
                {
                    "x": 966,
                    "y": 1144
                },
                {
                    "x": 603,
                    "y": 1144
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='129' style='font-size:14px'>The cost of the toy cars is 6 x $2 = $<<6*2=12>>12.<br>The cost of the teddy bears is 5 x $1 = $<<5*1=5>>5.<br>The total cost of the toys is $12 + $5 = $<<12+5=17>>17.<br>Dean has $28 - $17 = $<<28-17=11>>11 left.</p>",
            "id": 129,
            "page": 18,
            "text": "The cost of the toy cars is 6 x $2 = $<<6*2=12>>12. The cost of the teddy bears is 5 x $1 = $<<5*1=5>>5. The total cost of the toys is $12 + $5 = $<<12+5=17>>17. Dean has $28 - $17 = $<<28-17=11>>11 left."
        },
        {
            "bounding_box": [
                {
                    "x": 604,
                    "y": 1141
                },
                {
                    "x": 641,
                    "y": 1141
                },
                {
                    "x": 641,
                    "y": 1165
                },
                {
                    "x": 604,
                    "y": 1165
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='130' style='font-size:16px'>A: 11</p>",
            "id": 130,
            "page": 18,
            "text": "A: 11"
        },
        {
            "bounding_box": [
                {
                    "x": 601,
                    "y": 1195
                },
                {
                    "x": 788,
                    "y": 1195
                },
                {
                    "x": 788,
                    "y": 1217
                },
                {
                    "x": 601,
                    "y": 1217
                }
            ],
            "category": "paragraph",
            "html": "<p id='131' style='font-size:16px'>6B Verification: [incorrect]</p>",
            "id": 131,
            "page": 18,
            "text": "6B Verification: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 607,
                    "y": 1216
                },
                {
                    "x": 1098,
                    "y": 1216
                },
                {
                    "x": 1098,
                    "y": 1272
                },
                {
                    "x": 607,
                    "y": 1272
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='132' style='font-size:14px'>The cost of the toys for Dean was 6 x $2 = $<<6*2=12>>12.<br>The cost of the toys for his mother was 5 x $1 = $<<5*1=5>>5.<br>The total cost of the toys for both of them is $12 + $5 = $<<12+5=17>>17.</p>",
            "id": 132,
            "page": 18,
            "text": "The cost of the toys for Dean was 6 x $2 = $<<6*2=12>>12. The cost of the toys for his mother was 5 x $1 = $<<5*1=5>>5. The total cost of the toys for both of them is $12 + $5 = $<<12+5=17>>17."
        },
        {
            "bounding_box": [
                {
                    "x": 602,
                    "y": 1272
                },
                {
                    "x": 1243,
                    "y": 1272
                },
                {
                    "x": 1243,
                    "y": 1313
                },
                {
                    "x": 602,
                    "y": 1313
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='133' style='font-size:16px'>Dean's mother gives him an extra $10, which makes the total amount of money he has left $28 - $17<br>= $<<28-17=11>>11.</p>",
            "id": 133,
            "page": 18,
            "text": "Dean's mother gives him an extra $10, which makes the total amount of money he has left $28 - $17 = $<<28-17=11>>11."
        },
        {
            "bounding_box": [
                {
                    "x": 599,
                    "y": 1310
                },
                {
                    "x": 638,
                    "y": 1310
                },
                {
                    "x": 638,
                    "y": 1329
                },
                {
                    "x": 599,
                    "y": 1329
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='134' style='font-size:16px'>A: 11</p>",
            "id": 134,
            "page": 18,
            "text": "A: 11"
        },
        {
            "bounding_box": [
                {
                    "x": 600,
                    "y": 1358
                },
                {
                    "x": 786,
                    "y": 1358
                },
                {
                    "x": 786,
                    "y": 1381
                },
                {
                    "x": 600,
                    "y": 1381
                }
            ],
            "category": "paragraph",
            "html": "<p id='135' style='font-size:18px'>175B Finetuning: [correct]</p>",
            "id": 135,
            "page": 18,
            "text": "175B Finetuning: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 600,
                    "y": 1378
                },
                {
                    "x": 937,
                    "y": 1378
                },
                {
                    "x": 937,
                    "y": 1400
                },
                {
                    "x": 600,
                    "y": 1400
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='136' style='font-size:16px'>The cost of the toy cars is 6 x $2 = $<<6*2=12>>12.</p>",
            "id": 136,
            "page": 18,
            "text": "The cost of the toy cars is 6 x $2 = $<<6*2=12>>12."
        },
        {
            "bounding_box": [
                {
                    "x": 600,
                    "y": 1398
                },
                {
                    "x": 1160,
                    "y": 1398
                },
                {
                    "x": 1160,
                    "y": 1496
                },
                {
                    "x": 600,
                    "y": 1496
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='137' style='font-size:14px'>The cost of the teddy bears is 5 x $1 = $<<5*1=5>>5.<br>The total cost of the toys is $12 + $5 = $<<12+5=17>>17.<br>Dean has $28 - $17 = $<<28-17=11>>11 left.<br>His mother gives him an extra $10, which brings him to $11 + $10 = $<<11+10=21>>21.<br>A: 21</p>",
            "id": 137,
            "page": 18,
            "text": "The cost of the teddy bears is 5 x $1 = $<<5*1=5>>5. The total cost of the toys is $12 + $5 = $<<12+5=17>>17. Dean has $28 - $17 = $<<28-17=11>>11 left. His mother gives him an extra $10, which brings him to $11 + $10 = $<<11+10=21>>21. A: 21"
        },
        {
            "bounding_box": [
                {
                    "x": 604,
                    "y": 1523
                },
                {
                    "x": 793,
                    "y": 1523
                },
                {
                    "x": 793,
                    "y": 1544
                },
                {
                    "x": 604,
                    "y": 1544
                }
            ],
            "category": "paragraph",
            "html": "<p id='138' style='font-size:16px'>175B Verification: [correct]</p>",
            "id": 138,
            "page": 18,
            "text": "175B Verification: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 600,
                    "y": 1543
                },
                {
                    "x": 903,
                    "y": 1543
                },
                {
                    "x": 903,
                    "y": 1564
                },
                {
                    "x": 600,
                    "y": 1564
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='139' style='font-size:14px'>Dean spent 6*2 = $<<6*2=12>>12 on toy cars.</p>",
            "id": 139,
            "page": 18,
            "text": "Dean spent 6*2 = $<<6*2=12>>12 on toy cars."
        },
        {
            "bounding_box": [
                {
                    "x": 601,
                    "y": 1560
                },
                {
                    "x": 1105,
                    "y": 1560
                },
                {
                    "x": 1105,
                    "y": 1643
                },
                {
                    "x": 601,
                    "y": 1643
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='140' style='font-size:16px'>Dean spent 5*1 = $<<5*1=5>>5 on teddy bears.<br>He had 28-12-5 = $<<28-12-5=11>>11 left.<br>His mother gave him an extra $10 making his total 11+10 = $<<11+10=21>>21.<br>A: 21</p>",
            "id": 140,
            "page": 18,
            "text": "Dean spent 5*1 = $<<5*1=5>>5 on teddy bears. He had 28-12-5 = $<<28-12-5=11>>11 left. His mother gave him an extra $10 making his total 11+10 = $<<11+10=21>>21. A: 21"
        },
        {
            "bounding_box": [
                {
                    "x": 601,
                    "y": 1681
                },
                {
                    "x": 1245,
                    "y": 1681
                },
                {
                    "x": 1245,
                    "y": 1773
                },
                {
                    "x": 601,
                    "y": 1773
                }
            ],
            "category": "paragraph",
            "html": "<p id='141' style='font-size:16px'>A perfume company is trying to create new scents. They already have 4 vanilla scents and 8 fruity<br>scents available and they need to decide which kind of scent to focus on. They decide to focus on<br>whichever scent sells the most and monitor their number of sales as part of their research. By the end<br>of the day, they sell 5 of each of the vanilla scents and 2 of each of the fruity scents available. How<br>many more vanilla scents sold compared with the fruity scents?</p>",
            "id": 141,
            "page": 18,
            "text": "A perfume company is trying to create new scents. They already have 4 vanilla scents and 8 fruity scents available and they need to decide which kind of scent to focus on. They decide to focus on whichever scent sells the most and monitor their number of sales as part of their research. By the end of the day, they sell 5 of each of the vanilla scents and 2 of each of the fruity scents available. How many more vanilla scents sold compared with the fruity scents?"
        },
        {
            "bounding_box": [
                {
                    "x": 599,
                    "y": 1805
                },
                {
                    "x": 699,
                    "y": 1805
                },
                {
                    "x": 699,
                    "y": 1827
                },
                {
                    "x": 599,
                    "y": 1827
                }
            ],
            "category": "paragraph",
            "html": "<p id='142' style='font-size:16px'>Ground Truth:</p>",
            "id": 142,
            "page": 18,
            "text": "Ground Truth:"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 1831
                },
                {
                    "x": 1191,
                    "y": 1831
                },
                {
                    "x": 1191,
                    "y": 1905
                },
                {
                    "x": 603,
                    "y": 1905
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='143' style='font-size:14px'>The store sold 4 types of vanilla scents * 5 sales each = <<4*5=20>>20 of the vanilla scents.<br>The store sold 8 types of fruity scents * 2 sales each = <<8*2=16>>16 of the fruity scents.<br>This means that the store sold 20 vanilla - 16 fruity = <<20-16=4>>4 more vanilla scents.<br>A: 4</p>",
            "id": 143,
            "page": 18,
            "text": "The store sold 4 types of vanilla scents * 5 sales each = <<4*5=20>>20 of the vanilla scents. The store sold 8 types of fruity scents * 2 sales each = <<8*2=16>>16 of the fruity scents. This means that the store sold 20 vanilla - 16 fruity = <<20-16=4>>4 more vanilla scents. A: 4"
        },
        {
            "bounding_box": [
                {
                    "x": 602,
                    "y": 1933
                },
                {
                    "x": 787,
                    "y": 1933
                },
                {
                    "x": 787,
                    "y": 1954
                },
                {
                    "x": 602,
                    "y": 1954
                }
            ],
            "category": "paragraph",
            "html": "<p id='144' style='font-size:16px'>6B Finetuning: [incorrect]</p>",
            "id": 144,
            "page": 18,
            "text": "6B Finetuning: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 604,
                    "y": 1952
                },
                {
                    "x": 1238,
                    "y": 1952
                },
                {
                    "x": 1238,
                    "y": 2019
                },
                {
                    "x": 604,
                    "y": 2019
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='145' style='font-size:16px'>The perfume company sold 5 Vanilla A and 2 Vanilla B, so 5 + 2 = <<5+2=7>>7 Vanilla scents sold.<br>They also sold 2 Fruity A and 5 Fruity B, so 2 + 5 = <<2+5=7>>7 Fruity scents sold.<br>The Vanilla scents sold 7 - 5 = <<7-5=2>>2 more than the Fruity scents.</p>",
            "id": 145,
            "page": 18,
            "text": "The perfume company sold 5 Vanilla A and 2 Vanilla B, so 5 + 2 = <<5+2=7>>7 Vanilla scents sold. They also sold 2 Fruity A and 5 Fruity B, so 2 + 5 = <<2+5=7>>7 Fruity scents sold. The Vanilla scents sold 7 - 5 = <<7-5=2>>2 more than the Fruity scents."
        },
        {
            "bounding_box": [
                {
                    "x": 602,
                    "y": 2010
                },
                {
                    "x": 637,
                    "y": 2010
                },
                {
                    "x": 637,
                    "y": 2033
                },
                {
                    "x": 602,
                    "y": 2033
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='146' style='font-size:16px'>A: 2</p>",
            "id": 146,
            "page": 18,
            "text": "A: 2"
        },
        {
            "bounding_box": [
                {
                    "x": 600,
                    "y": 2060
                },
                {
                    "x": 773,
                    "y": 2060
                },
                {
                    "x": 773,
                    "y": 2080
                },
                {
                    "x": 600,
                    "y": 2080
                }
            ],
            "category": "paragraph",
            "html": "<p id='147' style='font-size:16px'>6B Verification: [correct]</p>",
            "id": 147,
            "page": 18,
            "text": "6B Verification: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 604,
                    "y": 2080
                },
                {
                    "x": 1181,
                    "y": 2080
                },
                {
                    "x": 1181,
                    "y": 2156
                },
                {
                    "x": 604,
                    "y": 2156
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='148' style='font-size:14px'>There were 5 vanilla scents sold in total, so they sold 5 x 4 = <<5*4=20>>20 vanilla scents.<br>They sold 2 fruity scents in total, so they sold 2 x 8 = <<2*8=16>>16 fruity scents.<br>Therefore, the vanilla scents sold 20 · 16 = <<20-16=4>>4 more than the fruity scents.<br>A: 4</p>",
            "id": 148,
            "page": 18,
            "text": "There were 5 vanilla scents sold in total, so they sold 5 x 4 = <<5*4=20>>20 vanilla scents. They sold 2 fruity scents in total, so they sold 2 x 8 = <<2*8=16>>16 fruity scents. Therefore, the vanilla scents sold 20 · 16 = <<20-16=4>>4 more than the fruity scents. A: 4"
        },
        {
            "bounding_box": [
                {
                    "x": 606,
                    "y": 2189
                },
                {
                    "x": 788,
                    "y": 2189
                },
                {
                    "x": 788,
                    "y": 2208
                },
                {
                    "x": 606,
                    "y": 2208
                }
            ],
            "category": "paragraph",
            "html": "<p id='149' style='font-size:18px'>175B Finetuning: [correct]</p>",
            "id": 149,
            "page": 18,
            "text": "175B Finetuning: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 2210
                },
                {
                    "x": 904,
                    "y": 2210
                },
                {
                    "x": 904,
                    "y": 2246
                },
                {
                    "x": 603,
                    "y": 2246
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='150' style='font-size:14px'>They sold 5 4 = <<5*4=20>>20 vanilla scents.<br>They sold 2 * 8 =<<2*8=16>>16 fruity scents.</p>",
            "id": 150,
            "page": 18,
            "text": "They sold 5 4 = <<5*4=20>>20 vanilla scents. They sold 2 * 8 =<<2*8=16>>16 fruity scents."
        },
        {
            "bounding_box": [
                {
                    "x": 599,
                    "y": 2245
                },
                {
                    "x": 958,
                    "y": 2245
                },
                {
                    "x": 958,
                    "y": 2266
                },
                {
                    "x": 599,
                    "y": 2266
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='151' style='font-size:14px'>They sold 20 - 16= <<20-16=4>>4 more vanilla scents.</p>",
            "id": 151,
            "page": 18,
            "text": "They sold 20 - 16= <<20-16=4>>4 more vanilla scents."
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 2264
                },
                {
                    "x": 633,
                    "y": 2264
                },
                {
                    "x": 633,
                    "y": 2287
                },
                {
                    "x": 603,
                    "y": 2287
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='152' style='font-size:14px'>A: 4</p>",
            "id": 152,
            "page": 18,
            "text": "A: 4"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 2315
                },
                {
                    "x": 789,
                    "y": 2315
                },
                {
                    "x": 789,
                    "y": 2335
                },
                {
                    "x": 603,
                    "y": 2335
                }
            ],
            "category": "paragraph",
            "html": "<p id='153' style='font-size:16px'>175B Verification: [correct]</p>",
            "id": 153,
            "page": 18,
            "text": "175B Verification: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 610,
                    "y": 2332
                },
                {
                    "x": 1239,
                    "y": 2332
                },
                {
                    "x": 1239,
                    "y": 2369
                },
                {
                    "x": 610,
                    "y": 2369
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='154' style='font-size:14px'>The perfume company sold 5 of each of the vanilla scents for a total of 5*4 = <<5*4=20>>20 vanilla<br>scents.</p>",
            "id": 154,
            "page": 18,
            "text": "The perfume company sold 5 of each of the vanilla scents for a total of 5*4 = <<5*4=20>>20 vanilla scents."
        },
        {
            "bounding_box": [
                {
                    "x": 600,
                    "y": 2410
                },
                {
                    "x": 631,
                    "y": 2410
                },
                {
                    "x": 631,
                    "y": 2432
                },
                {
                    "x": 600,
                    "y": 2432
                }
            ],
            "category": "paragraph",
            "html": "<p id='155' style='font-size:16px'>A: 4</p>",
            "id": 155,
            "page": 18,
            "text": "A: 4"
        },
        {
            "bounding_box": [
                {
                    "x": 610,
                    "y": 2370
                },
                {
                    "x": 1230,
                    "y": 2370
                },
                {
                    "x": 1230,
                    "y": 2419
                },
                {
                    "x": 610,
                    "y": 2419
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='156' style='font-size:16px'>They also sold 2 of each of the fruity scents for a total of 2*8 = <<2*8=16>>16 fruity scents.<br>Therefore, the perfume company sold 20-16 = <<20-16=4>>4 more vanilla scents than fruity scents.</p>",
            "id": 156,
            "page": 18,
            "text": "They also sold 2 of each of the fruity scents for a total of 2*8 = <<2*8=16>>16 fruity scents. Therefore, the perfume company sold 20-16 = <<20-16=4>>4 more vanilla scents than fruity scents."
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 776
                },
                {
                    "x": 1930,
                    "y": 776
                },
                {
                    "x": 1930,
                    "y": 818
                },
                {
                    "x": 1295,
                    "y": 818
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='157' style='font-size:16px'>Shiela is required to submit a 15-page research paper. She already finished writing 1/3 of the paper.<br>How many pages does she have left to write?</p>",
            "id": 157,
            "page": 18,
            "text": "Shiela is required to submit a 15-page research paper. She already finished writing 1/3 of the paper. How many pages does she have left to write?"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 845
                },
                {
                    "x": 1396,
                    "y": 845
                },
                {
                    "x": 1396,
                    "y": 865
                },
                {
                    "x": 1293,
                    "y": 865
                }
            ],
            "category": "paragraph",
            "html": "<p id='158' style='font-size:16px'>Ground Truth:</p>",
            "id": 158,
            "page": 18,
            "text": "Ground Truth:"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 906
                },
                {
                    "x": 1334,
                    "y": 906
                },
                {
                    "x": 1334,
                    "y": 923
                },
                {
                    "x": 1294,
                    "y": 923
                }
            ],
            "category": "paragraph",
            "html": "<p id='159' style='font-size:16px'>A: 10</p>",
            "id": 159,
            "page": 18,
            "text": "A: 10"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 866
                },
                {
                    "x": 1920,
                    "y": 866
                },
                {
                    "x": 1920,
                    "y": 906
                },
                {
                    "x": 1294,
                    "y": 906
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='160' style='font-size:16px'>Shiela has already written one third ofthe paper which is 15 pages x 1/3 = <<15*1/3=5>>5 pages.<br>So, she still needs to write 15 pages - 5 pages = <<15-5=10>>10 pages.</p>",
            "id": 160,
            "page": 18,
            "text": "Shiela has already written one third ofthe paper which is 15 pages x 1/3 = <<15*1/3=5>>5 pages. So, she still needs to write 15 pages - 5 pages = <<15-5=10>>10 pages."
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 958
                },
                {
                    "x": 1463,
                    "y": 958
                },
                {
                    "x": 1463,
                    "y": 975
                },
                {
                    "x": 1295,
                    "y": 975
                }
            ],
            "category": "paragraph",
            "html": "<p id='161' style='font-size:18px'>6B Finetuning: [correct]</p>",
            "id": 161,
            "page": 18,
            "text": "6B Finetuning: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 974
                },
                {
                    "x": 1751,
                    "y": 974
                },
                {
                    "x": 1751,
                    "y": 1033
                },
                {
                    "x": 1295,
                    "y": 1033
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='162' style='font-size:14px'>She has written 1/3 * 15 pages = <<1/3*15=5.0>>5 pages.<br>The rest of the paper is 15 pages - 5 pages = <<15-5=10.0>>10 pages.<br>A: 10</p>",
            "id": 162,
            "page": 18,
            "text": "She has written 1/3 * 15 pages = <<1/3*15=5.0>>5 pages. The rest of the paper is 15 pages - 5 pages = <<15-5=10.0>>10 pages. A: 10"
        },
        {
            "bounding_box": [
                {
                    "x": 1296,
                    "y": 1063
                },
                {
                    "x": 1468,
                    "y": 1063
                },
                {
                    "x": 1468,
                    "y": 1082
                },
                {
                    "x": 1296,
                    "y": 1082
                }
            ],
            "category": "paragraph",
            "html": "<p id='163' style='font-size:16px'>6B Verification: [correct]</p>",
            "id": 163,
            "page": 18,
            "text": "6B Verification: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 1084
                },
                {
                    "x": 1675,
                    "y": 1084
                },
                {
                    "x": 1675,
                    "y": 1140
                },
                {
                    "x": 1295,
                    "y": 1140
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='164' style='font-size:14px'>Shiela has written 1/3 x 15= <<1/3*15=5.0>>5.0 pages.<br>So, she has 15 - 5 = <<15-5=10.0>>10.0 pages left to write.<br>A: 10</p>",
            "id": 164,
            "page": 18,
            "text": "Shiela has written 1/3 x 15= <<1/3*15=5.0>>5.0 pages. So, she has 15 - 5 = <<15-5=10.0>>10.0 pages left to write. A: 10"
        },
        {
            "bounding_box": [
                {
                    "x": 1298,
                    "y": 1171
                },
                {
                    "x": 1478,
                    "y": 1171
                },
                {
                    "x": 1478,
                    "y": 1190
                },
                {
                    "x": 1298,
                    "y": 1190
                }
            ],
            "category": "paragraph",
            "html": "<p id='165' style='font-size:18px'>175B Finetuning: [correct]</p>",
            "id": 165,
            "page": 18,
            "text": "175B Finetuning: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 1296,
                    "y": 1190
                },
                {
                    "x": 1696,
                    "y": 1190
                },
                {
                    "x": 1696,
                    "y": 1241
                },
                {
                    "x": 1296,
                    "y": 1241
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='166' style='font-size:16px'>Shiela has written 1/3 x 15= <<1/3*15=5.0>>5 pages.<br>Therefore, she has 15 - 5= <<15-5=10>>10 pages left to write.<br>A: 10</p>",
            "id": 166,
            "page": 18,
            "text": "Shiela has written 1/3 x 15= <<1/3*15=5.0>>5 pages. Therefore, she has 15 - 5= <<15-5=10>>10 pages left to write. A: 10"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 1279
                },
                {
                    "x": 1487,
                    "y": 1279
                },
                {
                    "x": 1487,
                    "y": 1297
                },
                {
                    "x": 1294,
                    "y": 1297
                }
            ],
            "category": "paragraph",
            "html": "<p id='167' style='font-size:18px'>175B Verification: [correct]</p>",
            "id": 167,
            "page": 18,
            "text": "175B Verification: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 1297
                },
                {
                    "x": 1693,
                    "y": 1297
                },
                {
                    "x": 1693,
                    "y": 1338
                },
                {
                    "x": 1294,
                    "y": 1338
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='168' style='font-size:14px'>Shiela has finished writing 1/3 x 15 = <<1/3*15=5.0>>5 pages.<br>Thus, she has 15 - 5 = <<15-5=10.0>>10 pages left to write.</p>",
            "id": 168,
            "page": 18,
            "text": "Shiela has finished writing 1/3 x 15 = <<1/3*15=5.0>>5 pages. Thus, she has 15 - 5 = <<15-5=10.0>>10 pages left to write."
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 1337
                },
                {
                    "x": 1334,
                    "y": 1337
                },
                {
                    "x": 1334,
                    "y": 1355
                },
                {
                    "x": 1294,
                    "y": 1355
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='169' style='font-size:16px'>A: 10</p>",
            "id": 169,
            "page": 18,
            "text": "A: 10"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1436
                },
                {
                    "x": 1332,
                    "y": 1436
                },
                {
                    "x": 1332,
                    "y": 1457
                },
                {
                    "x": 1293,
                    "y": 1457
                }
            ],
            "category": "paragraph",
            "html": "<p id='170' style='font-size:18px'>buy?</p>",
            "id": 170,
            "page": 18,
            "text": "buy?"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 1396
                },
                {
                    "x": 1937,
                    "y": 1396
                },
                {
                    "x": 1937,
                    "y": 1438
                },
                {
                    "x": 1294,
                    "y": 1438
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='171' style='font-size:16px'>The cheese pizza is cut into 12 slices and the pepperoni pizza is cut into 8 slices. If Kate's 6 friends<br>each eat 6 cheese pizza slices and 4 pepperoni pizza slices, how many pizza pies does she need to</p>",
            "id": 171,
            "page": 18,
            "text": "The cheese pizza is cut into 12 slices and the pepperoni pizza is cut into 8 slices. If Kate's 6 friends each eat 6 cheese pizza slices and 4 pepperoni pizza slices, how many pizza pies does she need to"
        },
        {
            "bounding_box": [
                {
                    "x": 1292,
                    "y": 1484
                },
                {
                    "x": 1398,
                    "y": 1484
                },
                {
                    "x": 1398,
                    "y": 1505
                },
                {
                    "x": 1292,
                    "y": 1505
                }
            ],
            "category": "paragraph",
            "html": "<p id='172' style='font-size:16px'>Ground Truth:</p>",
            "id": 172,
            "page": 18,
            "text": "Ground Truth:"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 1506
                },
                {
                    "x": 1686,
                    "y": 1506
                },
                {
                    "x": 1686,
                    "y": 1525
                },
                {
                    "x": 1294,
                    "y": 1525
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='173' style='font-size:14px'>Kate's friends eat 6 x 6 = <<6*6=36>>36 cheese pizza slices.</p>",
            "id": 173,
            "page": 18,
            "text": "Kate's friends eat 6 x 6 = <<6*6=36>>36 cheese pizza slices."
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 1600
                },
                {
                    "x": 1326,
                    "y": 1600
                },
                {
                    "x": 1326,
                    "y": 1618
                },
                {
                    "x": 1294,
                    "y": 1618
                }
            ],
            "category": "paragraph",
            "html": "<p id='174' style='font-size:16px'>A: 6</p>",
            "id": 174,
            "page": 18,
            "text": "A: 6"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1519
                },
                {
                    "x": 1692,
                    "y": 1519
                },
                {
                    "x": 1692,
                    "y": 1600
                },
                {
                    "x": 1293,
                    "y": 1600
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='175' style='font-size:14px'>Her friends eat 6 x 4 = <<6*4=24>>24 pepperoni pizza slices.<br>Kate needs to buy 36 / 12 = <<36/12=3>>3 cheese pizza pies.<br>She needs to buy 24 / 8 = <<24/8=3>>3 pepperoni pizza pies.<br>She needs to buy a total of 3 + 3 = <<3+3=6>>6 pizza pies.</p>",
            "id": 175,
            "page": 18,
            "text": "Her friends eat 6 x 4 = <<6*4=24>>24 pepperoni pizza slices. Kate needs to buy 36 / 12 = <<36/12=3>>3 cheese pizza pies. She needs to buy 24 / 8 = <<24/8=3>>3 pepperoni pizza pies. She needs to buy a total of 3 + 3 = <<3+3=6>>6 pizza pies."
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1649
                },
                {
                    "x": 1478,
                    "y": 1649
                },
                {
                    "x": 1478,
                    "y": 1671
                },
                {
                    "x": 1293,
                    "y": 1671
                }
            ],
            "category": "paragraph",
            "html": "<p id='176' style='font-size:18px'>6B Finetuning: [incorrect]</p>",
            "id": 176,
            "page": 18,
            "text": "6B Finetuning: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 1726
                },
                {
                    "x": 1326,
                    "y": 1726
                },
                {
                    "x": 1326,
                    "y": 1745
                },
                {
                    "x": 1294,
                    "y": 1745
                }
            ],
            "category": "paragraph",
            "html": "<p id='177' style='font-size:16px'>A: 3</p>",
            "id": 177,
            "page": 18,
            "text": "A: 3"
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 1669
                },
                {
                    "x": 1918,
                    "y": 1669
                },
                {
                    "x": 1918,
                    "y": 1730
                },
                {
                    "x": 1295,
                    "y": 1730
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='178' style='font-size:14px'>Kate's 6 friends eat a total of 6 friends * 6 slices = <<6*6=36>>36 slices.<br>This is a total of 36 slices + 8 slices = <<36+8=44>>44 slices needed to buy.<br>Therefore, Kate needs 44 slices / 12 slices/pizza = <<44/12=3.6666666666666665>>3 pizza pies.</p>",
            "id": 178,
            "page": 18,
            "text": "Kate's 6 friends eat a total of 6 friends * 6 slices = <<6*6=36>>36 slices. This is a total of 36 slices + 8 slices = <<36+8=44>>44 slices needed to buy. Therefore, Kate needs 44 slices / 12 slices/pizza = <<44/12=3.6666666666666665>>3 pizza pies."
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 1777
                },
                {
                    "x": 1485,
                    "y": 1777
                },
                {
                    "x": 1485,
                    "y": 1796
                },
                {
                    "x": 1294,
                    "y": 1796
                }
            ],
            "category": "paragraph",
            "html": "<p id='179' style='font-size:16px'>6B Verification: [incorrect]</p>",
            "id": 179,
            "page": 18,
            "text": "6B Verification: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 1795
                },
                {
                    "x": 1917,
                    "y": 1795
                },
                {
                    "x": 1917,
                    "y": 1831
                },
                {
                    "x": 1294,
                    "y": 1831
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='180' style='font-size:16px'>If Kate's 6 friends eat 6 cheese pizza slices each, then she needs 6*12 = <<6*12=72>>72 cheese<br>pizza slices.</p>",
            "id": 180,
            "page": 18,
            "text": "If Kate's 6 friends eat 6 cheese pizza slices each, then she needs 6*12 = <<6*12=72>>72 cheese pizza slices."
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1836
                },
                {
                    "x": 1935,
                    "y": 1836
                },
                {
                    "x": 1935,
                    "y": 1873
                },
                {
                    "x": 1293,
                    "y": 1873
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='181' style='font-size:14px'>If Kate's 6 friends eat 4 pepperoni pizza slices each, then she needs 4*8 = <<4*8=32>>32 pepperoni<br>pizza slices.</p>",
            "id": 181,
            "page": 18,
            "text": "If Kate's 6 friends eat 4 pepperoni pizza slices each, then she needs 4*8 = <<4*8=32>>32 pepperoni pizza slices."
        },
        {
            "bounding_box": [
                {
                    "x": 1298,
                    "y": 1890
                },
                {
                    "x": 1342,
                    "y": 1890
                },
                {
                    "x": 1342,
                    "y": 1911
                },
                {
                    "x": 1298,
                    "y": 1911
                }
            ],
            "category": "paragraph",
            "html": "<p id='182' style='font-size:16px'>A: 104</p>",
            "id": 182,
            "page": 18,
            "text": "A: 104"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1941
                },
                {
                    "x": 1493,
                    "y": 1941
                },
                {
                    "x": 1493,
                    "y": 1961
                },
                {
                    "x": 1293,
                    "y": 1961
                }
            ],
            "category": "paragraph",
            "html": "<p id='183' style='font-size:16px'>175B Finetuning: [incorrect]</p>",
            "id": 183,
            "page": 18,
            "text": "175B Finetuning: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 1299,
                    "y": 1871
                },
                {
                    "x": 1690,
                    "y": 1871
                },
                {
                    "x": 1690,
                    "y": 1891
                },
                {
                    "x": 1299,
                    "y": 1891
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='184' style='font-size:14px'>In total, Kate needs 72+32 = <<72+32=104>>104 pizza slices.</p>",
            "id": 184,
            "page": 18,
            "text": "In total, Kate needs 72+32 = <<72+32=104>>104 pizza slices."
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1979
                },
                {
                    "x": 1838,
                    "y": 1979
                },
                {
                    "x": 1838,
                    "y": 2001
                },
                {
                    "x": 1293,
                    "y": 2001
                }
            ],
            "category": "paragraph",
            "html": "<p id='185' style='font-size:14px'>Friends eating pepperoni pizza will eat 8 * 4 = <<8*4=32>>32 pepperoni pizza slices.</p>",
            "id": 185,
            "page": 18,
            "text": "Friends eating pepperoni pizza will eat 8 * 4 = <<8*4=32>>32 pepperoni pizza slices."
        },
        {
            "bounding_box": [
                {
                    "x": 1296,
                    "y": 1997
                },
                {
                    "x": 1696,
                    "y": 1997
                },
                {
                    "x": 1696,
                    "y": 2017
                },
                {
                    "x": 1296,
                    "y": 2017
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='186' style='font-size:14px'>Total slices eaten will be 72 + 32 = <<72+32=104>>104 slices.</p>",
            "id": 186,
            "page": 18,
            "text": "Total slices eaten will be 72 + 32 = <<72+32=104>>104 slices."
        },
        {
            "bounding_box": [
                {
                    "x": 1297,
                    "y": 1963
                },
                {
                    "x": 1820,
                    "y": 1963
                },
                {
                    "x": 1820,
                    "y": 1986
                },
                {
                    "x": 1297,
                    "y": 1986
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='187' style='font-size:14px'>Friends eating cheese pizza will eat 12 * 6 = <<12*6=72>>72 cheese pizza slices.</p>",
            "id": 187,
            "page": 18,
            "text": "Friends eating cheese pizza will eat 12 * 6 = <<12*6=72>>72 cheese pizza slices."
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 2076
                },
                {
                    "x": 1333,
                    "y": 2076
                },
                {
                    "x": 1333,
                    "y": 2095
                },
                {
                    "x": 1293,
                    "y": 2095
                }
            ],
            "category": "paragraph",
            "html": "<p id='188' style='font-size:16px'>A: 21</p>",
            "id": 188,
            "page": 18,
            "text": "A: 21"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 2037
                },
                {
                    "x": 1758,
                    "y": 2037
                },
                {
                    "x": 1758,
                    "y": 2059
                },
                {
                    "x": 1293,
                    "y": 2059
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='189' style='font-size:14px'>Kate will need to buy 104 / 8 = <<104/8=13.0>>13 pepperoni pizza pies.</p>",
            "id": 189,
            "page": 18,
            "text": "Kate will need to buy 104 / 8 = <<104/8=13.0>>13 pepperoni pizza pies."
        },
        {
            "bounding_box": [
                {
                    "x": 1299,
                    "y": 2018
                },
                {
                    "x": 1848,
                    "y": 2018
                },
                {
                    "x": 1848,
                    "y": 2036
                },
                {
                    "x": 1299,
                    "y": 2036
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='190' style='font-size:14px'>Kate will need to buy 104 / 12 = <<104/12=8.666666666666666>>8 cheese pizza pies.</p>",
            "id": 190,
            "page": 18,
            "text": "Kate will need to buy 104 / 12 = <<104/12=8.666666666666666>>8 cheese pizza pies."
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 2055
                },
                {
                    "x": 1664,
                    "y": 2055
                },
                {
                    "x": 1664,
                    "y": 2078
                },
                {
                    "x": 1294,
                    "y": 2078
                }
            ],
            "category": "paragraph",
            "html": "<p id='191' style='font-size:14px'>She will need to buy 13 + 8 = <<13+8=21>>21 pizza pies.</p>",
            "id": 191,
            "page": 18,
            "text": "She will need to buy 13 + 8 = <<13+8=21>>21 pizza pies."
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 2124
                },
                {
                    "x": 1497,
                    "y": 2124
                },
                {
                    "x": 1497,
                    "y": 2144
                },
                {
                    "x": 1295,
                    "y": 2144
                }
            ],
            "category": "paragraph",
            "html": "<p id='192' style='font-size:16px'>175B Verification: [incorrect]</p>",
            "id": 192,
            "page": 18,
            "text": "175B Verification: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 2146
                },
                {
                    "x": 1937,
                    "y": 2146
                },
                {
                    "x": 1937,
                    "y": 2184
                },
                {
                    "x": 1293,
                    "y": 2184
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='193' style='font-size:14px'>She has 6 friends who eat 12 cheese slices each so they eat 6*12 = <<6*12=72>>72 cheese slices<br>She has 4 friends who eat 8 pepperoni slices each so they eat 4*8 = <<4*8=32>>32 pepperoni slices</p>",
            "id": 193,
            "page": 18,
            "text": "She has 6 friends who eat 12 cheese slices each so they eat 6*12 = <<6*12=72>>72 cheese slices She has 4 friends who eat 8 pepperoni slices each so they eat 4*8 = <<4*8=32>>32 pepperoni slices"
        },
        {
            "bounding_box": [
                {
                    "x": 1292,
                    "y": 2183
                },
                {
                    "x": 1682,
                    "y": 2183
                },
                {
                    "x": 1682,
                    "y": 2204
                },
                {
                    "x": 1292,
                    "y": 2204
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='194' style='font-size:16px'>Together her friends eat 72+32 = <<72+32=104>> 104 slices</p>",
            "id": 194,
            "page": 18,
            "text": "Together her friends eat 72+32 = <<72+32=104>> 104 slices"
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 2204
                },
                {
                    "x": 1940,
                    "y": 2204
                },
                {
                    "x": 1940,
                    "y": 2236
                },
                {
                    "x": 1295,
                    "y": 2236
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='195' style='font-size:16px'>There are 12 cheese slices in 1 pizza pie and she needs to buy 72 cheese slices so she needs 72/12<br>\" <<72/12=6.0>>6 pizza pies</p>",
            "id": 195,
            "page": 18,
            "text": "There are 12 cheese slices in 1 pizza pie and she needs to buy 72 cheese slices so she needs 72/12 \" <<72/12=6.0>>6 pizza pies"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 2317
                },
                {
                    "x": 1334,
                    "y": 2317
                },
                {
                    "x": 1334,
                    "y": 2336
                },
                {
                    "x": 1294,
                    "y": 2336
                }
            ],
            "category": "paragraph",
            "html": "<p id='196' style='font-size:16px'>A: 10</p>",
            "id": 196,
            "page": 18,
            "text": "A: 10"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 2279
                },
                {
                    "x": 1936,
                    "y": 2279
                },
                {
                    "x": 1936,
                    "y": 2317
                },
                {
                    "x": 1294,
                    "y": 2317
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='197' style='font-size:14px'>In total she needs to buy 6 pizza pies for cheese and 4 pizza pies for pepperoni so she needs to buy<br>6+4 = <<6+4=10>>10 pizza pies</p>",
            "id": 197,
            "page": 18,
            "text": "In total she needs to buy 6 pizza pies for cheese and 4 pizza pies for pepperoni so she needs to buy 6+4 = <<6+4=10>>10 pizza pies"
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 2239
                },
                {
                    "x": 1932,
                    "y": 2239
                },
                {
                    "x": 1932,
                    "y": 2275
                },
                {
                    "x": 1295,
                    "y": 2275
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='198' style='font-size:14px'>There are 8 pepperoni slices in 1 pizza pie and she needs to buy 32 pepperoni slices so she needs<br>32/8 = <<32/8=4.0>>4 pizza pies</p>",
            "id": 198,
            "page": 18,
            "text": "There are 8 pepperoni slices in 1 pizza pie and she needs to buy 32 pepperoni slices so she needs 32/8 = <<32/8=4.0>>4 pizza pies"
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 2897
                },
                {
                    "x": 1297,
                    "y": 2897
                },
                {
                    "x": 1297,
                    "y": 2931
                },
                {
                    "x": 1252,
                    "y": 2931
                }
            ],
            "category": "footer",
            "html": "<footer id='199' style='font-size:20px'>18</footer>",
            "id": 199,
            "page": 18,
            "text": "18"
        },
        {
            "bounding_box": [
                {
                    "x": 602,
                    "y": 537
                },
                {
                    "x": 1247,
                    "y": 537
                },
                {
                    "x": 1247,
                    "y": 596
                },
                {
                    "x": 602,
                    "y": 596
                }
            ],
            "category": "paragraph",
            "html": "<p id='200' style='font-size:16px'>Cindy's math and science books weigh 2 pounds each. Her French book weighs 4 pounds and her<br>English book weighs 3 pounds. Her history book weighs twice as much as her English book. If Cindy<br>carries all ofher books at once, what will be the total weight of the books she is carrying?</p>",
            "id": 200,
            "page": 19,
            "text": "Cindy's math and science books weigh 2 pounds each. Her French book weighs 4 pounds and her English book weighs 3 pounds. Her history book weighs twice as much as her English book. If Cindy carries all ofher books at once, what will be the total weight of the books she is carrying?"
        },
        {
            "bounding_box": [
                {
                    "x": 599,
                    "y": 627
                },
                {
                    "x": 698,
                    "y": 627
                },
                {
                    "x": 698,
                    "y": 645
                },
                {
                    "x": 599,
                    "y": 645
                }
            ],
            "category": "paragraph",
            "html": "<p id='201' style='font-size:16px'>Ground Truth:</p>",
            "id": 201,
            "page": 19,
            "text": "Ground Truth:"
        },
        {
            "bounding_box": [
                {
                    "x": 601,
                    "y": 640
                },
                {
                    "x": 1186,
                    "y": 640
                },
                {
                    "x": 1186,
                    "y": 758
                },
                {
                    "x": 601,
                    "y": 758
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='202' style='font-size:16px'>The math and science book weigh 2 pounds each so they weigh 2*2 = <<2*2=4>>4 pounds<br>Her history books weighs twice the amount of her 3 pound English book so it weighs 2*3 =<br><<2*3=6>>6 pounds<br>When you add the weight of all of her textbooks together, they weight 4 +4+3+6 =<br><<4+4+3+6=17>>17 pounds<br>A: 17</p>",
            "id": 202,
            "page": 19,
            "text": "The math and science book weigh 2 pounds each so they weigh 2*2 = <<2*2=4>>4 pounds Her history books weighs twice the amount of her 3 pound English book so it weighs 2*3 = <<2*3=6>>6 pounds When you add the weight of all of her textbooks together, they weight 4 +4+3+6 = <<4+4+3+6=17>>17 pounds A: 17"
        },
        {
            "bounding_box": [
                {
                    "x": 601,
                    "y": 790
                },
                {
                    "x": 770,
                    "y": 790
                },
                {
                    "x": 770,
                    "y": 809
                },
                {
                    "x": 601,
                    "y": 809
                }
            ],
            "category": "paragraph",
            "html": "<p id='203' style='font-size:20px'>6B Finetuning: [correct]</p>",
            "id": 203,
            "page": 19,
            "text": "6B Finetuning: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 799
                },
                {
                    "x": 1234,
                    "y": 799
                },
                {
                    "x": 1234,
                    "y": 947
                },
                {
                    "x": 603,
                    "y": 947
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='204' style='font-size:16px'>Cindy's math and science books weigh 2 pounds each for a total of 2*2 = <<2*2=4>>4 pounds<br>Her French book weighs 4 pounds and her English book weighs 3 pounds for a total of 4+3 =<br><<4+3=7>>7 pounds<br>Her history book weighs twice as much as her English book which weighs 3 pounds so it weighs 2*3<br>= <<2*3=6>>6 pounds<br>If you add up all of the books weights, the total weight is 4+7+6 = <<4+7+6=17>>17 pounds<br>A: 17</p>",
            "id": 204,
            "page": 19,
            "text": "Cindy's math and science books weigh 2 pounds each for a total of 2*2 = <<2*2=4>>4 pounds Her French book weighs 4 pounds and her English book weighs 3 pounds for a total of 4+3 = <<4+3=7>>7 pounds Her history book weighs twice as much as her English book which weighs 3 pounds so it weighs 2*3 = <<2*3=6>>6 pounds If you add up all of the books weights, the total weight is 4+7+6 = <<4+7+6=17>>17 pounds A: 17"
        },
        {
            "bounding_box": [
                {
                    "x": 601,
                    "y": 980
                },
                {
                    "x": 1209,
                    "y": 980
                },
                {
                    "x": 1209,
                    "y": 1111
                },
                {
                    "x": 601,
                    "y": 1111
                }
            ],
            "category": "paragraph",
            "html": "<p id='205' style='font-size:16px'>6B Verification: [incorrect]<br>The French book weighs 4 pounds and the English book weighs 3 pounds, for a total of 4 + 3 =<br><<4+3=7>>7 pounds.<br>Her history book weighs twice the weight of her English book, for a total of 2 x 3 = <<2*3=6>>6<br>pounds.<br>The total weight of her books is 7 + 6= <<7+6=13>>13 pounds.<br>A: 13</p>",
            "id": 205,
            "page": 19,
            "text": "6B Verification: [incorrect] The French book weighs 4 pounds and the English book weighs 3 pounds, for a total of 4 + 3 = <<4+3=7>>7 pounds. Her history book weighs twice the weight of her English book, for a total of 2 x 3 = <<2*3=6>>6 pounds. The total weight of her books is 7 + 6= <<7+6=13>>13 pounds. A: 13"
        },
        {
            "bounding_box": [
                {
                    "x": 602,
                    "y": 1140
                },
                {
                    "x": 798,
                    "y": 1140
                },
                {
                    "x": 798,
                    "y": 1159
                },
                {
                    "x": 602,
                    "y": 1159
                }
            ],
            "category": "paragraph",
            "html": "<p id='206' style='font-size:20px'>175B Finetuning: [incorrect]</p>",
            "id": 206,
            "page": 19,
            "text": "175B Finetuning: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 604,
                    "y": 1151
                },
                {
                    "x": 1109,
                    "y": 1151
                },
                {
                    "x": 1109,
                    "y": 1254
                },
                {
                    "x": 604,
                    "y": 1254
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='207' style='font-size:16px'>The total weight of Cindy's math and science books is 2*2=<<2*2=4>>4 pounds.<br>The total weight of her French and English books is 4+3=<<4+3=7>>7 pounds.<br>The weight of her history book is 7*2=<<7*2=14>>14 pounds.<br>The total weight of all of her books is 4+7+14=<<4+7+14=25>>25 pounds.<br>A: 25</p>",
            "id": 207,
            "page": 19,
            "text": "The total weight of Cindy's math and science books is 2*2=<<2*2=4>>4 pounds. The total weight of her French and English books is 4+3=<<4+3=7>>7 pounds. The weight of her history book is 7*2=<<7*2=14>>14 pounds. The total weight of all of her books is 4+7+14=<<4+7+14=25>>25 pounds. A: 25"
        },
        {
            "bounding_box": [
                {
                    "x": 605,
                    "y": 1286
                },
                {
                    "x": 801,
                    "y": 1286
                },
                {
                    "x": 801,
                    "y": 1304
                },
                {
                    "x": 605,
                    "y": 1304
                }
            ],
            "category": "paragraph",
            "html": "<p id='208' style='font-size:18px'>175B Verification: [incorrect]</p>",
            "id": 208,
            "page": 19,
            "text": "175B Verification: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 604,
                    "y": 1313
                },
                {
                    "x": 1050,
                    "y": 1313
                },
                {
                    "x": 1050,
                    "y": 1381
                },
                {
                    "x": 604,
                    "y": 1381
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='209' style='font-size:14px'>Her English book weighs 3 pounds.<br>Her history book weighs 3 x 2 = <<3*2=6>>6 pounds.<br>So all of her books weigh 2 + 4 + 3 + 6 = <<2+4+3+6=15>>15 pounds.<br>A: 15</p>",
            "id": 209,
            "page": 19,
            "text": "Her English book weighs 3 pounds. Her history book weighs 3 x 2 = <<3*2=6>>6 pounds. So all of her books weigh 2 + 4 + 3 + 6 = <<2+4+3+6=15>>15 pounds. A: 15"
        },
        {
            "bounding_box": [
                {
                    "x": 602,
                    "y": 1423
                },
                {
                    "x": 1246,
                    "y": 1423
                },
                {
                    "x": 1246,
                    "y": 1483
                },
                {
                    "x": 602,
                    "y": 1483
                }
            ],
            "category": "paragraph",
            "html": "<p id='210' style='font-size:16px'>The Kennel house keeps 3 German Shepherds and 2 Bulldogs. Ifa German Shepherd consumes 5<br>kilograms of dog food and a bulldog consumes 3 kilograms of dog food per day. How many kilograms<br>of dog food will they need in a week?</p>",
            "id": 210,
            "page": 19,
            "text": "The Kennel house keeps 3 German Shepherds and 2 Bulldogs. Ifa German Shepherd consumes 5 kilograms of dog food and a bulldog consumes 3 kilograms of dog food per day. How many kilograms of dog food will they need in a week?"
        },
        {
            "bounding_box": [
                {
                    "x": 598,
                    "y": 1510
                },
                {
                    "x": 702,
                    "y": 1510
                },
                {
                    "x": 702,
                    "y": 1530
                },
                {
                    "x": 598,
                    "y": 1530
                }
            ],
            "category": "paragraph",
            "html": "<p id='211' style='font-size:18px'>Ground Truth:</p>",
            "id": 211,
            "page": 19,
            "text": "Ground Truth:"
        },
        {
            "bounding_box": [
                {
                    "x": 601,
                    "y": 1519
                },
                {
                    "x": 1172,
                    "y": 1519
                },
                {
                    "x": 1172,
                    "y": 1629
                },
                {
                    "x": 601,
                    "y": 1629
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='212' style='font-size:16px'>The German Shepherds consume 3 x 5= <<3*5=15>>15 kilograms of dog food per day.<br>The Bulldogs consume 2 x 3 = <<2*3=6>>6 kilograms of dog food per day.<br>The dogs can consume a total of 15 + 6 = <<15+6=21>>21 kilograms of dog food per day.<br>Therefore, they need 21 x 7 = <<21*7=147>>147 kilograms of dog food in a week.<br>A: 147</p>",
            "id": 212,
            "page": 19,
            "text": "The German Shepherds consume 3 x 5= <<3*5=15>>15 kilograms of dog food per day. The Bulldogs consume 2 x 3 = <<2*3=6>>6 kilograms of dog food per day. The dogs can consume a total of 15 + 6 = <<15+6=21>>21 kilograms of dog food per day. Therefore, they need 21 x 7 = <<21*7=147>>147 kilograms of dog food in a week. A: 147"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 1657
                },
                {
                    "x": 785,
                    "y": 1657
                },
                {
                    "x": 785,
                    "y": 1678
                },
                {
                    "x": 603,
                    "y": 1678
                }
            ],
            "category": "paragraph",
            "html": "<p id='213' style='font-size:18px'>6B Finetuning: [incorrect]</p>",
            "id": 213,
            "page": 19,
            "text": "6B Finetuning: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 1676
                },
                {
                    "x": 1183,
                    "y": 1676
                },
                {
                    "x": 1183,
                    "y": 1756
                },
                {
                    "x": 603,
                    "y": 1756
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='214' style='font-size:16px'>The German Shepherd needs 5x7=<<5*7=35>>35 kilograms of dog food per week.<br>The Bulldogs need 2x 7 = <<2*7=14>>14 kilograms of dog food per week.<br>Therefore, they need a total of35 + 14 = <<35+14=49>>49 kilograms of dog food per week.<br>A: 49</p>",
            "id": 214,
            "page": 19,
            "text": "The German Shepherd needs 5x7=<<5*7=35>>35 kilograms of dog food per week. The Bulldogs need 2x 7 = <<2*7=14>>14 kilograms of dog food per week. Therefore, they need a total of35 + 14 = <<35+14=49>>49 kilograms of dog food per week. A: 49"
        },
        {
            "bounding_box": [
                {
                    "x": 605,
                    "y": 1785
                },
                {
                    "x": 1234,
                    "y": 1785
                },
                {
                    "x": 1234,
                    "y": 1901
                },
                {
                    "x": 605,
                    "y": 1901
                }
            ],
            "category": "paragraph",
            "html": "<p id='215' style='font-size:16px'>6B Verification: [correct]<br>3 German Shepherds will consume a total of 5 x3= <<3*5=15>>15 kilograms of dog food per day.<br>2 Bulldogs will consume a total of 3 x 2 = <<3*2=6>>6 kilograms of dog food per day.<br>So, they will consume a total of 15 + 6 = <<15+6=21>>21 kilograms of dog food per day.<br>Therefore, they will require 21 x 7 = <<21*7=147>>147 kilograms of dog food in a week.<br>A: 147</p>",
            "id": 215,
            "page": 19,
            "text": "6B Verification: [correct] 3 German Shepherds will consume a total of 5 x3= <<3*5=15>>15 kilograms of dog food per day. 2 Bulldogs will consume a total of 3 x 2 = <<3*2=6>>6 kilograms of dog food per day. So, they will consume a total of 15 + 6 = <<15+6=21>>21 kilograms of dog food per day. Therefore, they will require 21 x 7 = <<21*7=147>>147 kilograms of dog food in a week. A: 147"
        },
        {
            "bounding_box": [
                {
                    "x": 604,
                    "y": 1930
                },
                {
                    "x": 798,
                    "y": 1930
                },
                {
                    "x": 798,
                    "y": 1949
                },
                {
                    "x": 604,
                    "y": 1949
                }
            ],
            "category": "paragraph",
            "html": "<p id='216' style='font-size:20px'>175B Finetuning: [incorrect]</p>",
            "id": 216,
            "page": 19,
            "text": "175B Finetuning: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 604,
                    "y": 1943
                },
                {
                    "x": 1108,
                    "y": 1943
                },
                {
                    "x": 1108,
                    "y": 2029
                },
                {
                    "x": 604,
                    "y": 2029
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='217' style='font-size:16px'>The German Shepherd's total consumption is 5 x 7= <<5*7=35>>35 kilograms.<br>The bulldog's total consumption is 3 x 7= <<3*7=21>>21 kilograms.<br>So, the total consumption of the dogs is 35 + 21 = <<35+21=56>>56 kilograms.<br>A: 56</p>",
            "id": 217,
            "page": 19,
            "text": "The German Shepherd's total consumption is 5 x 7= <<5*7=35>>35 kilograms. The bulldog's total consumption is 3 x 7= <<3*7=21>>21 kilograms. So, the total consumption of the dogs is 35 + 21 = <<35+21=56>>56 kilograms. A: 56"
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 2056
                },
                {
                    "x": 787,
                    "y": 2056
                },
                {
                    "x": 787,
                    "y": 2075
                },
                {
                    "x": 603,
                    "y": 2075
                }
            ],
            "category": "paragraph",
            "html": "<p id='218' style='font-size:18px'>175B Verification: [correct]</p>",
            "id": 218,
            "page": 19,
            "text": "175B Verification: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 605,
                    "y": 2071
                },
                {
                    "x": 1173,
                    "y": 2071
                },
                {
                    "x": 1173,
                    "y": 2164
                },
                {
                    "x": 605,
                    "y": 2164
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='219' style='font-size:16px'>The 3 German Shepherd dogs consume 3 x 5 = <<3*5=15>>15 kilograms of food per day.<br>The 2 bulldogs consume 2 x 3 = <<2*3=6>>6 kilograms of food per day.<br>The two breeds of dogs consume 15 + 6= <<15+6=21>>21 kilograms of food per day.<br>During a week, they will need 21 x 7 = <<21*7=147>>147 kilograms of food.<br>A: 147</p>",
            "id": 219,
            "page": 19,
            "text": "The 3 German Shepherd dogs consume 3 x 5 = <<3*5=15>>15 kilograms of food per day. The 2 bulldogs consume 2 x 3 = <<2*3=6>>6 kilograms of food per day. The two breeds of dogs consume 15 + 6= <<15+6=21>>21 kilograms of food per day. During a week, they will need 21 x 7 = <<21*7=147>>147 kilograms of food. A: 147"
        },
        {
            "bounding_box": [
                {
                    "x": 1296,
                    "y": 536
                },
                {
                    "x": 1931,
                    "y": 536
                },
                {
                    "x": 1931,
                    "y": 578
                },
                {
                    "x": 1296,
                    "y": 578
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='220' style='font-size:16px'>Jeff and Brad are trying to divide 100 dollars between them. Jeff gets 4 times as much as Brad. How<br>much does Jeff get in dollars?</p>",
            "id": 220,
            "page": 19,
            "text": "Jeff and Brad are trying to divide 100 dollars between them. Jeff gets 4 times as much as Brad. How much does Jeff get in dollars?"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 609
                },
                {
                    "x": 1397,
                    "y": 609
                },
                {
                    "x": 1397,
                    "y": 628
                },
                {
                    "x": 1294,
                    "y": 628
                }
            ],
            "category": "paragraph",
            "html": "<p id='221' style='font-size:16px'>Ground Truth:</p>",
            "id": 221,
            "page": 19,
            "text": "Ground Truth:"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 621
                },
                {
                    "x": 1563,
                    "y": 621
                },
                {
                    "x": 1563,
                    "y": 680
                },
                {
                    "x": 1294,
                    "y": 680
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='222' style='font-size:16px'>Brad gets 100/5=<<100/5=20>>20 dollars.<br>Jeff gets 20*4=<<20*4=80>>80 dollars.<br>A: 80</p>",
            "id": 222,
            "page": 19,
            "text": "Brad gets 100/5=<<100/5=20>>20 dollars. Jeff gets 20*4=<<20*4=80>>80 dollars. A: 80"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 720
                },
                {
                    "x": 1493,
                    "y": 720
                },
                {
                    "x": 1493,
                    "y": 896
                },
                {
                    "x": 1294,
                    "y": 896
                }
            ],
            "category": "paragraph",
            "html": "<p id='223' style='font-size:16px'>6B Finetuning: [incorrect]<br>Let x be the amount Brad gets.<br>Jeff gets 4*x dollars.<br>100=x+4*x<br>100=5*x<br>100=5*x+20*x<br>100=20*x<br>100=100<br>x=<<25=25>>25 dollars<br>A: 25</p>",
            "id": 223,
            "page": 19,
            "text": "6B Finetuning: [incorrect] Let x be the amount Brad gets. Jeff gets 4*x dollars. 100=x+4*x 100=5*x 100=5*x+20*x 100=20*x 100=100 x=<<25=25>>25 dollars A: 25"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 936
                },
                {
                    "x": 1405,
                    "y": 936
                },
                {
                    "x": 1405,
                    "y": 955
                },
                {
                    "x": 1293,
                    "y": 955
                }
            ],
            "category": "paragraph",
            "html": "<p id='224' style='font-size:18px'>6B Verification:</p>",
            "id": 224,
            "page": 19,
            "text": "6B Verification:"
        },
        {
            "bounding_box": [
                {
                    "x": 1294,
                    "y": 946
                },
                {
                    "x": 1911,
                    "y": 946
                },
                {
                    "x": 1911,
                    "y": 1012
                },
                {
                    "x": 1294,
                    "y": 1012
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='225' style='font-size:14px'>[incorrect]<br>Since Brad gets 100 dollars, then 4 times as much Jeff gets 4*100 = <<4*100=400>>400 dollars.<br>Therefore, Jeff gets 400 dollars.<br>A: 400</p>",
            "id": 225,
            "page": 19,
            "text": "[incorrect] Since Brad gets 100 dollars, then 4 times as much Jeff gets 4*100 = <<4*100=400>>400 dollars. Therefore, Jeff gets 400 dollars. A: 400"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1049
                },
                {
                    "x": 1559,
                    "y": 1049
                },
                {
                    "x": 1559,
                    "y": 1193
                },
                {
                    "x": 1293,
                    "y": 1193
                }
            ],
            "category": "paragraph",
            "html": "<p id='226' style='font-size:16px'>175B Finetuning: [incorrect]<br>Let x be the amount of money Brad gets.<br>Jeff gets 4*x dollars.<br>4*x+x=100<br>5*x=100<br>x=<<25=25>>25<br>Jeff gets 25*4=<<25*4=100>>100 dollars.<br>A: 100</p>",
            "id": 226,
            "page": 19,
            "text": "175B Finetuning: [incorrect] Let x be the amount of money Brad gets. Jeff gets 4*x dollars. 4*x+x=100 5*x=100 x=<<25=25>>25 Jeff gets 25*4=<<25*4=100>>100 dollars. A: 100"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1229
                },
                {
                    "x": 1482,
                    "y": 1229
                },
                {
                    "x": 1482,
                    "y": 1249
                },
                {
                    "x": 1293,
                    "y": 1249
                }
            ],
            "category": "paragraph",
            "html": "<p id='227' style='font-size:18px'>175B Verification: [correct]</p>",
            "id": 227,
            "page": 19,
            "text": "175B Verification: [correct]"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1248
                },
                {
                    "x": 1587,
                    "y": 1248
                },
                {
                    "x": 1587,
                    "y": 1268
                },
                {
                    "x": 1293,
                    "y": 1268
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='228' style='font-size:16px'>Letx be the amount of money that Brad gets.</p>",
            "id": 228,
            "page": 19,
            "text": "Letx be the amount of money that Brad gets."
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 1271
                },
                {
                    "x": 1647,
                    "y": 1271
                },
                {
                    "x": 1647,
                    "y": 1369
                },
                {
                    "x": 1295,
                    "y": 1369
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='229' style='font-size:16px'>Jeff gets 4*x.<br>The total is x+4*x = 100 dollars.<br>This simplifies to 5*x = 100.<br>So the value of xis 100/5 = <<100/5=20.0>>20 dollars.<br>Then Jeff gets 4*x = 4*20 = <<4*20=80>>80 dollars.</p>",
            "id": 229,
            "page": 19,
            "text": "Jeff gets 4*x. The total is x+4*x = 100 dollars. This simplifies to 5*x = 100. So the value of xis 100/5 = <<100/5=20.0>>20 dollars. Then Jeff gets 4*x = 4*20 = <<4*20=80>>80 dollars."
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1362
                },
                {
                    "x": 1334,
                    "y": 1362
                },
                {
                    "x": 1334,
                    "y": 1380
                },
                {
                    "x": 1293,
                    "y": 1380
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='230' style='font-size:18px'>A: 80</p>",
            "id": 230,
            "page": 19,
            "text": "A: 80"
        },
        {
            "bounding_box": [
                {
                    "x": 1292,
                    "y": 1494
                },
                {
                    "x": 1395,
                    "y": 1494
                },
                {
                    "x": 1395,
                    "y": 1512
                },
                {
                    "x": 1292,
                    "y": 1512
                }
            ],
            "category": "paragraph",
            "html": "<p id='231' style='font-size:16px'>Ground Truth:</p>",
            "id": 231,
            "page": 19,
            "text": "Ground Truth:"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1422
                },
                {
                    "x": 1918,
                    "y": 1422
                },
                {
                    "x": 1918,
                    "y": 1463
                },
                {
                    "x": 1293,
                    "y": 1463
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='232' style='font-size:16px'>Bob spends $27000 distributed between 3 schools to buy books. He can buy 100 books for $500.<br>How many books can he buy per school?</p>",
            "id": 232,
            "page": 19,
            "text": "Bob spends $27000 distributed between 3 schools to buy books. He can buy 100 books for $500. How many books can he buy per school?"
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 1516
                },
                {
                    "x": 1710,
                    "y": 1516
                },
                {
                    "x": 1710,
                    "y": 1592
                },
                {
                    "x": 1295,
                    "y": 1592
                }
            ],
            "category": "paragraph",
            "html": "<p id='233' style='font-size:16px'>He spends 27000/3=$<<27000/3=9000>>9000<br>Each book cost 500/100=$<<500/100=5>>5<br>So he can buy 9000/5=<<9000/5=1800>>1800 books per school<br>A: 1800</p>",
            "id": 233,
            "page": 19,
            "text": "He spends 27000/3=$<<27000/3=9000>>9000 Each book cost 500/100=$<<500/100=5>>5 So he can buy 9000/5=<<9000/5=1800>>1800 books per school A: 1800"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1623
                },
                {
                    "x": 1658,
                    "y": 1623
                },
                {
                    "x": 1658,
                    "y": 1698
                },
                {
                    "x": 1293,
                    "y": 1698
                }
            ],
            "category": "paragraph",
            "html": "<p id='234' style='font-size:16px'>6B Finetuning: [incorrect]<br>He buys 27000/500=<<27000/500=54.0>>54 books<br>So he can buy 54/3=<<54/3=18.0>>18 books per school<br>A: 18</p>",
            "id": 234,
            "page": 19,
            "text": "6B Finetuning: [incorrect] He buys 27000/500=<<27000/500=54.0>>54 books So he can buy 54/3=<<54/3=18.0>>18 books per school A: 18"
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 1728
                },
                {
                    "x": 1481,
                    "y": 1728
                },
                {
                    "x": 1481,
                    "y": 1745
                },
                {
                    "x": 1295,
                    "y": 1745
                }
            ],
            "category": "paragraph",
            "html": "<p id='235' style='font-size:18px'>6B Verification: [incorrect]</p>",
            "id": 235,
            "page": 19,
            "text": "6B Verification: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 1296,
                    "y": 1745
                },
                {
                    "x": 1767,
                    "y": 1745
                },
                {
                    "x": 1767,
                    "y": 1804
                },
                {
                    "x": 1296,
                    "y": 1804
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='236' style='font-size:14px'>He has $27000 / $500 = <<27000/500=54.0>>54 books<br>So he can buy 54 books / 3 schools = <<54/3=18.0>>18 books per school<br>A: 18</p>",
            "id": 236,
            "page": 19,
            "text": "He has $27000 / $500 = <<27000/500=54.0>>54 books So he can buy 54 books / 3 schools = <<54/3=18.0>>18 books per school A: 18"
        },
        {
            "bounding_box": [
                {
                    "x": 1298,
                    "y": 1835
                },
                {
                    "x": 1493,
                    "y": 1835
                },
                {
                    "x": 1493,
                    "y": 1854
                },
                {
                    "x": 1298,
                    "y": 1854
                }
            ],
            "category": "paragraph",
            "html": "<p id='237' style='font-size:20px'>175B Finetuning: [incorrect]</p>",
            "id": 237,
            "page": 19,
            "text": "175B Finetuning: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 1297,
                    "y": 1894
                },
                {
                    "x": 1343,
                    "y": 1894
                },
                {
                    "x": 1343,
                    "y": 1915
                },
                {
                    "x": 1297,
                    "y": 1915
                }
            ],
            "category": "paragraph",
            "html": "<p id='238' style='font-size:18px'>A: 500</p>",
            "id": 238,
            "page": 19,
            "text": "A: 500"
        },
        {
            "bounding_box": [
                {
                    "x": 1295,
                    "y": 1856
                },
                {
                    "x": 1681,
                    "y": 1856
                },
                {
                    "x": 1681,
                    "y": 1900
                },
                {
                    "x": 1295,
                    "y": 1900
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='239' style='font-size:16px'>He spends 27000/500=<<27000/500=54.0>>5400$ per book<br>So he can buy 27000/54=<<27000/54=500.0>>500 books</p>",
            "id": 239,
            "page": 19,
            "text": "He spends 27000/500=<<27000/500=54.0>>5400$ per book So he can buy 27000/54=<<27000/54=500.0>>500 books"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1942
                },
                {
                    "x": 1499,
                    "y": 1942
                },
                {
                    "x": 1499,
                    "y": 1960
                },
                {
                    "x": 1293,
                    "y": 1960
                }
            ],
            "category": "paragraph",
            "html": "<p id='240' style='font-size:20px'>175B Verification: [incorrect]</p>",
            "id": 240,
            "page": 19,
            "text": "175B Verification: [incorrect]"
        },
        {
            "bounding_box": [
                {
                    "x": 1296,
                    "y": 2000
                },
                {
                    "x": 1343,
                    "y": 2000
                },
                {
                    "x": 1343,
                    "y": 2022
                },
                {
                    "x": 1296,
                    "y": 2022
                }
            ],
            "category": "paragraph",
            "html": "<p id='241' style='font-size:16px'>A: 162</p>",
            "id": 241,
            "page": 19,
            "text": "A: 162"
        },
        {
            "bounding_box": [
                {
                    "x": 1293,
                    "y": 1963
                },
                {
                    "x": 1748,
                    "y": 1963
                },
                {
                    "x": 1748,
                    "y": 2002
                },
                {
                    "x": 1293,
                    "y": 2002
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='242' style='font-size:16px'>He spent $27000 / $500 = <<27000/500=54. 0>>54 books per school<br>So he can buy 54 books/school x 3 schools = <<54*3=162>>162 books</p>",
            "id": 242,
            "page": 19,
            "text": "He spent $27000 / $500 = <<27000/500=54. 0>>54 books per school So he can buy 54 books/school x 3 schools = <<54*3=162>>162 books"
        },
        {
            "bounding_box": [
                {
                    "x": 1253,
                    "y": 2898
                },
                {
                    "x": 1295,
                    "y": 2898
                },
                {
                    "x": 1295,
                    "y": 2930
                },
                {
                    "x": 1253,
                    "y": 2930
                }
            ],
            "category": "footer",
            "html": "<footer id='243' style='font-size:22px'>19</footer>",
            "id": 243,
            "page": 19,
            "text": "19"
        },
        {
            "bounding_box": [
                {
                    "x": 552,
                    "y": 512
                },
                {
                    "x": 1117,
                    "y": 512
                },
                {
                    "x": 1117,
                    "y": 573
                },
                {
                    "x": 552,
                    "y": 573
                }
            ],
            "category": "paragraph",
            "html": "<p id='244' style='font-size:22px'>E Verifier Details</p>",
            "id": 244,
            "page": 20,
            "text": "E Verifier Details"
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 615
                },
                {
                    "x": 1998,
                    "y": 615
                },
                {
                    "x": 1998,
                    "y": 862
                },
                {
                    "x": 549,
                    "y": 862
                }
            ],
            "category": "paragraph",
            "html": "<p id='245' style='font-size:16px'>As noted in section 4.2, we train verifiers with a joint objective where the model<br>learns to label a model completion as correct or incorrect, in addition to the<br>original language modeling objective. Architecturally, this means our verifiers<br>are language models, with a small scalar head that outputs predictions on a<br>per-token basis.</p>",
            "id": 245,
            "page": 20,
            "text": "As noted in section 4.2, we train verifiers with a joint objective where the model learns to label a model completion as correct or incorrect, in addition to the original language modeling objective. Architecturally, this means our verifiers are language models, with a small scalar head that outputs predictions on a per-token basis."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 867
                },
                {
                    "x": 1999,
                    "y": 867
                },
                {
                    "x": 1999,
                    "y": 1163
                },
                {
                    "x": 549,
                    "y": 1163
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='246' style='font-size:20px'>We implement this scalar head as a single bias parameter and single gain<br>parameter that operate on the logits outputted by the language model's final<br>unembedding layer. Specifically, the bias and gain shift and scale the logit<br>corresponding to a special token in the vocabulary. As such, the logits for other<br>tokens can continue to represent the language modeling objective, while this<br>special token is reserved for the verifier's predictions.</p>",
            "id": 246,
            "page": 20,
            "text": "We implement this scalar head as a single bias parameter and single gain parameter that operate on the logits outputted by the language model's final unembedding layer. Specifically, the bias and gain shift and scale the logit corresponding to a special token in the vocabulary. As such, the logits for other tokens can continue to represent the language modeling objective, while this special token is reserved for the verifier's predictions."
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 1165
                },
                {
                    "x": 1997,
                    "y": 1165
                },
                {
                    "x": 1997,
                    "y": 1510
                },
                {
                    "x": 548,
                    "y": 1510
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='247' style='font-size:18px'>We can choose to initialize the verifier from the same pretrained language<br>model the generator was finetuned from, or from the generator itself. In our<br>ablations the latter performed slightly better; we suspect this is because better<br>understanding the language distribution that the generator learned should only<br>aid the verifier in scoring samples from that distribution. Unless otherwise<br>explicitly stated, we initialize our verifiers from their corresponding generators<br>in all experiments.</p>",
            "id": 247,
            "page": 20,
            "text": "We can choose to initialize the verifier from the same pretrained language model the generator was finetuned from, or from the generator itself. In our ablations the latter performed slightly better; we suspect this is because better understanding the language distribution that the generator learned should only aid the verifier in scoring samples from that distribution. Unless otherwise explicitly stated, we initialize our verifiers from their corresponding generators in all experiments."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 1513
                },
                {
                    "x": 1996,
                    "y": 1513
                },
                {
                    "x": 1996,
                    "y": 1913
                },
                {
                    "x": 549,
                    "y": 1913
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='248' style='font-size:18px'>When training verifiers with the joint objective, we use an equal mix of<br>language data and verifier data. Because we sample 100 completions for each<br>original training example to generate the verifier data, using an equal mix means<br>we effectively upsample the original language data by a factor of 100. To form<br>the joint objective, we simply add the verifier loss and language modeling loss<br>unweighted, and define an epoch of this joint objective as having seen each<br>verifier example once. With both objectives, we mask out tokens in the question<br>and only train on tokens in the solutions, as visualized in Figure 12.</p>",
            "id": 248,
            "page": 20,
            "text": "When training verifiers with the joint objective, we use an equal mix of language data and verifier data. Because we sample 100 completions for each original training example to generate the verifier data, using an equal mix means we effectively upsample the original language data by a factor of 100. To form the joint objective, we simply add the verifier loss and language modeling loss unweighted, and define an epoch of this joint objective as having seen each verifier example once. With both objectives, we mask out tokens in the question and only train on tokens in the solutions, as visualized in Figure 12."
        },
        {
            "bounding_box": [
                {
                    "x": 679,
                    "y": 1959
                },
                {
                    "x": 1885,
                    "y": 1959
                },
                {
                    "x": 1885,
                    "y": 2485
                },
                {
                    "x": 679,
                    "y": 2485
                }
            ],
            "category": "figure",
            "html": "<figure><img id='249' style='font-size:14px' alt=\"Language Modeling Objective Verifier Objective\nQ, Q2 Q. S, S2 S Q. Q。 S. S2 Sm\n7-1\nGenerator Verifier\nQ, Q. S2\nS Y, +2\nQ the i-th question token the k-th value prediction\nS the j-th solution token masked out (does not\ncontribute to loss)\" data-coord=\"top-left:(679,1959); bottom-right:(1885,2485)\" /></figure>",
            "id": 249,
            "page": 20,
            "text": "Language Modeling Objective Verifier Objective Q, Q2 Q. S, S2 S Q. Q。 S. S2 Sm 7-1 Generator Verifier Q, Q. S2 S Y, +2 Q the i-th question token the k-th value prediction S the j-th solution token masked out (does not contribute to loss)"
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 2522
                },
                {
                    "x": 1994,
                    "y": 2522
                },
                {
                    "x": 1994,
                    "y": 2623
                },
                {
                    "x": 550,
                    "y": 2623
                }
            ],
            "category": "caption",
            "html": "<caption id='250' style='font-size:18px'>Figure 12: Visualization of the joint training objective. We mask out tokens in<br>the question and only consider the loss corresponding to tokens in the solution.</caption>",
            "id": 250,
            "page": 20,
            "text": "Figure 12: Visualization of the joint training objective. We mask out tokens in the question and only consider the loss corresponding to tokens in the solution."
        },
        {
            "bounding_box": [
                {
                    "x": 1247,
                    "y": 2894
                },
                {
                    "x": 1297,
                    "y": 2894
                },
                {
                    "x": 1297,
                    "y": 2935
                },
                {
                    "x": 1247,
                    "y": 2935
                }
            ],
            "category": "footer",
            "html": "<footer id='251' style='font-size:16px'>20</footer>",
            "id": 251,
            "page": 20,
            "text": "20"
        },
        {
            "bounding_box": [
                {
                    "x": 551,
                    "y": 512
                },
                {
                    "x": 1294,
                    "y": 512
                },
                {
                    "x": 1294,
                    "y": 573
                },
                {
                    "x": 551,
                    "y": 573
                }
            ],
            "category": "paragraph",
            "html": "<p id='252' style='font-size:20px'>F Verifier Visualization</p>",
            "id": 252,
            "page": 21,
            "text": "F Verifier Visualization"
        },
        {
            "bounding_box": [
                {
                    "x": 769,
                    "y": 689
                },
                {
                    "x": 1793,
                    "y": 689
                },
                {
                    "x": 1793,
                    "y": 2111
                },
                {
                    "x": 769,
                    "y": 2111
                }
            ],
            "category": "figure",
            "html": "<figure><img id='253' style='font-size:14px' alt=\"Question & Model Generation Verifier Actual\nPred. Score\nClaire makes a 3 egg omelet every morning for breakfast. How many dozens\nof eggs will she eat in 4 weeks?\naire ma kes 3 omelets every morning, SO she eats 3*7=<<3*7=21>>21\nomelets per week\nShe eats 21 omelets per week SO over 4 weeks she will eat\n4*21=<<21*4=84>>84 ome lets\nThere are 12 in 1 dozen SO she will eat 84 /12=<<84/12=7  0>>7 dozens of\neggs\n####\nSophia and Rose went together to the market to buy onions and potatoes. x V\nRose bought 4 times the number of onions and potatoes Sophia bought. If\nRose bought 12 onions and 4 potatoes, how many onions and potatoes in\ntotal did Sophia buy at the market?\nIf Rose bought 12 onions and 4 potatoes, she bought 12+4 = <<12+4=16>>16\noni ons and potatoes\nIf Rose bought 4 times the number of oni ons and potatoes that Sophia\nbought, Sophia bought 16/4 = <<16/4=4 .0>>4 onions and potatoes at the\nmarket\n#### 4\nTwo sisters, Elizabeth and Margareth, bought beads. Elizabeth bought 1 x\npack of red and 2 packs of clear beads, while Margareth bought 3 packs\nof blue and 4 packs of red beads . How many more beads do one sister have\nthan the other, if each pack of beads contains 20 pieces of beads?\nElizabeth bought 1 pack of red and 2 packs of clear, totaling 1+2\n<<1+2=3>>3 packs of beads.\nMargareth bought 3 packs of blue and 4 packs of red, totaling 3+4 =\n<<3+4=7>>7 packs of beads.\nSo, Elizabeth has 3-7 = <<3-7=-4>>-4 more packs of beads than Margareth\nAnd since each pack of beads contains 20 pi eces of beads, Elizabeth has\n20*4 = <<20*4=80>>80 more beads than Margareth\n#### 80\nHoward spends $8 dollars at the arcade on Monday. On Tuesday, he spends x\ntwice as much at the arcade as he did on Monday. On Wednesday, he spends\n4 times as much at the arcade as he spent on Tuesday. If he originally\nhad $100, how much money does he have left?\nHe spent $8 dollars on Monday and $8*2= $<<8*2=16>>16 dollars on\nTuesday.\nHe spent $16 dollars on Tuesday and $16*4= $<<16*4=64>>64 dollars on\nWednesday.\nHe has $100 dollars and spent $64 dol lars SO he has 100-64=\n<<100-64=36>>36 dollars left.\n#### 36\nIn a jewelers store, the price of a gold Jewell is 4/5 times as much as x\nthe price of a diamond Jewell. The cost of a silver Jewell is $400 less\nthan the price of gold. If a diamond Jewell is $2000, find the total\nprice for all three jewels.\nThe price of a gold Jewell is 4/5*$2000 = $<<4/5*2000=1600.0>>1600.\nThe cost of a silver Jewell is $2000-$400= $<<2000-400=1600>>1600.\nThe total price for all the jewels is $2000+$1 600+$1600 =\n$<<2000+1 600+1 600=5200>>5200\n#### 5200\" data-coord=\"top-left:(769,689); bottom-right:(1793,2111)\" /></figure>",
            "id": 253,
            "page": 21,
            "text": "Question & Model Generation Verifier Actual Pred. Score Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks? aire ma kes 3 omelets every morning, SO she eats 3*7=<<3*7=21>>21 omelets per week She eats 21 omelets per week SO over 4 weeks she will eat 4*21=<<21*4=84>>84 ome lets There are 12 in 1 dozen SO she will eat 84 /12=<<84/12=7  0>>7 dozens of eggs #### Sophia and Rose went together to the market to buy onions and potatoes. x V Rose bought 4 times the number of onions and potatoes Sophia bought. If Rose bought 12 onions and 4 potatoes, how many onions and potatoes in total did Sophia buy at the market? If Rose bought 12 onions and 4 potatoes, she bought 12+4 = <<12+4=16>>16 oni ons and potatoes If Rose bought 4 times the number of oni ons and potatoes that Sophia bought, Sophia bought 16/4 = <<16/4=4 .0>>4 onions and potatoes at the market #### 4 Two sisters, Elizabeth and Margareth, bought beads. Elizabeth bought 1 x pack of red and 2 packs of clear beads, while Margareth bought 3 packs of blue and 4 packs of red beads . How many more beads do one sister have than the other, if each pack of beads contains 20 pieces of beads? Elizabeth bought 1 pack of red and 2 packs of clear, totaling 1+2 <<1+2=3>>3 packs of beads. Margareth bought 3 packs of blue and 4 packs of red, totaling 3+4 = <<3+4=7>>7 packs of beads. So, Elizabeth has 3-7 = <<3-7=-4>>-4 more packs of beads than Margareth And since each pack of beads contains 20 pi eces of beads, Elizabeth has 20*4 = <<20*4=80>>80 more beads than Margareth #### 80 Howard spends $8 dollars at the arcade on Monday. On Tuesday, he spends x twice as much at the arcade as he did on Monday. On Wednesday, he spends 4 times as much at the arcade as he spent on Tuesday. If he originally had $100, how much money does he have left? He spent $8 dollars on Monday and $8*2= $<<8*2=16>>16 dollars on Tuesday. He spent $16 dollars on Tuesday and $16*4= $<<16*4=64>>64 dollars on Wednesday. He has $100 dollars and spent $64 dol lars SO he has 100-64= <<100-64=36>>36 dollars left. #### 36 In a jewelers store, the price of a gold Jewell is 4/5 times as much as x the price of a diamond Jewell. The cost of a silver Jewell is $400 less than the price of gold. If a diamond Jewell is $2000, find the total price for all three jewels. The price of a gold Jewell is 4/5*$2000 = $<<4/5*2000=1600.0>>1600. The cost of a silver Jewell is $2000-$400= $<<2000-400=1600>>1600. The total price for all the jewels is $2000+$1 600+$1600 = $<<2000+1 600+1 600=5200>>5200 #### 5200"
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 2209
                },
                {
                    "x": 1998,
                    "y": 2209
                },
                {
                    "x": 1998,
                    "y": 2361
                },
                {
                    "x": 548,
                    "y": 2361
                }
            ],
            "category": "caption",
            "html": "<caption id='254' style='font-size:18px'>Figure 13: Five cherry-picked samples generated by a 175B finetuned model<br>and scored by a 175B token-level verifier. A green background color indicates a<br>high verifier score, and a red background color indicates a low one.</caption>",
            "id": 254,
            "page": 21,
            "text": "Figure 13: Five cherry-picked samples generated by a 175B finetuned model and scored by a 175B token-level verifier. A green background color indicates a high verifier score, and a red background color indicates a low one."
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 2416
                },
                {
                    "x": 1998,
                    "y": 2416
                },
                {
                    "x": 1998,
                    "y": 2714
                },
                {
                    "x": 548,
                    "y": 2714
                }
            ],
            "category": "paragraph",
            "html": "<p id='255' style='font-size:18px'>One benefit of the token-level verifiers is that these models become imme-<br>diately interpretable: we can visualize the predicted value for each token and<br>better understand how the verifier makes decisions on judging samples. Above<br>we present a visualization of the predicted values for five different cherry-picked<br>questions and model completions, verified by a 175B token-level verifier that<br>was trained on the full training set.</p>",
            "id": 255,
            "page": 21,
            "text": "One benefit of the token-level verifiers is that these models become immediately interpretable: we can visualize the predicted value for each token and better understand how the verifier makes decisions on judging samples. Above we present a visualization of the predicted values for five different cherry-picked questions and model completions, verified by a 175B token-level verifier that was trained on the full training set."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 2717
                },
                {
                    "x": 1998,
                    "y": 2717
                },
                {
                    "x": 1998,
                    "y": 2817
                },
                {
                    "x": 549,
                    "y": 2817
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='256' style='font-size:18px'>In the visualization, the background color of the text corresponds to the ver-<br>ifier score for that token, where red is low value (predicted incorrect) and green</p>",
            "id": 256,
            "page": 21,
            "text": "In the visualization, the background color of the text corresponds to the verifier score for that token, where red is low value (predicted incorrect) and green"
        },
        {
            "bounding_box": [
                {
                    "x": 1247,
                    "y": 2894
                },
                {
                    "x": 1295,
                    "y": 2894
                },
                {
                    "x": 1295,
                    "y": 2934
                },
                {
                    "x": 1247,
                    "y": 2934
                }
            ],
            "category": "footer",
            "html": "<footer id='257' style='font-size:16px'>21</footer>",
            "id": 257,
            "page": 21,
            "text": "21"
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 524
                },
                {
                    "x": 1997,
                    "y": 524
                },
                {
                    "x": 1997,
                    "y": 723
                },
                {
                    "x": 550,
                    "y": 723
                }
            ],
            "category": "paragraph",
            "html": "<p id='258' style='font-size:18px'>is high value (predicted correct). The second column of the table summarizes<br>the verifier's prediction, and the third column indicates whether the generated<br>model completion was actually correct or incorrect. Any disagreement between<br>the second and third columns indicates that the verifier made an error.</p>",
            "id": 258,
            "page": 22,
            "text": "is high value (predicted correct). The second column of the table summarizes the verifier's prediction, and the third column indicates whether the generated model completion was actually correct or incorrect. Any disagreement between the second and third columns indicates that the verifier made an error."
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 726
                },
                {
                    "x": 1997,
                    "y": 726
                },
                {
                    "x": 1997,
                    "y": 971
                },
                {
                    "x": 550,
                    "y": 971
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='259' style='font-size:18px'>The first row includes a true positive example, where the verifier correctly<br>classifies the completion as correct. Note that the model is initially unsure about<br>whether the solution is correct and gradually gains certainty as the solution<br>progresses: this is likely a property of the verifier training procedure, where it<br>trains on a large fraction of incorrect model-generated samples.</p>",
            "id": 259,
            "page": 22,
            "text": "The first row includes a true positive example, where the verifier correctly classifies the completion as correct. Note that the model is initially unsure about whether the solution is correct and gradually gains certainty as the solution progresses: this is likely a property of the verifier training procedure, where it trains on a large fraction of incorrect model-generated samples."
        },
        {
            "bounding_box": [
                {
                    "x": 549,
                    "y": 976
                },
                {
                    "x": 1997,
                    "y": 976
                },
                {
                    "x": 1997,
                    "y": 1119
                },
                {
                    "x": 549,
                    "y": 1119
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='260' style='font-size:18px'>The second row contains a problem where the solution is correct, but the ver-<br>ifier has rated it as incorrect. This is potentially due to the ambiguity between<br>the \"4 times\" and the \"4 potatoes\" in the problem description.</p>",
            "id": 260,
            "page": 22,
            "text": "The second row contains a problem where the solution is correct, but the verifier has rated it as incorrect. This is potentially due to the ambiguity between the \"4 times\" and the \"4 potatoes\" in the problem description."
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 1126
                },
                {
                    "x": 1997,
                    "y": 1126
                },
                {
                    "x": 1997,
                    "y": 1368
                },
                {
                    "x": 550,
                    "y": 1368
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='261' style='font-size:20px'>The third row consists of another false negative example. However, unlike the<br>previous example, here the model completion contains some faulty reasoning.<br>As such, even though the final answer in the model completion was correct,<br>the natural language explanation was incorrect, and SO the verifier correctly<br>assigned a low score.</p>",
            "id": 261,
            "page": 22,
            "text": "The third row consists of another false negative example. However, unlike the previous example, here the model completion contains some faulty reasoning. As such, even though the final answer in the model completion was correct, the natural language explanation was incorrect, and SO the verifier correctly assigned a low score."
        },
        {
            "bounding_box": [
                {
                    "x": 548,
                    "y": 1373
                },
                {
                    "x": 1998,
                    "y": 1373
                },
                {
                    "x": 1998,
                    "y": 1619
                },
                {
                    "x": 548,
                    "y": 1619
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='262' style='font-size:16px'>In the fourth row we see the verifier score a model completion that starts out<br>correct, but where the verifier gradually becomes less confident in the solution<br>as the solution progresses. After the solution makes a clear mistake (saying that<br>$64 dollars were spent, instead of the 64 + 16 + 8 = $88), the verifier judges the<br>solution as incorrect with a high degree of confidence.</p>",
            "id": 262,
            "page": 22,
            "text": "In the fourth row we see the verifier score a model completion that starts out correct, but where the verifier gradually becomes less confident in the solution as the solution progresses. After the solution makes a clear mistake (saying that $64 dollars were spent, instead of the 64 + 16 + 8 = $88), the verifier judges the solution as incorrect with a high degree of confidence."
        },
        {
            "bounding_box": [
                {
                    "x": 550,
                    "y": 1623
                },
                {
                    "x": 1997,
                    "y": 1623
                },
                {
                    "x": 1997,
                    "y": 1820
                },
                {
                    "x": 550,
                    "y": 1820
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='263' style='font-size:18px'>The final row contains a false positive, where the model makes a mistake<br>on the second step, where it subtracts 400 from the price of a diamond jewel<br>instead of a gold one. Verifiers occasionally make mistakes with performing this<br>variable binding of quantities to their relationships.</p>",
            "id": 263,
            "page": 22,
            "text": "The final row contains a false positive, where the model makes a mistake on the second step, where it subtracts 400 from the price of a diamond jewel instead of a gold one. Verifiers occasionally make mistakes with performing this variable binding of quantities to their relationships."
        },
        {
            "bounding_box": [
                {
                    "x": 1247,
                    "y": 2894
                },
                {
                    "x": 1298,
                    "y": 2894
                },
                {
                    "x": 1298,
                    "y": 2934
                },
                {
                    "x": 1247,
                    "y": 2934
                }
            ],
            "category": "footer",
            "html": "<footer id='264' style='font-size:14px'>22</footer>",
            "id": 264,
            "page": 22,
            "text": "22"
        }
    ]
}