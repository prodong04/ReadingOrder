{
    "id": "32bd64c6-0f94-11ef-8828-426932df3dcf",
    "pdf_path": "/root/data/pdf/2211.10435v2.pdf",
    "elements": [
        {
            "bounding_box": [
                {
                    "x": 731,
                    "y": 367
                },
                {
                    "x": 1755,
                    "y": 367
                },
                {
                    "x": 1755,
                    "y": 441
                },
                {
                    "x": 731,
                    "y": 441
                }
            ],
            "category": "paragraph",
            "html": "<p id='0' style='font-size:22px'>PAL: Program-aided Language Models</p>",
            "id": 0,
            "page": 1,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 274,
                    "y": 585
                },
                {
                    "x": 2196,
                    "y": 585
                },
                {
                    "x": 2196,
                    "y": 689
                },
                {
                    "x": 274,
                    "y": 689
                }
            ],
            "category": "paragraph",
            "html": "<p id='1' style='font-size:14px'>* 1 Aman Madaan * 1 Shuyan Zhou * 1 Uri Alon 1 Pengfei Liu 12 Yiming Yang 1 Jamie Callan 1<br>Luyu Gao<br>Graham Neubig 1 2</p>",
            "id": 1,
            "page": 1,
            "text": "* 1 Aman Madaan * 1 Shuyan Zhou * 1 Uri Alon 1 Pengfei Liu 12 Yiming Yang 1 Jamie Callan 1 Luyu Gao Graham Neubig 1 2"
        },
        {
            "bounding_box": [
                {
                    "x": 384,
                    "y": 690
                },
                {
                    "x": 2107,
                    "y": 690
                },
                {
                    "x": 2107,
                    "y": 744
                },
                {
                    "x": 384,
                    "y": 744
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='2' style='font-size:14px'>{luyug, amadaan, shuyanzh, ualon, pliu3, yiming, call an, gneubig}@cs · cmu · edu</p>",
            "id": 2,
            "page": 1,
            "text": "{luyug, amadaan, shuyanzh, ualon, pliu3, yiming, call an, gneubig}@cs · cmu · edu"
        },
        {
            "bounding_box": [
                {
                    "x": 618,
                    "y": 835
                },
                {
                    "x": 817,
                    "y": 835
                },
                {
                    "x": 817,
                    "y": 890
                },
                {
                    "x": 618,
                    "y": 890
                }
            ],
            "category": "paragraph",
            "html": "<p id='3' style='font-size:20px'>Abstract</p>",
            "id": 3,
            "page": 1,
            "text": "Abstract"
        },
        {
            "bounding_box": [
                {
                    "x": 305,
                    "y": 955
                },
                {
                    "x": 1140,
                    "y": 955
                },
                {
                    "x": 1140,
                    "y": 2758
                },
                {
                    "x": 305,
                    "y": 2758
                }
            ],
            "category": "paragraph",
            "html": "<p id='4' style='font-size:16px'>Large language models (LLMs) have recently<br>demonstrated an impressive ability to perform<br>arithmetic and symbolic reasoning tasks, when<br>provided with a few examples at test time (\"few-<br>shot prompting\"). Much of this success can be<br>attributed to prompting methods such as \"chain-<br>of-thought\", which employ LLMs for both under-<br>standing the problem description by decomposing<br>it into steps, as well as solving each step of the<br>problem. While LLMs seem to be adept at this<br>sort of step-by-step decomposition, LLMs often<br>make logical and arithmetic mistakes in the solu-<br>tion part, even when the problem is decomposed<br>correctly. In this paper, we present Program-<br>Aided Language models (PAL): a novel approach<br>that uses the LLM to read natural language prob-<br>lems and generate programs as the intermediate<br>reasoning steps, but offloads the solution step to a<br>runtime such as a Python interpreter. With PAL,<br>decomposing the natural language problem into<br>runnable steps remains the only learning task for<br>the LLM, while solving is delegated to the inter-<br>preter. We demonstrate this synergy between a<br>neural LLM and a symbolic interpreter across 13<br>mathematical, symbolic, and algorithmic reason-<br>ing tasks from BIG-Bench Hard and other bench-<br>marks. In all these natural language reasoning<br>tasks, generating code using an LLM and rea-<br>soning using a Python interpreter leads to more<br>accurate results than much larger models. For ex-<br>ample, PAL using CODEX achieves state-of-the-<br>art few-shot accuracy on the GSM8K benchmark<br>of math word problems, surpassing PaLM-540B<br>which uses chain-of-thought by absolute 15% top-<br>1. Our code and data are publicly available at<br>http : / / reasonwithpal · com ·</p>",
            "id": 4,
            "page": 1,
            "text": "Large language models (LLMs) have recently demonstrated an impressive ability to perform arithmetic and symbolic reasoning tasks, when provided with a few examples at test time (\"fewshot prompting\"). Much of this success can be attributed to prompting methods such as \"chainof-thought\", which employ LLMs for both understanding the problem description by decomposing it into steps, as well as solving each step of the problem. While LLMs seem to be adept at this sort of step-by-step decomposition, LLMs often make logical and arithmetic mistakes in the solution part, even when the problem is decomposed correctly. In this paper, we present ProgramAided Language models (PAL): a novel approach that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps, but offloads the solution step to a runtime such as a Python interpreter. With PAL, decomposing the natural language problem into runnable steps remains the only learning task for the LLM, while solving is delegated to the interpreter. We demonstrate this synergy between a neural LLM and a symbolic interpreter across 13 mathematical, symbolic, and algorithmic reasoning tasks from BIG-Bench Hard and other benchmarks. In all these natural language reasoning tasks, generating code using an LLM and reasoning using a Python interpreter leads to more accurate results than much larger models. For example, PAL using CODEX achieves state-of-theart few-shot accuracy on the GSM8K benchmark of math word problems, surpassing PaLM-540B which uses chain-of-thought by absolute 15% top1. Our code and data are publicly available at http : / / reasonwithpal · com ·"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2862
                },
                {
                    "x": 1217,
                    "y": 2862
                },
                {
                    "x": 1217,
                    "y": 2992
                },
                {
                    "x": 223,
                    "y": 2992
                }
            ],
            "category": "paragraph",
            "html": "<p id='5' style='font-size:18px'>The first three authors contributed equally. 1Language Tech-<br>nologies Institute, Carnegie Mellon University, USA 2Inspired<br>Cognition, USA.</p>",
            "id": 5,
            "page": 1,
            "text": "The first three authors contributed equally. 1Language Technologies Institute, Carnegie Mellon University, USA 2Inspired Cognition, USA."
        },
        {
            "bounding_box": [
                {
                    "x": 1276,
                    "y": 834
                },
                {
                    "x": 1605,
                    "y": 834
                },
                {
                    "x": 1605,
                    "y": 890
                },
                {
                    "x": 1276,
                    "y": 890
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='6' style='font-size:20px'>1. Introduction</p>",
            "id": 6,
            "page": 1,
            "text": "1. Introduction"
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 918
                },
                {
                    "x": 2267,
                    "y": 918
                },
                {
                    "x": 2267,
                    "y": 1421
                },
                {
                    "x": 1272,
                    "y": 1421
                }
            ],
            "category": "paragraph",
            "html": "<p id='7' style='font-size:16px'>Until as recently as two years ago, reasoning was considered<br>to be one of the most significant challenges that large lan-<br>guage models (LLMs) had not yet overcome (Marcus, 2018;<br>2020; Garcez & Lamb, 2020). Recently, LLMs have shown<br>impressive success on a wide range of tasks, including com-<br>monsense (Wei et al., 2021 ; Sanh et al., 2021 ; Madaan<br>et al., 2022), mathematical (Lewkowycz et al., 2022; Wu<br>et al., 2022; Mishra et al., 2022), and symbolic reason-<br>ing (Yao et al., 2022; Ahn et al., 2022), using few-shot<br>prompting (Brown et al., 2020).</p>",
            "id": 7,
            "page": 1,
            "text": "Until as recently as two years ago, reasoning was considered to be one of the most significant challenges that large language models (LLMs) had not yet overcome (Marcus, 2018; 2020; Garcez & Lamb, 2020). Recently, LLMs have shown impressive success on a wide range of tasks, including commonsense (Wei , 2021 ; Sanh , 2021 ; Madaan , 2022), mathematical (Lewkowycz , 2022; Wu , 2022; Mishra , 2022), and symbolic reasoning (Yao , 2022; Ahn , 2022), using few-shot prompting (Brown , 2020)."
        },
        {
            "bounding_box": [
                {
                    "x": 1269,
                    "y": 1442
                },
                {
                    "x": 2267,
                    "y": 1442
                },
                {
                    "x": 2267,
                    "y": 2393
                },
                {
                    "x": 1269,
                    "y": 2393
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='8' style='font-size:18px'>This process has been accelerated by methods that require<br>LLMs to generate their explicit reasoning steps, such as<br>\"chain-of-thought\" (Wei et al., 2022), \"scratchpads\" (Nye<br>et al., 2021), and \"least-to-most\" (Zhou et al., 2022) prompt-<br>ing. In particular, the widely used chain-of-thought (CoT)<br>method presents the model with the explicit intermediate<br>steps that are required to reach the final answer. Then, the<br>model is expected to apply a similar decomposition to the ac-<br>tual test example, and consecutively reach an accurate final<br>answer (Ling et al., 2017; Amini et al., 2019). Nevertheless,<br>while LLMs can decompose natural language problems into<br>steps and perform simple arithmetic operations, their perfor-<br>mance falls dramatically when dealing with complex arith-<br>metic (Hendrycks et al., 2021 ; Madaan & Yazdanbakhsh,<br>2022) or large numbers (Nogueira et al., 2021 ; Qian et al.,<br>2022). In fact, even when fine-tuning a PaLM-based model<br>on 164B tokens of explicit mathematical content, its two<br>most common failures are reportedly \"incorrect reasoning\"<br>and \"incorrect calculation\" (Lewkowycz et al., 2022).</p>",
            "id": 8,
            "page": 1,
            "text": "This process has been accelerated by methods that require LLMs to generate their explicit reasoning steps, such as \"chain-of-thought\" (Wei , 2022), \"scratchpads\" (Nye , 2021), and \"least-to-most\" (Zhou , 2022) prompting. In particular, the widely used chain-of-thought (CoT) method presents the model with the explicit intermediate steps that are required to reach the final answer. Then, the model is expected to apply a similar decomposition to the actual test example, and consecutively reach an accurate final answer (Ling , 2017; Amini , 2019). Nevertheless, while LLMs can decompose natural language problems into steps and perform simple arithmetic operations, their performance falls dramatically when dealing with complex arithmetic (Hendrycks , 2021 ; Madaan & Yazdanbakhsh, 2022) or large numbers (Nogueira , 2021 ; Qian , 2022). In fact, even when fine-tuning a PaLM-based model on 164B tokens of explicit mathematical content, its two most common failures are reportedly \"incorrect reasoning\" and \"incorrect calculation\" (Lewkowycz , 2022)."
        },
        {
            "bounding_box": [
                {
                    "x": 1270,
                    "y": 2414
                },
                {
                    "x": 2267,
                    "y": 2414
                },
                {
                    "x": 2267,
                    "y": 2969
                },
                {
                    "x": 1270,
                    "y": 2969
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='9' style='font-size:18px'>In this paper, we propose Program-Aided Language<br>model (PAL): a novel method that uses an LLM to read<br>natural language problems and generate programs as rea-<br>soning steps, but offloads the solution step to a Python inter-<br>preter, as illustrated in Figure 1. This offloading leverages an<br>LLM that can decompose a natural language problem into<br>programmatic steps, which is fortunately available using<br>contemporary state-of-the-art LLMs that are pre-trained on<br>both natural language and programming languages (Brown<br>et al., 2020; Chen et al., 2021a; Chowdhery et al., 2022).<br>While natural language understanding and decomposition</p>",
            "id": 9,
            "page": 1,
            "text": "In this paper, we propose Program-Aided Language model (PAL): a novel method that uses an LLM to read natural language problems and generate programs as reasoning steps, but offloads the solution step to a Python interpreter, as illustrated in Figure 1. This offloading leverages an LLM that can decompose a natural language problem into programmatic steps, which is fortunately available using contemporary state-of-the-art LLMs that are pre-trained on both natural language and programming languages (Brown , 2020; Chen , 2021a; Chowdhery , 2022). While natural language understanding and decomposition"
        },
        {
            "bounding_box": [
                {
                    "x": 64,
                    "y": 897
                },
                {
                    "x": 149,
                    "y": 897
                },
                {
                    "x": 149,
                    "y": 2345
                },
                {
                    "x": 64,
                    "y": 2345
                }
            ],
            "category": "footer",
            "html": "<br><footer id='10' style='font-size:14px'>2023<br>Jan<br>27<br>[cs.CL]<br>arXiv:2211.10435v2</footer>",
            "id": 10,
            "page": 1,
            "text": "2023 Jan 27 [cs.CL] arXiv:2211.10435v2"
        },
        {
            "bounding_box": [
                {
                    "x": 916,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 236
                },
                {
                    "x": 916,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='11' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 11,
            "page": 2,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2232,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 231
                },
                {
                    "x": 2232,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='12' style='font-size:14px'>2</header>",
            "id": 12,
            "page": 2,
            "text": "2"
        },
        {
            "bounding_box": [
                {
                    "x": 720,
                    "y": 305
                },
                {
                    "x": 2179,
                    "y": 305
                },
                {
                    "x": 2179,
                    "y": 359
                },
                {
                    "x": 720,
                    "y": 359
                }
            ],
            "category": "paragraph",
            "html": "<p id='13' style='font-size:20px'>(Wei et al., 2022) Program-aided models (this work)</p>",
            "id": 13,
            "page": 2,
            "text": "(Wei , 2022) Program-aided models (this work)"
        },
        {
            "bounding_box": [
                {
                    "x": 219,
                    "y": 332
                },
                {
                    "x": 2261,
                    "y": 332
                },
                {
                    "x": 2261,
                    "y": 1784
                },
                {
                    "x": 219,
                    "y": 1784
                }
            ],
            "category": "figure",
            "html": "<br><figure><img id='14' style='font-size:14px' alt=\"Chain-of-Thought Language\nInput Input\nQ: Roger has 5 tennis balls. He buys 2 more cans of\ntennis balls. Each can has 3 tennis balls. How many\nQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls does he have now?\ntennis balls. Each can has 3 tennis balls. How many\ntennis balls does he have now? A: Roger started with 5 tennis balls.\ntennis balls = 5\nA: Roger started with 5 tennis balls. 2 cans of 3 tennis 2 cans of 3 tennis balls each is\nballs each is 6 tennis balls. 5 + 6 = 11. The answer is 11. bought balls = 2 * 3\ntennis balls. The answer is\nQ: The bakers at the Beverly Hills Bakery baked 200 = tennis balls + bought_ balls\nanswer\nloaves of bread on Monday morning. They sold 93 loaves\nin the morning and 39 loaves in the afternoon. A grocery Q: The bakers at the Beverly Hills Bakery baked 200\nstore returned 6 unsold loaves. How many loaves of loaves of bread on Monday morning. They sold 93 loaves\nbread did they have left? in the morning and 39 loaves in the afternoon. A grocery\nstore returned 6 unsold loaves. How many loaves of bread\ndid they have left?\nModel Output Model Output\nA: The bakers started with 200 loaves. They sold 93 in A: The bakers started with 200 loaves\nthe morning and 39 in the afternoon. So they sold 93 + loaves baked = 200\n39 = 132 loaves. The grocery store returned 6 loaves. So They sold 93 in the morning and 39 in the afternoon\nthey had 200 - 132 - 6 = 62 loaves left. loaves sold morning = 93\nThe answer is 62.\nloaves sold afternoon = 39\nx The grocery store returned 6 loaves.\nloaves returned = 6\nThe answer is\nanswer = loaves baked - loaves sold morning\n- loaves sold afternoon + loaves returned\n>>> print(answer)\n74\" data-coord=\"top-left:(219,332); bottom-right:(2261,1784)\" /></figure>",
            "id": 14,
            "page": 2,
            "text": "Chain-of-Thought Language Input Input Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls does he have now? tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? A: Roger started with 5 tennis balls. tennis balls = 5 A: Roger started with 5 tennis balls. 2 cans of 3 tennis 2 cans of 3 tennis balls each is balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11. bought balls = 2 * 3 tennis balls. The answer is Q: The bakers at the Beverly Hills Bakery baked 200 = tennis balls + bought_ balls answer loaves of bread on Monday morning. They sold 93 loaves in the morning and 39 loaves in the afternoon. A grocery Q: The bakers at the Beverly Hills Bakery baked 200 store returned 6 unsold loaves. How many loaves of loaves of bread on Monday morning. They sold 93 loaves bread did they have left? in the morning and 39 loaves in the afternoon. A grocery store returned 6 unsold loaves. How many loaves of bread did they have left? Model Output Model Output A: The bakers started with 200 loaves. They sold 93 in A: The bakers started with 200 loaves the morning and 39 in the afternoon. So they sold 93 + loaves baked = 200 39 = 132 loaves. The grocery store returned 6 loaves. So They sold 93 in the morning and 39 in the afternoon they had 200 - 132 - 6 = 62 loaves left. loaves sold morning = 93 The answer is 62. loaves sold afternoon = 39 x The grocery store returned 6 loaves. loaves returned = 6 The answer is answer = loaves baked - loaves sold morning - loaves sold afternoon + loaves returned >>> print(answer) 74"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1816
                },
                {
                    "x": 2269,
                    "y": 1816
                },
                {
                    "x": 2269,
                    "y": 2077
                },
                {
                    "x": 223,
                    "y": 2077
                }
            ],
            "category": "caption",
            "html": "<caption id='15' style='font-size:18px'>Figure 1: A diagram illustrating PAL: Given a mathematical reasoning question, Chain-of-thought (left) generates interme-<br>diate reasoning steps of free-form text. In contrast, Program-aided Language models (PAL, right) generate intermediate<br>steps and Python code. This shifts the role of running the reasoning steps from the language model to the Python interpreter.<br>The final answer is obtained by running the generated reasoning chain. Chain-of-thought reasoning is highlighted in blue :<br>PAL steps are highlighted in gray and pink; the Python interpreter run is highlighted in black and green</caption>",
            "id": 15,
            "page": 2,
            "text": "Figure 1: A diagram illustrating PAL: Given a mathematical reasoning question, Chain-of-thought (left) generates intermediate reasoning steps of free-form text. In contrast, Program-aided Language models (PAL, right) generate intermediate steps and Python code. This shifts the role of running the reasoning steps from the language model to the Python interpreter. The final answer is obtained by running the generated reasoning chain. Chain-of-thought reasoning is highlighted in blue : PAL steps are highlighted in gray and pink; the Python interpreter run is highlighted in black and green"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2158
                },
                {
                    "x": 1214,
                    "y": 2158
                },
                {
                    "x": 1214,
                    "y": 2358
                },
                {
                    "x": 223,
                    "y": 2358
                }
            ],
            "category": "paragraph",
            "html": "<p id='16' style='font-size:16px'>require LLMs, solving and reasoning can be done with the<br>external solver. This bridges an important gap in chain-of-<br>thought-like methods, where reasoning chains can be correct<br>but produce an incorrect answer.</p>",
            "id": 16,
            "page": 2,
            "text": "require LLMs, solving and reasoning can be done with the external solver. This bridges an important gap in chain-ofthought-like methods, where reasoning chains can be correct but produce an incorrect answer."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 2379
                },
                {
                    "x": 1215,
                    "y": 2379
                },
                {
                    "x": 1215,
                    "y": 2983
                },
                {
                    "x": 224,
                    "y": 2983
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='17' style='font-size:16px'>We demonstrate the effectiveness of PAL across 13 arith-<br>metic and symbolic reasoning tasks. In all these tasks,<br>PAL using Codex (Chen et al., 2021a) outperforms much<br>larger models such as PaLM-540B using chain-of-thought<br>prompting. For example, on the popular GSM8K bench-<br>mark, PAL achieves state-of-the-art accuracy, surpassing<br>PaLM-540B with chain-of-thought by absolute 15% top-<br>1 accuracy. When the questions contain large numbers, a<br>dataset we call GSM-HARD, PAL outperforms CoT by an ab-<br>solute 40%. We believe that this seamless synergy between<br>a neural LLM and a symbolic interpreter is an essential step<br>towards general and robust AI reasoners.</p>",
            "id": 17,
            "page": 2,
            "text": "We demonstrate the effectiveness of PAL across 13 arithmetic and symbolic reasoning tasks. In all these tasks, PAL using Codex (Chen , 2021a) outperforms much larger models such as PaLM-540B using chain-of-thought prompting. For example, on the popular GSM8K benchmark, PAL achieves state-of-the-art accuracy, surpassing PaLM-540B with chain-of-thought by absolute 15% top1 accuracy. When the questions contain large numbers, a dataset we call GSM-HARD, PAL outperforms CoT by an absolute 40%. We believe that this seamless synergy between a neural LLM and a symbolic interpreter is an essential step towards general and robust AI reasoners."
        },
        {
            "bounding_box": [
                {
                    "x": 1270,
                    "y": 2150
                },
                {
                    "x": 2065,
                    "y": 2150
                },
                {
                    "x": 2065,
                    "y": 2212
                },
                {
                    "x": 1270,
                    "y": 2212
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='18' style='font-size:22px'>2. Background: Few-shot Prompting</p>",
            "id": 18,
            "page": 2,
            "text": "2. Background: Few-shot Prompting"
        },
        {
            "bounding_box": [
                {
                    "x": 1270,
                    "y": 2237
                },
                {
                    "x": 2270,
                    "y": 2237
                },
                {
                    "x": 2270,
                    "y": 2889
                },
                {
                    "x": 1270,
                    "y": 2889
                }
            ],
            "category": "paragraph",
            "html": "<p id='19' style='font-size:16px'>Few-shot prompting leverages the strength of large-language<br>models to solve a task with a set of k examples that are pro-<br>vided as part of the test-time input (Brown et al., 2020;<br>Liu et al., 2021 ; Chowdhery et al., 2022), where k is usu-<br>ally a number in the low single digits. These input-output<br>examples {(xi, yi)}ki=1 are concatenated in a prompt p<br>≡ <x1 · y1〉 II <x2 · y2> II · · · II <Xk · yk〉· where \" \" denotes<br>the concatenation of an input and output, and \"|\" indicate<br>the concatenation of different examples. During inference,<br>is appended to the prompt, and p = Xtest<br>a test instance Xtest<br>is passed to the model which attempts to complete p II Xtest,<br>and thereby generate an answer Ytest· Note that such few-<br>shot prompting does not modify the underlying LLM.</p>",
            "id": 19,
            "page": 2,
            "text": "Few-shot prompting leverages the strength of large-language models to solve a task with a set of k examples that are provided as part of the test-time input (Brown , 2020; Liu , 2021 ; Chowdhery , 2022), where k is usually a number in the low single digits. These input-output examples {(xi, yi)}ki=1 are concatenated in a prompt p ≡ <x1 · y1〉 II <x2 · y2> II · · · II <Xk · yk〉· where \" \" denotes the concatenation of an input and output, and \"|\" indicate the concatenation of different examples. During inference, is appended to the prompt, and p = Xtest a test instance Xtest is passed to the model which attempts to complete p II Xtest, and thereby generate an answer Ytest· Note that such fewshot prompting does not modify the underlying LLM."
        },
        {
            "bounding_box": [
                {
                    "x": 916,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 236
                },
                {
                    "x": 916,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='20' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 20,
            "page": 3,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2230,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 232
                },
                {
                    "x": 2230,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='21' style='font-size:14px'>3</header>",
            "id": 21,
            "page": 3,
            "text": "3"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 284
                },
                {
                    "x": 1215,
                    "y": 284
                },
                {
                    "x": 1215,
                    "y": 688
                },
                {
                    "x": 223,
                    "y": 688
                }
            ],
            "category": "paragraph",
            "html": "<p id='22' style='font-size:18px'>Wei et al. (2022) additionally augment each in-context exam-<br>ple with chain of thought (CoT) intermediate steps. Specifi-<br>cally, each in-context example in the CoT setup is a triplet<br><xi, ti, Yi〉, where Xi and Yi are input-output pair as before,<br>and ti is a natural language description of the steps that are<br>needed to arrive at the output Yi from the input xi. See Fig-<br>ure 1 for an example. With the additional \"thoughts\" ti, the<br>prompt is set to p ≡ <x1 ·t1 ·y1〉 = <x2·t2·y2>| · I|〈xk .tk ·yk〉·</p>",
            "id": 22,
            "page": 3,
            "text": "Wei  (2022) additionally augment each in-context example with chain of thought (CoT) intermediate steps. Specifically, each in-context example in the CoT setup is a triplet <xi, ti, Yi〉, where Xi and Yi are input-output pair as before, and ti is a natural language description of the steps that are needed to arrive at the output Yi from the input xi. See Figure 1 for an example. With the additional \"thoughts\" ti, the prompt is set to p ≡ <x1 ·t1 ·y1〉 = <x2·t2·y2>| · I|〈xk .tk ·yk〉·"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 708
                },
                {
                    "x": 1216,
                    "y": 708
                },
                {
                    "x": 1216,
                    "y": 1108
                },
                {
                    "x": 222,
                    "y": 1108
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='23' style='font-size:16px'>is appended to<br>During inference, the new question Xtest<br>the prompt as before and supplied to the LLM. Crucially,<br>the model is tasked with generating both the thought ttest<br>and the final answer Ytest. This approach of prompting the<br>model to first generate a reasoning process ttest improves<br>the accuracy of the answer Ytest across a wide range of<br>tasks (Wang et al., 2022a; Wei et al., 2022; Zhou et al.,<br>2022; Wang et al., 2022b).</p>",
            "id": 23,
            "page": 3,
            "text": "is appended to During inference, the new question Xtest the prompt as before and supplied to the LLM. Crucially, the model is tasked with generating both the thought ttest and the final answer Ytest. This approach of prompting the model to first generate a reasoning process ttest improves the accuracy of the answer Ytest across a wide range of tasks (Wang , 2022a; Wei , 2022; Zhou , 2022; Wang , 2022b)."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1167
                },
                {
                    "x": 1000,
                    "y": 1167
                },
                {
                    "x": 1000,
                    "y": 1227
                },
                {
                    "x": 223,
                    "y": 1227
                }
            ],
            "category": "paragraph",
            "html": "<p id='24' style='font-size:20px'>3. Program-aided Language Models</p>",
            "id": 24,
            "page": 3,
            "text": "3. Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 1255
                },
                {
                    "x": 1215,
                    "y": 1255
                },
                {
                    "x": 1215,
                    "y": 1757
                },
                {
                    "x": 222,
                    "y": 1757
                }
            ],
            "category": "paragraph",
            "html": "<p id='25' style='font-size:16px'>In a Program-aided Language model, we propose to gen-<br>erate the thoughts t for a given natural language prob-<br>lem x as interleaved natural language (NL) and program-<br>ming language (PL) statements. Since we delegate the<br>solution step to an interpreter, we do not provide the fi-<br>nal answers to the examples in our prompt. That is, ev-<br>ery in-context example in PAL is a pair <xi, ti〉, where<br>tj = [S1, S2, · · · , SN] with each Si E NL U PL, a sequence<br>of tokens in either NL or PL. The complete prompt is thus p<br>≡ <x1 · t1〉 II <x2 · t2> II · · · = (Xk · tk).</p>",
            "id": 25,
            "page": 3,
            "text": "In a Program-aided Language model, we propose to generate the thoughts t for a given natural language problem x as interleaved natural language (NL) and programming language (PL) statements. Since we delegate the solution step to an interpreter, we do not provide the final answers to the examples in our prompt. That is, every in-context example in PAL is a pair <xi, ti〉, where tj = [S1, S2, · · · , SN] with each Si E NL U PL, a sequence of tokens in either NL or PL. The complete prompt is thus p ≡ <x1 · t1〉 II <x2 · t2> II · · · = (Xk · tk)."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1780
                },
                {
                    "x": 1215,
                    "y": 1780
                },
                {
                    "x": 1215,
                    "y": 1980
                },
                {
                    "x": 223,
                    "y": 1980
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='26' style='font-size:16px'>Given a test instance Xtest, we append it to the prompt,<br>and p II Xtest is fed to the LM. We let the LM generate a<br>prediction ttest, which contains both the intermediate steps<br>and their corresponding programmatic statements.</p>",
            "id": 26,
            "page": 3,
            "text": "Given a test instance Xtest, we append it to the prompt, and p II Xtest is fed to the LM. We let the LM generate a prediction ttest, which contains both the intermediate steps and their corresponding programmatic statements."
        },
        {
            "bounding_box": [
                {
                    "x": 263,
                    "y": 2063
                },
                {
                    "x": 1191,
                    "y": 2063
                },
                {
                    "x": 1191,
                    "y": 2385
                },
                {
                    "x": 263,
                    "y": 2385
                }
            ],
            "category": "paragraph",
            "html": "<p id='27' style='font-size:16px'>A: Roger started with 5 tennis balls.<br>tennis balls = 5<br>2 cans of 3 tennis balls each is<br>bought balls = 2 * 3<br>tennis balls. The answer is<br>answer = tennis balls + bought balls</p>",
            "id": 27,
            "page": 3,
            "text": "A: Roger started with 5 tennis balls. tennis balls = 5 2 cans of 3 tennis balls each is bought balls = 2 * 3 tennis balls. The answer is answer = tennis balls + bought balls"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 2500
                },
                {
                    "x": 1213,
                    "y": 2500
                },
                {
                    "x": 1213,
                    "y": 2704
                },
                {
                    "x": 222,
                    "y": 2704
                }
            ],
            "category": "paragraph",
            "html": "<p id='28' style='font-size:20px'>Figure 2: A close-up of a single example from<br>a PAL prompt. Chain-of-thought reasoning is<br>highlighted in blue, and PAL programmatic steps<br>are highlighted in gray and pink.</p>",
            "id": 28,
            "page": 3,
            "text": "Figure 2: A close-up of a single example from a PAL prompt. Chain-of-thought reasoning is highlighted in blue, and PAL programmatic steps are highlighted in gray and pink."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2791
                },
                {
                    "x": 1215,
                    "y": 2791
                },
                {
                    "x": 1215,
                    "y": 2996
                },
                {
                    "x": 223,
                    "y": 2996
                }
            ],
            "category": "paragraph",
            "html": "<p id='29' style='font-size:18px'>Example A close-up of the example from Figure 1 is<br>shown in Figure 2. While chain-of-thought only de-<br>composes the solution in the prompt into natural lan-<br>guage steps such as Roger started with 5 tennis balls and</p>",
            "id": 29,
            "page": 3,
            "text": "Example A close-up of the example from Figure 1 is shown in Figure 2. While chain-of-thought only decomposes the solution in the prompt into natural language steps such as Roger started with 5 tennis balls and"
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 283
                },
                {
                    "x": 2265,
                    "y": 283
                },
                {
                    "x": 2265,
                    "y": 633
                },
                {
                    "x": 1272,
                    "y": 633
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='30' style='font-size:14px'>2 cans of 3 tennis balls each is 6, in PAL we also aug-<br>ment each such NL step with its corresponding pro-<br>grammatic statement such as tennis balls = 5 and<br>bought balls = 2 * 3. This way, the model learns<br>to generate a program that will provide the answer for the<br>test question, instead of relying on LLM to perform the<br>calculation correctly.</p>",
            "id": 30,
            "page": 3,
            "text": "2 cans of 3 tennis balls each is 6, in PAL we also augment each such NL step with its corresponding programmatic statement such as tennis balls = 5 and bought balls = 2 * 3. This way, the model learns to generate a program that will provide the answer for the test question, instead of relying on LLM to perform the calculation correctly."
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 657
                },
                {
                    "x": 2266,
                    "y": 657
                },
                {
                    "x": 2266,
                    "y": 1007
                },
                {
                    "x": 1272,
                    "y": 1007
                }
            ],
            "category": "paragraph",
            "html": "<p id='31' style='font-size:16px'>We prompt the language model to generate NL intermediate<br>\" in Python)<br>steps using comment syntax (e.g. \"# · · ·<br>such they will be ignored by the interpreter. We pass the<br>generated program ttest to its corresponding solver, we run<br>it, and obtain the final run result Ytest· In this work we use<br>a standard Python interpreter, but this can be any solver,<br>interpreter or a compiler.</p>",
            "id": 31,
            "page": 3,
            "text": "We prompt the language model to generate NL intermediate \" in Python) steps using comment syntax (e.g. \"# · · · such they will be ignored by the interpreter. We pass the generated program ttest to its corresponding solver, we run it, and obtain the final run result Ytest· In this work we use a standard Python interpreter, but this can be any solver, interpreter or a compiler."
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 1097
                },
                {
                    "x": 2265,
                    "y": 1097
                },
                {
                    "x": 2265,
                    "y": 1499
                },
                {
                    "x": 1272,
                    "y": 1499
                }
            ],
            "category": "paragraph",
            "html": "<p id='32' style='font-size:18px'>Crafting prompts for PAL In our experiments, we lever-<br>aged the prompts of existing work whenever available, and<br>otherwise randomly selected the same number (3-6) of ex-<br>amples as previous work for creating a fixed prompt for<br>every benchmark. In all cases, we augmented the free-form<br>text prompts into PAL-styled prompts, leveraging program-<br>ming constructs such as for loops and dictionaries when<br>needed. Generally, writing PAL prompts is easy and quick.</p>",
            "id": 32,
            "page": 3,
            "text": "Crafting prompts for PAL In our experiments, we leveraged the prompts of existing work whenever available, and otherwise randomly selected the same number (3-6) of examples as previous work for creating a fixed prompt for every benchmark. In all cases, we augmented the free-form text prompts into PAL-styled prompts, leveraging programming constructs such as for loops and dictionaries when needed. Generally, writing PAL prompts is easy and quick."
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 1522
                },
                {
                    "x": 2265,
                    "y": 1522
                },
                {
                    "x": 2265,
                    "y": 2021
                },
                {
                    "x": 1273,
                    "y": 2021
                }
            ],
            "category": "paragraph",
            "html": "<p id='33' style='font-size:16px'>We also ensure that variable names in the prompt mean-<br>ingfully reflect their roles. For example, a variable that<br>describes the number of apples in the basket should have a<br>name such as num_apples_in_basket. This keeps the<br>generated code linked to the entities in the question. In<br>Section 6 we show that such meaningful variable names are<br>critical. Notably, it is also possible to incrementally run<br>the PL segments and feed the execution results back to the<br>LLM to generate the following blocks. For simplicity, in<br>our experiments, we used a single, post-hoc, execution.</p>",
            "id": 33,
            "page": 3,
            "text": "We also ensure that variable names in the prompt meaningfully reflect their roles. For example, a variable that describes the number of apples in the basket should have a name such as num_apples_in_basket. This keeps the generated code linked to the entities in the question. In Section 6 we show that such meaningful variable names are critical. Notably, it is also possible to incrementally run the PL segments and feed the execution results back to the LLM to generate the following blocks. For simplicity, in our experiments, we used a single, post-hoc, execution."
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 2044
                },
                {
                    "x": 2266,
                    "y": 2044
                },
                {
                    "x": 2266,
                    "y": 2248
                },
                {
                    "x": 1272,
                    "y": 2248
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='34' style='font-size:18px'>This work focuses on CoT-style reasoning chain, but in<br>Appendix I we show that PAL also improves Least-to-<br>Most (Zhou et al., 2022) prompts, which introduce rea-<br>soning chains that decompose a question into sub-questions.</p>",
            "id": 34,
            "page": 3,
            "text": "This work focuses on CoT-style reasoning chain, but in Appendix I we show that PAL also improves Least-toMost (Zhou , 2022) prompts, which introduce reasoning chains that decompose a question into sub-questions."
        },
        {
            "bounding_box": [
                {
                    "x": 1275,
                    "y": 2308
                },
                {
                    "x": 1759,
                    "y": 2308
                },
                {
                    "x": 1759,
                    "y": 2367
                },
                {
                    "x": 1275,
                    "y": 2367
                }
            ],
            "category": "paragraph",
            "html": "<p id='35' style='font-size:22px'>4. Experimental Setup</p>",
            "id": 35,
            "page": 3,
            "text": "4. Experimental Setup"
        },
        {
            "bounding_box": [
                {
                    "x": 1269,
                    "y": 2393
                },
                {
                    "x": 2265,
                    "y": 2393
                },
                {
                    "x": 2265,
                    "y": 2996
                },
                {
                    "x": 1269,
                    "y": 2996
                }
            ],
            "category": "paragraph",
            "html": "<p id='36' style='font-size:18px'>Data and in-context examples We experiment with three<br>broad classes of reasoning tasks: (1) mathematical prob-<br>lems (§4.1) from a wide range of datasets including<br>GSM8K (Cobbe et al., 2021), SVAMP (Patel et al., 2021),<br>ASDIV (Miao et al., 2020), and MAWPS (Koncel-Kedziorski<br>et al., 2016); (2) symbolic reasoning (§4.2) from BIG-Bench<br>Hard (Suzgun et al., 2022); (3) and algorithmic problems<br>(§4.3) from BIG-Bench Hard as well. Details of all datasets<br>are shown in Appendix H. For all of the experiments for<br>which CoT prompts were available, we use the same in-<br>context examples as used by previous work. Otherwise, we<br>randomly sampled a fixed set of in-context examples, and</p>",
            "id": 36,
            "page": 3,
            "text": "Data and in-context examples We experiment with three broad classes of reasoning tasks: (1) mathematical problems (§4.1) from a wide range of datasets including GSM8K (Cobbe , 2021), SVAMP (Patel , 2021), ASDIV (Miao , 2020), and MAWPS (Koncel-Kedziorski , 2016); (2) symbolic reasoning (§4.2) from BIG-Bench Hard (Suzgun , 2022); (3) and algorithmic problems (§4.3) from BIG-Bench Hard as well. Details of all datasets are shown in Appendix H. For all of the experiments for which CoT prompts were available, we use the same incontext examples as used by previous work. Otherwise, we randomly sampled a fixed set of in-context examples, and"
        },
        {
            "bounding_box": [
                {
                    "x": 917,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 235
                },
                {
                    "x": 917,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='37' style='font-size:22px'>PAL: Program-aided Language Models</header>",
            "id": 37,
            "page": 4,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2231,
                    "y": 194
                },
                {
                    "x": 2260,
                    "y": 194
                },
                {
                    "x": 2260,
                    "y": 231
                },
                {
                    "x": 2231,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='38' style='font-size:16px'>4</header>",
            "id": 38,
            "page": 4,
            "text": "4"
        },
        {
            "bounding_box": [
                {
                    "x": 423,
                    "y": 278
                },
                {
                    "x": 1984,
                    "y": 278
                },
                {
                    "x": 1984,
                    "y": 327
                },
                {
                    "x": 423,
                    "y": 327
                }
            ],
            "category": "paragraph",
            "html": "<p id='39' style='font-size:20px'>Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?</p>",
            "id": 39,
            "page": 4,
            "text": "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?"
        },
        {
            "bounding_box": [
                {
                    "x": 737,
                    "y": 365
                },
                {
                    "x": 1642,
                    "y": 365
                },
                {
                    "x": 1642,
                    "y": 620
                },
                {
                    "x": 737,
                    "y": 620
                }
            ],
            "category": "paragraph",
            "html": "<p id='40' style='font-size:14px'>money_initial = 23<br>bagels = 5<br>bagel_cost = 3<br>money_spent = bagels * bagel_cost<br>money_left = money_initial - money_spent<br>answer = money_left</p>",
            "id": 40,
            "page": 4,
            "text": "money_initial = 23 bagels = 5 bagel_cost = 3 money_spent = bagels * bagel_cost money_left = money_initial - money_spent answer = money_left"
        },
        {
            "bounding_box": [
                {
                    "x": 452,
                    "y": 700
                },
                {
                    "x": 2028,
                    "y": 700
                },
                {
                    "x": 2028,
                    "y": 751
                },
                {
                    "x": 452,
                    "y": 751
                }
            ],
            "category": "paragraph",
            "html": "<p id='41' style='font-size:20px'>Figure 3: Example prompt for the mathematical reasoning tasks, from the GSM8K benchmark.</p>",
            "id": 41,
            "page": 4,
            "text": "Figure 3: Example prompt for the mathematical reasoning tasks, from the GSM8K benchmark."
        },
        {
            "bounding_box": [
                {
                    "x": 420,
                    "y": 800
                },
                {
                    "x": 2061,
                    "y": 800
                },
                {
                    "x": 2061,
                    "y": 947
                },
                {
                    "x": 420,
                    "y": 947
                }
            ],
            "category": "paragraph",
            "html": "<p id='42' style='font-size:18px'>Q: On the table, you see a bunch of objects arranged in a row: a purple paperclip, a pink stress ball,<br>a brown keychain, a green scrunchiephone charger, a mauve fidget spinner, and a burgundy pen.<br>What is the color of the object directly to the right of the stress ball?</p>",
            "id": 42,
            "page": 4,
            "text": "Q: On the table, you see a bunch of objects arranged in a row: a purple paperclip, a pink stress ball, a brown keychain, a green scrunchiephone charger, a mauve fidget spinner, and a burgundy pen. What is the color of the object directly to the right of the stress ball?"
        },
        {
            "bounding_box": [
                {
                    "x": 736,
                    "y": 967
                },
                {
                    "x": 1243,
                    "y": 967
                },
                {
                    "x": 1243,
                    "y": 1041
                },
                {
                    "x": 736,
                    "y": 1041
                }
            ],
            "category": "paragraph",
            "html": "<p id='43' style='font-size:14px'>· · ·<br>stress_ball_idx = None</p>",
            "id": 43,
            "page": 4,
            "text": "· · · stress_ball_idx = None"
        },
        {
            "bounding_box": [
                {
                    "x": 737,
                    "y": 1044
                },
                {
                    "x": 1547,
                    "y": 1044
                },
                {
                    "x": 1547,
                    "y": 1082
                },
                {
                    "x": 737,
                    "y": 1082
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='44' style='font-size:16px'>for i, object in enumerate (objects) :</p>",
            "id": 44,
            "page": 4,
            "text": "for i, object in enumerate (objects) :"
        },
        {
            "bounding_box": [
                {
                    "x": 826,
                    "y": 1084
                },
                {
                    "x": 1510,
                    "y": 1084
                },
                {
                    "x": 1510,
                    "y": 1206
                },
                {
                    "x": 826,
                    "y": 1206
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='45' style='font-size:14px'>if object [0] == , stress ball , :<br>stress_ball_idx = i<br>break</p>",
            "id": 45,
            "page": 4,
            "text": "if object  == , stress ball , : stress_ball_idx = i break"
        },
        {
            "bounding_box": [
                {
                    "x": 736,
                    "y": 1213
                },
                {
                    "x": 1663,
                    "y": 1213
                },
                {
                    "x": 1663,
                    "y": 1359
                },
                {
                    "x": 736,
                    "y": 1359
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='46' style='font-size:16px'># Find the directly right object<br>direct_right = objects [stress_ball_idx-1]<br># Check the directly right object 's color<br>answer = direct_right [1]</p>",
            "id": 46,
            "page": 4,
            "text": "# Find the directly right object direct_right = objects [stress_ball_idx-1] # Check the directly right object 's color answer = direct_right "
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1422
                },
                {
                    "x": 2262,
                    "y": 1422
                },
                {
                    "x": 2262,
                    "y": 1523
                },
                {
                    "x": 224,
                    "y": 1523
                }
            ],
            "category": "paragraph",
            "html": "<p id='47' style='font-size:18px'>Figure 4: An example for a PAL prompt in the COLORED OBJECTS task. For space considerations, we omit the code that<br>creates the list objects.</p>",
            "id": 47,
            "page": 4,
            "text": "Figure 4: An example for a PAL prompt in the COLORED OBJECTS task. For space considerations, we omit the code that creates the list objects."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1612
                },
                {
                    "x": 843,
                    "y": 1612
                },
                {
                    "x": 843,
                    "y": 1659
                },
                {
                    "x": 223,
                    "y": 1659
                }
            ],
            "category": "paragraph",
            "html": "<p id='48' style='font-size:18px'>used the same set for PAL and CoT.</p>",
            "id": 48,
            "page": 4,
            "text": "used the same set for PAL and CoT."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 1710
                },
                {
                    "x": 1216,
                    "y": 1710
                },
                {
                    "x": 1216,
                    "y": 2263
                },
                {
                    "x": 225,
                    "y": 2263
                }
            ],
            "category": "paragraph",
            "html": "<p id='49' style='font-size:18px'>Baselines We consider three prompting strategies: DI-<br>RECT prompting - the standard prompting approach us-<br>ing pairs of questions and immediate answers (e.g., 11 as<br>in Brown et al. (2020); chain-of-thought (CoT) prompt-<br>ing (Wei et al., 2022); and our PAL prompting. We per-<br>formed greedy decoding from the language model using<br>a temperature of 0. Unless stated otherwise, we used<br>CODEX (code-davinci-002) as our backend LLM for<br>both PAL, DIRECT, and CoT. In datasets where results for<br>additional base LMs, such as PaLM-540B, were available<br>from previous work, we included them as CoT PaLM-540B・</p>",
            "id": 49,
            "page": 4,
            "text": "Baselines We consider three prompting strategies: DIRECT prompting - the standard prompting approach using pairs of questions and immediate answers (e.g., 11 as in Brown  (2020); chain-of-thought (CoT) prompting (Wei , 2022); and our PAL prompting. We performed greedy decoding from the language model using a temperature of 0. Unless stated otherwise, we used CODEX (code-davinci-002) as our backend LLM for both PAL, DIRECT, and CoT. In datasets where results for additional base LMs, such as PaLM-540B, were available from previous work, we included them as CoT PaLM-540B・"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2315
                },
                {
                    "x": 751,
                    "y": 2315
                },
                {
                    "x": 751,
                    "y": 2366
                },
                {
                    "x": 223,
                    "y": 2366
                }
            ],
            "category": "paragraph",
            "html": "<p id='50' style='font-size:22px'>4.1. Mathematical Reasoning</p>",
            "id": 50,
            "page": 4,
            "text": "4.1. Mathematical Reasoning"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2392
                },
                {
                    "x": 1214,
                    "y": 2392
                },
                {
                    "x": 1214,
                    "y": 2743
                },
                {
                    "x": 223,
                    "y": 2743
                }
            ],
            "category": "paragraph",
            "html": "<p id='51' style='font-size:20px'>We evaluate PAL on eight mathematical word problem<br>datasets. Each question in these tasks is an algebra word<br>problem at grade-school level. An example for a question<br>and PAL example prompt is shown in Figure 3. We found<br>that using explicit NL intermediate steps does not further<br>benefit these math reasoning tasks, hence we kept only the<br>meaningful variable names in the prompt.</p>",
            "id": 51,
            "page": 4,
            "text": "We evaluate PAL on eight mathematical word problem datasets. Each question in these tasks is an algebra word problem at grade-school level. An example for a question and PAL example prompt is shown in Figure 3. We found that using explicit NL intermediate steps does not further benefit these math reasoning tasks, hence we kept only the meaningful variable names in the prompt."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 2792
                },
                {
                    "x": 1213,
                    "y": 2792
                },
                {
                    "x": 1213,
                    "y": 2994
                },
                {
                    "x": 225,
                    "y": 2994
                }
            ],
            "category": "paragraph",
            "html": "<p id='52' style='font-size:18px'>GSM-HARD LLMs can perform simple calculations with<br>small numbers. However, Madaan & Yazdanbakhsh (2022)<br>found that 50% of the numbers in the popular GSM8K<br>dataset of math reasoning problems are integers between 0</p>",
            "id": 52,
            "page": 4,
            "text": "GSM-HARD LLMs can perform simple calculations with small numbers. However, Madaan & Yazdanbakhsh (2022) found that 50% of the numbers in the popular GSM8K dataset of math reasoning problems are integers between 0"
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 1612
                },
                {
                    "x": 2265,
                    "y": 1612
                },
                {
                    "x": 2265,
                    "y": 1962
                },
                {
                    "x": 1272,
                    "y": 1962
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='53' style='font-size:18px'>and 8. This raises the question of whether LLMs can gener-<br>alize to larger and non-integer numbers? We constructed a<br>harder version of GSM8K, which we call GSM-HARD, by re-<br>placing the numbers in the questions of GSM8K with larger<br>numbers. Specifically, one of the numbers in a question<br>was replaced with a random integer of up to 7 digits. More<br>details regarding the this new dataset are provided in H.1.</p>",
            "id": 53,
            "page": 4,
            "text": "and 8. This raises the question of whether LLMs can generalize to larger and non-integer numbers? We constructed a harder version of GSM8K, which we call GSM-HARD, by replacing the numbers in the questions of GSM8K with larger numbers. Specifically, one of the numbers in a question was replaced with a random integer of up to 7 digits. More details regarding the this new dataset are provided in H.1."
        },
        {
            "bounding_box": [
                {
                    "x": 1271,
                    "y": 2015
                },
                {
                    "x": 1717,
                    "y": 2015
                },
                {
                    "x": 1717,
                    "y": 2064
                },
                {
                    "x": 1271,
                    "y": 2064
                }
            ],
            "category": "paragraph",
            "html": "<p id='54' style='font-size:22px'>4.2. Symbolic Reasoning</p>",
            "id": 54,
            "page": 4,
            "text": "4.2. Symbolic Reasoning"
        },
        {
            "bounding_box": [
                {
                    "x": 1269,
                    "y": 2092
                },
                {
                    "x": 2266,
                    "y": 2092
                },
                {
                    "x": 2266,
                    "y": 2993
                },
                {
                    "x": 1269,
                    "y": 2993
                }
            ],
            "category": "paragraph",
            "html": "<p id='55' style='font-size:20px'>We applied PAL to three symbolic reasoning tasks from<br>BIG-Bench Hard (Suzgun et al., 2022), which involve rea-<br>soning about objects and concepts: (1) COLORED OBJECTS<br>requires answering questions about colored objects on a sur-<br>face. This task requires keeping track of relative positions,<br>absolute positions, and the color of each object. Figure 4<br>shows an example for a question and example PAL prompt.<br>(2) PENGUINS describes a table of penguins and some ad-<br>ditional information in natural language, and the task is to<br>answer a question about the attributes of the penguins, for<br>example, \"how many penguins are less than 8 years old?\".<br>While both PENGUINS and COLORED OBJECT tasks re-<br>quire tracking objects, PENGUINS describes dynamics as<br>well, since the penguins in the problem can be added or<br>removed. Figure 17 in Appendix J.2 shows an example for<br>a question, a chain-of-thought prompt, and PAL prompt.<br>(3) DATE is a date understanding task that involves inferring<br>dates from natural language descriptions, performing addi-</p>",
            "id": 55,
            "page": 4,
            "text": "We applied PAL to three symbolic reasoning tasks from BIG-Bench Hard (Suzgun , 2022), which involve reasoning about objects and concepts: (1) COLORED OBJECTS requires answering questions about colored objects on a surface. This task requires keeping track of relative positions, absolute positions, and the color of each object. Figure 4 shows an example for a question and example PAL prompt. (2) PENGUINS describes a table of penguins and some additional information in natural language, and the task is to answer a question about the attributes of the penguins, for example, \"how many penguins are less than 8 years old?\". While both PENGUINS and COLORED OBJECT tasks require tracking objects, PENGUINS describes dynamics as well, since the penguins in the problem can be added or removed. Figure 17 in Appendix J.2 shows an example for a question, a chain-of-thought prompt, and PAL prompt. (3) DATE is a date understanding task that involves inferring dates from natural language descriptions, performing addi-"
        },
        {
            "bounding_box": [
                {
                    "x": 917,
                    "y": 190
                },
                {
                    "x": 1558,
                    "y": 190
                },
                {
                    "x": 1558,
                    "y": 235
                },
                {
                    "x": 917,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='56' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 56,
            "page": 5,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2231,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 231
                },
                {
                    "x": 2231,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='57' style='font-size:16px'>5</header>",
            "id": 57,
            "page": 5,
            "text": "5"
        },
        {
            "bounding_box": [
                {
                    "x": 421,
                    "y": 276
                },
                {
                    "x": 2059,
                    "y": 276
                },
                {
                    "x": 2059,
                    "y": 375
                },
                {
                    "x": 421,
                    "y": 375
                }
            ],
            "category": "paragraph",
            "html": "<p id='58' style='font-size:16px'>Q: I have a chair, two potatoes, a cauliflower, a lettuce head, two tables, a cabbage, two onions, and<br>three fridges. How many vegetables do I have?</p>",
            "id": 58,
            "page": 5,
            "text": "Q: I have a chair, two potatoes, a cauliflower, a lettuce head, two tables, a cabbage, two onions, and three fridges. How many vegetables do I have?"
        },
        {
            "bounding_box": [
                {
                    "x": 741,
                    "y": 392
                },
                {
                    "x": 1705,
                    "y": 392
                },
                {
                    "x": 1705,
                    "y": 435
                },
                {
                    "x": 741,
                    "y": 435
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='59' style='font-size:16px'># note : I 'm not counting the chair, tables,</p>",
            "id": 59,
            "page": 5,
            "text": "# note : I 'm not counting the chair, tables,"
        },
        {
            "bounding_box": [
                {
                    "x": 744,
                    "y": 420
                },
                {
                    "x": 1700,
                    "y": 420
                },
                {
                    "x": 1700,
                    "y": 793
                },
                {
                    "x": 744,
                    "y": 793
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='60' style='font-size:14px'>or fridges<br>vegetables_to_count = {<br>potato , : 2,<br>, cauliflower , : 1,<br>, lettuce head , : 1,<br>, cabbage , 1,<br>:<br>, onion , 2<br>:<br>}<br>answer = sum (vegetables_to_count · values () )</p>",
            "id": 60,
            "page": 5,
            "text": "or fridges vegetables_to_count = { potato , : 2, , cauliflower , : 1, , lettuce head , : 1, , cabbage , 1, : , onion , 2 : } answer = sum (vegetables_to_count · values () )"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 887
                },
                {
                    "x": 2263,
                    "y": 887
                },
                {
                    "x": 2263,
                    "y": 1043
                },
                {
                    "x": 222,
                    "y": 1043
                }
            ],
            "category": "caption",
            "html": "<caption id='61' style='font-size:18px'>Figure 5: An example for a PAL prompt in the OBJECT COUNTING task. The base LM is expected to convert the input into<br>a dictionary where keys are entities and values are their quantities, while filtering out non-vegetable entities. Finally, the<br>answer is the sum of the dictionary values.</caption>",
            "id": 61,
            "page": 5,
            "text": "Figure 5: An example for a PAL prompt in the OBJECT COUNTING task. The base LM is expected to convert the input into a dictionary where keys are entities and values are their quantities, while filtering out non-vegetable entities. Finally, the answer is the sum of the dictionary values."
        },
        {
            "bounding_box": [
                {
                    "x": 236,
                    "y": 1089
                },
                {
                    "x": 2242,
                    "y": 1089
                },
                {
                    "x": 2242,
                    "y": 1541
                },
                {
                    "x": 236,
                    "y": 1541
                }
            ],
            "category": "table",
            "html": "<table id='62' style='font-size:14px'><tr><td></td><td>GSM8K</td><td>GSM-HARD</td><td>SVAMP</td><td>ASDIV</td><td>SINGLEEQ</td><td>SINGLEOP</td><td>ADDSUB</td><td>MULTIARITH</td></tr><tr><td>DIRECT Codex</td><td>19.7</td><td>5.0</td><td>69.9</td><td>74.0</td><td>86.8</td><td>93.1</td><td>90.9</td><td>44.0</td></tr><tr><td>CoT UL2-20B</td><td>4.1</td><td>-</td><td>12.6</td><td>16.9</td><td>-</td><td>-</td><td>18.2</td><td>10.7</td></tr><tr><td>CoT LaMDA-137B</td><td>17.1</td><td>-</td><td>39.9</td><td>49.0</td><td>-</td><td>-</td><td>52.9</td><td>51.8</td></tr><tr><td>CoT Codex</td><td>65.6</td><td>23.1</td><td>74.8</td><td>76.9</td><td>89.1</td><td>91.9</td><td>86.0</td><td>95.9</td></tr><tr><td>CoT PaLM-540B</td><td>56.9</td><td>-</td><td>79.0</td><td>73.9</td><td>92.3</td><td>94.1</td><td>91.9</td><td>94.7</td></tr><tr><td>CoT Minerva 540B</td><td>58.8</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td><td>-</td></tr><tr><td>PAL</td><td>72.0</td><td>61.2</td><td>79.4</td><td>79.6</td><td>96.1</td><td>94.6</td><td>92.5</td><td>99.2</td></tr></table>",
            "id": 62,
            "page": 5,
            "text": "GSM8K GSM-HARD SVAMP ASDIV SINGLEEQ SINGLEOP ADDSUB MULTIARITH  DIRECT Codex 19.7 5.0 69.9 74.0 86.8 93.1 90.9 44.0  CoT UL2-20B 4.1 - 12.6 16.9 - - 18.2 10.7  CoT LaMDA-137B 17.1 - 39.9 49.0 - - 52.9 51.8  CoT Codex 65.6 23.1 74.8 76.9 89.1 91.9 86.0 95.9  CoT PaLM-540B 56.9 - 79.0 73.9 92.3 94.1 91.9 94.7  CoT Minerva 540B 58.8 - - - - - -  PAL 72.0 61.2 79.4 79.6 96.1 94.6 92.5"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 1573
                },
                {
                    "x": 2267,
                    "y": 1573
                },
                {
                    "x": 2267,
                    "y": 1779
                },
                {
                    "x": 222,
                    "y": 1779
                }
            ],
            "category": "paragraph",
            "html": "<p id='63' style='font-size:18px'>Table 1: Problem solve rate (%) on mathematical reasoning datasets. The highest number on each task is in bold. The<br>results for DIRECT and PaLM-540B are from Wei et al. (2022), the results for LaMDA and UL2 are from Wang et al.<br>(2022b), and the results for Minerva are from Lewkowycz et al. (2022). We ran PAL on each benchmark 3 times and report<br>the average; the standard deviation is provided in Table 7.</p>",
            "id": 63,
            "page": 5,
            "text": "Table 1: Problem solve rate (%) on mathematical reasoning datasets. The highest number on each task is in bold. The results for DIRECT and PaLM-540B are from Wei  (2022), the results for LaMDA and UL2 are from Wang  (2022b), and the results for Minerva are from Lewkowycz  (2022). We ran PAL on each benchmark 3 times and report the average; the standard deviation is provided in Table 7."
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 1864
                },
                {
                    "x": 1216,
                    "y": 1864
                },
                {
                    "x": 1216,
                    "y": 2068
                },
                {
                    "x": 222,
                    "y": 2068
                }
            ],
            "category": "paragraph",
            "html": "<p id='64' style='font-size:20px'>tion and subtraction of relative periods of time, and having<br>some global knowledge such as \"how many days are there<br>in February\", and performing the computation accordingly.<br>Appendix J.3 shows example prompts.</p>",
            "id": 64,
            "page": 5,
            "text": "tion and subtraction of relative periods of time, and having some global knowledge such as \"how many days are there in February\", and performing the computation accordingly. Appendix J.3 shows example prompts."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2119
                },
                {
                    "x": 634,
                    "y": 2119
                },
                {
                    "x": 634,
                    "y": 2168
                },
                {
                    "x": 223,
                    "y": 2168
                }
            ],
            "category": "paragraph",
            "html": "<p id='65' style='font-size:20px'>4.3. Algorithmic Tasks</p>",
            "id": 65,
            "page": 5,
            "text": "4.3. Algorithmic Tasks"
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 2194
                },
                {
                    "x": 1217,
                    "y": 2194
                },
                {
                    "x": 1217,
                    "y": 2849
                },
                {
                    "x": 224,
                    "y": 2849
                }
            ],
            "category": "paragraph",
            "html": "<p id='66' style='font-size:18px'>Finally, we compare PAL and CoT on algorithmic reason-<br>ing. These are tasks where a human programmer can write<br>a deterministic program with prior knowledge of the ques-<br>tion. We experiment with two algorithmic tasks: OBJECT<br>COUNTING and REPEAT COPY. OBJECT COUNTING in-<br>volves answering questions about the number of objects be-<br>longing to a certain type. For example, as shown in Figure 5:<br>\"I have a chair, two potatoes, a cauliflower, a lettuce head,<br>two tables, ... How many vegetables do I have?\"). REPEAT<br>COPY requires generating a sequence of words according<br>to instructions. For example, as shown in Appendix J.6:<br>\"Repeat the word duck four times, but halfway through also<br>say quack \").</p>",
            "id": 66,
            "page": 5,
            "text": "Finally, we compare PAL and CoT on algorithmic reasoning. These are tasks where a human programmer can write a deterministic program with prior knowledge of the question. We experiment with two algorithmic tasks: OBJECT COUNTING and REPEAT COPY. OBJECT COUNTING involves answering questions about the number of objects belonging to a certain type. For example, as shown in Figure 5: \"I have a chair, two potatoes, a cauliflower, a lettuce head, two tables, ... How many vegetables do I have?\"). REPEAT COPY requires generating a sequence of words according to instructions. For example, as shown in Appendix J.6: \"Repeat the word duck four times, but halfway through also say quack \")."
        },
        {
            "bounding_box": [
                {
                    "x": 1274,
                    "y": 1858
                },
                {
                    "x": 1491,
                    "y": 1858
                },
                {
                    "x": 1491,
                    "y": 1912
                },
                {
                    "x": 1274,
                    "y": 1912
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='67' style='font-size:22px'>5. Results</p>",
            "id": 67,
            "page": 5,
            "text": "5. Results"
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 1946
                },
                {
                    "x": 1595,
                    "y": 1946
                },
                {
                    "x": 1595,
                    "y": 1993
                },
                {
                    "x": 1273,
                    "y": 1993
                }
            ],
            "category": "paragraph",
            "html": "<p id='68' style='font-size:18px'>5.1. Math Results</p>",
            "id": 68,
            "page": 5,
            "text": "5.1. Math Results"
        },
        {
            "bounding_box": [
                {
                    "x": 1274,
                    "y": 2023
                },
                {
                    "x": 2267,
                    "y": 2023
                },
                {
                    "x": 2267,
                    "y": 2272
                },
                {
                    "x": 1274,
                    "y": 2272
                }
            ],
            "category": "paragraph",
            "html": "<p id='69' style='font-size:18px'>Table 1 shows the following results: across all tasks,<br>PAL using Codex sets a new few-shot state-of-the-art top-<br>1 decoding across all datasets, outperforming CoT Codex,<br>COTPaLM-540B, and CoT Minerva 540B which was fine-tuned<br>on explicit mathematical content.</p>",
            "id": 69,
            "page": 5,
            "text": "Table 1 shows the following results: across all tasks, PAL using Codex sets a new few-shot state-of-the-art top1 decoding across all datasets, outperforming CoT Codex, COTPaLM-540B, and CoT Minerva 540B which was fine-tuned on explicit mathematical content."
        },
        {
            "bounding_box": [
                {
                    "x": 1274,
                    "y": 2298
                },
                {
                    "x": 2267,
                    "y": 2298
                },
                {
                    "x": 2267,
                    "y": 2498
                },
                {
                    "x": 1274,
                    "y": 2498
                }
            ],
            "category": "paragraph",
            "html": "<p id='70' style='font-size:18px'>Interestingly, CoT also benefits from Codex over PaLM-<br>540B in some of the datasets such as ASDIV, but performs<br>worse than PaLM-540B in others such as SVAMP. Yet,<br>using PAL further improves the solve rate across all datasets.</p>",
            "id": 70,
            "page": 5,
            "text": "Interestingly, CoT also benefits from Codex over PaLM540B in some of the datasets such as ASDIV, but performs worse than PaLM-540B in others such as SVAMP. Yet, using PAL further improves the solve rate across all datasets."
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 2593
                },
                {
                    "x": 2266,
                    "y": 2593
                },
                {
                    "x": 2266,
                    "y": 2994
                },
                {
                    "x": 1273,
                    "y": 2994
                }
            ],
            "category": "paragraph",
            "html": "<p id='71' style='font-size:20px'>GSM-HARD On GSM-HARD (Table 1), the accuracy of<br>DIRECT drops dramatically from 19.7% to 5.0% (a relative<br>drop of 74%), the accuracy of CoT drops from 65.6% to<br>20.1% (a relative drop of almost 70%), while PAL remains<br>stable at 61.5%, dropping by only 14.3%. The results of<br>CoT on GSM-HARD did not improve even when we replaced<br>its prompts with prompts that include large numbers (Ap-<br>pendix B). This shows how PAL provides not only better</p>",
            "id": 71,
            "page": 5,
            "text": "GSM-HARD On GSM-HARD (Table 1), the accuracy of DIRECT drops dramatically from 19.7% to 5.0% (a relative drop of 74%), the accuracy of CoT drops from 65.6% to 20.1% (a relative drop of almost 70%), while PAL remains stable at 61.5%, dropping by only 14.3%. The results of CoT on GSM-HARD did not improve even when we replaced its prompts with prompts that include large numbers (Appendix B). This shows how PAL provides not only better"
        },
        {
            "bounding_box": [
                {
                    "x": 916,
                    "y": 190
                },
                {
                    "x": 1558,
                    "y": 190
                },
                {
                    "x": 1558,
                    "y": 236
                },
                {
                    "x": 916,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='72' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 72,
            "page": 6,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 350,
                    "y": 268
                },
                {
                    "x": 2122,
                    "y": 268
                },
                {
                    "x": 2122,
                    "y": 629
                },
                {
                    "x": 350,
                    "y": 629
                }
            ],
            "category": "table",
            "html": "<table id='73' style='font-size:14px'><tr><td></td><td>COLORED OBJECT</td><td>PENGUINS</td><td>DATE</td><td>REPEAT COPY</td><td>OBJECT COUNTING</td></tr><tr><td>DIRECT Codex</td><td>75.7</td><td>71.1</td><td>49.9</td><td>81.3</td><td>37.6</td></tr><tr><td>CoT LaMDA-137B</td><td>-</td><td>-</td><td>26.8</td><td>-</td><td>-</td></tr><tr><td>CoT PaLM-540B</td><td>-</td><td>65.1</td><td>65.3</td><td>-</td><td>-</td></tr><tr><td>CoT Codex</td><td>86.3</td><td>79.2</td><td>64.8</td><td>68.8</td><td>73.0</td></tr><tr><td>PAL Codex</td><td>95.1</td><td>93.3</td><td>76.2</td><td>90.6</td><td>96.7</td></tr></table>",
            "id": 73,
            "page": 6,
            "text": "COLORED OBJECT PENGUINS DATE REPEAT COPY OBJECT COUNTING  DIRECT Codex 75.7 71.1 49.9 81.3 37.6  CoT LaMDA-137B - - 26.8 -  CoT PaLM-540B - 65.1 65.3 -  CoT Codex 86.3 79.2 64.8 68.8 73.0  PAL Codex 95.1 93.3 76.2 90.6"
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 663
                },
                {
                    "x": 2265,
                    "y": 663
                },
                {
                    "x": 2265,
                    "y": 816
                },
                {
                    "x": 221,
                    "y": 816
                }
            ],
            "category": "paragraph",
            "html": "<p id='74' style='font-size:18px'>Table 2: Solve rate on three symbolic reasoning datasets and two algorithmic datasets, In all datasets, PAL achieves a much<br>higher accuracy than chain-of-thought. Results with closed models LaMDA-137B and PaLM-540B are included if available<br>to public (Wei et al., 2022; Suzgun et al., 2022).</p>",
            "id": 74,
            "page": 6,
            "text": "Table 2: Solve rate on three symbolic reasoning datasets and two algorithmic datasets, In all datasets, PAL achieves a much higher accuracy than chain-of-thought. Results with closed models LaMDA-137B and PaLM-540B are included if available to public (Wei , 2022; Suzgun , 2022)."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 904
                },
                {
                    "x": 1214,
                    "y": 904
                },
                {
                    "x": 1214,
                    "y": 1105
                },
                {
                    "x": 223,
                    "y": 1105
                }
            ],
            "category": "paragraph",
            "html": "<p id='75' style='font-size:18px'>results on the standard benchmarks, but is also much more<br>robust. In fact, since PAL offloads the computation to the<br>Python interpreter, any complex computation can be per-<br>formed accurately given the correctly generated program.</p>",
            "id": 75,
            "page": 6,
            "text": "results on the standard benchmarks, but is also much more robust. In fact, since PAL offloads the computation to the Python interpreter, any complex computation can be performed accurately given the correctly generated program."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1184
                },
                {
                    "x": 1216,
                    "y": 1184
                },
                {
                    "x": 1216,
                    "y": 1739
                },
                {
                    "x": 224,
                    "y": 1739
                }
            ],
            "category": "paragraph",
            "html": "<p id='76' style='font-size:18px'>Large Numbers or Incorrect Reasoning? Are the fail-<br>ures on GSM-HARD primarily due to the inability of LLMs<br>to do arithmetic, or do the large numbers in the question<br>\"confuse\" the LM which generates irrational intermediate<br>steps? To investigate this, we evaluated the outputs gen-<br>erated by CoT for the two versions of the same question<br>(with and without large numbers). We find that in 16 out<br>of 25 cases we analyzed, CoT generates nearly identical<br>natural language \"thoughts\", indicating that the primary fail-<br>ure mode is the inability to perform arithmetic accurately.<br>Sample outputs are provided in the Appendix, Table 11.</p>",
            "id": 76,
            "page": 6,
            "text": "Large Numbers or Incorrect Reasoning? Are the failures on GSM-HARD primarily due to the inability of LLMs to do arithmetic, or do the large numbers in the question \"confuse\" the LM which generates irrational intermediate steps? To investigate this, we evaluated the outputs generated by CoT for the two versions of the same question (with and without large numbers). We find that in 16 out of 25 cases we analyzed, CoT generates nearly identical natural language \"thoughts\", indicating that the primary failure mode is the inability to perform arithmetic accurately. Sample outputs are provided in the Appendix, Table 11."
        },
        {
            "bounding_box": [
                {
                    "x": 461,
                    "y": 1865
                },
                {
                    "x": 968,
                    "y": 1865
                },
                {
                    "x": 968,
                    "y": 2274
                },
                {
                    "x": 461,
                    "y": 2274
                }
            ],
            "category": "table",
            "html": "<table id='77' style='font-size:16px'><tr><td></td><td>GSM8K</td></tr><tr><td>CoT UL2-20B</td><td>7.3</td></tr><tr><td>CoT LaMDA-137B</td><td>27.7</td></tr><tr><td>CoT Codex</td><td>78.0</td></tr><tr><td>CoT PaLM-540B</td><td>74.4</td></tr><tr><td>CoT Minerva 540B</td><td>78.5</td></tr><tr><td>PAL Codex</td><td>80.4</td></tr></table>",
            "id": 77,
            "page": 6,
            "text": "GSM8K  CoT UL2-20B 7.3  CoT LaMDA-137B 27.7  CoT Codex 78.0  CoT PaLM-540B 74.4  CoT Minerva 540B 78.5  PAL Codex"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2308
                },
                {
                    "x": 1215,
                    "y": 2308
                },
                {
                    "x": 1215,
                    "y": 2410
                },
                {
                    "x": 223,
                    "y": 2410
                }
            ],
            "category": "caption",
            "html": "<caption id='78' style='font-size:18px'>Table 3: Problem solve rate (%) on GSM8K using<br>ma jority@40 (Wang et al., 2022b)</caption>",
            "id": 78,
            "page": 6,
            "text": "Table 3: Problem solve rate (%) on GSM8K using ma jority@40 (Wang , 2022b)"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 2493
                },
                {
                    "x": 1215,
                    "y": 2493
                },
                {
                    "x": 1215,
                    "y": 2995
                },
                {
                    "x": 222,
                    "y": 2995
                }
            ],
            "category": "paragraph",
            "html": "<p id='79' style='font-size:18px'>Multi-sample Generation As found by Wang et al.<br>(2022b), chain-of-thought-style methods can be further im-<br>proved by sampling k > 1 outputs, and selecting the final<br>answer using majority voting. We thus repeated the greedy-<br>decoding experiments using nucleus sampling (Holtzman<br>et al., 2019) with p = 0.95 and k = 40 as in Lewkowycz<br>et al. (2022) and temperature of 0.7. As shown in Table 3,<br>this further increases the accuracy of PAL from 72.0% to<br>80.4% on GSM8K, obtaining 1.9% higher accuracy than<br>Minerva-540B using the same number of samples.</p>",
            "id": 79,
            "page": 6,
            "text": "Multi-sample Generation As found by Wang  (2022b), chain-of-thought-style methods can be further improved by sampling k > 1 outputs, and selecting the final answer using majority voting. We thus repeated the greedydecoding experiments using nucleus sampling (Holtzman , 2019) with p = 0.95 and k = 40 as in Lewkowycz  (2022) and temperature of 0.7. As shown in Table 3, this further increases the accuracy of PAL from 72.0% to 80.4% on GSM8K, obtaining 1.9% higher accuracy than Minerva-540B using the same number of samples."
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 903
                },
                {
                    "x": 2238,
                    "y": 903
                },
                {
                    "x": 2238,
                    "y": 951
                },
                {
                    "x": 1272,
                    "y": 951
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='80' style='font-size:22px'>5.2. Symbolic Reasoning & Algorithmic Tasks Results</p>",
            "id": 80,
            "page": 6,
            "text": "5.2. Symbolic Reasoning & Algorithmic Tasks Results"
        },
        {
            "bounding_box": [
                {
                    "x": 1271,
                    "y": 982
                },
                {
                    "x": 2266,
                    "y": 982
                },
                {
                    "x": 2266,
                    "y": 1282
                },
                {
                    "x": 1271,
                    "y": 1282
                }
            ],
            "category": "paragraph",
            "html": "<p id='81' style='font-size:18px'>Results for symbolic reasoning and algorithmic tasks are<br>shown in Table 2. In COLORED OBJECTS, PAL improves<br>over the strong CoT by 8.8%, and by 19.4% over the stan-<br>dard direct prompting. In PENGUINS, PAL provides a gain<br>of absolute 14.1% over CoT. In DATE, PAL further provides<br>11.4% gain over both CoT Codex, PaLM-540B, and LaMDA-137B·</p>",
            "id": 81,
            "page": 6,
            "text": "Results for symbolic reasoning and algorithmic tasks are shown in Table 2. In COLORED OBJECTS, PAL improves over the strong CoT by 8.8%, and by 19.4% over the standard direct prompting. In PENGUINS, PAL provides a gain of absolute 14.1% over CoT. In DATE, PAL further provides 11.4% gain over both CoT Codex, PaLM-540B, and LaMDA-137B·"
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 1304
                },
                {
                    "x": 2266,
                    "y": 1304
                },
                {
                    "x": 2266,
                    "y": 1653
                },
                {
                    "x": 1273,
                    "y": 1653
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='82' style='font-size:20px'>The two rightmost columns of Table 2 show that PAL is<br>close to solving OBJECT COUNTING, reaching 96.7% and<br>improving over CoT by absolute 23.7%. Similarly, PAL<br>vastly outperforms CoT by absolute 21.8% on REPEAT<br>COPY. Surprisingly, DIRECT prompting performs better<br>than CoT on REPEAT COPY. Yet, PAL improves over<br>DIRECT by 9.3% in REPEAT COPY.</p>",
            "id": 82,
            "page": 6,
            "text": "The two rightmost columns of Table 2 show that PAL is close to solving OBJECT COUNTING, reaching 96.7% and improving over CoT by absolute 23.7%. Similarly, PAL vastly outperforms CoT by absolute 21.8% on REPEAT COPY. Surprisingly, DIRECT prompting performs better than CoT on REPEAT COPY. Yet, PAL improves over DIRECT by 9.3% in REPEAT COPY."
        },
        {
            "bounding_box": [
                {
                    "x": 1282,
                    "y": 1722
                },
                {
                    "x": 2308,
                    "y": 1722
                },
                {
                    "x": 2308,
                    "y": 2258
                },
                {
                    "x": 1282,
                    "y": 2258
                }
            ],
            "category": "figure",
            "html": "<figure><img id='83' style='font-size:14px' alt=\"1\nAccuracy\n0.8\nPaL\n0.6\n-▲- CoT\n[0,2] [3,5] [6,8] [9.11/[12.14/15.17/18.20/21.23/24,25]\nNumber of Objects\" data-coord=\"top-left:(1282,1722); bottom-right:(2308,2258)\" /></figure>",
            "id": 83,
            "page": 6,
            "text": "1 Accuracy 0.8 PaL 0.6 -▲- CoT    [9.11/[12.14/15.17/18.20/21.23/24,25] Number of Objects"
        },
        {
            "bounding_box": [
                {
                    "x": 1274,
                    "y": 2302
                },
                {
                    "x": 2266,
                    "y": 2302
                },
                {
                    "x": 2266,
                    "y": 2405
                },
                {
                    "x": 1274,
                    "y": 2405
                }
            ],
            "category": "caption",
            "html": "<caption id='84' style='font-size:16px'>Figure 6: The solve rate on COLORED OBJECTS with re-<br>spect to the number of objects included in the test question.</caption>",
            "id": 84,
            "page": 6,
            "text": "Figure 6: The solve rate on COLORED OBJECTS with respect to the number of objects included in the test question."
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 2542
                },
                {
                    "x": 2267,
                    "y": 2542
                },
                {
                    "x": 2267,
                    "y": 2995
                },
                {
                    "x": 1272,
                    "y": 2995
                }
            ],
            "category": "paragraph",
            "html": "<p id='85' style='font-size:18px'>Is PAL sensitive to the complexity of the question? We<br>examined how the performance of PAL and CoT change as<br>the complexity of the input question grows, measured as the<br>number of objects in the question of COLORED OBJECTS.<br>As shown in Figure 6, PAL is superior CoT across all input<br>lengths. As the number of objects in the question increases,<br>COT's accuracy is unstable and drops, while PAL remains<br>consistently close to 100%. More analysis on the token-level<br>predictions can be found in Appendix G.</p>",
            "id": 85,
            "page": 6,
            "text": "Is PAL sensitive to the complexity of the question? We examined how the performance of PAL and CoT change as the complexity of the input question grows, measured as the number of objects in the question of COLORED OBJECTS. As shown in Figure 6, PAL is superior CoT across all input lengths. As the number of objects in the question increases, COT's accuracy is unstable and drops, while PAL remains consistently close to 100%. More analysis on the token-level predictions can be found in Appendix G."
        },
        {
            "bounding_box": [
                {
                    "x": 916,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 236
                },
                {
                    "x": 916,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='86' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 86,
            "page": 7,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2231,
                    "y": 191
                },
                {
                    "x": 2260,
                    "y": 191
                },
                {
                    "x": 2260,
                    "y": 229
                },
                {
                    "x": 2231,
                    "y": 229
                }
            ],
            "category": "header",
            "html": "<br><header id='87' style='font-size:14px'>7</header>",
            "id": 87,
            "page": 7,
            "text": "7"
        },
        {
            "bounding_box": [
                {
                    "x": 226,
                    "y": 284
                },
                {
                    "x": 1222,
                    "y": 284
                },
                {
                    "x": 1222,
                    "y": 779
                },
                {
                    "x": 226,
                    "y": 779
                }
            ],
            "category": "figure",
            "html": "<figure><img id='88' style='font-size:14px' alt=\"80\n● - PAL 72.0\n▲ CoT\n60\nWoo Relative Improvement 60.1\nrate\n40\nSolve\n31.8\n21.7 26.0\n20\n19.1 22.3%\n19.8%\n13.6%\n0\ncode-cushman-001 code-davinci-001 code-davinci-002\" data-coord=\"top-left:(226,284); bottom-right:(1222,779)\" /></figure>",
            "id": 88,
            "page": 7,
            "text": "80 ● - PAL 72.0 ▲ CoT 60 Woo Relative Improvement 60.1 rate 40 Solve 31.8 21.7 26.0 20 19.1 22.3% 19.8% 13.6% 0 code-cushman-001 code-davinci-001 code-davinci-002"
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 814
                },
                {
                    "x": 1156,
                    "y": 814
                },
                {
                    "x": 1156,
                    "y": 1066
                },
                {
                    "x": 221,
                    "y": 1066
                }
            ],
            "category": "caption",
            "html": "<caption id='89' style='font-size:16px'>Figure 7: PAL with different models on GSM8K: though<br>the absolute accuracies with code-cushman-001<br>and code-davinci-001 are lower than<br>code-davinci-002, the relative improvement of<br>PAL over CoT is consistent across models.</caption>",
            "id": 89,
            "page": 7,
            "text": "Figure 7: PAL with different models on GSM8K: though the absolute accuracies with code-cushman-001 and code-davinci-001 are lower than code-davinci-002, the relative improvement of PAL over CoT is consistent across models."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 1158
                },
                {
                    "x": 465,
                    "y": 1158
                },
                {
                    "x": 465,
                    "y": 1213
                },
                {
                    "x": 225,
                    "y": 1213
                }
            ],
            "category": "paragraph",
            "html": "<p id='90' style='font-size:22px'>6. Analysis</p>",
            "id": 90,
            "page": 7,
            "text": "6. Analysis"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1239
                },
                {
                    "x": 1218,
                    "y": 1239
                },
                {
                    "x": 1218,
                    "y": 1795
                },
                {
                    "x": 223,
                    "y": 1795
                }
            ],
            "category": "paragraph",
            "html": "<p id='91' style='font-size:16px'>Does PAL work with weaker LMs? In all our experi-<br>ments in Section 5, PAL used the code-davinci-002<br>model; but can PAL work with weaker models of code? We<br>compared PAL with CoT when both prompting approaches<br>use the same weaker base LMs code-cushman-001<br>and code-davinci-001. As shown in Figure 7, even<br>though the absolute accuracies of code-cushman-001<br>and code-davinci -001 are lower, the relative improve-<br>ment of PAL over CoT remains consistent across models.<br>This shows that PAL can work with weaker models, while<br>its benefit scales elegantly to stronger models as well.</p>",
            "id": 91,
            "page": 7,
            "text": "Does PAL work with weaker LMs? In all our experiments in Section 5, PAL used the code-davinci-002 model; but can PAL work with weaker models of code? We compared PAL with CoT when both prompting approaches use the same weaker base LMs code-cushman-001 and code-davinci-001. As shown in Figure 7, even though the absolute accuracies of code-cushman-001 and code-davinci -001 are lower, the relative improvement of PAL over CoT remains consistent across models. This shows that PAL can work with weaker models, while its benefit scales elegantly to stronger models as well."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1842
                },
                {
                    "x": 1216,
                    "y": 1842
                },
                {
                    "x": 1216,
                    "y": 2446
                },
                {
                    "x": 224,
                    "y": 2446
                }
            ],
            "category": "paragraph",
            "html": "<p id='92' style='font-size:18px'>Does PAL work with LMs of natural language? We<br>also experimented with PAL using the text-davinci<br>series. Figure 8 shows the following interesting re-<br>sults: when the base LM's \"code modeling ability\" is<br>weak (using text-davinci-001), CoT performs better<br>than PAL. However, once the LM's code modeling abil-<br>ity is sufficiently high (using text-davinci-002 and<br>text-davinci -003), PAL outperforms CoT, and PAL<br>text-davinci-003 performs almost as PAL<br>code-davinci-002·<br>This shows that PAL is not limited to LMs of code, but it<br>can work with LMs that were mainly trained for natural<br>language, if they have a sufficiently high coding ability.</p>",
            "id": 92,
            "page": 7,
            "text": "Does PAL work with LMs of natural language? We also experimented with PAL using the text-davinci series. Figure 8 shows the following interesting results: when the base LM's \"code modeling ability\" is weak (using text-davinci-001), CoT performs better than PAL. However, once the LM's code modeling ability is sufficiently high (using text-davinci-002 and text-davinci -003), PAL outperforms CoT, and PAL text-davinci-003 performs almost as PAL code-davinci-002· This shows that PAL is not limited to LMs of code, but it can work with LMs that were mainly trained for natural language, if they have a sufficiently high coding ability."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2492
                },
                {
                    "x": 1216,
                    "y": 2492
                },
                {
                    "x": 1216,
                    "y": 2995
                },
                {
                    "x": 223,
                    "y": 2995
                }
            ],
            "category": "paragraph",
            "html": "<p id='93' style='font-size:18px'>Is PAL better because of the Python prompt or because<br>of the interpreter? We experimented with generating<br>Python code, while requiring the neural LM to \"execute\" it<br>as well, without using an interpreter, following Nye et al.<br>(2021); Madaan et al. (2022). We created prompts that are<br>similar to PAL's, except that they do include the final answer.<br>This resulted in a 23.2 solve rate on GSM8K, much lower<br>than PAL (72.0), and only 4.5 points higher than DIRECT.<br>These results reinforce our hypothesis that the main benefit<br>of PAL comes from the synergy with the interpreter, and</p>",
            "id": 93,
            "page": 7,
            "text": "Is PAL better because of the Python prompt or because of the interpreter? We experimented with generating Python code, while requiring the neural LM to \"execute\" it as well, without using an interpreter, following Nye  (2021); Madaan  (2022). We created prompts that are similar to PAL's, except that they do include the final answer. This resulted in a 23.2 solve rate on GSM8K, much lower than PAL (72.0), and only 4.5 points higher than DIRECT. These results reinforce our hypothesis that the main benefit of PAL comes from the synergy with the interpreter, and"
        },
        {
            "bounding_box": [
                {
                    "x": 1303,
                    "y": 286
                },
                {
                    "x": 2220,
                    "y": 286
                },
                {
                    "x": 2220,
                    "y": 727
                },
                {
                    "x": 1303,
                    "y": 727
                }
            ],
            "category": "figure",
            "html": "<br><figure><img id='94' style='font-size:16px' alt=\"80\n0. CoT . PAL 69.8\n65.8 65.3\n60\n46.9\n40\n26.5\n20\n8.6\n0\" data-coord=\"top-left:(1303,286); bottom-right:(2220,727)\" /></figure>",
            "id": 94,
            "page": 7,
            "text": "80 0. CoT . PAL 69.8 65.8 65.3 60 46.9 40 26.5 20 8.6 0"
        },
        {
            "bounding_box": [
                {
                    "x": 1347,
                    "y": 738
                },
                {
                    "x": 2229,
                    "y": 738
                },
                {
                    "x": 2229,
                    "y": 783
                },
                {
                    "x": 1347,
                    "y": 783
                }
            ],
            "category": "caption",
            "html": "<br><caption id='95' style='font-size:16px'>text-davinci-001 text-davinci-002 text-davinci-003</caption>",
            "id": 95,
            "page": 7,
            "text": "text-davinci-001 text-davinci-002 text-davinci-003"
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 823
                },
                {
                    "x": 2264,
                    "y": 823
                },
                {
                    "x": 2264,
                    "y": 1076
                },
                {
                    "x": 1273,
                    "y": 1076
                }
            ],
            "category": "paragraph",
            "html": "<p id='96' style='font-size:16px'>Figure 8: PAL with NL LMs on GSM8K: though<br>CoT outperforms PAL with text-davinci-001, once<br>the base LM is sufficiently strong, PAL is beneficial<br>with text-davinci-002 and text-davinci-003<br>as well. That is, PAL is not limited to code-LMs only.</p>",
            "id": 96,
            "page": 7,
            "text": "Figure 8: PAL with NL LMs on GSM8K: though CoT outperforms PAL with text-davinci-001, once the base LM is sufficiently strong, PAL is beneficial with text-davinci-002 and text-davinci-003 as well. That is, PAL is not limited to code-LMs only."
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 1165
                },
                {
                    "x": 2263,
                    "y": 1165
                },
                {
                    "x": 2263,
                    "y": 1364
                },
                {
                    "x": 1273,
                    "y": 1364
                }
            ],
            "category": "paragraph",
            "html": "<p id='97' style='font-size:16px'>not only from having a better prompt. Additional details<br>are provided in Appendix B. For additional discussion on<br>the advantages of code-prompts over textual-prompts, see<br>Appendix G.</p>",
            "id": 97,
            "page": 7,
            "text": "not only from having a better prompt. Additional details are provided in Appendix B. For additional discussion on the advantages of code-prompts over textual-prompts, see Appendix G."
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 1413
                },
                {
                    "x": 2266,
                    "y": 1413
                },
                {
                    "x": 2266,
                    "y": 1715
                },
                {
                    "x": 1273,
                    "y": 1715
                }
            ],
            "category": "paragraph",
            "html": "<p id='98' style='font-size:16px'>Do variable names matter? In all our experiments, we<br>used meaningful variable names in the PAL prompts, to ease<br>the model's grounding of variables to the entities they rep-<br>resent. For the Python interpreter, however, variable names<br>are meaningless. To measure the importance of meaningful<br>variable names, we experimented with two prompts variants:</p>",
            "id": 98,
            "page": 7,
            "text": "Do variable names matter? In all our experiments, we used meaningful variable names in the PAL prompts, to ease the model's grounding of variables to the entities they represent. For the Python interpreter, however, variable names are meaningless. To measure the importance of meaningful variable names, we experimented with two prompts variants:"
        },
        {
            "bounding_box": [
                {
                    "x": 1303,
                    "y": 1762
                },
                {
                    "x": 2265,
                    "y": 1762
                },
                {
                    "x": 2265,
                    "y": 2044
                },
                {
                    "x": 1303,
                    "y": 2044
                }
            ],
            "category": "paragraph",
            "html": "<p id='99' style='font-size:14px'>1. PAL_comment - the PAL prompt without intermediate<br>NL comments.<br>2. PAL -var - the PAL prompt without intermediate<br>comment<br>NL comments and with variable names substituted<br>with random characters.</p>",
            "id": 99,
            "page": 7,
            "text": "1. PAL_comment - the PAL prompt without intermediate NL comments. 2. PAL -var - the PAL prompt without intermediate comment NL comments and with variable names substituted with random characters."
        },
        {
            "bounding_box": [
                {
                    "x": 1270,
                    "y": 2092
                },
                {
                    "x": 2265,
                    "y": 2092
                },
                {
                    "x": 2265,
                    "y": 2696
                },
                {
                    "x": 1270,
                    "y": 2696
                }
            ],
            "category": "paragraph",
            "html": "<p id='100' style='font-size:18px'>The results are shown in Figure 9. In COLORED OBJECTED<br>and DATE, removing intermediate NL comments but keep-<br>ing meaningful variable names (PAL-comment) - slightly re-<br>duces the results compared to the full PAL prompt, butit still<br>achieves higher accuracy than the baselines CoT. Remov-<br>ing variable names as well (PAL =comment) further decreases<br>accuracy, and performs worse than CoT. Since variable<br>names have an important part in code quality (Gellenbeck<br>& Cook, 1991 ; Takang et al., 1996), meaningful variable<br>names are only expected to ease reasoning for Codex, which<br>was trained on mostly meaningful names, as was also found<br>by Madaan et al. (2022).</p>",
            "id": 100,
            "page": 7,
            "text": "The results are shown in Figure 9. In COLORED OBJECTED and DATE, removing intermediate NL comments but keeping meaningful variable names (PAL-comment) - slightly reduces the results compared to the full PAL prompt, butit still achieves higher accuracy than the baselines CoT. Removing variable names as well (PAL =comment) further decreases accuracy, and performs worse than CoT. Since variable names have an important part in code quality (Gellenbeck & Cook, 1991 ; Takang , 1996), meaningful variable names are only expected to ease reasoning for Codex, which was trained on mostly meaningful names, as was also found by Madaan  (2022)."
        },
        {
            "bounding_box": [
                {
                    "x": 1275,
                    "y": 2756
                },
                {
                    "x": 1631,
                    "y": 2756
                },
                {
                    "x": 1631,
                    "y": 2808
                },
                {
                    "x": 1275,
                    "y": 2808
                }
            ],
            "category": "paragraph",
            "html": "<p id='101' style='font-size:20px'>7. Related Work</p>",
            "id": 101,
            "page": 7,
            "text": "7. Related Work"
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 2843
                },
                {
                    "x": 2264,
                    "y": 2843
                },
                {
                    "x": 2264,
                    "y": 2994
                },
                {
                    "x": 1273,
                    "y": 2994
                }
            ],
            "category": "paragraph",
            "html": "<p id='102' style='font-size:16px'>Prompting Few-shot prompting (Brown et al., 2020) has<br>been shown to be an effective approach for a variety of<br>tasks (Liu et al., 2021) ranging from text- (Gehrmann et al.,</p>",
            "id": 102,
            "page": 7,
            "text": "Prompting Few-shot prompting (Brown , 2020) has been shown to be an effective approach for a variety of tasks (Liu , 2021) ranging from text- (Gehrmann ,"
        },
        {
            "bounding_box": [
                {
                    "x": 916,
                    "y": 190
                },
                {
                    "x": 1558,
                    "y": 190
                },
                {
                    "x": 1558,
                    "y": 236
                },
                {
                    "x": 916,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='103' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 103,
            "page": 8,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2231,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 231
                },
                {
                    "x": 2231,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='104' style='font-size:14px'>8</header>",
            "id": 104,
            "page": 8,
            "text": "8"
        },
        {
            "bounding_box": [
                {
                    "x": 338,
                    "y": 287
                },
                {
                    "x": 2158,
                    "y": 287
                },
                {
                    "x": 2158,
                    "y": 776
                },
                {
                    "x": 338,
                    "y": 776
                }
            ],
            "category": "figure",
            "html": "<figure><img id='105' style='font-size:14px' alt=\"100 0. CoT IIPAL 00 PAL comment PAL var\n95.2\ncomment 93.3\n91.1 91.3 91.9\n90\n84.4\n79.9 79.2\n80 76.2\n69.1\n70\n64.8\n63.4\n60\nColored Objects Date Penguins\" data-coord=\"top-left:(338,287); bottom-right:(2158,776)\" /></figure>",
            "id": 105,
            "page": 8,
            "text": "100 0. CoT IIPAL 00 PAL comment PAL var 95.2 comment 93.3 91.1 91.3 91.9 90 84.4 79.9 79.2 80 76.2 69.1 70 64.8 63.4 60 Colored Objects Date Penguins"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 821
                },
                {
                    "x": 2265,
                    "y": 821
                },
                {
                    "x": 2265,
                    "y": 978
                },
                {
                    "x": 222,
                    "y": 978
                }
            ],
            "category": "caption",
            "html": "<caption id='106' style='font-size:16px'>Figure 9: Ablation study of PAL prompt formats. We consider the original PAL prompt, it with natural language comments<br>removed (PAL-comment), and further variable names replaced with random character (PAL_comment). As a reference, we also<br>show the CoT performance (blue).</caption>",
            "id": 106,
            "page": 8,
            "text": "Figure 9: Ablation study of PAL prompt formats. We consider the original PAL prompt, it with natural language comments removed (PAL-comment), and further variable names replaced with random character (PAL_comment). As a reference, we also show the CoT performance (blue)."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1058
                },
                {
                    "x": 1218,
                    "y": 1058
                },
                {
                    "x": 1218,
                    "y": 1764
                },
                {
                    "x": 223,
                    "y": 1764
                }
            ],
            "category": "paragraph",
            "html": "<p id='107' style='font-size:16px'>2021 ; Reif et al., 2021 ; Wei et al., 2021; Sanh et al., 2021)<br>to code-generation (Chen et al., 2021b). Methods such as<br>chain-of-thought prompting (CoT) have further unlocked a<br>variety of reasoning tasks, boosting the performance of mod-<br>els on a variety of benchmarks. Nevertheless, all previous<br>approaches suffer from inaccuracy in arithmetic calculation<br>and incorrect reasoning (Lewkowycz et al., 2022; Hendrycks<br>et al., 2021 ; Madaan & Yazdanbakhsh, 2022). PAL avoids<br>these problems by offloading the calculation and some of<br>the reasoning to a Python interpreter, which is correct by<br>construction, given the right program. Further, not only<br>that PAL can improve the standard chain-of-thought, it can<br>improve least-to-most prompting (Zhou et al., 2022) as well,<br>as we show in Appendix I.</p>",
            "id": 107,
            "page": 8,
            "text": "2021 ; Reif , 2021 ; Wei , 2021; Sanh , 2021) to code-generation (Chen , 2021b). Methods such as chain-of-thought prompting (CoT) have further unlocked a variety of reasoning tasks, boosting the performance of models on a variety of benchmarks. Nevertheless, all previous approaches suffer from inaccuracy in arithmetic calculation and incorrect reasoning (Lewkowycz , 2022; Hendrycks , 2021 ; Madaan & Yazdanbakhsh, 2022). PAL avoids these problems by offloading the calculation and some of the reasoning to a Python interpreter, which is correct by construction, given the right program. Further, not only that PAL can improve the standard chain-of-thought, it can improve least-to-most prompting (Zhou , 2022) as well, as we show in Appendix I."
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 1844
                },
                {
                    "x": 1218,
                    "y": 1844
                },
                {
                    "x": 1218,
                    "y": 2997
                },
                {
                    "x": 222,
                    "y": 2997
                }
            ],
            "category": "paragraph",
            "html": "<p id='108' style='font-size:16px'>LMs with external tools Several prior works have<br>equipped neural models with specialized modules. For ex-<br>ample, Cobbe et al. (2021) employ a calculator for arith-<br>metic operations as a post hoc processing, and Demeter<br>& Downey (2020) add specialized modules for generating<br>cities and dates. Unlike these works, PAL generates code<br>for a Python interpreter, which is general enough to handle<br>both arithmetic calculations and dates, without specialized<br>modules and ad-hoc fixes. Chowdhery et al. (2022) and Wei<br>et al. (2022) have also experimented with external calcula-<br>tors; however, the calculator had improved Codex by only<br>2.3% (absolute) on GSM8K and improved PaLM-540B by<br>1.7%, while PAL improves Codex by 6.4% on the same<br>benchmark (Section 5.1). Similarly to our work, Chowd-<br>hery et al. (2022) have also experimented with generating<br>Python code for solving the GSM8K benchmark, but their<br>experiments resulted in lower accuracy than the standard<br>PaLM-540B that uses chain-of-thought. Pi et al. (2022)<br>pretrain the model on execution results of random expres-<br>sions on a calculator, instead of using the solver at test time<br>as well. While their model can hypothetically perform arith-<br>metic better than other pretrained LMs, their results on the<br>SVAMP benchmark are much lower: 57.4% using a T5-11B</p>",
            "id": 108,
            "page": 8,
            "text": "LMs with external tools Several prior works have equipped neural models with specialized modules. For example, Cobbe  (2021) employ a calculator for arithmetic operations as a post hoc processing, and Demeter & Downey (2020) add specialized modules for generating cities and dates. Unlike these works, PAL generates code for a Python interpreter, which is general enough to handle both arithmetic calculations and dates, without specialized modules and ad-hoc fixes. Chowdhery  (2022) and Wei  (2022) have also experimented with external calculators; however, the calculator had improved Codex by only 2.3% (absolute) on GSM8K and improved PaLM-540B by 1.7%, while PAL improves Codex by 6.4% on the same benchmark (Section 5.1). Similarly to our work, Chowdhery  (2022) have also experimented with generating Python code for solving the GSM8K benchmark, but their experiments resulted in lower accuracy than the standard PaLM-540B that uses chain-of-thought. Pi  (2022) pretrain the model on execution results of random expressions on a calculator, instead of using the solver at test time as well. While their model can hypothetically perform arithmetic better than other pretrained LMs, their results on the SVAMP benchmark are much lower: 57.4% using a T5-11B"
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 1063
                },
                {
                    "x": 2264,
                    "y": 1063
                },
                {
                    "x": 2264,
                    "y": 1164
                },
                {
                    "x": 1272,
                    "y": 1164
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='109' style='font-size:16px'>model, while PAL achieves 79.4% on the same benchmark<br>without any specialized pretraining.</p>",
            "id": 109,
            "page": 8,
            "text": "model, while PAL achieves 79.4% on the same benchmark without any specialized pretraining."
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 1188
                },
                {
                    "x": 2267,
                    "y": 1188
                },
                {
                    "x": 2267,
                    "y": 1688
                },
                {
                    "x": 1272,
                    "y": 1688
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='110' style='font-size:16px'>Shortly after a preprint of our work was submitted to arXiv,<br>another related work on \"program of thought prompting\"<br>(Chen et al., 2022) was also submitted to arXiv. Their<br>method is conceptually similar to ours, but PoT (1) only<br>demonstrates efficacy on mathematical problems, whereas<br>we demonstrate gains on symbolic and algorithmic bench-<br>marks as well, and (2) chose benchmark-specific prompt<br>examples, while we used the same prompt examples as pre-<br>vious work, to disentangled the benefit of our approach from<br>the benefit of the choice of examples.</p>",
            "id": 110,
            "page": 8,
            "text": "Shortly after a preprint of our work was submitted to arXiv, another related work on \"program of thought prompting\" (Chen , 2022) was also submitted to arXiv. Their method is conceptually similar to ours, but PoT (1) only demonstrates efficacy on mathematical problems, whereas we demonstrate gains on symbolic and algorithmic benchmarks as well, and (2) chose benchmark-specific prompt examples, while we used the same prompt examples as previous work, to disentangled the benefit of our approach from the benefit of the choice of examples."
        },
        {
            "bounding_box": [
                {
                    "x": 1268,
                    "y": 1944
                },
                {
                    "x": 2267,
                    "y": 1944
                },
                {
                    "x": 2267,
                    "y": 2995
                },
                {
                    "x": 1268,
                    "y": 2995
                }
            ],
            "category": "paragraph",
            "html": "<p id='111' style='font-size:16px'>Semantic parsing Our work can also be seen as a very<br>general form of semantic parsing, where instead of parsing<br>into strict domain-specific languages, the model generates<br>free-form Python code. Some works constrain the decoder<br>using a Context-Free Grammar (CFG) to generate a domain-<br>specific meaning representation (Shin & Van Durme, 2021)<br>or a canonical utterance, which can be converted to a Lisp-<br>like meaning representation (Shin et al., 2021). In contrast,<br>PAL does not require any constraining or domain-specific<br>representations other than Python code. Further, LMs that<br>were pretrained on Python are abundant compared to other<br>domain-specific languages, making Python code a much<br>more preferable representation. Andor et al. (2019) generate<br>task-specific arithmetic operations for reading comprehen-<br>sion tasks; Gupta et al. (2019) design neural modules such<br>as count to deal with arithmetic operations. PAL gener-<br>alizes these works by generating general Python programs,<br>without the need for defining specialized modules. The clos-<br>est work to ours technically may be Binder (Cheng et al.,<br>2022), but it addressed mostly answering questions about<br>tables using SQL and SQL-like Python.</p>",
            "id": 111,
            "page": 8,
            "text": "Semantic parsing Our work can also be seen as a very general form of semantic parsing, where instead of parsing into strict domain-specific languages, the model generates free-form Python code. Some works constrain the decoder using a Context-Free Grammar (CFG) to generate a domainspecific meaning representation (Shin & Van Durme, 2021) or a canonical utterance, which can be converted to a Lisplike meaning representation (Shin , 2021). In contrast, PAL does not require any constraining or domain-specific representations other than Python code. Further, LMs that were pretrained on Python are abundant compared to other domain-specific languages, making Python code a much more preferable representation. Andor  (2019) generate task-specific arithmetic operations for reading comprehension tasks; Gupta  (2019) design neural modules such as count to deal with arithmetic operations. PAL generalizes these works by generating general Python programs, without the need for defining specialized modules. The closest work to ours technically may be Binder (Cheng , 2022), but it addressed mostly answering questions about tables using SQL and SQL-like Python."
        },
        {
            "bounding_box": [
                {
                    "x": 917,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 190
                },
                {
                    "x": 1559,
                    "y": 235
                },
                {
                    "x": 917,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='112' style='font-size:16px'>PAL: Program-aided Language Models</header>",
            "id": 112,
            "page": 9,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2230,
                    "y": 191
                },
                {
                    "x": 2262,
                    "y": 191
                },
                {
                    "x": 2262,
                    "y": 230
                },
                {
                    "x": 2230,
                    "y": 230
                }
            ],
            "category": "header",
            "html": "<br><header id='113' style='font-size:14px'>9</header>",
            "id": 113,
            "page": 9,
            "text": "9"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 276
                },
                {
                    "x": 523,
                    "y": 276
                },
                {
                    "x": 523,
                    "y": 333
                },
                {
                    "x": 223,
                    "y": 333
                }
            ],
            "category": "paragraph",
            "html": "<p id='114' style='font-size:22px'>8. Conclusion</p>",
            "id": 114,
            "page": 9,
            "text": "8. Conclusion"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 363
                },
                {
                    "x": 1218,
                    "y": 363
                },
                {
                    "x": 1218,
                    "y": 1115
                },
                {
                    "x": 222,
                    "y": 1115
                }
            ],
            "category": "paragraph",
            "html": "<p id='115' style='font-size:14px'>We introduce PAL, a new method for natural language rea-<br>soning, using programs as intermediate reasoning steps.<br>Differently from existing LM-based reasoning approaches,<br>the main idea is to offload solving and calculating to an<br>external Python interpreter, instead of using the LLM for<br>both understanding the problem and solving. This results<br>in a final answer that is guaranteed to be accurate, given the<br>correctly predicted programmatic steps. We demonstrate<br>this seamless synergy between an LLM and a Python in-<br>terpreter across 13 tasks from BIG-Bench Hard and other<br>benchmarks. In all these benchmarks, PAL outperforms<br>larger LLMs such as PaLM-540B which use the popular<br>\"chain-of-thought\" method and sets new state-of-the-art ac-<br>curacy on all of them. We believe that these results unlock<br>exciting directions for future neuro-symbolic AI reasoners.</p>",
            "id": 115,
            "page": 9,
            "text": "We introduce PAL, a new method for natural language reasoning, using programs as intermediate reasoning steps. Differently from existing LM-based reasoning approaches, the main idea is to offload solving and calculating to an external Python interpreter, instead of using the LLM for both understanding the problem and solving. This results in a final answer that is guaranteed to be accurate, given the correctly predicted programmatic steps. We demonstrate this seamless synergy between an LLM and a Python interpreter across 13 tasks from BIG-Bench Hard and other benchmarks. In all these benchmarks, PAL outperforms larger LLMs such as PaLM-540B which use the popular \"chain-of-thought\" method and sets new state-of-the-art accuracy on all of them. We believe that these results unlock exciting directions for future neuro-symbolic AI reasoners."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 1175
                },
                {
                    "x": 469,
                    "y": 1175
                },
                {
                    "x": 469,
                    "y": 1229
                },
                {
                    "x": 225,
                    "y": 1229
                }
            ],
            "category": "paragraph",
            "html": "<p id='116' style='font-size:20px'>References</p>",
            "id": 116,
            "page": 9,
            "text": "References"
        },
        {
            "bounding_box": [
                {
                    "x": 227,
                    "y": 1252
                },
                {
                    "x": 1218,
                    "y": 1252
                },
                {
                    "x": 1218,
                    "y": 1851
                },
                {
                    "x": 227,
                    "y": 1851
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='117' style='font-size:18px'>Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, 0.,<br>David, B., Finn, C., Fu, C., Gopalakrishnan, K., Hausman,<br>K., Herzog, A., Ho, D., Hsu, J., Ibarz, J., Ichter, B.,<br>Irpan, A., Jang, E., Ruano, R. J., Jeffrey, K., Jesmonth,<br>S., Joshi, N. J., Julian, R., Kalashnikov, D., Kuang, Y.,<br>Lee, K.-H., Levine, S., Lu, Y., Luu, L., Parada, C., Pastor,<br>P., Quiambao, J., Rao, K., Rettinghouse, J., Reyes, D.,<br>Sermanet, P., Sievers, N., Tan, C., Toshev, A., Vanhoucke,<br>V., Xia, F., Xiao, T., Xu, P., Xu, S., Yan, M., and Zeng,<br>A. Do as I Can, not as I Say: Grounding Language in<br>Robotic Affordances. arXiv preprint arXiv:2204.01691,<br>2022.</p>",
            "id": 117,
            "page": 9,
            "text": "Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, 0., David, B., Finn, C., Fu, C., Gopalakrishnan, K., Hausman, K., Herzog, A., Ho, D., Hsu, J., Ibarz, J., Ichter, B., Irpan, A., Jang, E., Ruano, R. J., Jeffrey, K., Jesmonth, S., Joshi, N. J., Julian, R., Kalashnikov, D., Kuang, Y., Lee, K.-H., Levine, S., Lu, Y., Luu, L., Parada, C., Pastor, P., Quiambao, J., Rao, K., Rettinghouse, J., Reyes, D., Sermanet, P., Sievers, N., Tan, C., Toshev, A., Vanhoucke, V., Xia, F., Xiao, T., Xu, P., Xu, S., Yan, M., and Zeng, A. Do as I Can, not as I Say: Grounding Language in Robotic Affordances. arXiv preprint arXiv:2204.01691, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1889
                },
                {
                    "x": 1216,
                    "y": 1889
                },
                {
                    "x": 1216,
                    "y": 2086
                },
                {
                    "x": 224,
                    "y": 2086
                }
            ],
            "category": "paragraph",
            "html": "<p id='118' style='font-size:16px'>Amini, A., Gabriel, S., Lin, S., Koncel-Kedziorski, R., Choi,<br>Y., and Hajishirzi, H. MathQA: Towards Interpretable<br>Math Word Problem Solving with Operation-Based For-<br>malisms. In ACL, 2019.</p>",
            "id": 118,
            "page": 9,
            "text": "Amini, A., Gabriel, S., Lin, S., Koncel-Kedziorski, R., Choi, Y., and Hajishirzi, H. MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms. In ACL, 2019."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 2124
                },
                {
                    "x": 1215,
                    "y": 2124
                },
                {
                    "x": 1215,
                    "y": 2275
                },
                {
                    "x": 224,
                    "y": 2275
                }
            ],
            "category": "paragraph",
            "html": "<p id='119' style='font-size:18px'>Andor, D., He, L., Lee, K., and Pitler, E. Giving bert a cal-<br>culator: Finding operations and arguments with reading<br>comprehension. arXiv preprint arXiv:1909.00109, 2019.</p>",
            "id": 119,
            "page": 9,
            "text": "Andor, D., He, L., Lee, K., and Pitler, E. Giving bert a calculator: Finding operations and arguments with reading comprehension. arXiv preprint arXiv:1909.00109, 2019."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 2308
                },
                {
                    "x": 1216,
                    "y": 2308
                },
                {
                    "x": 1216,
                    "y": 2709
                },
                {
                    "x": 224,
                    "y": 2709
                }
            ],
            "category": "paragraph",
            "html": "<p id='120' style='font-size:18px'>Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,<br>J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,<br>Askell, A., Agarwal, S., Herbert- Voss, A., Krueger, G.,<br>Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu,<br>J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,<br>Gray, S., Chess, B., Clark, J., Berner, C., McCandlish,<br>S., Radford, A., Sutskever, I., and Amodei, D. Language<br>Models are Few-Shot Learners. In NeurIPS, 2020.</p>",
            "id": 120,
            "page": 9,
            "text": "Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert- Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language Models are Few-Shot Learners. In NeurIPS, 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 2742
                },
                {
                    "x": 1219,
                    "y": 2742
                },
                {
                    "x": 1219,
                    "y": 2994
                },
                {
                    "x": 224,
                    "y": 2994
                }
            ],
            "category": "paragraph",
            "html": "<p id='121' style='font-size:20px'>Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. 0.,<br>Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman,<br>G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf,<br>H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N.,<br>Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter,</p>",
            "id": 121,
            "page": 9,
            "text": "Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. 0., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter,"
        },
        {
            "bounding_box": [
                {
                    "x": 1313,
                    "y": 282
                },
                {
                    "x": 2268,
                    "y": 282
                },
                {
                    "x": 2268,
                    "y": 780
                },
                {
                    "x": 1313,
                    "y": 780
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='122' style='font-size:18px'>C., Tillet, P., Such, F. P., Cummings, D., Plappert, M.,<br>Chantzis, F., Barnes, E., Herbert- Voss, A., Guss, W. H.,<br>Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin,<br>I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr,<br>A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E.,<br>Radford, A., Knight, M., Brundage, M., Murati, M.,<br>Mayer, K., Welinder, P., McGrew, B., Amodei, D., Mc-<br>Candlish, S., Sutskever, I., and Zaremba, W. Evaluating<br>Large Language Models Trained on Code. arXiv preprint<br>arXiv:2107.03374, 2021a.</p>",
            "id": 122,
            "page": 9,
            "text": "C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert- Voss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W. Evaluating Large Language Models Trained on Code. arXiv preprint arXiv:2107.03374, 2021a."
        },
        {
            "bounding_box": [
                {
                    "x": 1274,
                    "y": 812
                },
                {
                    "x": 2267,
                    "y": 812
                },
                {
                    "x": 2267,
                    "y": 1013
                },
                {
                    "x": 1274,
                    "y": 1013
                }
            ],
            "category": "paragraph",
            "html": "<p id='123' style='font-size:16px'>Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. 0.,<br>Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman,<br>G., et al. Evaluating large language models trained on<br>code. arXiv preprint arXiv:2107.03374, 2021b.</p>",
            "id": 123,
            "page": 9,
            "text": "Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. 0., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G.,  Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021b."
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 1043
                },
                {
                    "x": 2265,
                    "y": 1043
                },
                {
                    "x": 2265,
                    "y": 1241
                },
                {
                    "x": 1273,
                    "y": 1241
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='124' style='font-size:18px'>Chen, W., Ma, X., Wang, X., and Cohen, W. W. Program<br>of thoughts prompting: Disentangling computation from<br>reasoning for numerical reasoning tasks. arXiv preprint<br>arXiv:2211.12588, 2022.</p>",
            "id": 124,
            "page": 9,
            "text": "Chen, W., Ma, X., Wang, X., and Cohen, W. W. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 1273
                },
                {
                    "x": 2267,
                    "y": 1273
                },
                {
                    "x": 2267,
                    "y": 1520
                },
                {
                    "x": 1273,
                    "y": 1520
                }
            ],
            "category": "paragraph",
            "html": "<p id='125' style='font-size:18px'>Cheng, Z., Xie, T., Shi, P., Li, C., Nadkarni, R., Hu, Y.,<br>Xiong, C., Radev, D., Ostendorf, M., Zettlemoyer, L.,<br>Smith, N. A., and Yu, T. Binding language models in<br>symbolic languages. arXiv preprint arXiv:2210.02875,<br>2022.</p>",
            "id": 125,
            "page": 9,
            "text": "Cheng, Z., Xie, T., Shi, P., Li, C., Nadkarni, R., Hu, Y., Xiong, C., Radev, D., Ostendorf, M., Zettlemoyer, L., Smith, N. A., and Yu, T. Binding language models in symbolic languages. arXiv preprint arXiv:2210.02875, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 1269,
                    "y": 1550
                },
                {
                    "x": 2268,
                    "y": 1550
                },
                {
                    "x": 2268,
                    "y": 2403
                },
                {
                    "x": 1269,
                    "y": 2403
                }
            ],
            "category": "paragraph",
            "html": "<p id='126' style='font-size:20px'>Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra,<br>G., Roberts, A., Barham, P., Chung, H. W., Sutton,<br>C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko,<br>S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer,<br>N., Prabhakaran, V., Reif, E., Du, N., Hutchinson, B.,<br>Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari,<br>G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev,<br>S., Michalewski, H., Garcia, X., Misra, V., Robinson,<br>K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim,<br>H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D.,<br>Agrawal, S., Omernick, M., Dai, A. M., Pillai, T. S.,<br>Pellat, M., Lewkowycz, A., Moreira, E., Child, R., Polo-<br>ZOV, 0., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz,<br>M., Firat, 0., Catasta, M., Wei, J., Meier-Hellstern, K.,<br>Eck, D., Dean, J., Petrov, S., and Fiedel, N. PaLM: Scal-<br>ing Language Modeling with Pathways. arXiv preprint<br>arXiv:2204.02311, 2022.</p>",
            "id": 126,
            "page": 9,
            "text": "Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsvyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Prabhakaran, V., Reif, E., Du, N., Hutchinson, B., Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari, G., Yin, P., Duke, T., Levskaya, A., Ghemawat, S., Dev, S., Michalewski, H., Garcia, X., Misra, V., Robinson, K., Fedus, L., Zhou, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D., Agrawal, S., Omernick, M., Dai, A. M., Pillai, T. S., Pellat, M., Lewkowycz, A., Moreira, E., Child, R., PoloZOV, 0., Lee, K., Zhou, Z., Wang, X., Saeta, B., Diaz, M., Firat, 0., Catasta, M., Wei, J., Meier-Hellstern, K., Eck, D., Dean, J., Petrov, S., and Fiedel, N. PaLM: Scaling Language Modeling with Pathways. arXiv preprint arXiv:2204.02311, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 2432
                },
                {
                    "x": 2267,
                    "y": 2432
                },
                {
                    "x": 2267,
                    "y": 2630
                },
                {
                    "x": 1272,
                    "y": 2630
                }
            ],
            "category": "paragraph",
            "html": "<p id='127' style='font-size:16px'>Cobbe, K., Kosaraju, V., Bavarian, M., Hilton, J., Nakano,<br>R., Hesse, C., and Schulman, J. Training Veri-<br>fiers to Solve Math Word Problems. arXiv preprint<br>arXiv:2110.14168, 2021.</p>",
            "id": 127,
            "page": 9,
            "text": "Cobbe, K., Kosaraju, V., Bavarian, M., Hilton, J., Nakano, R., Hesse, C., and Schulman, J. Training Verifiers to Solve Math Word Problems. arXiv preprint arXiv:2110.14168, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 1275,
                    "y": 2662
                },
                {
                    "x": 2268,
                    "y": 2662
                },
                {
                    "x": 2268,
                    "y": 2860
                },
                {
                    "x": 1275,
                    "y": 2860
                }
            ],
            "category": "paragraph",
            "html": "<p id='128' style='font-size:16px'>Demeter, D. and Downey, D. Just add functions: A neural-<br>symbolic language model. In Proceedings of the AAAI<br>Conference on Artificial Intelligence, volume 34, pp.<br>7634-7642, 2020.</p>",
            "id": 128,
            "page": 9,
            "text": "Demeter, D. and Downey, D. Just add functions: A neuralsymbolic language model. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 7634-7642, 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 1274,
                    "y": 2891
                },
                {
                    "x": 2264,
                    "y": 2891
                },
                {
                    "x": 2264,
                    "y": 2992
                },
                {
                    "x": 1274,
                    "y": 2992
                }
            ],
            "category": "paragraph",
            "html": "<p id='129' style='font-size:14px'>Garcez, A. d. and Lamb, L. C. Neurosymbolic ai: the 3rd<br>wave. arXiv preprint arXiv:2012.05876, 2020.</p>",
            "id": 129,
            "page": 9,
            "text": "Garcez, A. d. and Lamb, L. C. Neurosymbolic ai: the 3rd wave. arXiv preprint arXiv:2012.05876, 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 191
                },
                {
                    "x": 1548,
                    "y": 191
                },
                {
                    "x": 1548,
                    "y": 235
                },
                {
                    "x": 908,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='130' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 130,
            "page": 10,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2215,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 232
                },
                {
                    "x": 2215,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='131' style='font-size:14px'>10</header>",
            "id": 131,
            "page": 10,
            "text": "10"
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 281
                },
                {
                    "x": 1220,
                    "y": 281
                },
                {
                    "x": 1220,
                    "y": 1082
                },
                {
                    "x": 221,
                    "y": 1082
                }
            ],
            "category": "paragraph",
            "html": "<p id='132' style='font-size:22px'>Gehrmann, S., Adewumi, T., Aggarwal, K., Ammana-<br>manchi, P. S., Anuoluwapo, A., Bosselut, A., Chandu,<br>K. R., Clinciu, M., Das, D., Dhole, K. D., Du, W., Dur-<br>mus, E., Dusek, 0., Emezue, C., Gangal, V., Garbacea,<br>C., Hashimoto, T., Hou, Y., Jernite, Y., Jhamtani, H., Ji,<br>Y., Jolly, S., Kale, M., Kumar, D., Ladhak, F., Madaan, A.,<br>Maddela, M., Mahajan, K., Mahamood, S., Majumder,<br>B. P., Martins, P. H., McMillan-Major, A., Mille, S.,<br>van Miltenburg, E., Nadeem, M., Narayan, S., Niko-<br>laev, V., Niyongabo, R. A., Osei, S., Parikh, A., Perez-<br>Beltrachini, L., Rao, N. R., Raunak, V., Rodriguez, J. D.,<br>Santhanam, S., Sedoc, J., Sellam, T., Shaikh, S., Shimo-<br>rina, A., Cabezudo, M. A. S., Strobelt, H., Subramani, N.,<br>Xu, W., Yang, D., Yerukola, A., and Zhou, J. The GEM<br>Benchmark: Natural Language Generation, its Evaluation<br>and Metrics. arXiv preprint arXiv:2102.01672, 2021.</p>",
            "id": 132,
            "page": 10,
            "text": "Gehrmann, S., Adewumi, T., Aggarwal, K., Ammanamanchi, P. S., Anuoluwapo, A., Bosselut, A., Chandu, K. R., Clinciu, M., Das, D., Dhole, K. D., Du, W., Durmus, E., Dusek, 0., Emezue, C., Gangal, V., Garbacea, C., Hashimoto, T., Hou, Y., Jernite, Y., Jhamtani, H., Ji, Y., Jolly, S., Kale, M., Kumar, D., Ladhak, F., Madaan, A., Maddela, M., Mahajan, K., Mahamood, S., Majumder, B. P., Martins, P. H., McMillan-Major, A., Mille, S., van Miltenburg, E., Nadeem, M., Narayan, S., Nikolaev, V., Niyongabo, R. A., Osei, S., Parikh, A., PerezBeltrachini, L., Rao, N. R., Raunak, V., Rodriguez, J. D., Santhanam, S., Sedoc, J., Sellam, T., Shaikh, S., Shimorina, A., Cabezudo, M. A. S., Strobelt, H., Subramani, N., Xu, W., Yang, D., Yerukola, A., and Zhou, J. The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics. arXiv preprint arXiv:2102.01672, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1124
                },
                {
                    "x": 1216,
                    "y": 1124
                },
                {
                    "x": 1216,
                    "y": 1374
                },
                {
                    "x": 224,
                    "y": 1374
                }
            ],
            "category": "paragraph",
            "html": "<p id='133' style='font-size:18px'>Gellenbeck, E. M. and Cook, C. R. An investigation of<br>procedure and variable names as beacons during program<br>comprehension. In Empirical studies of programmers:<br>Fourth workshop, pp. 65-81. Ablex Publishing, Norwood,<br>NJ, 1991.</p>",
            "id": 133,
            "page": 10,
            "text": "Gellenbeck, E. M. and Cook, C. R. An investigation of procedure and variable names as beacons during program comprehension. In Empirical studies of programmers: Fourth workshop, pp. 65-81. Ablex Publishing, Norwood, NJ, 1991."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1421
                },
                {
                    "x": 1216,
                    "y": 1421
                },
                {
                    "x": 1216,
                    "y": 1570
                },
                {
                    "x": 223,
                    "y": 1570
                }
            ],
            "category": "paragraph",
            "html": "<p id='134' style='font-size:20px'>Gupta, N., Lin, K., Roth, D., Singh, S., and Gardner, M.<br>Neural module networks for reasoning over text. arXiv<br>preprint arXiv:1912.04971, 2019.</p>",
            "id": 134,
            "page": 10,
            "text": "Gupta, N., Lin, K., Roth, D., Singh, S., and Gardner, M. Neural module networks for reasoning over text. arXiv preprint arXiv:1912.04971, 2019."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1615
                },
                {
                    "x": 1215,
                    "y": 1615
                },
                {
                    "x": 1215,
                    "y": 1865
                },
                {
                    "x": 224,
                    "y": 1865
                }
            ],
            "category": "paragraph",
            "html": "<p id='135' style='font-size:20px'>Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart,<br>S., Tang, E., Song, D., and Steinhardt, J. Measuring<br>mathematical problem solving with the MATH dataset,<br>2021. URL https : / / openreview net / forum?<br>id=7Bywt2mQsCe.</p>",
            "id": 135,
            "page": 10,
            "text": "Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., and Steinhardt, J. Measuring mathematical problem solving with the MATH dataset, 2021. URL https : / / openreview net / forum? id=7Bywt2mQsCe."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1909
                },
                {
                    "x": 1215,
                    "y": 1909
                },
                {
                    "x": 1215,
                    "y": 2057
                },
                {
                    "x": 223,
                    "y": 2057
                }
            ],
            "category": "paragraph",
            "html": "<p id='136' style='font-size:20px'>Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y.<br>The Curious Case of Neural Text Degeneration. In ICLR,<br>2019.</p>",
            "id": 136,
            "page": 10,
            "text": "Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The Curious Case of Neural Text Degeneration. In ICLR, 2019."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 2105
                },
                {
                    "x": 1216,
                    "y": 2105
                },
                {
                    "x": 1216,
                    "y": 2402
                },
                {
                    "x": 225,
                    "y": 2402
                }
            ],
            "category": "paragraph",
            "html": "<p id='137' style='font-size:22px'>Koncel-Kedziorski, R., Roy, S., Amini, A., Kushman, N.,<br>and Hajishirzi, H. Mawps: A math word problem reposi-<br>tory. In Proceedings of the 2016 Conference of the North<br>American Chapter of the Association for Computational<br>Linguistics: Human Language Technologies, pp. 1152-<br>1157, 2016.</p>",
            "id": 137,
            "page": 10,
            "text": "Koncel-Kedziorski, R., Roy, S., Amini, A., Kushman, N., and Hajishirzi, H. Mawps: A math word problem repository. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 11521157, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2447
                },
                {
                    "x": 1217,
                    "y": 2447
                },
                {
                    "x": 1217,
                    "y": 2748
                },
                {
                    "x": 223,
                    "y": 2748
                }
            ],
            "category": "paragraph",
            "html": "<p id='138' style='font-size:22px'>Lewkowycz, A., Andreassen, A., Dohan, D., Dyer, E.,<br>Michalewski, H., Ramasesh, V., Slone, A., Anil, C.,<br>Schlag, I., Gutman-Solo, T., Wu, Y., Neyshabur, B.,<br>Gur-Ari, G., and Misra, V. Solving quantitative rea-<br>soning problems with language models. arXiv preprint<br>arXiv:2206.14858, 2022.</p>",
            "id": 138,
            "page": 10,
            "text": "Lewkowycz, A., Andreassen, A., Dohan, D., Dyer, E., Michalewski, H., Ramasesh, V., Slone, A., Anil, C., Schlag, I., Gutman-Solo, T., Wu, Y., Neyshabur, B., Gur-Ari, G., and Misra, V. Solving quantitative reasoning problems with language models. arXiv preprint arXiv:2206.14858, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 2792
                },
                {
                    "x": 1215,
                    "y": 2792
                },
                {
                    "x": 1215,
                    "y": 2992
                },
                {
                    "x": 224,
                    "y": 2992
                }
            ],
            "category": "paragraph",
            "html": "<p id='139' style='font-size:22px'>Ling, W., Yogatama, D., Dyer, C., and Blunsom, P. Program<br>Induction by Rationale Generation: Learning to Solve<br>and Explain Algebraic Word Problems. arXiv preprint<br>arXiv:1705.04146, 2017.</p>",
            "id": 139,
            "page": 10,
            "text": "Ling, W., Yogatama, D., Dyer, C., and Blunsom, P. Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems. arXiv preprint arXiv:1705.04146, 2017."
        },
        {
            "bounding_box": [
                {
                    "x": 1271,
                    "y": 283
                },
                {
                    "x": 2267,
                    "y": 283
                },
                {
                    "x": 2267,
                    "y": 482
                },
                {
                    "x": 1271,
                    "y": 482
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='140' style='font-size:22px'>Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig,<br>G. Pre-train, Prompt, and Predict: A Systematic Survey<br>of Prompting Methods in Natural Language Processing.<br>arXiv preprint arXiv:2107.13586, 2021.</p>",
            "id": 140,
            "page": 10,
            "text": "Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. arXiv preprint arXiv:2107.13586, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 516
                },
                {
                    "x": 2265,
                    "y": 516
                },
                {
                    "x": 2265,
                    "y": 666
                },
                {
                    "x": 1272,
                    "y": 666
                }
            ],
            "category": "paragraph",
            "html": "<p id='141' style='font-size:14px'>Madaan, A. and Yazdanbakhsh, A. Text and patterns: For<br>effective chain of thought, it takes two to tango. arXiv<br>preprint arXiv:2209.07686, 2022.</p>",
            "id": 141,
            "page": 10,
            "text": "Madaan, A. and Yazdanbakhsh, A. Text and patterns: For effective chain of thought, it takes two to tango. arXiv preprint arXiv:2209.07686, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 698
                },
                {
                    "x": 2265,
                    "y": 698
                },
                {
                    "x": 2265,
                    "y": 848
                },
                {
                    "x": 1273,
                    "y": 848
                }
            ],
            "category": "paragraph",
            "html": "<p id='142' style='font-size:20px'>Madaan, A., Zhou, S., Alon, U., Yang, Y., and Neubig, G.<br>Language models of code are few-shot commonsense<br>learners. arXiv preprint arXiv:2210.07128, 2022.</p>",
            "id": 142,
            "page": 10,
            "text": "Madaan, A., Zhou, S., Alon, U., Yang, Y., and Neubig, G. Language models of code are few-shot commonsense learners. arXiv preprint arXiv:2210.07128, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 1274,
                    "y": 882
                },
                {
                    "x": 2262,
                    "y": 882
                },
                {
                    "x": 2262,
                    "y": 982
                },
                {
                    "x": 1274,
                    "y": 982
                }
            ],
            "category": "paragraph",
            "html": "<p id='143' style='font-size:20px'>Marcus, G. Deep learning: A critical appraisal. arXiv<br>preprint arXiv:1801.00631, 2018.</p>",
            "id": 143,
            "page": 10,
            "text": "Marcus, G. Deep learning: A critical appraisal. arXiv preprint arXiv:1801.00631, 2018."
        },
        {
            "bounding_box": [
                {
                    "x": 1275,
                    "y": 1015
                },
                {
                    "x": 2265,
                    "y": 1015
                },
                {
                    "x": 2265,
                    "y": 1163
                },
                {
                    "x": 1275,
                    "y": 1163
                }
            ],
            "category": "paragraph",
            "html": "<p id='144' style='font-size:16px'>Marcus, G. The next decade in ai: four steps towards robust<br>artificial intelligence. arXiv preprint arXiv:2002.06177,<br>2020.</p>",
            "id": 144,
            "page": 10,
            "text": "Marcus, G. The next decade in ai: four steps towards robust artificial intelligence. arXiv preprint arXiv:2002.06177, 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 1273,
                    "y": 1197
                },
                {
                    "x": 2269,
                    "y": 1197
                },
                {
                    "x": 2269,
                    "y": 1595
                },
                {
                    "x": 1273,
                    "y": 1595
                }
            ],
            "category": "paragraph",
            "html": "<p id='145' style='font-size:18px'>Miao, S.-y., Liang, C.-C., and Su, K.-Y. A diverse cor-<br>pus for evaluating and developing English math word<br>problem solvers. In Proceedings of the 58th Annual Meet-<br>ing of the Association for Computational Linguistics, pp.<br>975-984, Online, July 2020. Association for Compu-<br>tational Linguistics. doi: 10.18653/v1/2020.acl-main.<br>92. URL https : / / aclanthology · org/2020 .<br>acl -main · 92.</p>",
            "id": 145,
            "page": 10,
            "text": "Miao, S.-y., Liang, C.-C., and Su, K.-Y. A diverse corpus for evaluating and developing English math word problem solvers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 975-984, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main. 92. URL https : / / aclanthology · org/2020 . acl -main · 92."
        },
        {
            "bounding_box": [
                {
                    "x": 1275,
                    "y": 1629
                },
                {
                    "x": 2266,
                    "y": 1629
                },
                {
                    "x": 2266,
                    "y": 1929
                },
                {
                    "x": 1275,
                    "y": 1929
                }
            ],
            "category": "paragraph",
            "html": "<p id='146' style='font-size:22px'>Mishra, S., Finlayson, M., Lu, P., Tang, L., Welleck, S.,<br>Baral, C., Rajpurohit, T., Tafjord, 0., Sabharwal, A.,<br>Clark, P., and Kalyan, A. Lila: A unified benchmark<br>for mathematical reasoning. In Proceedings of the 2022<br>Conference on Empirical Methods in Natural Language<br>Processing (EMNLP), 2022.</p>",
            "id": 146,
            "page": 10,
            "text": "Mishra, S., Finlayson, M., Lu, P., Tang, L., Welleck, S., Baral, C., Rajpurohit, T., Tafjord, 0., Sabharwal, A., Clark, P., and Kalyan, A. Lila: A unified benchmark for mathematical reasoning. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 1274,
                    "y": 1961
                },
                {
                    "x": 2266,
                    "y": 1961
                },
                {
                    "x": 2266,
                    "y": 2112
                },
                {
                    "x": 1274,
                    "y": 2112
                }
            ],
            "category": "paragraph",
            "html": "<p id='147' style='font-size:20px'>Nogueira, R., Jiang, Z., and Lin, J. Investigating the limita-<br>tions of transformers with simple arithmetic tasks. arXiv<br>preprint arXiv:2102.13019, 2021.</p>",
            "id": 147,
            "page": 10,
            "text": "Nogueira, R., Jiang, Z., and Lin, J. Investigating the limitations of transformers with simple arithmetic tasks. arXiv preprint arXiv:2102.13019, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 1275,
                    "y": 2146
                },
                {
                    "x": 2267,
                    "y": 2146
                },
                {
                    "x": 2267,
                    "y": 2441
                },
                {
                    "x": 1275,
                    "y": 2441
                }
            ],
            "category": "paragraph",
            "html": "<p id='148' style='font-size:20px'>Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H.,<br>Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma,<br>M., Luan, D., Sutton, C., and Odena, A. Show your<br>Work: Scratchpads for Intermediate Computation with<br>Language Models. arXiv preprint arXiv:2112.00114,<br>2021.</p>",
            "id": 148,
            "page": 10,
            "text": "Nye, M., Andreassen, A. J., Gur-Ari, G., Michalewski, H., Austin, J., Bieber, D., Dohan, D., Lewkowycz, A., Bosma, M., Luan, D., Sutton, C., and Odena, A. Show your Work: Scratchpads for Intermediate Computation with Language Models. arXiv preprint arXiv:2112.00114, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 1275,
                    "y": 2477
                },
                {
                    "x": 2263,
                    "y": 2477
                },
                {
                    "x": 2263,
                    "y": 2626
                },
                {
                    "x": 1275,
                    "y": 2626
                }
            ],
            "category": "paragraph",
            "html": "<p id='149' style='font-size:18px'>Patel, A., Bhattamishra, S., and Goyal, N. Are NLP Models<br>Really Able to Solve Simple Math Word Problems? arXiv<br>preprint arXiv:2103.07191, 2021.</p>",
            "id": 149,
            "page": 10,
            "text": "Patel, A., Bhattamishra, S., and Goyal, N. Are NLP Models Really Able to Solve Simple Math Word Problems? arXiv preprint arXiv:2103.07191, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 1272,
                    "y": 2660
                },
                {
                    "x": 2267,
                    "y": 2660
                },
                {
                    "x": 2267,
                    "y": 2811
                },
                {
                    "x": 1272,
                    "y": 2811
                }
            ],
            "category": "paragraph",
            "html": "<p id='150' style='font-size:22px'>Pi, X., Liu, Q., Chen, B., Ziyadi, M., Lin, Z., Gao, Y., Fu,<br>Q., Lou, J.-G., and Chen, W. Reasoning like program<br>executors. arXiv preprint arXiv:2201.11473, 2022.</p>",
            "id": 150,
            "page": 10,
            "text": "Pi, X., Liu, Q., Chen, B., Ziyadi, M., Lin, Z., Gao, Y., Fu, Q., Lou, J.-G., and Chen, W. Reasoning like program executors. arXiv preprint arXiv:2201.11473, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 1275,
                    "y": 2842
                },
                {
                    "x": 2265,
                    "y": 2842
                },
                {
                    "x": 2265,
                    "y": 2992
                },
                {
                    "x": 1275,
                    "y": 2992
                }
            ],
            "category": "paragraph",
            "html": "<p id='151' style='font-size:20px'>Qian, J., Wang, H., Li, Z., Li, S., and Yan, X. Limitations<br>of language models in arithmetic and symbolic induction.<br>arXiv preprint arXiv:2208.05051, 2022.</p>",
            "id": 151,
            "page": 10,
            "text": "Qian, J., Wang, H., Li, Z., Li, S., and Yan, X. Limitations of language models in arithmetic and symbolic induction. arXiv preprint arXiv:2208.05051, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 191
                },
                {
                    "x": 1548,
                    "y": 191
                },
                {
                    "x": 1548,
                    "y": 235
                },
                {
                    "x": 908,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='152' style='font-size:18px'>PAL: Program-aided Language Models</header>",
            "id": 152,
            "page": 11,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2216,
                    "y": 194
                },
                {
                    "x": 2257,
                    "y": 194
                },
                {
                    "x": 2257,
                    "y": 232
                },
                {
                    "x": 2216,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='153' style='font-size:14px'>11</header>",
            "id": 153,
            "page": 11,
            "text": "11"
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 282
                },
                {
                    "x": 1215,
                    "y": 282
                },
                {
                    "x": 1215,
                    "y": 481
                },
                {
                    "x": 224,
                    "y": 481
                }
            ],
            "category": "paragraph",
            "html": "<p id='154' style='font-size:20px'>Reif, E., Ippolito, D., Yuan, A., Coenen, A., Callison-<br>Burch, C., and Wei, J. A Recipe for Arbitrary Text Style<br>Transfer with Large Language Models. arXiv preprint<br>arXiv:2109.03910, 2021.</p>",
            "id": 154,
            "page": 11,
            "text": "Reif, E., Ippolito, D., Yuan, A., Coenen, A., CallisonBurch, C., and Wei, J. A Recipe for Arbitrary Text Style Transfer with Large Language Models. arXiv preprint arXiv:2109.03910, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 227,
                    "y": 512
                },
                {
                    "x": 1218,
                    "y": 512
                },
                {
                    "x": 1218,
                    "y": 1014
                },
                {
                    "x": 227,
                    "y": 1014
                }
            ],
            "category": "paragraph",
            "html": "<p id='155' style='font-size:22px'>Sanh, V., Webson, A., Raffel, C., Bach, S. H., Sutawika, L.,<br>Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T. L., Raja,<br>A., Dey, M., Bari, M. S., Xu, C., Thakker, U., Sharma,<br>S. S., Szczechla, E., Kim, T., Chhablani, G., Nayak, N.,<br>Datta, D., Chang, J., Jiang, M. T.-J., Wang, H., Manica,<br>M., Shen, S., Yong, Z. X., Pandey, H., Bawden, R., Wang,<br>T., Neeraj, T., Rozen, J., Sharma, A., Santilli, A., Fevry,<br>T., Fries, J. A., Teehan, R., Biderman, S., Gao, L., Bers, T.,<br>Wolf, T., and Rush, A. M. Multitask Prompted Training<br>Enables Zero-Shot Task Generalization, 2021.</p>",
            "id": 155,
            "page": 11,
            "text": "Sanh, V., Webson, A., Raffel, C., Bach, S. H., Sutawika, L., Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T. L., Raja, A., Dey, M., Bari, M. S., Xu, C., Thakker, U., Sharma, S. S., Szczechla, E., Kim, T., Chhablani, G., Nayak, N., Datta, D., Chang, J., Jiang, M. T.-J., Wang, H., Manica, M., Shen, S., Yong, Z. X., Pandey, H., Bawden, R., Wang, T., Neeraj, T., Rozen, J., Sharma, A., Santilli, A., Fevry, T., Fries, J. A., Teehan, R., Biderman, S., Gao, L., Bers, T., Wolf, T., and Rush, A. M. Multitask Prompted Training Enables Zero-Shot Task Generalization, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1044
                },
                {
                    "x": 1215,
                    "y": 1044
                },
                {
                    "x": 1215,
                    "y": 1191
                },
                {
                    "x": 224,
                    "y": 1191
                }
            ],
            "category": "paragraph",
            "html": "<p id='156' style='font-size:16px'>Shin, R. and Van Durme, B. Few-shot semantic parsing<br>with language models trained on code. arXiv preprint<br>arXiv:2112.08696, 2021.</p>",
            "id": 156,
            "page": 11,
            "text": "Shin, R. and Van Durme, B. Few-shot semantic parsing with language models trained on code. arXiv preprint arXiv:2112.08696, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1225
                },
                {
                    "x": 1216,
                    "y": 1225
                },
                {
                    "x": 1216,
                    "y": 1424
                },
                {
                    "x": 224,
                    "y": 1424
                }
            ],
            "category": "paragraph",
            "html": "<p id='157' style='font-size:18px'>Shin, R., Lin, C. H., Thomson, S., Chen, C., Roy, S., Platan-<br>ios, E. A., Pauls, A., Klein, D., Eisner, J., and Van Durme,<br>B. Constrained language models yield few-shot semantic<br>parsers. arXiv preprint arXiv:2104.08768, 2021.</p>",
            "id": 157,
            "page": 11,
            "text": "Shin, R., Lin, C. H., Thomson, S., Chen, C., Roy, S., Platanios, E. A., Pauls, A., Klein, D., Eisner, J., and Van Durme, B. Constrained language models yield few-shot semantic parsers. arXiv preprint arXiv:2104.08768, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 1459
                },
                {
                    "x": 1217,
                    "y": 1459
                },
                {
                    "x": 1217,
                    "y": 1702
                },
                {
                    "x": 225,
                    "y": 1702
                }
            ],
            "category": "paragraph",
            "html": "<p id='158' style='font-size:22px'>Suzgun, M., Scales, N., Scharli, N., Gehrmann, S., Tay, Y.,<br>Chung, H. W., Chowdhery, A., Le, Q. V., Chi, E., Zhou,<br>D., and Wei, J. Challenging big-bench tasks and whether<br>chain-of-thought can solve them. ArXiv, abs/2210.09261,<br>2022.</p>",
            "id": 158,
            "page": 11,
            "text": "Suzgun, M., Scales, N., Scharli, N., Gehrmann, S., Tay, Y., Chung, H. W., Chowdhery, A., Le, Q. V., Chi, E., Zhou, D., and Wei, J. Challenging big-bench tasks and whether chain-of-thought can solve them. ArXiv, abs/2210.09261, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 1737
                },
                {
                    "x": 1214,
                    "y": 1737
                },
                {
                    "x": 1214,
                    "y": 1936
                },
                {
                    "x": 225,
                    "y": 1936
                }
            ],
            "category": "paragraph",
            "html": "<p id='159' style='font-size:16px'>Takang, A. A., Grubb, P. A., and Macredie, R. D. The<br>effects of comments and identifier names on program<br>comprehensibility: an experimental investigation. J. Prog.<br>Lang., 4(3):143-167, 1996.</p>",
            "id": 159,
            "page": 11,
            "text": "Takang, A. A., Grubb, P. A., and Macredie, R. D. The effects of comments and identifier names on program comprehensibility: an experimental investigation. J. Prog. Lang., 4(3):143-167, 1996."
        },
        {
            "bounding_box": [
                {
                    "x": 226,
                    "y": 1969
                },
                {
                    "x": 1215,
                    "y": 1969
                },
                {
                    "x": 1215,
                    "y": 2117
                },
                {
                    "x": 226,
                    "y": 2117
                }
            ],
            "category": "paragraph",
            "html": "<p id='160' style='font-size:20px'>Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and<br>Zhou, D. Rationale-Augmented Ensembles in Language<br>Models. arXiv preprints arXiv:2207.00747, 2022a.</p>",
            "id": 160,
            "page": 11,
            "text": "Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Rationale-Augmented Ensembles in Language Models. arXiv preprints arXiv:2207.00747, 2022a."
        },
        {
            "bounding_box": [
                {
                    "x": 226,
                    "y": 2150
                },
                {
                    "x": 1215,
                    "y": 2150
                },
                {
                    "x": 1215,
                    "y": 2347
                },
                {
                    "x": 226,
                    "y": 2347
                }
            ],
            "category": "paragraph",
            "html": "<p id='161' style='font-size:22px'>Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E.,<br>and Zhou, D. Self-Consistency Improves Chain of<br>Thought Reasoning in Language Models. arXiv preprint<br>arXiv:2203.11171, 2022b.</p>",
            "id": 161,
            "page": 11,
            "text": "Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Self-Consistency Improves Chain of Thought Reasoning in Language Models. arXiv preprint arXiv:2203.11171, 2022b."
        },
        {
            "bounding_box": [
                {
                    "x": 227,
                    "y": 2381
                },
                {
                    "x": 1217,
                    "y": 2381
                },
                {
                    "x": 1217,
                    "y": 2577
                },
                {
                    "x": 227,
                    "y": 2577
                }
            ],
            "category": "paragraph",
            "html": "<p id='162' style='font-size:18px'>Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester,<br>B., Du, N., Dai, A. M., and Le, Q. V. Finetuned Lan-<br>guage Models are Zero-shot Learners. arXiv preprint<br>arXiv:2109.01652, 2021.</p>",
            "id": 162,
            "page": 11,
            "text": "Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V. Finetuned Language Models are Zero-shot Learners. arXiv preprint arXiv:2109.01652, 2021."
        },
        {
            "bounding_box": [
                {
                    "x": 226,
                    "y": 2611
                },
                {
                    "x": 1215,
                    "y": 2611
                },
                {
                    "x": 1215,
                    "y": 2809
                },
                {
                    "x": 226,
                    "y": 2809
                }
            ],
            "category": "paragraph",
            "html": "<p id='163' style='font-size:20px'>Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le,<br>Q., and Zhou, D. Chain of Thought Prompting Elicits<br>Reasoning in Large Language Models. arXiv preprint<br>arXiv:2201.11903, 2022.</p>",
            "id": 163,
            "page": 11,
            "text": "Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou, D. Chain of Thought Prompting Elicits Reasoning in Large Language Models. arXiv preprint arXiv:2201.11903, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 2841
                },
                {
                    "x": 1216,
                    "y": 2841
                },
                {
                    "x": 1216,
                    "y": 2995
                },
                {
                    "x": 225,
                    "y": 2995
                }
            ],
            "category": "paragraph",
            "html": "<p id='164' style='font-size:20px'>Wu, Y., Jiang, A. Q., Li, W., Rabe, M. N., Staats, C., Jamnik,<br>M., and Szegedy, C. Autoformalization with Large Lan-<br>guage Models. arXiv preprint arXiv:2205.12615, 2022.</p>",
            "id": 164,
            "page": 11,
            "text": "Wu, Y., Jiang, A. Q., Li, W., Rabe, M. N., Staats, C., Jamnik, M., and Szegedy, C. Autoformalization with Large Language Models. arXiv preprint arXiv:2205.12615, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 1276,
                    "y": 282
                },
                {
                    "x": 2268,
                    "y": 282
                },
                {
                    "x": 2268,
                    "y": 480
                },
                {
                    "x": 1276,
                    "y": 480
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='165' style='font-size:20px'>Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,<br>K., and Cao, Y. React: Synergizing reasoning and acting<br>in language models. arXiv preprint arXiv:2210.03629,<br>2022.</p>",
            "id": 165,
            "page": 11,
            "text": "Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 1271,
                    "y": 515
                },
                {
                    "x": 2270,
                    "y": 515
                },
                {
                    "x": 2270,
                    "y": 765
                },
                {
                    "x": 1271,
                    "y": 765
                }
            ],
            "category": "paragraph",
            "html": "<p id='166' style='font-size:22px'>Zhou, D., Sch�rli, N., Hou, L., Wei, J., Scales, N., Wang, X.,<br>Schuurmans, D., Bousquet, 0., Le, Q., and Chi, E. Least-<br>to-Most Prompting Enables Complex Reasoning in Large<br>Language Models. arXiv preprint arXiv:2205.10625,<br>2022.</p>",
            "id": 166,
            "page": 11,
            "text": "Zhou, D., Sch�rli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Bousquet, 0., Le, Q., and Chi, E. Leastto-Most Prompting Enables Complex Reasoning in Large Language Models. arXiv preprint arXiv:2205.10625, 2022."
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 236
                },
                {
                    "x": 908,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='167' style='font-size:18px'>PAL: Program-aided Language Models</header>",
            "id": 167,
            "page": 12,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2216,
                    "y": 192
                },
                {
                    "x": 2259,
                    "y": 192
                },
                {
                    "x": 2259,
                    "y": 232
                },
                {
                    "x": 2216,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='168' style='font-size:16px'>12</header>",
            "id": 168,
            "page": 12,
            "text": "12"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 265
                },
                {
                    "x": 592,
                    "y": 265
                },
                {
                    "x": 592,
                    "y": 464
                },
                {
                    "x": 222,
                    "y": 464
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='169' style='font-size:22px'>Part I<br>Appendix</p>",
            "id": 169,
            "page": 12,
            "text": "Part I Appendix"
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 544
                },
                {
                    "x": 687,
                    "y": 544
                },
                {
                    "x": 687,
                    "y": 608
                },
                {
                    "x": 225,
                    "y": 608
                }
            ],
            "category": "caption",
            "html": "<caption id='170' style='font-size:20px'>Table of Contents</caption>",
            "id": 170,
            "page": 12,
            "text": "Table of Contents"
        },
        {
            "bounding_box": [
                {
                    "x": 313,
                    "y": 615
                },
                {
                    "x": 2170,
                    "y": 615
                },
                {
                    "x": 2170,
                    "y": 2294
                },
                {
                    "x": 313,
                    "y": 2294
                }
            ],
            "category": "paragraph",
            "html": "<p id='171' style='font-size:14px'>A Alternative Prompts without Meaningful Variable Names 13<br>B Additional analysis on Arithmetic Reasoning 13<br>C Effect of Using Language Models of Code 14<br>D Analyzing the Effect of Increasing Number of Samples on PAL 14<br>E Standard Deviations Across Multiple Order of Prompts 17<br>F PAL Beyond Benchmarks 17<br>G Closer Look into Token-level Behaviors of Different Mechanisms 20<br>H Datasets 20<br>H.1 Creating GSM-HARD · · · · · · · · · · · · · 23<br>H.2 GSM-HARD Analysis 23<br>I Generalization of PAL to Least-to-Most Prompting 24<br>J Prompts 26<br>J.1 Reasoning about Colored Objects · · · · · · · 26<br>J.2 Penguins in a Table 27<br>J.3 Date Understanding · 28<br>J.4 Math · · 29<br>J.5 Object Counting · 31<br>J.6 Repeat Copy · · · 32<br>K Success and Failure Modes in Symbolic Tasks 33<br>K.1 Colored Objects · · · 33<br>K.2 Penguins in a Table 33<br>K.3 Date Understanding · 34</p>",
            "id": 171,
            "page": 12,
            "text": "A Alternative Prompts without Meaningful Variable Names 13 B Additional analysis on Arithmetic Reasoning 13 C Effect of Using Language Models of Code 14 D Analyzing the Effect of Increasing Number of Samples on PAL 14 E Standard Deviations Across Multiple Order of Prompts 17 F PAL Beyond Benchmarks 17 G Closer Look into Token-level Behaviors of Different Mechanisms 20 H Datasets 20 H.1 Creating GSM-HARD · · · · · · · · · · · · · 23 H.2 GSM-HARD Analysis 23 I Generalization of PAL to Least-to-Most Prompting 24 J Prompts 26 J.1 Reasoning about Colored Objects · · · · · · · 26 J.2 Penguins in a Table 27 J.3 Date Understanding · 28 J.4 Math · · 29 J.5 Object Counting · 31 J.6 Repeat Copy · · · 32 K Success and Failure Modes in Symbolic Tasks 33 K.1 Colored Objects · · · 33 K.2 Penguins in a Table 33 K.3 Date Understanding · 34"
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 191
                },
                {
                    "x": 1546,
                    "y": 191
                },
                {
                    "x": 1546,
                    "y": 235
                },
                {
                    "x": 908,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='172' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 172,
            "page": 13,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2216,
                    "y": 194
                },
                {
                    "x": 2259,
                    "y": 194
                },
                {
                    "x": 2259,
                    "y": 230
                },
                {
                    "x": 2216,
                    "y": 230
                }
            ],
            "category": "header",
            "html": "<br><header id='173' style='font-size:18px'>13</header>",
            "id": 173,
            "page": 13,
            "text": "13"
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 278
                },
                {
                    "x": 1515,
                    "y": 278
                },
                {
                    "x": 1515,
                    "y": 335
                },
                {
                    "x": 225,
                    "y": 335
                }
            ],
            "category": "paragraph",
            "html": "<p id='174' style='font-size:22px'>A. Alternative Prompts without Meaningful Variable Names</p>",
            "id": 174,
            "page": 13,
            "text": "A. Alternative Prompts without Meaningful Variable Names"
        },
        {
            "bounding_box": [
                {
                    "x": 278,
                    "y": 390
                },
                {
                    "x": 498,
                    "y": 390
                },
                {
                    "x": 498,
                    "y": 641
                },
                {
                    "x": 278,
                    "y": 641
                }
            ],
            "category": "paragraph",
            "html": "<p id='175' style='font-size:14px'>= 23<br>b = 5<br>C = 3<br>d = b * C<br>e = a - d<br>print (e)</p>",
            "id": 175,
            "page": 13,
            "text": "= 23 b = 5 C = 3 d = b * C e = a - d print (e)"
        },
        {
            "bounding_box": [
                {
                    "x": 675,
                    "y": 706
                },
                {
                    "x": 1808,
                    "y": 706
                },
                {
                    "x": 1808,
                    "y": 749
                },
                {
                    "x": 675,
                    "y": 749
                }
            ],
            "category": "paragraph",
            "html": "<p id='176' style='font-size:16px'>(a) Structured explanation with uninformative variable names (PAL - var)</p>",
            "id": 176,
            "page": 13,
            "text": "(a) Structured explanation with uninformative variable names (PAL - var)"
        },
        {
            "bounding_box": [
                {
                    "x": 281,
                    "y": 767
                },
                {
                    "x": 857,
                    "y": 767
                },
                {
                    "x": 857,
                    "y": 1213
                },
                {
                    "x": 281,
                    "y": 1213
                }
            ],
            "category": "paragraph",
            "html": "<p id='177' style='font-size:14px'># Olivia has $23<br>a = 23<br># number of bagels bought<br>b = 5<br># price of each bagel<br>C = 3<br># total price of bagels<br>d = b * C<br># money left<br>e = a - d<br>print (e)</p>",
            "id": 177,
            "page": 13,
            "text": "# Olivia has $23 a = 23 # number of bagels bought b = 5 # price of each bagel C = 3 # total price of bagels d = b * C # money left e = a - d print (e)"
        },
        {
            "bounding_box": [
                {
                    "x": 436,
                    "y": 1281
                },
                {
                    "x": 2051,
                    "y": 1281
                },
                {
                    "x": 2051,
                    "y": 1326
                },
                {
                    "x": 436,
                    "y": 1326
                }
            ],
            "category": "paragraph",
            "html": "<p id='178' style='font-size:16px'>(b) Structured explanation with uninformative variable names, but useful comments (PAL - var + comms)</p>",
            "id": 178,
            "page": 13,
            "text": "(b) Structured explanation with uninformative variable names, but useful comments (PAL - var + comms)"
        },
        {
            "bounding_box": [
                {
                    "x": 276,
                    "y": 1337
                },
                {
                    "x": 1165,
                    "y": 1337
                },
                {
                    "x": 1165,
                    "y": 1629
                },
                {
                    "x": 276,
                    "y": 1629
                }
            ],
            "category": "paragraph",
            "html": "<p id='179' style='font-size:14px'>money_initial = 23<br>bagels = 5<br>bagel_cost = 3<br>money_spent = bagels * bagel_cost<br>money_left = money_initial - money_spent<br>result = money_left<br>print (result)</p>",
            "id": 179,
            "page": 13,
            "text": "money_initial = 23 bagels = 5 bagel_cost = 3 money_spent = bagels * bagel_cost money_left = money_initial - money_spent result = money_left print (result)"
        },
        {
            "bounding_box": [
                {
                    "x": 1111,
                    "y": 1693
                },
                {
                    "x": 1373,
                    "y": 1693
                },
                {
                    "x": 1373,
                    "y": 1739
                },
                {
                    "x": 1111,
                    "y": 1739
                }
            ],
            "category": "paragraph",
            "html": "<p id='180' style='font-size:18px'>(c) PAL prompts</p>",
            "id": 180,
            "page": 13,
            "text": "(c) PAL prompts"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 1776
                },
                {
                    "x": 2265,
                    "y": 1776
                },
                {
                    "x": 2265,
                    "y": 1926
                },
                {
                    "x": 222,
                    "y": 1926
                }
            ],
            "category": "paragraph",
            "html": "<p id='181' style='font-size:20px'>Figure 10: Role of text in PAL: three different reasoning steps for the question Olivia has $23. She bought five bagels for<br>$3 each. How much money does she have left? Uninformative variable names (left), Uninformative variable names with<br>useful comments (left), and PAL. Including text description</p>",
            "id": 181,
            "page": 13,
            "text": "Figure 10: Role of text in PAL: three different reasoning steps for the question Olivia has $23. She bought five bagels for $3 each. How much money does she have left? Uninformative variable names (left), Uninformative variable names with useful comments (left), and PAL. Including text description"
        },
        {
            "bounding_box": [
                {
                    "x": 698,
                    "y": 2001
                },
                {
                    "x": 1788,
                    "y": 2001
                },
                {
                    "x": 1788,
                    "y": 2154
                },
                {
                    "x": 698,
                    "y": 2154
                }
            ],
            "category": "table",
            "html": "<table id='182' style='font-size:16px'><tr><td>Setting</td><td>CoT</td><td>PAL - var</td><td>PAL - var + comms</td><td>PAL</td></tr><tr><td>Solve Rate</td><td>63.1</td><td>59.0</td><td>69.0</td><td>71.8</td></tr></table>",
            "id": 182,
            "page": 13,
            "text": "Setting CoT PAL - var PAL - var + comms PAL  Solve Rate 63.1 59.0 69.0"
        },
        {
            "bounding_box": [
                {
                    "x": 220,
                    "y": 2188
                },
                {
                    "x": 2266,
                    "y": 2188
                },
                {
                    "x": 2266,
                    "y": 2341
                },
                {
                    "x": 220,
                    "y": 2341
                }
            ],
            "category": "paragraph",
            "html": "<p id='183' style='font-size:18px'>Table 4: Role of text: including text either as informative variable names (PAL) or comments is important (PAL - var +<br>comms). Uninformative variable names PAL - var cause a drastic drop in performance, indicating that just structure is not<br>sufficient. The corresponding prompts are shown in Figure 10.</p>",
            "id": 183,
            "page": 13,
            "text": "Table 4: Role of text: including text either as informative variable names (PAL) or comments is important (PAL - var + comms). Uninformative variable names PAL - var cause a drastic drop in performance, indicating that just structure is not sufficient. The corresponding prompts are shown in Figure 10."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 2392
                },
                {
                    "x": 2263,
                    "y": 2392
                },
                {
                    "x": 2263,
                    "y": 2695
                },
                {
                    "x": 225,
                    "y": 2695
                }
            ],
            "category": "paragraph",
            "html": "<p id='184' style='font-size:18px'>For mathematical problems, since our standard prompts do not use much comment, we start by creating alternative prompts<br>where the informative variable names are replaced with single-letters (Figure 10). The results in Table 4 shows a considerable<br>performance drop: from an average of 71.8% to 59%. Note that the ablation where structured outputs are completely<br>removed in favor of purely text explanations is precisely the CoT setting, which achieves a solve rate of 63%. These results<br>underscore the importance of text but more importantly show that combining both text and procedural statements leads to<br>higher performance gains-either is sub-optimal.</p>",
            "id": 184,
            "page": 13,
            "text": "For mathematical problems, since our standard prompts do not use much comment, we start by creating alternative prompts where the informative variable names are replaced with single-letters (Figure 10). The results in Table 4 shows a considerable performance drop: from an average of 71.8% to 59%. Note that the ablation where structured outputs are completely removed in favor of purely text explanations is precisely the CoT setting, which achieves a solve rate of 63%. These results underscore the importance of text but more importantly show that combining both text and procedural statements leads to higher performance gains-either is sub-optimal."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 2756
                },
                {
                    "x": 1246,
                    "y": 2756
                },
                {
                    "x": 1246,
                    "y": 2814
                },
                {
                    "x": 225,
                    "y": 2814
                }
            ],
            "category": "paragraph",
            "html": "<p id='185' style='font-size:22px'>B. Additional analysis on Arithmetic Reasoning</p>",
            "id": 185,
            "page": 13,
            "text": "B. Additional analysis on Arithmetic Reasoning"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2841
                },
                {
                    "x": 2264,
                    "y": 2841
                },
                {
                    "x": 2264,
                    "y": 2993
                },
                {
                    "x": 223,
                    "y": 2993
                }
            ],
            "category": "paragraph",
            "html": "<p id='186' style='font-size:20px'>GSM-hard with hard prompts The GSM-HARD experiments used prompts that were sampled from the GSM8K training<br>set. Will CoT be helped by using larger numbers in the prompts as well? To investigate this, we create prompts where the<br>numbers are changed to larger numbers, matching the distribution of numbers in GSM-HARD. The results in Table 5 shows</p>",
            "id": 186,
            "page": 13,
            "text": "GSM-hard with hard prompts The GSM-HARD experiments used prompts that were sampled from the GSM8K training set. Will CoT be helped by using larger numbers in the prompts as well? To investigate this, we create prompts where the numbers are changed to larger numbers, matching the distribution of numbers in GSM-HARD. The results in Table 5 shows"
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 236
                },
                {
                    "x": 908,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='187' style='font-size:18px'>PAL: Program-aided Language Models</header>",
            "id": 187,
            "page": 14,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2216,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 232
                },
                {
                    "x": 2216,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='188' style='font-size:14px'>14</header>",
            "id": 188,
            "page": 14,
            "text": "14"
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 285
                },
                {
                    "x": 2264,
                    "y": 285
                },
                {
                    "x": 2264,
                    "y": 433
                },
                {
                    "x": 221,
                    "y": 433
                }
            ],
            "category": "paragraph",
            "html": "<p id='189' style='font-size:16px'>that even with a prompt that matches the numbers, there are only modest gains in performance. These results show that the<br>gains achieved by using code-based reasoning chains may not be achieved simply by using better few-shot examples for<br>CoT.</p>",
            "id": 189,
            "page": 14,
            "text": "that even with a prompt that matches the numbers, there are only modest gains in performance. These results show that the gains achieved by using code-based reasoning chains may not be achieved simply by using better few-shot examples for CoT."
        },
        {
            "bounding_box": [
                {
                    "x": 742,
                    "y": 465
                },
                {
                    "x": 1738,
                    "y": 465
                },
                {
                    "x": 1738,
                    "y": 623
                },
                {
                    "x": 742,
                    "y": 623
                }
            ],
            "category": "table",
            "html": "<table id='190' style='font-size:20px'><tr><td></td><td>Regular Prompt</td><td>Prompt with Larger Numbers</td></tr><tr><td>CoT</td><td>23.3</td><td>23.8</td></tr></table>",
            "id": 190,
            "page": 14,
            "text": "Regular Prompt Prompt with Larger Numbers  CoT 23.3"
        },
        {
            "bounding_box": [
                {
                    "x": 540,
                    "y": 655
                },
                {
                    "x": 1939,
                    "y": 655
                },
                {
                    "x": 1939,
                    "y": 707
                },
                {
                    "x": 540,
                    "y": 707
                }
            ],
            "category": "caption",
            "html": "<caption id='191' style='font-size:16px'>Table 5: GSM-hard results, when the prompts also had examples of larger numbers.</caption>",
            "id": 191,
            "page": 14,
            "text": "Table 5: GSM-hard results, when the prompts also had examples of larger numbers."
        },
        {
            "bounding_box": [
                {
                    "x": 219,
                    "y": 794
                },
                {
                    "x": 2264,
                    "y": 794
                },
                {
                    "x": 2264,
                    "y": 1001
                },
                {
                    "x": 219,
                    "y": 1001
                }
            ],
            "category": "paragraph",
            "html": "<p id='192' style='font-size:14px'>Succinct Code The programs used in few-shot examples by PAL are multi-step, and show a step-by-step breakdown of<br>the reasoning process. Is this breakdown necessary? Alternatively, can we return a single line expression (see Figure 11b) to<br>calculate the result? Results in Table 6 (4th row) shows that is not the case. With single-line expressions, the performance of<br>PAL falls to the level of direct prompting.</p>",
            "id": 192,
            "page": 14,
            "text": "Succinct Code The programs used in few-shot examples by PAL are multi-step, and show a step-by-step breakdown of the reasoning process. Is this breakdown necessary? Alternatively, can we return a single line expression (see Figure 11b) to calculate the result? Results in Table 6 (4th row) shows that is not the case. With single-line expressions, the performance of PAL falls to the level of direct prompting."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1047
                },
                {
                    "x": 2263,
                    "y": 1047
                },
                {
                    "x": 2263,
                    "y": 1401
                },
                {
                    "x": 223,
                    "y": 1401
                }
            ],
            "category": "paragraph",
            "html": "<p id='193' style='font-size:14px'>Generating the answer directly PAL first generates a reasoning chain in the form of a Python program, and passes the<br>generated program to a runtime to obtain an answer. Is PAL better only because of the program-style intermediate reasoning<br>chains, or are the improvements derived from offloading execution to the Python runtime? To investigate this, we experiment<br>with a variant that forces the LLM to generate the answer after generating the reasoning chain (Figure 11e). This setting<br>compels the LLM to condition on the generated code-based reasoning to generate an answer, simulating the runtime. The<br>results in Table 6 (5th row) show that the solve rate drops to near DIRECT levels. This reinforces our hypothesis that while<br>current LLMs can be excellent at specifying a high-level plan to solve a task-they are still incapable of executing them.</p>",
            "id": 193,
            "page": 14,
            "text": "Generating the answer directly PAL first generates a reasoning chain in the form of a Python program, and passes the generated program to a runtime to obtain an answer. Is PAL better only because of the program-style intermediate reasoning chains, or are the improvements derived from offloading execution to the Python runtime? To investigate this, we experiment with a variant that forces the LLM to generate the answer after generating the reasoning chain (Figure 11e). This setting compels the LLM to condition on the generated code-based reasoning to generate an answer, simulating the runtime. The results in Table 6 (5th row) show that the solve rate drops to near DIRECT levels. This reinforces our hypothesis that while current LLMs can be excellent at specifying a high-level plan to solve a task-they are still incapable of executing them."
        },
        {
            "bounding_box": [
                {
                    "x": 785,
                    "y": 1441
                },
                {
                    "x": 1697,
                    "y": 1441
                },
                {
                    "x": 1697,
                    "y": 1796
                },
                {
                    "x": 785,
                    "y": 1796
                }
            ],
            "category": "table",
            "html": "<table id='194' style='font-size:16px'><tr><td>Ablation</td><td>Solve Rate</td></tr><tr><td>DIRECT (no intermediate reasoning)</td><td>19.7</td></tr><tr><td>CoT</td><td>65.6</td></tr><tr><td>PAL</td><td>72.0</td></tr><tr><td>Succinct Code</td><td>47.8</td></tr><tr><td>LLM Simulating Runtime</td><td>23.2</td></tr></table>",
            "id": 194,
            "page": 14,
            "text": "Ablation Solve Rate  DIRECT (no intermediate reasoning) 19.7  CoT 65.6  PAL 72.0  Succinct Code 47.8  LLM Simulating Runtime"
        },
        {
            "bounding_box": [
                {
                    "x": 951,
                    "y": 1829
                },
                {
                    "x": 1533,
                    "y": 1829
                },
                {
                    "x": 1533,
                    "y": 1879
                },
                {
                    "x": 951,
                    "y": 1879
                }
            ],
            "category": "caption",
            "html": "<caption id='195' style='font-size:14px'>Table 6: Solve Rates for Ablations</caption>",
            "id": 195,
            "page": 14,
            "text": "Table 6: Solve Rates for Ablations"
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1972
                },
                {
                    "x": 1180,
                    "y": 1972
                },
                {
                    "x": 1180,
                    "y": 2030
                },
                {
                    "x": 224,
                    "y": 2030
                }
            ],
            "category": "paragraph",
            "html": "<p id='196' style='font-size:22px'>C. Effect of Using Language Models of Code</p>",
            "id": 196,
            "page": 14,
            "text": "C. Effect of Using Language Models of Code"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2057
                },
                {
                    "x": 2264,
                    "y": 2057
                },
                {
                    "x": 2264,
                    "y": 2361
                },
                {
                    "x": 223,
                    "y": 2361
                }
            ],
            "category": "paragraph",
            "html": "<p id='197' style='font-size:14px'>In our experiments, we focused on evaluating the performance of a language model for code. We aimed to investigate<br>whether the additional performance boost observed in our results was due to the use of models like Codex, or whether our<br>formulation was useful even for text-based models. To this end, we conducted additional experiments using text-based<br>language models. Our findings indicate that the PAL approach is not restricted to working solely with Codex, but can also<br>be applied to natural language (NL) models, as long as the model is sufficiently strong. Specifically, our results showed that<br>in the text-davinci-001 model, the use of the CoT approach resulted in better performance.</p>",
            "id": 197,
            "page": 14,
            "text": "In our experiments, we focused on evaluating the performance of a language model for code. We aimed to investigate whether the additional performance boost observed in our results was due to the use of models like Codex, or whether our formulation was useful even for text-based models. To this end, we conducted additional experiments using text-based language models. Our findings indicate that the PAL approach is not restricted to working solely with Codex, but can also be applied to natural language (NL) models, as long as the model is sufficiently strong. Specifically, our results showed that in the text-davinci-001 model, the use of the CoT approach resulted in better performance."
        },
        {
            "bounding_box": [
                {
                    "x": 974,
                    "y": 2403
                },
                {
                    "x": 1510,
                    "y": 2403
                },
                {
                    "x": 1510,
                    "y": 2657
                },
                {
                    "x": 974,
                    "y": 2657
                }
            ],
            "category": "table",
            "html": "<table id='198' style='font-size:14px'><tr><td>Model</td><td>CoT</td><td>PaL</td></tr><tr><td>text-davinci-001</td><td>26.5</td><td>8.6</td></tr><tr><td>text-davinci-002</td><td>46.9</td><td>65.8</td></tr><tr><td>text-davinci-003</td><td>65.3</td><td>69.8</td></tr></table>",
            "id": 198,
            "page": 14,
            "text": "Model CoT PaL  text-davinci-001 26.5 8.6  text-davinci-002 46.9 65.8  text-davinci-003 65.3"
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 2741
                },
                {
                    "x": 1624,
                    "y": 2741
                },
                {
                    "x": 1624,
                    "y": 2800
                },
                {
                    "x": 224,
                    "y": 2800
                }
            ],
            "category": "paragraph",
            "html": "<p id='199' style='font-size:22px'>D. Analyzing the Effect of Increasing Number of Samples on PAL</p>",
            "id": 199,
            "page": 14,
            "text": "D. Analyzing the Effect of Increasing Number of Samples on PAL"
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 2826
                },
                {
                    "x": 2265,
                    "y": 2826
                },
                {
                    "x": 2265,
                    "y": 2981
                },
                {
                    "x": 221,
                    "y": 2981
                }
            ],
            "category": "paragraph",
            "html": "<p id='200' style='font-size:16px'>In Section 5.1, we show that PAL outperforms strong baselines both for a single sample and by drawing 40 samples and<br>using majority voting. Figure 12 illustrates the trends for cases when the number of samples drawn are between 1 and 40,<br>and the interpolation estimates demonstrate that PAL remains competitive throughout the number of samples.</p>",
            "id": 200,
            "page": 14,
            "text": "In Section 5.1, we show that PAL outperforms strong baselines both for a single sample and by drawing 40 samples and using majority voting. Figure 12 illustrates the trends for cases when the number of samples drawn are between 1 and 40, and the interpolation estimates demonstrate that PAL remains competitive throughout the number of samples."
        },
        {
            "bounding_box": [
                {
                    "x": 909,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 237
                },
                {
                    "x": 909,
                    "y": 237
                }
            ],
            "category": "header",
            "html": "<header id='201' style='font-size:22px'>PAL: Program-aided Language Models</header>",
            "id": 201,
            "page": 15,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2215,
                    "y": 193
                },
                {
                    "x": 2260,
                    "y": 193
                },
                {
                    "x": 2260,
                    "y": 232
                },
                {
                    "x": 2215,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='202' style='font-size:18px'>15</header>",
            "id": 202,
            "page": 15,
            "text": "15"
        },
        {
            "bounding_box": [
                {
                    "x": 430,
                    "y": 441
                },
                {
                    "x": 1969,
                    "y": 441
                },
                {
                    "x": 1969,
                    "y": 521
                },
                {
                    "x": 430,
                    "y": 521
                }
            ],
            "category": "paragraph",
            "html": "<p id='203' style='font-size:16px'>def solution () :<br>\" \" \"Shawn has five toys. For Christmas, he got two toys each from his</p>",
            "id": 203,
            "page": 15,
            "text": "def solution () : \" \" \"Shawn has five toys. For Christmas, he got two toys each from his"
        },
        {
            "bounding_box": [
                {
                    "x": 439,
                    "y": 496
                },
                {
                    "x": 1971,
                    "y": 496
                },
                {
                    "x": 1971,
                    "y": 852
                },
                {
                    "x": 439,
                    "y": 852
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='204' style='font-size:14px'>; mom and dad. How many toys does he have now?\"\"\"<br>toys_initial = 5<br>mom_toys = 2<br>dad_toys = 2<br>total_received = mom_toys + dad_toys<br>total_toys = toys_initial + total_received<br>result = total_toys<br>return result</p>",
            "id": 204,
            "page": 15,
            "text": "; mom and dad. How many toys does he have now?\"\"\" toys_initial = 5 mom_toys = 2 dad_toys = 2 total_received = mom_toys + dad_toys total_toys = toys_initial + total_received result = total_toys return result"
        },
        {
            "bounding_box": [
                {
                    "x": 1077,
                    "y": 922
                },
                {
                    "x": 1407,
                    "y": 922
                },
                {
                    "x": 1407,
                    "y": 965
                },
                {
                    "x": 1077,
                    "y": 965
                }
            ],
            "category": "paragraph",
            "html": "<p id='205' style='font-size:22px'>(a) Original Example</p>",
            "id": 205,
            "page": 15,
            "text": "(a) Original Example"
        },
        {
            "bounding_box": [
                {
                    "x": 428,
                    "y": 974
                },
                {
                    "x": 803,
                    "y": 974
                },
                {
                    "x": 803,
                    "y": 1057
                },
                {
                    "x": 428,
                    "y": 1057
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='206' style='font-size:14px'>def solution () :<br>return 5 + 2 + 2</p>",
            "id": 206,
            "page": 15,
            "text": "def solution () : return 5 + 2 + 2"
        },
        {
            "bounding_box": [
                {
                    "x": 1101,
                    "y": 1123
                },
                {
                    "x": 1383,
                    "y": 1123
                },
                {
                    "x": 1383,
                    "y": 1166
                },
                {
                    "x": 1101,
                    "y": 1166
                }
            ],
            "category": "paragraph",
            "html": "<p id='207' style='font-size:18px'>(b) Succinct Code</p>",
            "id": 207,
            "page": 15,
            "text": "(b) Succinct Code"
        },
        {
            "bounding_box": [
                {
                    "x": 439,
                    "y": 1178
                },
                {
                    "x": 1973,
                    "y": 1178
                },
                {
                    "x": 1973,
                    "y": 1588
                },
                {
                    "x": 439,
                    "y": 1588
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='208' style='font-size:16px'>def solution () :<br>\"\" \"Shawn has 10312864 toys. For Christmas, he got 13267894 toys each<br>from his mom and dad. How many toys does he have now?\"\"\"<br>toys_initial = 10312864<br>mom_toys = 13267894<br>dad_toys = 13267894<br>total_received = mom_toys + dad_toys<br>total_toys = toys_initial + total_received<br>result = total_toys<br>return result</p>",
            "id": 208,
            "page": 15,
            "text": "def solution () : \"\" \"Shawn has 10312864 toys. For Christmas, he got 13267894 toys each from his mom and dad. How many toys does he have now?\"\"\" toys_initial = 10312864 mom_toys = 13267894 dad_toys = 13267894 total_received = mom_toys + dad_toys total_toys = toys_initial + total_received result = total_toys return result"
        },
        {
            "bounding_box": [
                {
                    "x": 965,
                    "y": 1657
                },
                {
                    "x": 1520,
                    "y": 1657
                },
                {
                    "x": 1520,
                    "y": 1704
                },
                {
                    "x": 965,
                    "y": 1704
                }
            ],
            "category": "paragraph",
            "html": "<p id='209' style='font-size:20px'>(c) Hard Examples in Prompt (PAL)</p>",
            "id": 209,
            "page": 15,
            "text": "(c) Hard Examples in Prompt (PAL)"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1715
                },
                {
                    "x": 2032,
                    "y": 1715
                },
                {
                    "x": 2032,
                    "y": 2040
                },
                {
                    "x": 443,
                    "y": 2040
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='210' style='font-size:16px'>Example (<br>question=\"Shawn has 10312864 toys. For Christmas, he got 13267894 toys<br>each from his mom and dad. How many toys does he have now?\" ,<br>thought=\"Shawn started with 10312864 toys. If he got 13267894 toys each<br>from his mom and dad, then that is 26535788 more toys. 10312864 +<br>26535788 = 36848652.\",<br>answer=\"36848652\" ,<br>) ,</p>",
            "id": 210,
            "page": 15,
            "text": "Example ( question=\"Shawn has 10312864 toys. For Christmas, he got 13267894 toys each from his mom and dad. How many toys does he have now?\" , thought=\"Shawn started with 10312864 toys. If he got 13267894 toys each from his mom and dad, then that is 26535788 more toys. 10312864 + 26535788 = 36848652.\", answer=\"36848652\" , ) ,"
        },
        {
            "bounding_box": [
                {
                    "x": 965,
                    "y": 2108
                },
                {
                    "x": 1519,
                    "y": 2108
                },
                {
                    "x": 1519,
                    "y": 2156
                },
                {
                    "x": 965,
                    "y": 2156
                }
            ],
            "category": "paragraph",
            "html": "<p id='211' style='font-size:20px'>(d) Hard Examples in Prompt (CoT)</p>",
            "id": 211,
            "page": 15,
            "text": "(d) Hard Examples in Prompt (CoT)"
        },
        {
            "bounding_box": [
                {
                    "x": 435,
                    "y": 2163
                },
                {
                    "x": 1982,
                    "y": 2163
                },
                {
                    "x": 1982,
                    "y": 2619
                },
                {
                    "x": 435,
                    "y": 2619
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='212' style='font-size:14px'>def solution () :<br>\" \" \" Shawn has five toys. For Christmas, he got two toys each from his<br>; mom and dad. How many toys does he have now?\" \" \"<br>toys_initial = 5<br>mom_toys = 2<br>dad_toys = 2<br>total_received = mom_toys + dad_toys<br>total_toys = toys_initial + total_received<br>result = total_toys<br>return result<br>ans = 9</p>",
            "id": 212,
            "page": 15,
            "text": "def solution () : \" \" \" Shawn has five toys. For Christmas, he got two toys each from his ; mom and dad. How many toys does he have now?\" \" \" toys_initial = 5 mom_toys = 2 dad_toys = 2 total_received = mom_toys + dad_toys total_toys = toys_initial + total_received result = total_toys return result ans = 9"
        },
        {
            "bounding_box": [
                {
                    "x": 991,
                    "y": 2685
                },
                {
                    "x": 1491,
                    "y": 2685
                },
                {
                    "x": 1491,
                    "y": 2733
                },
                {
                    "x": 991,
                    "y": 2733
                }
            ],
            "category": "paragraph",
            "html": "<p id='213' style='font-size:20px'>(e) Generating Answers Directly</p>",
            "id": 213,
            "page": 15,
            "text": "(e) Generating Answers Directly"
        },
        {
            "bounding_box": [
                {
                    "x": 459,
                    "y": 2769
                },
                {
                    "x": 2021,
                    "y": 2769
                },
                {
                    "x": 2021,
                    "y": 2825
                },
                {
                    "x": 459,
                    "y": 2825
                }
            ],
            "category": "paragraph",
            "html": "<p id='214' style='font-size:22px'>Figure 11: Ablations of the original example solution for the few-shot prompting experiment.</p>",
            "id": 214,
            "page": 15,
            "text": "Figure 11: Ablations of the original example solution for the few-shot prompting experiment."
        },
        {
            "bounding_box": [
                {
                    "x": 907,
                    "y": 189
                },
                {
                    "x": 1549,
                    "y": 189
                },
                {
                    "x": 1549,
                    "y": 237
                },
                {
                    "x": 907,
                    "y": 237
                }
            ],
            "category": "header",
            "html": "<header id='215' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 215,
            "page": 16,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2213,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 235
                },
                {
                    "x": 2213,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<br><header id='216' style='font-size:16px'>16</header>",
            "id": 216,
            "page": 16,
            "text": "16"
        },
        {
            "bounding_box": [
                {
                    "x": 564,
                    "y": 985
                },
                {
                    "x": 1942,
                    "y": 985
                },
                {
                    "x": 1942,
                    "y": 2127
                },
                {
                    "x": 564,
                    "y": 2127
                }
            ],
            "category": "figure",
            "html": "<figure><img id='217' style='font-size:14px' alt=\"85\n80\n(%) 70\nRate\n◇\nSolve\n△\n60\nPAL\nCoT\nMinerva\nPaLM\n50\n1 8 15 40\nNumber of sampled generations for each question\" data-coord=\"top-left:(564,985); bottom-right:(1942,2127)\" /></figure>",
            "id": 217,
            "page": 16,
            "text": "85 80 (%) 70 Rate ◇ Solve △ 60 PAL CoT Minerva PaLM 50 1 8 15 40 Number of sampled generations for each question"
        },
        {
            "bounding_box": [
                {
                    "x": 219,
                    "y": 2160
                },
                {
                    "x": 2268,
                    "y": 2160
                },
                {
                    "x": 2268,
                    "y": 2271
                },
                {
                    "x": 219,
                    "y": 2271
                }
            ],
            "category": "caption",
            "html": "<caption id='218' style='font-size:18px'>Figure 12: Comparison of solve rates between PAL and baselines as the number of samples increases from 1 to 40. Note that<br>the solve rates for the baselines (PaLM, CoT, Minerva) are obtained through logistic interpolation of solve rates at 1 and 40</caption>",
            "id": 218,
            "page": 16,
            "text": "Figure 12: Comparison of solve rates between PAL and baselines as the number of samples increases from 1 to 40. Note that the solve rates for the baselines (PaLM, CoT, Minerva) are obtained through logistic interpolation of solve rates at 1 and 40"
        },
        {
            "bounding_box": [
                {
                    "x": 909,
                    "y": 191
                },
                {
                    "x": 1547,
                    "y": 191
                },
                {
                    "x": 1547,
                    "y": 235
                },
                {
                    "x": 909,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='219' style='font-size:18px'>PAL: Program-aided Language Models</header>",
            "id": 219,
            "page": 17,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2214,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 232
                },
                {
                    "x": 2214,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='220' style='font-size:16px'>17</header>",
            "id": 220,
            "page": 17,
            "text": "17"
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 277
                },
                {
                    "x": 1475,
                    "y": 277
                },
                {
                    "x": 1475,
                    "y": 337
                },
                {
                    "x": 225,
                    "y": 337
                }
            ],
            "category": "paragraph",
            "html": "<p id='221' style='font-size:22px'>E. Standard Deviations Across Multiple Order of Prompts</p>",
            "id": 221,
            "page": 17,
            "text": "E. Standard Deviations Across Multiple Order of Prompts"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 366
                },
                {
                    "x": 2261,
                    "y": 366
                },
                {
                    "x": 2261,
                    "y": 465
                },
                {
                    "x": 223,
                    "y": 465
                }
            ],
            "category": "paragraph",
            "html": "<p id='222' style='font-size:14px'>For each math reasoning task, we run inference using three random orderings of the prompts. As shown in Table 7, the<br>standard deviation between the results obtained from the three different seeds is minimal.</p>",
            "id": 222,
            "page": 17,
            "text": "For each math reasoning task, we run inference using three random orderings of the prompts. As shown in Table 7, the standard deviation between the results obtained from the three different seeds is minimal."
        },
        {
            "bounding_box": [
                {
                    "x": 492,
                    "y": 501
                },
                {
                    "x": 1993,
                    "y": 501
                },
                {
                    "x": 1993,
                    "y": 1050
                },
                {
                    "x": 492,
                    "y": 1050
                }
            ],
            "category": "table",
            "html": "<table id='223' style='font-size:16px'><tr><td></td><td colspan=\"2\">CoT</td><td colspan=\"2\">PAL</td></tr><tr><td></td><td>Average</td><td>Standard Deviation</td><td>Average</td><td>Standard Deviation</td></tr><tr><td>GSM8K</td><td>65.6</td><td>1.10</td><td>72.0</td><td>0.16</td></tr><tr><td>SVAMP</td><td>74.8</td><td>0.19</td><td>79.4</td><td>0.20</td></tr><tr><td>ASDIV</td><td>76.9</td><td>0.65</td><td>79.6</td><td>0.14</td></tr><tr><td>GSM-HARD</td><td>23.3</td><td>0.49</td><td>61.2</td><td>0.91</td></tr><tr><td>MAWPS-SingleEq</td><td>89.1</td><td>0.54</td><td>96.1</td><td>0.30</td></tr><tr><td>MAWPS-SingleOp</td><td>91.9</td><td>0.55</td><td>94.6</td><td>0.36</td></tr><tr><td>MAWPS-AddSub</td><td>86.0</td><td>0.62</td><td>92.5</td><td>0.34</td></tr><tr><td>MAWPS-MultiArith</td><td>95.9</td><td>0.51</td><td>99.2</td><td>0.48</td></tr></table>",
            "id": 223,
            "page": 17,
            "text": "CoT PAL   Average Standard Deviation Average Standard Deviation  GSM8K 65.6 1.10 72.0 0.16  SVAMP 74.8 0.19 79.4 0.20  ASDIV 76.9 0.65 79.6 0.14  GSM-HARD 23.3 0.49 61.2 0.91  MAWPS-SingleEq 89.1 0.54 96.1 0.30  MAWPS-SingleOp 91.9 0.55 94.6 0.36  MAWPS-AddSub 86.0 0.62 92.5 0.34  MAWPS-MultiArith 95.9 0.51 99.2"
        },
        {
            "bounding_box": [
                {
                    "x": 612,
                    "y": 1081
                },
                {
                    "x": 1873,
                    "y": 1081
                },
                {
                    "x": 1873,
                    "y": 1137
                },
                {
                    "x": 612,
                    "y": 1137
                }
            ],
            "category": "paragraph",
            "html": "<p id='224' style='font-size:14px'>Table 7: Standard deviations for three runs for the math reasoning datasets.</p>",
            "id": 224,
            "page": 17,
            "text": "Table 7: Standard deviations for three runs for the math reasoning datasets."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1236
                },
                {
                    "x": 836,
                    "y": 1236
                },
                {
                    "x": 836,
                    "y": 1295
                },
                {
                    "x": 224,
                    "y": 1295
                }
            ],
            "category": "paragraph",
            "html": "<p id='225' style='font-size:20px'>F. PAL Beyond Benchmarks</p>",
            "id": 225,
            "page": 17,
            "text": "F. PAL Beyond Benchmarks"
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1324
                },
                {
                    "x": 2264,
                    "y": 1324
                },
                {
                    "x": 2264,
                    "y": 1576
                },
                {
                    "x": 224,
                    "y": 1576
                }
            ],
            "category": "paragraph",
            "html": "<p id='226' style='font-size:16px'>We argue that symbolic reasoning is a crucial component in solving a wide range of tasks. In this section, we demonstrate<br>examples of tasks that may not initially appear to require using programs as intermediate reasoning steps, but can be<br>improved through the use of PAL-style reasoning. We demonstrate these examples using the ChatGPT tool. 1 In contrast to<br>the in-context-learning methods we used in the main paper, here we instruct ChatGPT to perform program-aided reasoning<br>through one of the user utterances.</p>",
            "id": 226,
            "page": 17,
            "text": "We argue that symbolic reasoning is a crucial component in solving a wide range of tasks. In this section, we demonstrate examples of tasks that may not initially appear to require using programs as intermediate reasoning steps, but can be improved through the use of PAL-style reasoning. We demonstrate these examples using the ChatGPT tool. 1 In contrast to the in-context-learning methods we used in the main paper, here we instruct ChatGPT to perform program-aided reasoning through one of the user utterances."
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 1598
                },
                {
                    "x": 2263,
                    "y": 1598
                },
                {
                    "x": 2263,
                    "y": 1749
                },
                {
                    "x": 222,
                    "y": 1749
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='227' style='font-size:16px'>In Figure 13, in CoT-style reasoning, while the reasoning chain is correct, the final answer is wrong. In contrast, PAL-style<br>reasoning could not only accurately extract the color of objects from the question but also produce the correct lines of code<br>to branch to different situations that yield their corresponding correct answers.</p>",
            "id": 227,
            "page": 17,
            "text": "In Figure 13, in CoT-style reasoning, while the reasoning chain is correct, the final answer is wrong. In contrast, PAL-style reasoning could not only accurately extract the color of objects from the question but also produce the correct lines of code to branch to different situations that yield their corresponding correct answers."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1771
                },
                {
                    "x": 2265,
                    "y": 1771
                },
                {
                    "x": 2265,
                    "y": 2074
                },
                {
                    "x": 224,
                    "y": 2074
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='228' style='font-size:16px'>A more intriguing example is letting an LLM count the number of letters in the word \"intriguing\". In Figure 14a, while the<br>step-by-step explanation appears reasonable by splitting the letters by spaces, ChatGPT does not change the answer after<br>this explicit reasoning and insists on the wrong answer. Explicitly instructing the model to perform step-by-step reasoning<br>before answering the question still yields the wrong answer. In contrast, PAL-style reasoning only takes a few lines of code,<br>and the execution does produce the correct answer, in this case. These examples indicate that PAL can benefit even an<br>ostensibly powerful model like ChatGPT.</p>",
            "id": 228,
            "page": 17,
            "text": "A more intriguing example is letting an LLM count the number of letters in the word \"intriguing\". In Figure 14a, while the step-by-step explanation appears reasonable by splitting the letters by spaces, ChatGPT does not change the answer after this explicit reasoning and insists on the wrong answer. Explicitly instructing the model to perform step-by-step reasoning before answering the question still yields the wrong answer. In contrast, PAL-style reasoning only takes a few lines of code, and the execution does produce the correct answer, in this case. These examples indicate that PAL can benefit even an ostensibly powerful model like ChatGPT."
        },
        {
            "bounding_box": [
                {
                    "x": 275,
                    "y": 2943
                },
                {
                    "x": 643,
                    "y": 2943
                },
                {
                    "x": 643,
                    "y": 2992
                },
                {
                    "x": 275,
                    "y": 2992
                }
            ],
            "category": "footer",
            "html": "<footer id='229' style='font-size:14px'>1 chat · openai · com</footer>",
            "id": 229,
            "page": 17,
            "text": "1 chat · openai · com"
        },
        {
            "bounding_box": [
                {
                    "x": 910,
                    "y": 192
                },
                {
                    "x": 1547,
                    "y": 192
                },
                {
                    "x": 1547,
                    "y": 235
                },
                {
                    "x": 910,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='230' style='font-size:22px'>PAL: Program-aided Language Models</header>",
            "id": 230,
            "page": 18,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2215,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 231
                },
                {
                    "x": 2215,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='231' style='font-size:20px'>18</header>",
            "id": 231,
            "page": 18,
            "text": "18"
        },
        {
            "bounding_box": [
                {
                    "x": 578,
                    "y": 642
                },
                {
                    "x": 611,
                    "y": 642
                },
                {
                    "x": 611,
                    "y": 673
                },
                {
                    "x": 578,
                    "y": 673
                }
            ],
            "category": "paragraph",
            "html": "<p id='232' style='font-size:14px'>e</p>",
            "id": 232,
            "page": 18,
            "text": "e"
        },
        {
            "bounding_box": [
                {
                    "x": 624,
                    "y": 633
                },
                {
                    "x": 1802,
                    "y": 633
                },
                {
                    "x": 1802,
                    "y": 759
                },
                {
                    "x": 624,
                    "y": 759
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='233' style='font-size:14px'>Let's say our plane crashed onto an exotic island, where everything that is usually yellow<br>looks blue here. We know that mango and banana are all yellow, do they have the same<br>color on this island?</p>",
            "id": 233,
            "page": 18,
            "text": "Let's say our plane crashed onto an exotic island, where everything that is usually yellow looks blue here. We know that mango and banana are all yellow, do they have the same color on this island?"
        },
        {
            "bounding_box": [
                {
                    "x": 619,
                    "y": 902
                },
                {
                    "x": 1755,
                    "y": 902
                },
                {
                    "x": 1755,
                    "y": 997
                },
                {
                    "x": 619,
                    "y": 997
                }
            ],
            "category": "paragraph",
            "html": "<p id='234' style='font-size:14px'>If you were on an exotic island where everything that is usually yellow looks blue, then<br>mangoes and bananas would not have the same color.</p>",
            "id": 234,
            "page": 18,
            "text": "If you were on an exotic island where everything that is usually yellow looks blue, then mangoes and bananas would not have the same color."
        },
        {
            "bounding_box": [
                {
                    "x": 655,
                    "y": 1039
                },
                {
                    "x": 1808,
                    "y": 1039
                },
                {
                    "x": 1808,
                    "y": 1129
                },
                {
                    "x": 655,
                    "y": 1129
                }
            ],
            "category": "paragraph",
            "html": "<p id='235' style='font-size:16px'>Mangoes are typically yellow in color, but on this island, they would look blue. Bananas are<br>also typically yellow in color, but on this island, they would also look blue.</p>",
            "id": 235,
            "page": 18,
            "text": "Mangoes are typically yellow in color, but on this island, they would look blue. Bananas are also typically yellow in color, but on this island, they would also look blue."
        },
        {
            "bounding_box": [
                {
                    "x": 654,
                    "y": 1171
                },
                {
                    "x": 1807,
                    "y": 1171
                },
                {
                    "x": 1807,
                    "y": 1311
                },
                {
                    "x": 654,
                    "y": 1311
                }
            ],
            "category": "paragraph",
            "html": "<p id='236' style='font-size:16px'>Therefore, even though both mangoes and bananas are typically yellow in color, on this<br>island they would have a different color. Mangoes and bananas would both look blue on<br>this island, but they would not have the same color, as blue is a different color from yellow.</p>",
            "id": 236,
            "page": 18,
            "text": "Therefore, even though both mangoes and bananas are typically yellow in color, on this island they would have a different color. Mangoes and bananas would both look blue on this island, but they would not have the same color, as blue is a different color from yellow."
        },
        {
            "bounding_box": [
                {
                    "x": 658,
                    "y": 1357
                },
                {
                    "x": 1454,
                    "y": 1357
                },
                {
                    "x": 1454,
                    "y": 1391
                },
                {
                    "x": 658,
                    "y": 1391
                }
            ],
            "category": "paragraph",
            "html": "<p id='237' style='font-size:14px'>I hope this helps! Let me know if you have any other questions.</p>",
            "id": 237,
            "page": 18,
            "text": "I hope this helps! Let me know if you have any other questions."
        },
        {
            "bounding_box": [
                {
                    "x": 545,
                    "y": 1535
                },
                {
                    "x": 1937,
                    "y": 1535
                },
                {
                    "x": 1937,
                    "y": 1582
                },
                {
                    "x": 545,
                    "y": 1582
                }
            ],
            "category": "paragraph",
            "html": "<p id='238' style='font-size:20px'>(a) In CoT style reasoning, the correct intermediate reasoning chain leads to wrong answers.</p>",
            "id": 238,
            "page": 18,
            "text": "(a) In CoT style reasoning, the correct intermediate reasoning chain leads to wrong answers."
        },
        {
            "bounding_box": [
                {
                    "x": 712,
                    "y": 1646
                },
                {
                    "x": 1850,
                    "y": 1646
                },
                {
                    "x": 1850,
                    "y": 1833
                },
                {
                    "x": 712,
                    "y": 1833
                }
            ],
            "category": "paragraph",
            "html": "<p id='239' style='font-size:18px'>Let's say our plane crashed onto an exotic island, where everything that is<br>usually yellow looks blue here. We know that mango and banana are all<br>yellow, do they have the same color on this island? Write a Python program<br>to answer the question.</p>",
            "id": 239,
            "page": 18,
            "text": "Let's say our plane crashed onto an exotic island, where everything that is usually yellow looks blue here. We know that mango and banana are all yellow, do they have the same color on this island? Write a Python program to answer the question."
        },
        {
            "bounding_box": [
                {
                    "x": 1241,
                    "y": 1847
                },
                {
                    "x": 1335,
                    "y": 1847
                },
                {
                    "x": 1335,
                    "y": 1883
                },
                {
                    "x": 1241,
                    "y": 1883
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='240' style='font-size:14px'>く 3 / 3</p>",
            "id": 240,
            "page": 18,
            "text": "く 3 / 3"
        },
        {
            "bounding_box": [
                {
                    "x": 710,
                    "y": 2085
                },
                {
                    "x": 1115,
                    "y": 2085
                },
                {
                    "x": 1115,
                    "y": 2187
                },
                {
                    "x": 710,
                    "y": 2187
                }
            ],
            "category": "paragraph",
            "html": "<p id='241' style='font-size:16px'>color_of_mango = \"blue\"<br>color_of_banana = \"blue\"</p>",
            "id": 241,
            "page": 18,
            "text": "color_of_mango = \"blue\" color_of_banana = \"blue\""
        },
        {
            "bounding_box": [
                {
                    "x": 715,
                    "y": 2241
                },
                {
                    "x": 1833,
                    "y": 2241
                },
                {
                    "x": 1833,
                    "y": 2460
                },
                {
                    "x": 715,
                    "y": 2460
                }
            ],
            "category": "paragraph",
            "html": "<p id='242' style='font-size:18px'>if color_of_mango == color_of_banana:<br>print(\"Yes, mango and banana have the same color on this island.\")<br>else:<br>print(\" No, mango and banana do not have the same color on this island.\")</p>",
            "id": 242,
            "page": 18,
            "text": "if color_of_mango == color_of_banana: print(\"Yes, mango and banana have the same color on this island.\") else: print(\" No, mango and banana do not have the same color on this island.\")"
        },
        {
            "bounding_box": [
                {
                    "x": 619,
                    "y": 2607
                },
                {
                    "x": 1865,
                    "y": 2607
                },
                {
                    "x": 1865,
                    "y": 2747
                },
                {
                    "x": 619,
                    "y": 2747
                }
            ],
            "category": "paragraph",
            "html": "<p id='243' style='font-size:20px'>(b) In PAL, the execution of the code will produce the correct answer.<br>Figure 13: ChatGPT with PAL and CoT to answer a user-posted question</p>",
            "id": 243,
            "page": 18,
            "text": "(b) In PAL, the execution of the code will produce the correct answer. Figure 13: ChatGPT with PAL and CoT to answer a user-posted question"
        },
        {
            "bounding_box": [
                {
                    "x": 911,
                    "y": 194
                },
                {
                    "x": 1546,
                    "y": 194
                },
                {
                    "x": 1546,
                    "y": 233
                },
                {
                    "x": 911,
                    "y": 233
                }
            ],
            "category": "header",
            "html": "<header id='244' style='font-size:22px'>PAL: Program-aided Language Models</header>",
            "id": 244,
            "page": 19,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2218,
                    "y": 196
                },
                {
                    "x": 2258,
                    "y": 196
                },
                {
                    "x": 2258,
                    "y": 228
                },
                {
                    "x": 2218,
                    "y": 228
                }
            ],
            "category": "header",
            "html": "<br><header id='245' style='font-size:20px'>19</header>",
            "id": 245,
            "page": 19,
            "text": "19"
        },
        {
            "bounding_box": [
                {
                    "x": 729,
                    "y": 335
                },
                {
                    "x": 1398,
                    "y": 335
                },
                {
                    "x": 1398,
                    "y": 377
                },
                {
                    "x": 729,
                    "y": 377
                }
            ],
            "category": "paragraph",
            "html": "<p id='246' style='font-size:16px'>How many letters are in the word 'intriguing'?</p>",
            "id": 246,
            "page": 19,
            "text": "How many letters are in the word 'intriguing'?"
        },
        {
            "bounding_box": [
                {
                    "x": 642,
                    "y": 493
                },
                {
                    "x": 1240,
                    "y": 493
                },
                {
                    "x": 1240,
                    "y": 542
                },
                {
                    "x": 642,
                    "y": 542
                }
            ],
            "category": "paragraph",
            "html": "<p id='247' style='font-size:18px'>The word 'intriguing' has 9 letters.</p>",
            "id": 247,
            "page": 19,
            "text": "The word 'intriguing' has 9 letters."
        },
        {
            "bounding_box": [
                {
                    "x": 731,
                    "y": 649
                },
                {
                    "x": 1564,
                    "y": 649
                },
                {
                    "x": 1564,
                    "y": 693
                },
                {
                    "x": 731,
                    "y": 693
                }
            ],
            "category": "paragraph",
            "html": "<p id='248' style='font-size:20px'>Interesting, can you explain your reasoning step by step?</p>",
            "id": 248,
            "page": 19,
            "text": "Interesting, can you explain your reasoning step by step?"
        },
        {
            "bounding_box": [
                {
                    "x": 731,
                    "y": 812
                },
                {
                    "x": 1314,
                    "y": 812
                },
                {
                    "x": 1314,
                    "y": 854
                },
                {
                    "x": 731,
                    "y": 854
                }
            ],
            "category": "paragraph",
            "html": "<p id='249' style='font-size:20px'>Sure, here's my reasoning step by step:</p>",
            "id": 249,
            "page": 19,
            "text": "Sure, here's my reasoning step by step:"
        },
        {
            "bounding_box": [
                {
                    "x": 730,
                    "y": 909
                },
                {
                    "x": 1872,
                    "y": 909
                },
                {
                    "x": 1872,
                    "y": 1064
                },
                {
                    "x": 730,
                    "y": 1064
                }
            ],
            "category": "paragraph",
            "html": "<p id='250' style='font-size:16px'>1. I read the word 'intriguing'<br>2. I counted the number of letters in the word, which are: i, n, t, r, i, g, u, i, n, g<br>3. | added the number of letters, which is 9.</p>",
            "id": 250,
            "page": 19,
            "text": "1. I read the word 'intriguing' 2. I counted the number of letters in the word, which are: i, n, t, r, i, g, u, i, n, g 3. | added the number of letters, which is 9."
        },
        {
            "bounding_box": [
                {
                    "x": 733,
                    "y": 1117
                },
                {
                    "x": 1464,
                    "y": 1117
                },
                {
                    "x": 1464,
                    "y": 1157
                },
                {
                    "x": 733,
                    "y": 1157
                }
            ],
            "category": "paragraph",
            "html": "<p id='251' style='font-size:18px'>So, in summary, the word 'intriguing' has 9 letters.</p>",
            "id": 251,
            "page": 19,
            "text": "So, in summary, the word 'intriguing' has 9 letters."
        },
        {
            "bounding_box": [
                {
                    "x": 580,
                    "y": 1235
                },
                {
                    "x": 1910,
                    "y": 1235
                },
                {
                    "x": 1910,
                    "y": 1314
                },
                {
                    "x": 580,
                    "y": 1314
                }
            ],
            "category": "paragraph",
            "html": "<p id='252' style='font-size:20px'>(a) Step-by-step reasoning struggle on counting the number of letters in the word \"intrigu-<br>ing\" which has ten letters.</p>",
            "id": 252,
            "page": 19,
            "text": "(a) Step-by-step reasoning struggle on counting the number of letters in the word \"intriguing\" which has ten letters."
        },
        {
            "bounding_box": [
                {
                    "x": 708,
                    "y": 1349
                },
                {
                    "x": 1725,
                    "y": 1349
                },
                {
                    "x": 1725,
                    "y": 1388
                },
                {
                    "x": 708,
                    "y": 1388
                }
            ],
            "category": "paragraph",
            "html": "<p id='253' style='font-size:20px'>How many letters are in the word 'intriguing'? Think step by step</p>",
            "id": 253,
            "page": 19,
            "text": "How many letters are in the word 'intriguing'? Think step by step"
        },
        {
            "bounding_box": [
                {
                    "x": 702,
                    "y": 1520
                },
                {
                    "x": 1899,
                    "y": 1520
                },
                {
                    "x": 1899,
                    "y": 1813
                },
                {
                    "x": 702,
                    "y": 1813
                }
            ],
            "category": "paragraph",
            "html": "<p id='254' style='font-size:18px'>1. Start by counting the letters in the first syllable, \"in\" - there are 2 letters.<br>2. Next, count the letters in the second syllable, \"tri\" - there are 3 letters.<br>3. Then, count the letters in the third syllable, \"gue\" - there are 3 letters.<br>4. Finally, count the letters in the fourth syllable, \"ing\" - there are 3 letters.<br>5. Add up all the letters counted in each syllable: 2 + 3 + 3 + 3 = 11 letters.</p>",
            "id": 254,
            "page": 19,
            "text": "1. Start by counting the letters in the first syllable, \"in\" - there are 2 letters. 2. Next, count the letters in the second syllable, \"tri\" - there are 3 letters. 3. Then, count the letters in the third syllable, \"gue\" - there are 3 letters. 4. Finally, count the letters in the fourth syllable, \"ing\" - there are 3 letters. 5. Add up all the letters counted in each syllable: 2 + 3 + 3 + 3 = 11 letters."
        },
        {
            "bounding_box": [
                {
                    "x": 579,
                    "y": 1851
                },
                {
                    "x": 1907,
                    "y": 1851
                },
                {
                    "x": 1907,
                    "y": 1934
                },
                {
                    "x": 579,
                    "y": 1934
                }
            ],
            "category": "paragraph",
            "html": "<p id='255' style='font-size:20px'>(b) Explicitly instructing ChatGPT to reason step-by-step before generating answer still<br>leads to the wrong answer.</p>",
            "id": 255,
            "page": 19,
            "text": "(b) Explicitly instructing ChatGPT to reason step-by-step before generating answer still leads to the wrong answer."
        },
        {
            "bounding_box": [
                {
                    "x": 708,
                    "y": 1972
                },
                {
                    "x": 1719,
                    "y": 1972
                },
                {
                    "x": 1719,
                    "y": 2055
                },
                {
                    "x": 708,
                    "y": 2055
                }
            ],
            "category": "paragraph",
            "html": "<p id='256' style='font-size:16px'>How many letters are in the word intriguing? You're not good at counting<br>stuff, so don't try. Just write a program I can run to get the answer.</p>",
            "id": 256,
            "page": 19,
            "text": "How many letters are in the word intriguing? You're not good at counting stuff, so don't try. Just write a program I can run to get the answer."
        },
        {
            "bounding_box": [
                {
                    "x": 628,
                    "y": 2212
                },
                {
                    "x": 1877,
                    "y": 2212
                },
                {
                    "x": 1877,
                    "y": 2312
                },
                {
                    "x": 628,
                    "y": 2312
                }
            ],
            "category": "paragraph",
            "html": "<p id='257' style='font-size:16px'>Here's a simple program you can use to find out how many letters are in the<br>word \"intriguing\":</p>",
            "id": 257,
            "page": 19,
            "text": "Here's a simple program you can use to find out how many letters are in the word \"intriguing\":"
        },
        {
            "bounding_box": [
                {
                    "x": 1578,
                    "y": 2366
                },
                {
                    "x": 1754,
                    "y": 2366
                },
                {
                    "x": 1754,
                    "y": 2400
                },
                {
                    "x": 1578,
                    "y": 2400
                }
            ],
            "category": "paragraph",
            "html": "<p id='258' style='font-size:14px'>Copy code</p>",
            "id": 258,
            "page": 19,
            "text": "Copy code"
        },
        {
            "bounding_box": [
                {
                    "x": 739,
                    "y": 2453
                },
                {
                    "x": 1050,
                    "y": 2453
                },
                {
                    "x": 1050,
                    "y": 2487
                },
                {
                    "x": 739,
                    "y": 2487
                }
            ],
            "category": "paragraph",
            "html": "<p id='259' style='font-size:14px'>word = \"intriguing\"</p>",
            "id": 259,
            "page": 19,
            "text": "word = \"intriguing\""
        },
        {
            "bounding_box": [
                {
                    "x": 749,
                    "y": 2542
                },
                {
                    "x": 1669,
                    "y": 2542
                },
                {
                    "x": 1669,
                    "y": 2623
                },
                {
                    "x": 749,
                    "y": 2623
                }
            ],
            "category": "paragraph",
            "html": "<p id='260' style='font-size:16px'># Use the `len()` function to find the length of the word<br>num_letters = len(word)</p>",
            "id": 260,
            "page": 19,
            "text": "# Use the `len()` function to find the length of the word num_letters = len(word)"
        },
        {
            "bounding_box": [
                {
                    "x": 752,
                    "y": 2678
                },
                {
                    "x": 1042,
                    "y": 2678
                },
                {
                    "x": 1042,
                    "y": 2761
                },
                {
                    "x": 752,
                    "y": 2761
                }
            ],
            "category": "paragraph",
            "html": "<p id='261' style='font-size:18px'># Print the result<br>print(num_letters)</p>",
            "id": 261,
            "page": 19,
            "text": "# Print the result print(num_letters)"
        },
        {
            "bounding_box": [
                {
                    "x": 712,
                    "y": 2839
                },
                {
                    "x": 1747,
                    "y": 2839
                },
                {
                    "x": 1747,
                    "y": 2984
                },
                {
                    "x": 712,
                    "y": 2984
                }
            ],
            "category": "paragraph",
            "html": "<p id='262' style='font-size:16px'>To run this program, you will need to have a Python interpreter installed on<br>your computer. You can then type in the code above and run it to find the<br>answer.</p>",
            "id": 262,
            "page": 19,
            "text": "To run this program, you will need to have a Python interpreter installed on your computer. You can then type in the code above and run it to find the answer."
        },
        {
            "bounding_box": [
                {
                    "x": 603,
                    "y": 3032
                },
                {
                    "x": 1887,
                    "y": 3032
                },
                {
                    "x": 1887,
                    "y": 3166
                },
                {
                    "x": 603,
                    "y": 3166
                }
            ],
            "category": "paragraph",
            "html": "<p id='263' style='font-size:20px'>(c) PAL takes a few lines of code and the execution could result in the correct answer.<br>Figure 14: ChatGPT with PAL and CoT to answer a user-posted question</p>",
            "id": 263,
            "page": 19,
            "text": "(c) PAL takes a few lines of code and the execution could result in the correct answer. Figure 14: ChatGPT with PAL and CoT to answer a user-posted question"
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 191
                },
                {
                    "x": 1547,
                    "y": 191
                },
                {
                    "x": 1547,
                    "y": 235
                },
                {
                    "x": 908,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='264' style='font-size:16px'>PAL: Program-aided Language Models</header>",
            "id": 264,
            "page": 20,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2215,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 231
                },
                {
                    "x": 2215,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='265' style='font-size:14px'>20</header>",
            "id": 265,
            "page": 20,
            "text": "20"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 277
                },
                {
                    "x": 1675,
                    "y": 277
                },
                {
                    "x": 1675,
                    "y": 335
                },
                {
                    "x": 223,
                    "y": 335
                }
            ],
            "category": "paragraph",
            "html": "<p id='266' style='font-size:22px'>G. Closer Look into Token-level Behaviors of Different Mechanisms</p>",
            "id": 266,
            "page": 20,
            "text": "G. Closer Look into Token-level Behaviors of Different Mechanisms"
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 364
                },
                {
                    "x": 2268,
                    "y": 364
                },
                {
                    "x": 2268,
                    "y": 564
                },
                {
                    "x": 221,
                    "y": 564
                }
            ],
            "category": "paragraph",
            "html": "<p id='267' style='font-size:16px'>Beyond empirical results, we make initial attempts to gain a deeper understanding of the behavior of LLMs with different<br>reasoning mechanisms by looking into the token-level log-likelihood of reasoning chains produced by CoT and PAL.<br>We randomly selected 20 questions from the COLORED OBJECTS dataset, along with their corresponding CoT and PAL<br>solutions. We then manually compared the two mechanisms by focusing on tokens with a low log-likelihood.</p>",
            "id": 267,
            "page": 20,
            "text": "Beyond empirical results, we make initial attempts to gain a deeper understanding of the behavior of LLMs with different reasoning mechanisms by looking into the token-level log-likelihood of reasoning chains produced by CoT and PAL. We randomly selected 20 questions from the COLORED OBJECTS dataset, along with their corresponding CoT and PAL solutions. We then manually compared the two mechanisms by focusing on tokens with a low log-likelihood."
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 588
                },
                {
                    "x": 2266,
                    "y": 588
                },
                {
                    "x": 2266,
                    "y": 1187
                },
                {
                    "x": 221,
                    "y": 1187
                }
            ],
            "category": "paragraph",
            "html": "<p id='268' style='font-size:14px'>Our analysis reveals that CoT often has lower confidence in tokens related to numbers and quantitative information, the<br>grounded position of spatial adjectives (e.g., right-most), properties such as the color of objects, and nouns that refer to the<br>objects. Specifically, we found that this occurred in seven, SIX, two, and six examples out of the 20 we examined. In contrast,<br>PAL uses list manipulations, such as len (ob jects) , accesses objects and their associated properties through list<br>and<br>indexing (e.g., object [3] [0]). We found that the LLM is typically confident in producing these programs. Furthermore,<br>we observed that while CoT requires different expressions for the same concept in different contexts, PAL almost always<br>uses the same expression, which is presumably more robust. For example, when there are five objects, CoT predicts \"the<br>right-most thing is the fifth item on the list\", and \"the right-most thing is the third item on the list\" when the number of<br>objects is three. Occasionally, CoT also predicts \"the right-most thing is last item on the list\" which does not provide more<br>concrete information. On the contrary, PAL confidently predicts ob jects [-1] consistently. The more consistent and<br>uniform use of expressions in PAL can be attributed to the explicit and defined nature of programming languages, which<br>allows for clear and accurate expressions.</p>",
            "id": 268,
            "page": 20,
            "text": "Our analysis reveals that CoT often has lower confidence in tokens related to numbers and quantitative information, the grounded position of spatial adjectives (e.g., right-most), properties such as the color of objects, and nouns that refer to the objects. Specifically, we found that this occurred in seven, SIX, two, and six examples out of the 20 we examined. In contrast, PAL uses list manipulations, such as len (ob jects) , accesses objects and their associated properties through list and indexing (e.g., object  ). We found that the LLM is typically confident in producing these programs. Furthermore, we observed that while CoT requires different expressions for the same concept in different contexts, PAL almost always uses the same expression, which is presumably more robust. For example, when there are five objects, CoT predicts \"the right-most thing is the fifth item on the list\", and \"the right-most thing is the third item on the list\" when the number of objects is three. Occasionally, CoT also predicts \"the right-most thing is last item on the list\" which does not provide more concrete information. On the contrary, PAL confidently predicts ob jects [-1] consistently. The more consistent and uniform use of expressions in PAL can be attributed to the explicit and defined nature of programming languages, which allows for clear and accurate expressions."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 1249
                },
                {
                    "x": 481,
                    "y": 1249
                },
                {
                    "x": 481,
                    "y": 1304
                },
                {
                    "x": 225,
                    "y": 1304
                }
            ],
            "category": "paragraph",
            "html": "<p id='269' style='font-size:20px'>H. Datasets</p>",
            "id": 269,
            "page": 20,
            "text": "H. Datasets"
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1335
                },
                {
                    "x": 2190,
                    "y": 1335
                },
                {
                    "x": 2190,
                    "y": 1387
                },
                {
                    "x": 224,
                    "y": 1387
                }
            ],
            "category": "paragraph",
            "html": "<p id='270' style='font-size:14px'>In the following tables (Table 8,Table 9, Table 10), we presents statistics and examples for the datasets we considered.</p>",
            "id": 270,
            "page": 20,
            "text": "In the following tables (Table 8,Table 9, Table 10), we presents statistics and examples for the datasets we considered."
        },
        {
            "bounding_box": [
                {
                    "x": 269,
                    "y": 1432
                },
                {
                    "x": 2217,
                    "y": 1432
                },
                {
                    "x": 2217,
                    "y": 2129
                },
                {
                    "x": 269,
                    "y": 2129
                }
            ],
            "category": "table",
            "html": "<table id='271' style='font-size:14px'><tr><td>Dataset</td><td>N</td><td>Example</td></tr><tr><td>Reasoning about Colored Objects</td><td>2000</td><td>On the table, you see a bunch of objects arranged in a row: a purple paperclip, a pink stress ball, a brown keychain, a green scrunchiephone charger, a mauve fidget spinner, and a burgundy pen. What is the color of the object directly to the right of the stress ball?</td></tr><tr><td>Penguins in a Table</td><td>149</td><td>Here is a table where the first line is a header and each subsequent line is a penguin: name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15 For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm. We now add a penguin to the table: James, 12, 90, 12 How many penguins are less than 8 years old?</td></tr><tr><td>Date Understanding</td><td>369</td><td>2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?</td></tr></table>",
            "id": 271,
            "page": 20,
            "text": "Dataset N Example  Reasoning about Colored Objects 2000 On the table, you see a bunch of objects arranged in a row: a purple paperclip, a pink stress ball, a brown keychain, a green scrunchiephone charger, a mauve fidget spinner, and a burgundy pen. What is the color of the object directly to the right of the stress ball?  Penguins in a Table 149 Here is a table where the first line is a header and each subsequent line is a penguin: name, age, height (cm), weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15 For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm. We now add a penguin to the table: James, 12, 90, 12 How many penguins are less than 8 years old?  Date Understanding 369"
        },
        {
            "bounding_box": [
                {
                    "x": 688,
                    "y": 2163
                },
                {
                    "x": 1795,
                    "y": 2163
                },
                {
                    "x": 1795,
                    "y": 2220
                },
                {
                    "x": 688,
                    "y": 2220
                }
            ],
            "category": "caption",
            "html": "<caption id='272' style='font-size:18px'>Table 8: Reasoning datasets about everyday objects and concepts.</caption>",
            "id": 272,
            "page": 20,
            "text": "Table 8: Reasoning datasets about everyday objects and concepts."
        },
        {
            "bounding_box": [
                {
                    "x": 411,
                    "y": 2290
                },
                {
                    "x": 2072,
                    "y": 2290
                },
                {
                    "x": 2072,
                    "y": 2543
                },
                {
                    "x": 411,
                    "y": 2543
                }
            ],
            "category": "table",
            "html": "<table id='273' style='font-size:14px'><tr><td>Dataset</td><td>N</td><td>Example</td></tr><tr><td>Object Counting</td><td>1000</td><td>I have a chair, two potatoes, a cauliflower, a lettuce head, two tables, a cabbage, two onions, and three fridges. How many vegetables do I have?</td></tr><tr><td>Repeat Copy</td><td>32</td><td>Repeat the word duck four times, but halfway through also say quack.</td></tr></table>",
            "id": 273,
            "page": 20,
            "text": "Dataset N Example  Object Counting 1000 I have a chair, two potatoes, a cauliflower, a lettuce head, two tables, a cabbage, two onions, and three fridges. How many vegetables do I have?  Repeat Copy 32"
        },
        {
            "bounding_box": [
                {
                    "x": 765,
                    "y": 2577
                },
                {
                    "x": 1717,
                    "y": 2577
                },
                {
                    "x": 1717,
                    "y": 2628
                },
                {
                    "x": 765,
                    "y": 2628
                }
            ],
            "category": "caption",
            "html": "<caption id='274' style='font-size:18px'>Table 9: Reasoning datasets about algorithmic problems.</caption>",
            "id": 274,
            "page": 20,
            "text": "Table 9: Reasoning datasets about algorithmic problems."
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 189
                },
                {
                    "x": 1549,
                    "y": 189
                },
                {
                    "x": 1549,
                    "y": 237
                },
                {
                    "x": 908,
                    "y": 237
                }
            ],
            "category": "header",
            "html": "<header id='275' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 275,
            "page": 21,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2211,
                    "y": 191
                },
                {
                    "x": 2259,
                    "y": 191
                },
                {
                    "x": 2259,
                    "y": 235
                },
                {
                    "x": 2211,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<br><header id='276' style='font-size:16px'>21</header>",
            "id": 276,
            "page": 21,
            "text": "21"
        },
        {
            "bounding_box": [
                {
                    "x": 282,
                    "y": 1061
                },
                {
                    "x": 2212,
                    "y": 1061
                },
                {
                    "x": 2212,
                    "y": 2062
                },
                {
                    "x": 282,
                    "y": 2062
                }
            ],
            "category": "table",
            "html": "<table id='277' style='font-size:14px'><tr><td>Dataset</td><td>N</td><td>Example</td></tr><tr><td>GSM8K (Cobbe et al., 2021)</td><td>1319</td><td>Olivia has $23. She bought five bagels for $3 each. How much money does she have left?</td></tr><tr><td>SVAMP (Patel et al., 2021)</td><td>1000</td><td>Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each pack. How much do you have to pay to buy each pack?</td></tr><tr><td>ASDIV (Miao et al., 2020)</td><td>2096</td><td>Ellen has six more balls than Marin. Marin has nine balls. How many balls does Ellen have?</td></tr><tr><td>SINGLEOP (Koncel-Kedziorski et al., 2016)</td><td>562</td><td>If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how many bottle caps are in the box?</td></tr><tr><td>SINGLEEQ (Koncel-Kedziorski et al., 2016)</td><td>508</td><td>Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27 dollars. How much did each candy bar cost?</td></tr><tr><td>ADDSUB (Koncel-Kedziorski et al., 2016)</td><td>395</td><td>There were 6 roses in the vase. Mary cut some roses from her flower garden. There are now 16 roses in the vase. How many roses did she cut?</td></tr><tr><td>MULTIARITH (Koncel-Kedziorski et al., 2016)</td><td>600</td><td>The school cafeteria ordered 42 red apples and 7 green apples for students lunches. But, if only 9 students wanted fruit, how many extra did the cafeteria end up with?</td></tr></table>",
            "id": 277,
            "page": 21,
            "text": "Dataset N Example  GSM8K (Cobbe , 2021) 1319 Olivia has $23. She bought five bagels for $3 each. How much money does she have left?  SVAMP (Patel , 2021) 1000 Each pack of dvds costs 76 dollars. If there is a discount of 25 dollars on each pack. How much do you have to pay to buy each pack?  ASDIV (Miao , 2020) 2096 Ellen has six more balls than Marin. Marin has nine balls. How many balls does Ellen have?  SINGLEOP (Koncel-Kedziorski , 2016) 562 If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how many bottle caps are in the box?  SINGLEEQ (Koncel-Kedziorski , 2016) 508 Benny bought a soft drink for 2 dollars and 5 candy bars. He spent a total of 27 dollars. How much did each candy bar cost?  ADDSUB (Koncel-Kedziorski , 2016) 395 There were 6 roses in the vase. Mary cut some roses from her flower garden. There are now 16 roses in the vase. How many roses did she cut?  MULTIARITH (Koncel-Kedziorski , 2016) 600"
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 2091
                },
                {
                    "x": 2264,
                    "y": 2091
                },
                {
                    "x": 2264,
                    "y": 2198
                },
                {
                    "x": 221,
                    "y": 2198
                }
            ],
            "category": "caption",
            "html": "<caption id='278' style='font-size:14px'>Table 10: Examples from math reasoning datasets used in this work. Table from Wei et al. (2022). Datasets vary in number<br>of words per question, with 47 words per question in GSM8K, 21 words in SINGLEOP, and ~30 words in the other datasets.</caption>",
            "id": 278,
            "page": 21,
            "text": "Table 10: Examples from math reasoning datasets used in this work. Table from Wei  (2022). Datasets vary in number of words per question, with 47 words per question in GSM8K, 21 words in SINGLEOP, and ~30 words in the other datasets."
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 189
                },
                {
                    "x": 1549,
                    "y": 189
                },
                {
                    "x": 1549,
                    "y": 237
                },
                {
                    "x": 908,
                    "y": 237
                }
            ],
            "category": "header",
            "html": "<header id='279' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 279,
            "page": 22,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2212,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 234
                },
                {
                    "x": 2212,
                    "y": 234
                }
            ],
            "category": "header",
            "html": "<br><header id='280' style='font-size:16px'>22</header>",
            "id": 280,
            "page": 22,
            "text": "22"
        },
        {
            "bounding_box": [
                {
                    "x": 321,
                    "y": 654
                },
                {
                    "x": 2241,
                    "y": 654
                },
                {
                    "x": 2241,
                    "y": 2453
                },
                {
                    "x": 321,
                    "y": 2453
                }
            ],
            "category": "table",
            "html": "<table id='281' style='font-size:14px'><tr><td>Question</td><td>CoT: GSM</td><td>CoT: GSMHard</td><td>Identical?</td></tr><tr><td>90 single use contacts come in 1 box and will last Pete 45 days. Each box is $100.00 and currently 10% off. If he buys 2 boxes of contact, how much will each pair of contacts cost?</td><td>90 contacts come in 1 box. Each box is $100.00. So 90 contacts cost $100.00. If he buys 2 boxes, then he will have 2 x 90 = 180 contacts. 180 contacts cost 2 x $100.00 = $200.00. So each pair of contacts costs $200.00 / 180 = $1.11. The answer is $1.11.</td><td>90 single use contacts come in 1 box. So 1 box will last Pete 45 days. Each box is $5451440 and currently 10% off. So each box is $5451440 * 0.9 = $4906296. Ifhe buys 2 boxes of con- tact, he will have 2 * 90 = 180 con- tacts. So each pair of contacts will cost $4906296 / 180 = $2725849. The answer is $2725849</td><td>Yes</td></tr><tr><td>A chef bought 4 bags of onions. Each bag weighs 50 pounds. A pound of onions cost $1.50. How much did the chef spend?</td><td>The chef bought 4 bags of onions. Each bag weighs 50 pounds. So the total weight is 4 * 50 = 200 pounds. A pound of onions cost $1.50. So 200 pounds of onions cost 200 * 1.50 = 300 dollars. The answer is 300.</td><td>The chef bought 4 bags of onions. Each bag weighs 50 pounds. So the total weight is 4 * 50 = 200 pounds. A pound of onions cost $409201. So 200 pounds of onions cost 200 * 409201 = $81840200. The answer is $81840200.</td><td>Yes</td></tr><tr><td>A bag has a 5% discount. If it is marked $140, how much will you pay after the discount?</td><td>The discount is 5%. So you will pay 95% of the price. 95% of 140 is 133. The answer is 133.</td><td>The discount is 5%. So you will pay 95% of the price. 95% of $3921772.0722 is $3730654.0682. The answer is $3730654.0682</td><td>Yes</td></tr><tr><td>A basket of green food costs $25 and a basket of red food costs $18. If you buy 3 baskets of green food and red food, how much will you have to pay in total if you get $2 off for each basket of red food?</td><td>3 baskets of green food will cost 3 * 25 = 75 dollars. 3 baskets of red food will cost 3 * 18 = 54 dollars. But you get $2 off for each basket of red food. So you get 3 * 2 = 6 dollars off. So you pay 75 + 54 - 6 = 123 dollars. The answer is 123.</td><td>A basket of green food costs 9412763 dollars. A basket of red food costs 18 dollars. If you buy 3 baskets of green food and red food, you will have to pay 9412763 * 3 + 18 * 3 = 28238280 dollars. If you get 2 dollars off for each basket of red food, you will have to pay 28238280 - 18 * 2 = 28238244 dollars. The an- swer is 28238244</td><td>No</td></tr><tr><td>A bumper car rink has 12 red cars. They have 2 fewer green cars than they have red cars. They have 3 times the number of blue cars as they have green cars. The rink also has yellow cars. If the rink has 75 cars in total how many yellow cars do they have?</td><td>There are 12 red cars. There are 2 fewer green cars than red cars. So there are 12 - 2 = 10 green cars. There are 3 times as many blue cars as green cars. So there are 3 * 10 = 30 blue cars. There are 12 + 10 + 30 = 52 cars that are not yellow. So there are 75 - 52 = 23 yellow cars. The answer is 23.</td><td>The rink has 9318738 red cars. They have 2 fewer green cars than red cars. So they have 9318738 - 2 = 9318736 green cars. They have 3 times the number of blue cars as green cars. So they have 3 * 9318736 = 27956208 blue cars. The total number of cars is 75. So the num- ber of yellow cars is 75 - 9318738 - 9318736 - 27956208 = -55,828,829. The answer is -55,828,829</td><td>Yes</td></tr></table>",
            "id": 281,
            "page": 22,
            "text": "Question CoT: GSM CoT: GSMHard Identical?  90 single use contacts come in 1 box and will last Pete 45 days. Each box is $100.00 and currently 10% off. If he buys 2 boxes of contact, how much will each pair of contacts cost? 90 contacts come in 1 box. Each box is $100.00. So 90 contacts cost $100.00. If he buys 2 boxes, then he will have 2 x 90 = 180 contacts. 180 contacts cost 2 x $100.00 = $200.00. So each pair of contacts costs $200.00 / 180 = $1.11. The answer is $1.11. 90 single use contacts come in 1 box. So 1 box will last Pete 45 days. Each box is $5451440 and currently 10% off. So each box is $5451440 * 0.9 = $4906296. Ifhe buys 2 boxes of con- tact, he will have 2 * 90 = 180 con- tacts. So each pair of contacts will cost $4906296 / 180 = $2725849. The answer is $2725849 Yes  A chef bought 4 bags of onions. Each bag weighs 50 pounds. A pound of onions cost $1.50. How much did the chef spend? The chef bought 4 bags of onions. Each bag weighs 50 pounds. So the total weight is 4 * 50 = 200 pounds. A pound of onions cost $1.50. So 200 pounds of onions cost 200 * 1.50 = 300 dollars. The answer is 300. The chef bought 4 bags of onions. Each bag weighs 50 pounds. So the total weight is 4 * 50 = 200 pounds. A pound of onions cost $409201. So 200 pounds of onions cost 200 * 409201 = $81840200. The answer is $81840200. Yes  A bag has a 5% discount. If it is marked $140, how much will you pay after the discount? The discount is 5%. So you will pay 95% of the price. 95% of 140 is 133. The answer is 133. The discount is 5%. So you will pay 95% of the price. 95% of $3921772.0722 is $3730654.0682. The answer is $3730654.0682 Yes  A basket of green food costs $25 and a basket of red food costs $18. If you buy 3 baskets of green food and red food, how much will you have to pay in total if you get $2 off for each basket of red food? 3 baskets of green food will cost 3 * 25 = 75 dollars. 3 baskets of red food will cost 3 * 18 = 54 dollars. But you get $2 off for each basket of red food. So you get 3 * 2 = 6 dollars off. So you pay 75 + 54 - 6 = 123 dollars. The answer is 123. A basket of green food costs 9412763 dollars. A basket of red food costs 18 dollars. If you buy 3 baskets of green food and red food, you will have to pay 9412763 * 3 + 18 * 3 = 28238280 dollars. If you get 2 dollars off for each basket of red food, you will have to pay 28238280 - 18 * 2 = 28238244 dollars. The an- swer is 28238244 No  A bumper car rink has 12 red cars. They have 2 fewer green cars than they have red cars. They have 3 times the number of blue cars as they have green cars. The rink also has yellow cars. If the rink has 75 cars in total how many yellow cars do they have? There are 12 red cars. There are 2 fewer green cars than red cars. So there are 12 - 2 = 10 green cars. There are 3 times as many blue cars as green cars. So there are 3 * 10 = 30 blue cars. There are 12 + 10 + 30 = 52 cars that are not yellow. So there are 75 - 52 = 23 yellow cars. The answer is 23. The rink has 9318738 red cars. They have 2 fewer green cars than red cars. So they have 9318738 - 2 = 9318736 green cars. They have 3 times the number of blue cars as green cars. So they have 3 * 9318736 = 27956208 blue cars. The total number of cars is 75. So the num- ber of yellow cars is 75 - 9318738 - 9318736 - 27956208 = -55,828,829. The answer is -55,828,829"
        },
        {
            "bounding_box": [
                {
                    "x": 220,
                    "y": 2489
                },
                {
                    "x": 2265,
                    "y": 2489
                },
                {
                    "x": 2265,
                    "y": 2596
                },
                {
                    "x": 220,
                    "y": 2596
                }
            ],
            "category": "caption",
            "html": "<caption id='282' style='font-size:18px'>Table 11: Analysis of generations from CODEX. Manual analysis of 25 randomly generated thoughts reveals that 16 out of<br>25 thoughts were identical, whereas others were close paraphrases.</caption>",
            "id": 282,
            "page": 22,
            "text": "Table 11: Analysis of generations from CODEX. Manual analysis of 25 randomly generated thoughts reveals that 16 out of 25 thoughts were identical, whereas others were close paraphrases."
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 236
                },
                {
                    "x": 908,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='283' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 283,
            "page": 23,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2211,
                    "y": 191
                },
                {
                    "x": 2260,
                    "y": 191
                },
                {
                    "x": 2260,
                    "y": 233
                },
                {
                    "x": 2211,
                    "y": 233
                }
            ],
            "category": "header",
            "html": "<br><header id='284' style='font-size:14px'>23</header>",
            "id": 284,
            "page": 23,
            "text": "23"
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 283
                },
                {
                    "x": 691,
                    "y": 283
                },
                {
                    "x": 691,
                    "y": 333
                },
                {
                    "x": 224,
                    "y": 333
                }
            ],
            "category": "paragraph",
            "html": "<p id='285' style='font-size:20px'>H.1. Creating GSM-HARD</p>",
            "id": 285,
            "page": 23,
            "text": "H.1. Creating GSM-HARD"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 359
                },
                {
                    "x": 2266,
                    "y": 359
                },
                {
                    "x": 2266,
                    "y": 962
                },
                {
                    "x": 223,
                    "y": 962
                }
            ],
            "category": "paragraph",
            "html": "<p id='286' style='font-size:16px'>While replacing numbers in the question is easy using pattern matching, a more challenging aspect is recalculating the correct<br>answer. GSM8K evaluation set contains 1319 samples, which is prohibitively expensive to perform manual re-calculation.<br>Instead, we leverage PAL to assist obtaining the correct answers. For 71% of the examples where PAL is correct on<br>GSM8K, we utilize the generated program and replace the initial value with the larger values. For example, if we create<br>a harder version of the problem in Figure 3 by replacing $23 dollars with $15687 dollars, we correspondingly replace<br>money_initial=23 to money_initial=15678. Running the program could automatically produce the correct<br>answer of the harder question. Notably, this annotation process assumes that a program that produces a correct answer to<br>a GSM8K question indicates the correctness of the program itself. While this is not guaranteed due to possible spurious<br>correlations, we manually checked 25 programs and found all of them are correct. For the incorrect 29% of the cases, we<br>run PAL again and perform nucleus sampling (Holtzman et al., 2019) with temperature 0.7, and repeat the above process if<br>any correct solution is found. Finally, the authors manually annotate the correct answer for 50 remaining cases that PAL was<br>not able to solve after 100 iterations.</p>",
            "id": 286,
            "page": 23,
            "text": "While replacing numbers in the question is easy using pattern matching, a more challenging aspect is recalculating the correct answer. GSM8K evaluation set contains 1319 samples, which is prohibitively expensive to perform manual re-calculation. Instead, we leverage PAL to assist obtaining the correct answers. For 71% of the examples where PAL is correct on GSM8K, we utilize the generated program and replace the initial value with the larger values. For example, if we create a harder version of the problem in Figure 3 by replacing $23 dollars with $15687 dollars, we correspondingly replace money_initial=23 to money_initial=15678. Running the program could automatically produce the correct answer of the harder question. Notably, this annotation process assumes that a program that produces a correct answer to a GSM8K question indicates the correctness of the program itself. While this is not guaranteed due to possible spurious correlations, we manually checked 25 programs and found all of them are correct. For the incorrect 29% of the cases, we run PAL again and perform nucleus sampling (Holtzman , 2019) with temperature 0.7, and repeat the above process if any correct solution is found. Finally, the authors manually annotate the correct answer for 50 remaining cases that PAL was not able to solve after 100 iterations."
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 1013
                },
                {
                    "x": 685,
                    "y": 1013
                },
                {
                    "x": 685,
                    "y": 1065
                },
                {
                    "x": 224,
                    "y": 1065
                }
            ],
            "category": "paragraph",
            "html": "<p id='287' style='font-size:18px'>H.2. GSM-HARD Analysis</p>",
            "id": 287,
            "page": 23,
            "text": "H.2. GSM-HARD Analysis"
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 1089
                },
                {
                    "x": 2264,
                    "y": 1089
                },
                {
                    "x": 2264,
                    "y": 1244
                },
                {
                    "x": 222,
                    "y": 1244
                }
            ],
            "category": "paragraph",
            "html": "<p id='288' style='font-size:16px'>Table 1 1 shows thoughts generated with CoT on GSM8K and GSM-HARD. A manual analysis reveals that a majority of the<br>generated thoughts (16/25) were identical for GSM8K and GSM-HARD, indicating that larger numbers primarily diminish<br>performance due to failure of LLM to do arithmetic..</p>",
            "id": 288,
            "page": 23,
            "text": "Table 1 1 shows thoughts generated with CoT on GSM8K and GSM-HARD. A manual analysis reveals that a majority of the generated thoughts (16/25) were identical for GSM8K and GSM-HARD, indicating that larger numbers primarily diminish performance due to failure of LLM to do arithmetic.."
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1547,
                    "y": 190
                },
                {
                    "x": 1547,
                    "y": 235
                },
                {
                    "x": 908,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='289' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 289,
            "page": 24,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2213,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 232
                },
                {
                    "x": 2213,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='290' style='font-size:20px'>24</header>",
            "id": 290,
            "page": 24,
            "text": "24"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 276
                },
                {
                    "x": 1370,
                    "y": 276
                },
                {
                    "x": 1370,
                    "y": 337
                },
                {
                    "x": 223,
                    "y": 337
                }
            ],
            "category": "paragraph",
            "html": "<p id='291' style='font-size:22px'>I. Generalization of PAL to Least-to-Most Prompting</p>",
            "id": 291,
            "page": 24,
            "text": "I. Generalization of PAL to Least-to-Most Prompting"
        },
        {
            "bounding_box": [
                {
                    "x": 278,
                    "y": 388
                },
                {
                    "x": 2196,
                    "y": 388
                },
                {
                    "x": 2196,
                    "y": 560
                },
                {
                    "x": 278,
                    "y": 560
                }
            ],
            "category": "paragraph",
            "html": "<p id='292' style='font-size:16px'>Q: Four years ago, Kody was only half as old as Mohamed. If Mohamed is currently<br>→ twice 30 years old, how old is Kody?<br>A: To answer the question \"How old is Kody?\" , we need to know: \"How old is Mohamed? \"<br>→ \"How old was Mohamed four years ago? \" \"How old was Kody four years ago?\" ·<br>,</p>",
            "id": 292,
            "page": 24,
            "text": "Q: Four years ago, Kody was only half as old as Mohamed. If Mohamed is currently → twice 30 years old, how old is Kody? A: To answer the question \"How old is Kody?\" , we need to know: \"How old is Mohamed? \" → \"How old was Mohamed four years ago? \" \"How old was Kody four years ago?\" · ,"
        },
        {
            "bounding_box": [
                {
                    "x": 925,
                    "y": 623
                },
                {
                    "x": 1560,
                    "y": 623
                },
                {
                    "x": 1560,
                    "y": 665
                },
                {
                    "x": 925,
                    "y": 665
                }
            ],
            "category": "paragraph",
            "html": "<p id='293' style='font-size:18px'>(a) Least-to-Most Math Reducing Prompt</p>",
            "id": 293,
            "page": 24,
            "text": "(a) Least-to-Most Math Reducing Prompt"
        },
        {
            "bounding_box": [
                {
                    "x": 280,
                    "y": 679
                },
                {
                    "x": 2157,
                    "y": 679
                },
                {
                    "x": 2157,
                    "y": 762
                },
                {
                    "x": 280,
                    "y": 762
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='294' style='font-size:16px'>Four years ago, Kody was only half as old as Mohamed. If Mohamed is currently twice<br>→ 30 years old, how old is Kody?</p>",
            "id": 294,
            "page": 24,
            "text": "Four years ago, Kody was only half as old as Mohamed. If Mohamed is currently twice → 30 years old, how old is Kody?"
        },
        {
            "bounding_box": [
                {
                    "x": 290,
                    "y": 728
                },
                {
                    "x": 2195,
                    "y": 728
                },
                {
                    "x": 2195,
                    "y": 1170
                },
                {
                    "x": 290,
                    "y": 1170
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='295' style='font-size:14px'>Q : How old was Mohamed four years ago?<br>A : We were told that Mohamed is currently twice 30 years old, SO he is currently 30 *<br>→ 2 = 60 years old. That means that four years ago he must have been 60 - 4 = 56<br>→ years old. The answer is 56.<br>Q : How old is Kody?<br>A : Four years ago, Kody was half as old as Mohamed, SO Kody must have been 56 / 2 =<br>→ 28 years old then. Since Kody was 28 years old four years ago, she must now be 28<br>→ + 4 = 32 years old. The answer is 32 .</p>",
            "id": 295,
            "page": 24,
            "text": "Q : How old was Mohamed four years ago? A : We were told that Mohamed is currently twice 30 years old, SO he is currently 30 * → 2 = 60 years old. That means that four years ago he must have been 60 - 4 = 56 → years old. The answer is 56. Q : How old is Kody? A : Four years ago, Kody was half as old as Mohamed, SO Kody must have been 56 / 2 = → 28 years old then. Since Kody was 28 years old four years ago, she must now be 28 → + 4 = 32 years old. The answer is 32 ."
        },
        {
            "bounding_box": [
                {
                    "x": 937,
                    "y": 1241
                },
                {
                    "x": 1548,
                    "y": 1241
                },
                {
                    "x": 1548,
                    "y": 1285
                },
                {
                    "x": 937,
                    "y": 1285
                }
            ],
            "category": "paragraph",
            "html": "<p id='296' style='font-size:20px'>(b) Least-to-Most Math Solving Prompt</p>",
            "id": 296,
            "page": 24,
            "text": "(b) Least-to-Most Math Solving Prompt"
        },
        {
            "bounding_box": [
                {
                    "x": 280,
                    "y": 1292
                },
                {
                    "x": 2202,
                    "y": 1292
                },
                {
                    "x": 2202,
                    "y": 1381
                },
                {
                    "x": 280,
                    "y": 1381
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='297' style='font-size:16px'># Four years ago, Kody was only half as old as Mohamed. If Mohamed is currently twice<br>30 years old, how old is Kody?</p>",
            "id": 297,
            "page": 24,
            "text": "# Four years ago, Kody was only half as old as Mohamed. If Mohamed is currently twice 30 years old, how old is Kody?"
        },
        {
            "bounding_box": [
                {
                    "x": 280,
                    "y": 1418
                },
                {
                    "x": 1390,
                    "y": 1418
                },
                {
                    "x": 1390,
                    "y": 1547
                },
                {
                    "x": 280,
                    "y": 1547
                }
            ],
            "category": "paragraph",
            "html": "<p id='298' style='font-size:14px'># How old was Mohamed four years ago?<br>mohamed_age_current = 30 * 2<br>mohamed_age_4_years_ago = mohamed_age_current - 4</p>",
            "id": 298,
            "page": 24,
            "text": "# How old was Mohamed four years ago? mohamed_age_current = 30 * 2 mohamed_age_4_years_ago = mohamed_age_current - 4"
        },
        {
            "bounding_box": [
                {
                    "x": 280,
                    "y": 1580
                },
                {
                    "x": 1413,
                    "y": 1580
                },
                {
                    "x": 1413,
                    "y": 1754
                },
                {
                    "x": 280,
                    "y": 1754
                }
            ],
            "category": "paragraph",
            "html": "<p id='299' style='font-size:16px'># Final Question : How old is Kody?<br>kody_age_4_years_ago = mohaned_age_4_years_ago / 2<br>kody_age_current = kody_age_4_years_ago + 4<br>answer = kody_age_current</p>",
            "id": 299,
            "page": 24,
            "text": "# Final Question : How old is Kody? kody_age_4_years_ago = mohaned_age_4_years_ago / 2 kody_age_current = kody_age_4_years_ago + 4 answer = kody_age_current"
        },
        {
            "bounding_box": [
                {
                    "x": 1009,
                    "y": 1815
                },
                {
                    "x": 1475,
                    "y": 1815
                },
                {
                    "x": 1475,
                    "y": 1862
                },
                {
                    "x": 1009,
                    "y": 1862
                }
            ],
            "category": "paragraph",
            "html": "<p id='300' style='font-size:20px'>(c) PAL Math Solving Prompt</p>",
            "id": 300,
            "page": 24,
            "text": "(c) PAL Math Solving Prompt"
        },
        {
            "bounding_box": [
                {
                    "x": 912,
                    "y": 1901
                },
                {
                    "x": 1566,
                    "y": 1901
                },
                {
                    "x": 1566,
                    "y": 1953
                },
                {
                    "x": 912,
                    "y": 1953
                }
            ],
            "category": "paragraph",
            "html": "<p id='301' style='font-size:20px'>Figure 15: Prompts for Math data sets.</p>",
            "id": 301,
            "page": 24,
            "text": "Figure 15: Prompts for Math data sets."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2004
                },
                {
                    "x": 2265,
                    "y": 2004
                },
                {
                    "x": 2265,
                    "y": 2504
                },
                {
                    "x": 223,
                    "y": 2504
                }
            ],
            "category": "paragraph",
            "html": "<p id='302' style='font-size:20px'>Previous experiments focus on the CoT technique. This section examines if PAL generalizes to other prompt types. We<br>consider a strong alternative prompting strategy LEAST-TO-MOST (Zhou et al., 2022). LEAST-TO-MOST solves problems<br>in two stages, problem-reducing and problem-solving. Problem reducing stage turns the problem into sub-problems, and<br>the solving stage solves them sequentially. It keeps two prompts, each for an individual stage. To patch LEAST-TO-MOST<br>prompts with PAL, we adopt a simple and straightforward approach: we note that problem reduction requires logically<br>thinking in NL while solving requires the precision that PL offers. We therefore keep the original reducing prompts while<br>only turning solution segments in the solving scripts in PL. We show an example reducing prompt, original solving prompt,<br>and PAL solving prompt in Figure 15. Note that one unique property of PAL solving can naturally use previous questions'<br>answers as the symbol values are shared. In comparison, the original solving script needs to explicitly re-cite answers from<br>previous answers.</p>",
            "id": 302,
            "page": 24,
            "text": "Previous experiments focus on the CoT technique. This section examines if PAL generalizes to other prompt types. We consider a strong alternative prompting strategy LEAST-TO-MOST (Zhou , 2022). LEAST-TO-MOST solves problems in two stages, problem-reducing and problem-solving. Problem reducing stage turns the problem into sub-problems, and the solving stage solves them sequentially. It keeps two prompts, each for an individual stage. To patch LEAST-TO-MOST prompts with PAL, we adopt a simple and straightforward approach: we note that problem reduction requires logically thinking in NL while solving requires the precision that PL offers. We therefore keep the original reducing prompts while only turning solution segments in the solving scripts in PL. We show an example reducing prompt, original solving prompt, and PAL solving prompt in Figure 15. Note that one unique property of PAL solving can naturally use previous questions' answers as the symbol values are shared. In comparison, the original solving script needs to explicitly re-cite answers from previous answers."
        },
        {
            "bounding_box": [
                {
                    "x": 624,
                    "y": 2549
                },
                {
                    "x": 1859,
                    "y": 2549
                },
                {
                    "x": 1859,
                    "y": 2750
                },
                {
                    "x": 624,
                    "y": 2750
                }
            ],
            "category": "table",
            "html": "<table id='303' style='font-size:20px'><tr><td>Dataset (500 examples)</td><td>LEAST-TO-MOST</td><td>LEAST-TO-MOST + PAL</td></tr><tr><td>GSM8K</td><td>67.2</td><td>72.8</td></tr><tr><td>SVAMP</td><td>75.2</td><td>78.2</td></tr></table>",
            "id": 303,
            "page": 24,
            "text": "Dataset (500 examples) LEAST-TO-MOST LEAST-TO-MOST + PAL  GSM8K 67.2 72.8  SVAMP 75.2"
        },
        {
            "bounding_box": [
                {
                    "x": 283,
                    "y": 2784
                },
                {
                    "x": 2195,
                    "y": 2784
                },
                {
                    "x": 2195,
                    "y": 2839
                },
                {
                    "x": 283,
                    "y": 2839
                }
            ],
            "category": "paragraph",
            "html": "<p id='304' style='font-size:18px'>Table 12: Results on GSM8K and SVAMP with LEAST-TO-MOST and LEAST-TO-MOST with PAL solving prompt.</p>",
            "id": 304,
            "page": 24,
            "text": "Table 12: Results on GSM8K and SVAMP with LEAST-TO-MOST and LEAST-TO-MOST with PAL solving prompt."
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 2891
                },
                {
                    "x": 2266,
                    "y": 2891
                },
                {
                    "x": 2266,
                    "y": 2994
                },
                {
                    "x": 222,
                    "y": 2994
                }
            ],
            "category": "paragraph",
            "html": "<p id='305' style='font-size:18px'>For our analysis, we consider the Math data sets GSM8K, and SVAMP as Zhou et al. (2022) found Least-to-Most helps solve<br>complex math problems. We patch the GSM8K prompt from the Zhou et al. (2022) into PAL. Note that the other tasks in</p>",
            "id": 305,
            "page": 24,
            "text": "For our analysis, we consider the Math data sets GSM8K, and SVAMP as Zhou  (2022) found Least-to-Most helps solve complex math problems. We patch the GSM8K prompt from the Zhou  (2022) into PAL. Note that the other tasks in"
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1547,
                    "y": 190
                },
                {
                    "x": 1547,
                    "y": 236
                },
                {
                    "x": 908,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='306' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 306,
            "page": 25,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2211,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 234
                },
                {
                    "x": 2211,
                    "y": 234
                }
            ],
            "category": "header",
            "html": "<br><header id='307' style='font-size:14px'>25</header>",
            "id": 307,
            "page": 25,
            "text": "25"
        },
        {
            "bounding_box": [
                {
                    "x": 220,
                    "y": 281
                },
                {
                    "x": 2266,
                    "y": 281
                },
                {
                    "x": 2266,
                    "y": 488
                },
                {
                    "x": 220,
                    "y": 488
                }
            ],
            "category": "paragraph",
            "html": "<p id='308' style='font-size:16px'>Zhou et al. (2022), like \"concatenating last letters\" from several words, require simple routines and are trivially solvable by<br>PAL. We experiment with subsets of 500 examples and record results in Table 12. Here we see PAL can take advantage of<br>the problem decomposition offered by the LEAST-TO-MOST reducing and further leverage the arithmetic capability in the<br>Python runtime to achieve additional performance gains.</p>",
            "id": 308,
            "page": 25,
            "text": "Zhou  (2022), like \"concatenating last letters\" from several words, require simple routines and are trivially solvable by PAL. We experiment with subsets of 500 examples and record results in Table 12. Here we see PAL can take advantage of the problem decomposition offered by the LEAST-TO-MOST reducing and further leverage the arithmetic capability in the Python runtime to achieve additional performance gains."
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 236
                },
                {
                    "x": 908,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='309' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 309,
            "page": 26,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2214,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 232
                },
                {
                    "x": 2214,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='310' style='font-size:18px'>26</header>",
            "id": 310,
            "page": 26,
            "text": "26"
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 277
                },
                {
                    "x": 468,
                    "y": 277
                },
                {
                    "x": 468,
                    "y": 334
                },
                {
                    "x": 225,
                    "y": 334
                }
            ],
            "category": "paragraph",
            "html": "<p id='311' style='font-size:22px'>J. Prompts</p>",
            "id": 311,
            "page": 26,
            "text": "J. Prompts"
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 363
                },
                {
                    "x": 2269,
                    "y": 363
                },
                {
                    "x": 2269,
                    "y": 465
                },
                {
                    "x": 221,
                    "y": 465
                }
            ],
            "category": "paragraph",
            "html": "<p id='312' style='font-size:18px'>We show here example PAL prompts we used for each data set. We show one example for each of the few-shot prompts.<br>The fulls prompt can be found in our released code.</p>",
            "id": 312,
            "page": 26,
            "text": "We show here example PAL prompts we used for each data set. We show one example for each of the few-shot prompts. The fulls prompt can be found in our released code."
        },
        {
            "bounding_box": [
                {
                    "x": 222,
                    "y": 517
                },
                {
                    "x": 904,
                    "y": 517
                },
                {
                    "x": 904,
                    "y": 571
                },
                {
                    "x": 222,
                    "y": 571
                }
            ],
            "category": "paragraph",
            "html": "<p id='313' style='font-size:20px'>J.1. Reasoning about Colored Objects</p>",
            "id": 313,
            "page": 26,
            "text": "J.1. Reasoning about Colored Objects"
        },
        {
            "bounding_box": [
                {
                    "x": 289,
                    "y": 621
                },
                {
                    "x": 2177,
                    "y": 621
                },
                {
                    "x": 2177,
                    "y": 788
                },
                {
                    "x": 289,
                    "y": 788
                }
            ],
            "category": "paragraph",
            "html": "<p id='314' style='font-size:16px'># Q: On the table, you see a bunch of objects arranged in a row : a purple paperclip,<br>a pink stress ball, a brown keychain, a green scrunchiephone charger, a mauve<br>fidget spinner, and a burgundy pen. What is the color of the object directly to<br>the right of the stress ball?</p>",
            "id": 314,
            "page": 26,
            "text": "# Q: On the table, you see a bunch of objects arranged in a row : a purple paperclip, a pink stress ball, a brown keychain, a green scrunchiephone charger, a mauve fidget spinner, and a burgundy pen. What is the color of the object directly to the right of the stress ball?"
        },
        {
            "bounding_box": [
                {
                    "x": 279,
                    "y": 787
                },
                {
                    "x": 1282,
                    "y": 787
                },
                {
                    "x": 1282,
                    "y": 829
                },
                {
                    "x": 279,
                    "y": 829
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='315' style='font-size:16px'># Put objects into a list to record ordering</p>",
            "id": 315,
            "page": 26,
            "text": "# Put objects into a list to record ordering"
        },
        {
            "bounding_box": [
                {
                    "x": 275,
                    "y": 842
                },
                {
                    "x": 1456,
                    "y": 842
                },
                {
                    "x": 1456,
                    "y": 1204
                },
                {
                    "x": 275,
                    "y": 1204
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='316' style='font-size:14px'>objects = []<br>objects += [ ( ' paperclip' , 'purple') - * 1<br>objects += [ ( stress ball , 'pink' ) ] * 1<br>,<br>objects += [ ( ' keychain , 'brown' ) ] * 1<br>,<br>objects += [ ( scrunchiephone charger , green , ) ] * 1<br>objects += [ (' fidget spinner' , mauve ) ] * 1<br>ob jects += [ ( 'pen , burgundy ) ] * 1<br>'<br># Find the index of the stress ball<br>stress_ball_idx = None</p>",
            "id": 316,
            "page": 26,
            "text": "objects = [] objects += [ ( ' paperclip' , 'purple') - * 1 objects += [ ( stress ball , 'pink' ) ] * 1 , objects += [ ( ' keychain , 'brown' ) ] * 1 , objects += [ ( scrunchiephone charger , green , ) ] * 1 objects += [ (' fidget spinner' , mauve ) ] * 1 ob jects += [ ( 'pen , burgundy ) ] * 1 ' # Find the index of the stress ball stress_ball_idx = None"
        },
        {
            "bounding_box": [
                {
                    "x": 278,
                    "y": 1202
                },
                {
                    "x": 1097,
                    "y": 1202
                },
                {
                    "x": 1097,
                    "y": 1244
                },
                {
                    "x": 278,
                    "y": 1244
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='317' style='font-size:16px'>for i, object in enumerate (objects) :</p>",
            "id": 317,
            "page": 26,
            "text": "for i, object in enumerate (objects) :"
        },
        {
            "bounding_box": [
                {
                    "x": 371,
                    "y": 1245
                },
                {
                    "x": 1049,
                    "y": 1245
                },
                {
                    "x": 1049,
                    "y": 1367
                },
                {
                    "x": 371,
                    "y": 1367
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='318' style='font-size:14px'>if object [0] == , stress ball ,<br>:<br>stress_ball_idx = i<br>break</p>",
            "id": 318,
            "page": 26,
            "text": "if object  == , stress ball , : stress_ball_idx = i break"
        },
        {
            "bounding_box": [
                {
                    "x": 277,
                    "y": 1369
                },
                {
                    "x": 1215,
                    "y": 1369
                },
                {
                    "x": 1215,
                    "y": 1579
                },
                {
                    "x": 277,
                    "y": 1579
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='319' style='font-size:16px'># Find the directly right object<br>direct_right = objects[stress_ball idx+1]<br># Check the directly right object , S color<br>direct right_color = direct_right[1]<br>answer = direct_right_color</p>",
            "id": 319,
            "page": 26,
            "text": "# Find the directly right object direct_right = objects[stress_ball idx+1] # Check the directly right object , S color direct right_color = direct_right answer = direct_right_color"
        },
        {
            "bounding_box": [
                {
                    "x": 907,
                    "y": 189
                },
                {
                    "x": 1548,
                    "y": 189
                },
                {
                    "x": 1548,
                    "y": 237
                },
                {
                    "x": 907,
                    "y": 237
                }
            ],
            "category": "header",
            "html": "<header id='320' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 320,
            "page": 27,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2212,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 232
                },
                {
                    "x": 2212,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='321' style='font-size:18px'>27</header>",
            "id": 321,
            "page": 27,
            "text": "27"
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 282
                },
                {
                    "x": 653,
                    "y": 282
                },
                {
                    "x": 653,
                    "y": 333
                },
                {
                    "x": 224,
                    "y": 333
                }
            ],
            "category": "paragraph",
            "html": "<p id='322' style='font-size:16px'>J.2. Penguins in a Table</p>",
            "id": 322,
            "page": 27,
            "text": "J.2. Penguins in a Table"
        },
        {
            "bounding_box": [
                {
                    "x": 274,
                    "y": 380
                },
                {
                    "x": 2201,
                    "y": 380
                },
                {
                    "x": 2201,
                    "y": 1217
                },
                {
                    "x": 274,
                    "y": 1217
                }
            ],
            "category": "paragraph",
            "html": "<p id='323' style='font-size:14px'>\" \" \" Q: Here is a table where the first line is a header and each subsequent line is a<br>penguin : name, age, height (cm) , weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13<br>Vincent, 9, 60, 11 Gwen, 8, 70, 15 For example: the age of Louis is 7, the weight<br>of Gwen is 15 kg, the height of Bernard is 80 cm. We now add a penguin to the<br>table: James, 12, 90, 12<br>How many penguins are less than 8 years old?<br>\" \"\"<br># Put the penguins into a list.<br>penguins = []<br>penguins · append ( ( Louis , 7, 50, 11))<br>,<br>penguins · append ( ( Bernard , 5, 80, 13))<br>penguins · append ( ( , Vincent , 9, 60, 11))<br>,<br>penguins · append ( ( , Gwen , 8, 70, 15) )<br>,<br># Add penguin James ·<br>penguins · append ( ( 'James , 12, 90, 12))<br>,<br># Find penguins under 8 years old.<br>penguins_under_8_years_old = [penguin for penguin in penguins if penguin [1] < 8]<br># Count number of perguins under 8<br>num_penguin_under_8 = len (penguins_under_&_years_old)<br>answer = num_penguin_under_8</p>",
            "id": 323,
            "page": 27,
            "text": "\" \" \" Q: Here is a table where the first line is a header and each subsequent line is a penguin : name, age, height (cm) , weight (kg) Louis, 7, 50, 11 Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8, 70, 15 For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm. We now add a penguin to the table: James, 12, 90, 12 How many penguins are less than 8 years old? \" \"\" # Put the penguins into a list. penguins = [] penguins · append ( ( Louis , 7, 50, 11)) , penguins · append ( ( Bernard , 5, 80, 13)) penguins · append ( ( , Vincent , 9, 60, 11)) , penguins · append ( ( , Gwen , 8, 70, 15) ) , # Add penguin James · penguins · append ( ( 'James , 12, 90, 12)) , # Find penguins under 8 years old. penguins_under_8_years_old = [penguin for penguin in penguins if penguin  < 8] # Count number of perguins under 8 num_penguin_under_8 = len (penguins_under_&_years_old) answer = num_penguin_under_8"
        },
        {
            "bounding_box": [
                {
                    "x": 1154,
                    "y": 1261
                },
                {
                    "x": 1331,
                    "y": 1261
                },
                {
                    "x": 1331,
                    "y": 1315
                },
                {
                    "x": 1154,
                    "y": 1315
                }
            ],
            "category": "footer",
            "html": "<footer id='324' style='font-size:22px'>Figure 17</footer>",
            "id": 324,
            "page": 27,
            "text": "Figure 17"
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 237
                },
                {
                    "x": 908,
                    "y": 237
                }
            ],
            "category": "header",
            "html": "<header id='325' style='font-size:18px'>PAL: Program-aided Language Models</header>",
            "id": 325,
            "page": 28,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2213,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 191
                },
                {
                    "x": 2261,
                    "y": 233
                },
                {
                    "x": 2213,
                    "y": 233
                }
            ],
            "category": "header",
            "html": "<br><header id='326' style='font-size:16px'>28</header>",
            "id": 326,
            "page": 28,
            "text": "28"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 283
                },
                {
                    "x": 669,
                    "y": 283
                },
                {
                    "x": 669,
                    "y": 334
                },
                {
                    "x": 223,
                    "y": 334
                }
            ],
            "category": "paragraph",
            "html": "<p id='327' style='font-size:20px'>J.3. Date Understanding</p>",
            "id": 327,
            "page": 28,
            "text": "J.3. Date Understanding"
        },
        {
            "bounding_box": [
                {
                    "x": 276,
                    "y": 378
                },
                {
                    "x": 2187,
                    "y": 378
                },
                {
                    "x": 2187,
                    "y": 683
                },
                {
                    "x": 276,
                    "y": 683
                }
            ],
            "category": "paragraph",
            "html": "<p id='328' style='font-size:14px'># Q: 2015 is coming in 36 hours · What is the date one week from today in MM/DD/YYYY?<br># If 2015 is coming in 36 hours, then today is 36 hours before.<br>today = datetime (2015, 1, 1) - relativedelta (hours=36)<br># One week from today,<br>one_week_from_today = today + relativedelta (weeks=1)<br># The answer formatted with 응m/응d/응Y is<br>one_week_from_today · strftime ( , 응m/응d/응Y )</p>",
            "id": 328,
            "page": 28,
            "text": "# Q: 2015 is coming in 36 hours · What is the date one week from today in MM/DD/YYYY? # If 2015 is coming in 36 hours, then today is 36 hours before. today = datetime (2015, 1, 1) - relativedelta (hours=36) # One week from today, one_week_from_today = today + relativedelta (weeks=1) # The answer formatted with 응m/응d/응Y is one_week_from_today · strftime ( , 응m/응d/응Y )"
        },
        {
            "bounding_box": [
                {
                    "x": 907,
                    "y": 189
                },
                {
                    "x": 1547,
                    "y": 189
                },
                {
                    "x": 1547,
                    "y": 236
                },
                {
                    "x": 907,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='329' style='font-size:22px'>PAL: Program-aided Language Models</header>",
            "id": 329,
            "page": 29,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2214,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 231
                },
                {
                    "x": 2214,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='330' style='font-size:20px'>29</header>",
            "id": 330,
            "page": 29,
            "text": "29"
        },
        {
            "bounding_box": [
                {
                    "x": 226,
                    "y": 282
                },
                {
                    "x": 405,
                    "y": 282
                },
                {
                    "x": 405,
                    "y": 333
                },
                {
                    "x": 226,
                    "y": 333
                }
            ],
            "category": "paragraph",
            "html": "<p id='331' style='font-size:20px'>J.4. Math</p>",
            "id": 331,
            "page": 29,
            "text": "J.4. Math"
        },
        {
            "bounding_box": [
                {
                    "x": 247,
                    "y": 383
                },
                {
                    "x": 2183,
                    "y": 383
                },
                {
                    "x": 2183,
                    "y": 455
                },
                {
                    "x": 247,
                    "y": 455
                }
            ],
            "category": "paragraph",
            "html": "<p id='332' style='font-size:18px'>#Q: Olivia has \\$23. She bought five bagels for \\$3 each. How much money does she have<br>left?</p>",
            "id": 332,
            "page": 29,
            "text": "#Q: Olivia has \\$23. She bought five bagels for \\$3 each. How much money does she have left?"
        },
        {
            "bounding_box": [
                {
                    "x": 235,
                    "y": 463
                },
                {
                    "x": 1146,
                    "y": 463
                },
                {
                    "x": 1146,
                    "y": 727
                },
                {
                    "x": 235,
                    "y": 727
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='333' style='font-size:14px'>money_initial = 23<br>bagels = 5<br>bagel_cost = 3<br>money_spent = bagels * bagel_cost<br>money_left = money_initial - money_spent<br>print (money_left)</p>",
            "id": 333,
            "page": 29,
            "text": "money_initial = 23 bagels = 5 bagel_cost = 3 money_spent = bagels * bagel_cost money_left = money_initial - money_spent print (money_left)"
        },
        {
            "bounding_box": [
                {
                    "x": 243,
                    "y": 752
                },
                {
                    "x": 2202,
                    "y": 752
                },
                {
                    "x": 2202,
                    "y": 832
                },
                {
                    "x": 243,
                    "y": 832
                }
            ],
            "category": "paragraph",
            "html": "<p id='334' style='font-size:16px'>#Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost<br>2 more · How many golf balls did he have at the end of wednesday?</p>",
            "id": 334,
            "page": 29,
            "text": "#Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more · How many golf balls did he have at the end of wednesday?"
        },
        {
            "bounding_box": [
                {
                    "x": 242,
                    "y": 830
                },
                {
                    "x": 1688,
                    "y": 830
                },
                {
                    "x": 1688,
                    "y": 1011
                },
                {
                    "x": 242,
                    "y": 1011
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='335' style='font-size:14px'>golf_balls_initial = 58<br>golf_balls_lost_tuesday = 23<br>golf_balls_lost_wednesday = 2<br>golf_balls_left = golf_balls_initial - golf_balls_lost_tuesday -</p>",
            "id": 335,
            "page": 29,
            "text": "golf_balls_initial = 58 golf_balls_lost_tuesday = 23 golf_balls_lost_wednesday = 2 golf_balls_left = golf_balls_initial - golf_balls_lost_tuesday -"
        },
        {
            "bounding_box": [
                {
                    "x": 333,
                    "y": 1005
                },
                {
                    "x": 899,
                    "y": 1005
                },
                {
                    "x": 899,
                    "y": 1047
                },
                {
                    "x": 333,
                    "y": 1047
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='336' style='font-size:20px'>golf_balls_lost_wednesday</p>",
            "id": 336,
            "page": 29,
            "text": "golf_balls_lost_wednesday"
        },
        {
            "bounding_box": [
                {
                    "x": 236,
                    "y": 1046
                },
                {
                    "x": 738,
                    "y": 1046
                },
                {
                    "x": 738,
                    "y": 1088
                },
                {
                    "x": 236,
                    "y": 1088
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='337' style='font-size:18px'>print (golf_balls_left)</p>",
            "id": 337,
            "page": 29,
            "text": "print (golf_balls_left)"
        },
        {
            "bounding_box": [
                {
                    "x": 241,
                    "y": 1128
                },
                {
                    "x": 2161,
                    "y": 1128
                },
                {
                    "x": 2161,
                    "y": 1215
                },
                {
                    "x": 241,
                    "y": 1215
                }
            ],
            "category": "paragraph",
            "html": "<p id='338' style='font-size:16px'>#Q: There were nine computers in the server room. Five more computers were installed<br>each day, from monday to thursday. How many computers are now in the server room?</p>",
            "id": 338,
            "page": 29,
            "text": "#Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?"
        },
        {
            "bounding_box": [
                {
                    "x": 239,
                    "y": 1254
                },
                {
                    "x": 1444,
                    "y": 1254
                },
                {
                    "x": 1444,
                    "y": 1504
                },
                {
                    "x": 239,
                    "y": 1504
                }
            ],
            "category": "paragraph",
            "html": "<p id='339' style='font-size:14px'>computers_initial = 9<br>computers_per_day = 5<br>num_days = 4 # 4 days between monday and thursday<br>computers_added = computers_per_day * num_days<br>computers_total = computers_initial + computers_added<br>print (computers_total)</p>",
            "id": 339,
            "page": 29,
            "text": "computers_initial = 9 computers_per_day = 5 num_days = 4 # 4 days between monday and thursday computers_added = computers_per_day * num_days computers_total = computers_initial + computers_added print (computers_total)"
        },
        {
            "bounding_box": [
                {
                    "x": 237,
                    "y": 1579
                },
                {
                    "x": 2207,
                    "y": 1579
                },
                {
                    "x": 2207,
                    "y": 1825
                },
                {
                    "x": 237,
                    "y": 1825
                }
            ],
            "category": "paragraph",
            "html": "<p id='340' style='font-size:16px'>#Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in<br>the parking lot?<br>cars_initial = 3<br>cars_arrived = 2<br>total_cars = cars_ initial + cars_arrived<br>print (total_cars)</p>",
            "id": 340,
            "page": 29,
            "text": "#Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot? cars_initial = 3 cars_arrived = 2 total_cars = cars_ initial + cars_arrived print (total_cars)"
        },
        {
            "bounding_box": [
                {
                    "x": 243,
                    "y": 1873
                },
                {
                    "x": 2141,
                    "y": 1873
                },
                {
                    "x": 2141,
                    "y": 1960
                },
                {
                    "x": 243,
                    "y": 1960
                }
            ],
            "category": "paragraph",
            "html": "<p id='341' style='font-size:18px'>#Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do<br>they have left in total?</p>",
            "id": 341,
            "page": 29,
            "text": "#Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?"
        },
        {
            "bounding_box": [
                {
                    "x": 238,
                    "y": 1998
                },
                {
                    "x": 1468,
                    "y": 1998
                },
                {
                    "x": 1468,
                    "y": 2251
                },
                {
                    "x": 238,
                    "y": 2251
                }
            ],
            "category": "paragraph",
            "html": "<p id='342' style='font-size:14px'>leah_chocolates = 32<br>sister_chocolates = 42<br>total_chocolates = leah_chocolates + sister_chocolates<br>chocolates_eaten = 35<br>chocolates_left = total_chocolates - chocolates_eaten<br>print (chocolates_left)</p>",
            "id": 342,
            "page": 29,
            "text": "leah_chocolates = 32 sister_chocolates = 42 total_chocolates = leah_chocolates + sister_chocolates chocolates_eaten = 35 chocolates_left = total_chocolates - chocolates_eaten print (chocolates_left)"
        },
        {
            "bounding_box": [
                {
                    "x": 761,
                    "y": 2333
                },
                {
                    "x": 1725,
                    "y": 2333
                },
                {
                    "x": 1725,
                    "y": 2387
                },
                {
                    "x": 761,
                    "y": 2387
                }
            ],
            "category": "paragraph",
            "html": "<p id='343' style='font-size:22px'>Figure 19: Prompt used for mathematical reasoning (1/2)</p>",
            "id": 343,
            "page": 29,
            "text": "Figure 19: Prompt used for mathematical reasoning (1/2)"
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 189
                },
                {
                    "x": 1548,
                    "y": 189
                },
                {
                    "x": 1548,
                    "y": 237
                },
                {
                    "x": 908,
                    "y": 237
                }
            ],
            "category": "header",
            "html": "<header id='344' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 344,
            "page": 30,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2215,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 231
                },
                {
                    "x": 2215,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='345' style='font-size:18px'>30</header>",
            "id": 345,
            "page": 30,
            "text": "30"
        },
        {
            "bounding_box": [
                {
                    "x": 240,
                    "y": 1001
                },
                {
                    "x": 2153,
                    "y": 1001
                },
                {
                    "x": 2153,
                    "y": 1086
                },
                {
                    "x": 240,
                    "y": 1086
                }
            ],
            "category": "paragraph",
            "html": "<p id='346' style='font-size:18px'>#Q: Jason had 20 lollipops. He gave Denny some lollipops · Now Jason has 12 lollipops .<br>How many lollipops did Jason give to Denny?</p>",
            "id": 346,
            "page": 30,
            "text": "#Q: Jason had 20 lollipops. He gave Denny some lollipops · Now Jason has 12 lollipops . How many lollipops did Jason give to Denny?"
        },
        {
            "bounding_box": [
                {
                    "x": 240,
                    "y": 1085
                },
                {
                    "x": 1705,
                    "y": 1085
                },
                {
                    "x": 1705,
                    "y": 1258
                },
                {
                    "x": 240,
                    "y": 1258
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='347' style='font-size:14px'>jason_lollipops_initial = 20<br>jason_lcllipops_after = 12<br>denny_lollipops = jason_lollipops_initial - jason_lcllipops_after<br>print (denny_lollipops)</p>",
            "id": 347,
            "page": 30,
            "text": "jason_lollipops_initial = 20 jason_lcllipops_after = 12 denny_lollipops = jason_lollipops_initial - jason_lcllipops_after print (denny_lollipops)"
        },
        {
            "bounding_box": [
                {
                    "x": 243,
                    "y": 1373
                },
                {
                    "x": 2197,
                    "y": 1373
                },
                {
                    "x": 2197,
                    "y": 1501
                },
                {
                    "x": 243,
                    "y": 1501
                }
            ],
            "category": "paragraph",
            "html": "<p id='348' style='font-size:16px'>#Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today.<br>After they are done, there will be 21 trees. How many trees did the grove workers<br>plant today?</p>",
            "id": 348,
            "page": 30,
            "text": "#Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?"
        },
        {
            "bounding_box": [
                {
                    "x": 237,
                    "y": 1501
                },
                {
                    "x": 1171,
                    "y": 1501
                },
                {
                    "x": 1171,
                    "y": 1671
                },
                {
                    "x": 237,
                    "y": 1671
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='349' style='font-size:14px'>trees_initial = 15<br>trees_after = 21<br>trees_added = trees_after - trees_initial<br>print (trees_added)</p>",
            "id": 349,
            "page": 30,
            "text": "trees_initial = 15 trees_after = 21 trees_added = trees_after - trees_initial print (trees_added)"
        },
        {
            "bounding_box": [
                {
                    "x": 242,
                    "y": 1748
                },
                {
                    "x": 2185,
                    "y": 1748
                },
                {
                    "x": 2185,
                    "y": 1836
                },
                {
                    "x": 242,
                    "y": 1836
                }
            ],
            "category": "paragraph",
            "html": "<p id='350' style='font-size:16px'>#Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How<br>many toys does he have now?</p>",
            "id": 350,
            "page": 30,
            "text": "#Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?"
        },
        {
            "bounding_box": [
                {
                    "x": 237,
                    "y": 1872
                },
                {
                    "x": 1198,
                    "y": 1872
                },
                {
                    "x": 1198,
                    "y": 2127
                },
                {
                    "x": 237,
                    "y": 2127
                }
            ],
            "category": "paragraph",
            "html": "<p id='351' style='font-size:14px'>toys_initial = 5<br>mom_toys = 2<br>dad_toys = 2<br>total_received = mom_toys dad_toys<br>total_toys = toys_initial total_received<br>print (total_toys)</p>",
            "id": 351,
            "page": 30,
            "text": "toys_initial = 5 mom_toys = 2 dad_toys = 2 total_received = mom_toys dad_toys total_toys = toys_initial total_received print (total_toys)"
        },
        {
            "bounding_box": [
                {
                    "x": 759,
                    "y": 2204
                },
                {
                    "x": 1724,
                    "y": 2204
                },
                {
                    "x": 1724,
                    "y": 2261
                },
                {
                    "x": 759,
                    "y": 2261
                }
            ],
            "category": "paragraph",
            "html": "<p id='352' style='font-size:22px'>Figure 20: Prompt used for mathematical reasoning (2/2)</p>",
            "id": 352,
            "page": 30,
            "text": "Figure 20: Prompt used for mathematical reasoning (2/2)"
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 236
                },
                {
                    "x": 908,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='353' style='font-size:22px'>PAL: Program-aided Language Models</header>",
            "id": 353,
            "page": 31,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2214,
                    "y": 193
                },
                {
                    "x": 2258,
                    "y": 193
                },
                {
                    "x": 2258,
                    "y": 232
                },
                {
                    "x": 2214,
                    "y": 232
                }
            ],
            "category": "header",
            "html": "<br><header id='354' style='font-size:20px'>31</header>",
            "id": 354,
            "page": 31,
            "text": "31"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 282
                },
                {
                    "x": 606,
                    "y": 282
                },
                {
                    "x": 606,
                    "y": 335
                },
                {
                    "x": 223,
                    "y": 335
                }
            ],
            "category": "paragraph",
            "html": "<p id='355' style='font-size:22px'>J.5. Object Counting</p>",
            "id": 355,
            "page": 31,
            "text": "J.5. Object Counting"
        },
        {
            "bounding_box": [
                {
                    "x": 294,
                    "y": 386
                },
                {
                    "x": 2069,
                    "y": 386
                },
                {
                    "x": 2069,
                    "y": 471
                },
                {
                    "x": 294,
                    "y": 471
                }
            ],
            "category": "paragraph",
            "html": "<p id='356' style='font-size:18px'># Q: I have a chair, two potatoes, a cauliflower, a lettuce head, two tables, a<br>cabbage, two onions, and three fridges. How many vegetables do I have?</p>",
            "id": 356,
            "page": 31,
            "text": "# Q: I have a chair, two potatoes, a cauliflower, a lettuce head, two tables, a cabbage, two onions, and three fridges. How many vegetables do I have?"
        },
        {
            "bounding_box": [
                {
                    "x": 278,
                    "y": 512
                },
                {
                    "x": 1505,
                    "y": 512
                },
                {
                    "x": 1505,
                    "y": 592
                },
                {
                    "x": 278,
                    "y": 592
                }
            ],
            "category": "paragraph",
            "html": "<p id='357' style='font-size:18px'># note: I'm not counting the chair, tables, or fridges<br>vegetables_to_count = {</p>",
            "id": 357,
            "page": 31,
            "text": "# note: I'm not counting the chair, tables, or fridges vegetables_to_count = {"
        },
        {
            "bounding_box": [
                {
                    "x": 374,
                    "y": 597
                },
                {
                    "x": 779,
                    "y": 597
                },
                {
                    "x": 779,
                    "y": 802
                },
                {
                    "x": 374,
                    "y": 802
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='358' style='font-size:14px'>'potato : 2,<br>, cauliflower : 1,<br>, lettuce head , : 1 ,<br>, cabbage , : 1,<br>, onion , : 2</p>",
            "id": 358,
            "page": 31,
            "text": "'potato : 2, , cauliflower : 1, , lettuce head , : 1 , , cabbage , : 1, , onion , : 2"
        },
        {
            "bounding_box": [
                {
                    "x": 290,
                    "y": 809
                },
                {
                    "x": 305,
                    "y": 809
                },
                {
                    "x": 305,
                    "y": 836
                },
                {
                    "x": 290,
                    "y": 836
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='359' style='font-size:14px'>}</p>",
            "id": 359,
            "page": 31,
            "text": "}"
        },
        {
            "bounding_box": [
                {
                    "x": 276,
                    "y": 841
                },
                {
                    "x": 1185,
                    "y": 841
                },
                {
                    "x": 1185,
                    "y": 889
                },
                {
                    "x": 276,
                    "y": 889
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='360' style='font-size:16px'>print (sum (vegetables_to_count · values () ) )</p>",
            "id": 360,
            "page": 31,
            "text": "print (sum (vegetables_to_count · values () ) )"
        },
        {
            "bounding_box": [
                {
                    "x": 284,
                    "y": 964
                },
                {
                    "x": 2048,
                    "y": 964
                },
                {
                    "x": 2048,
                    "y": 1054
                },
                {
                    "x": 284,
                    "y": 1054
                }
            ],
            "category": "paragraph",
            "html": "<p id='361' style='font-size:18px'># Q: I have a drum, a flute, a clarinet, a violin, four accordions, a piano, a<br>trombone, and a trumpet. How many musical instruments do I have?</p>",
            "id": 361,
            "page": 31,
            "text": "# Q: I have a drum, a flute, a clarinet, a violin, four accordions, a piano, a trombone, and a trumpet. How many musical instruments do I have?"
        },
        {
            "bounding_box": [
                {
                    "x": 275,
                    "y": 1090
                },
                {
                    "x": 1005,
                    "y": 1090
                },
                {
                    "x": 1005,
                    "y": 1137
                },
                {
                    "x": 275,
                    "y": 1137
                }
            ],
            "category": "paragraph",
            "html": "<p id='362' style='font-size:16px'>misical_instruments_to_count = {</p>",
            "id": 362,
            "page": 31,
            "text": "misical_instruments_to_count = {"
        },
        {
            "bounding_box": [
                {
                    "x": 374,
                    "y": 1138
                },
                {
                    "x": 713,
                    "y": 1138
                },
                {
                    "x": 713,
                    "y": 1468
                },
                {
                    "x": 374,
                    "y": 1468
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='363' style='font-size:14px'>drum , 1 ,<br>:<br>, flute , : 1 ,<br>, clarinet , : 1,<br>, violin ▼ : 1,<br>, accordion , : 4 ,<br>piano , 1,<br>:<br>trombone ' : 1 ,<br>trumpet : 1</p>",
            "id": 363,
            "page": 31,
            "text": "drum , 1 , : , flute , : 1 , , clarinet , : 1, , violin ▼ : 1, , accordion , : 4 , piano , 1, : trombone ' : 1 , trumpet : 1"
        },
        {
            "bounding_box": [
                {
                    "x": 290,
                    "y": 1473
                },
                {
                    "x": 307,
                    "y": 1473
                },
                {
                    "x": 307,
                    "y": 1500
                },
                {
                    "x": 290,
                    "y": 1500
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='364' style='font-size:14px'>}</p>",
            "id": 364,
            "page": 31,
            "text": "}"
        },
        {
            "bounding_box": [
                {
                    "x": 287,
                    "y": 1487
                },
                {
                    "x": 2027,
                    "y": 1487
                },
                {
                    "x": 2027,
                    "y": 1836
                },
                {
                    "x": 287,
                    "y": 1836
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='365' style='font-size:18px'>print (sum (musical_instruments_to_count values () ) )<br># Q: I have a chair, two ovens, and three tables. How many objects do I have?<br>objects_to_count = {</p>",
            "id": 365,
            "page": 31,
            "text": "print (sum (musical_instruments_to_count values () ) ) # Q: I have a chair, two ovens, and three tables. How many objects do I have? objects_to_count = {"
        },
        {
            "bounding_box": [
                {
                    "x": 377,
                    "y": 1841
                },
                {
                    "x": 618,
                    "y": 1841
                },
                {
                    "x": 618,
                    "y": 1963
                },
                {
                    "x": 377,
                    "y": 1963
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='366' style='font-size:14px'>chair , : 1,<br>, oven , : 2,<br>'table ' : 3</p>",
            "id": 366,
            "page": 31,
            "text": "chair , : 1, , oven , : 2, 'table ' : 3"
        },
        {
            "bounding_box": [
                {
                    "x": 290,
                    "y": 1970
                },
                {
                    "x": 307,
                    "y": 1970
                },
                {
                    "x": 307,
                    "y": 1999
                },
                {
                    "x": 290,
                    "y": 1999
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='367' style='font-size:14px'>}</p>",
            "id": 367,
            "page": 31,
            "text": "}"
        },
        {
            "bounding_box": [
                {
                    "x": 275,
                    "y": 2002
                },
                {
                    "x": 1116,
                    "y": 2002
                },
                {
                    "x": 1116,
                    "y": 2049
                },
                {
                    "x": 275,
                    "y": 2049
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='368' style='font-size:16px'>print (sum (objects_to_count · values () ) )</p>",
            "id": 368,
            "page": 31,
            "text": "print (sum (objects_to_count · values () ) )"
        },
        {
            "bounding_box": [
                {
                    "x": 825,
                    "y": 2128
                },
                {
                    "x": 1658,
                    "y": 2128
                },
                {
                    "x": 1658,
                    "y": 2183
                },
                {
                    "x": 825,
                    "y": 2183
                }
            ],
            "category": "paragraph",
            "html": "<p id='369' style='font-size:20px'>Figure 21: Prompt used for OBJECT COUNTING.</p>",
            "id": 369,
            "page": 31,
            "text": "Figure 21: Prompt used for OBJECT COUNTING."
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1549,
                    "y": 190
                },
                {
                    "x": 1549,
                    "y": 236
                },
                {
                    "x": 908,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='370' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 370,
            "page": 32,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2213,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 231
                },
                {
                    "x": 2213,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='371' style='font-size:18px'>32</header>",
            "id": 371,
            "page": 32,
            "text": "32"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 282
                },
                {
                    "x": 537,
                    "y": 282
                },
                {
                    "x": 537,
                    "y": 338
                },
                {
                    "x": 223,
                    "y": 338
                }
            ],
            "category": "paragraph",
            "html": "<p id='372' style='font-size:22px'>J.6. Repeat Copy</p>",
            "id": 372,
            "page": 32,
            "text": "J.6. Repeat Copy"
        },
        {
            "bounding_box": [
                {
                    "x": 286,
                    "y": 389
                },
                {
                    "x": 314,
                    "y": 389
                },
                {
                    "x": 314,
                    "y": 425
                },
                {
                    "x": 286,
                    "y": 425
                }
            ],
            "category": "paragraph",
            "html": "<p id='373' style='font-size:16px'>#</p>",
            "id": 373,
            "page": 32,
            "text": "#"
        },
        {
            "bounding_box": [
                {
                    "x": 314,
                    "y": 388
                },
                {
                    "x": 1910,
                    "y": 388
                },
                {
                    "x": 1910,
                    "y": 429
                },
                {
                    "x": 314,
                    "y": 429
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='374' style='font-size:14px'>Q: Repeat the word duck four times, but halfway through also say quack</p>",
            "id": 374,
            "page": 32,
            "text": "Q: Repeat the word duck four times, but halfway through also say quack"
        },
        {
            "bounding_box": [
                {
                    "x": 279,
                    "y": 415
                },
                {
                    "x": 2190,
                    "y": 415
                },
                {
                    "x": 2190,
                    "y": 1978
                },
                {
                    "x": 279,
                    "y": 1978
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='375' style='font-size:14px'>result = []<br>for i in range(1, 5) :<br>result . append (\"duck\")<br>if i == 2:<br>result.append ( \" quack\")<br>print (\" W join (result) )<br>·<br># Q: Print boolean eleven times, but after the 3rd and 8th also say correct<br>result = []<br>for i in range(1, 12) :<br>result.append (\"boolean\")<br>if i == 3 or i == 8 :<br>result.append ( \"correct\")<br>print ( \" \" join(result) )<br>·<br># Q: say java twice and data once, and then repeat all of this three times.<br>result = []<br>tmp = [\"java\", \"java\", \"data\"]<br>for i in range (3) :<br>result.extend (tmp)<br>print ( \" \" join (result) )<br>·<br># Q: ask a group of insects in what family? four times. after the fourth time say The<br>happy family<br>result = []<br>tmp = []<br>for i in range(1, 5) :<br>tmp. append(\"a group of insects in what family?\")<br>tmp · append (\"The happy family\")<br>result. extend (tmp)<br>print ( \" \" join (result) )<br>·</p>",
            "id": 375,
            "page": 32,
            "text": "result = [] for i in range(1, 5) : result . append (\"duck\") if i == 2: result.append ( \" quack\") print (\" W join (result) ) · # Q: Print boolean eleven times, but after the 3rd and 8th also say correct result = [] for i in range(1, 12) : result.append (\"boolean\") if i == 3 or i == 8 : result.append ( \"correct\") print ( \" \" join(result) ) · # Q: say java twice and data once, and then repeat all of this three times. result = [] tmp = [\"java\", \"java\", \"data\"] for i in range (3) : result.extend (tmp) print ( \" \" join (result) ) · # Q: ask a group of insects in what family? four times. after the fourth time say The happy family result = [] tmp = [] for i in range(1, 5) : tmp. append(\"a group of insects in what family?\") tmp · append (\"The happy family\") result. extend (tmp) print ( \" \" join (result) ) ·"
        },
        {
            "bounding_box": [
                {
                    "x": 873,
                    "y": 2047
                },
                {
                    "x": 1609,
                    "y": 2047
                },
                {
                    "x": 1609,
                    "y": 2099
                },
                {
                    "x": 873,
                    "y": 2099
                }
            ],
            "category": "paragraph",
            "html": "<p id='376' style='font-size:18px'>Figure 22: Prompt used for REPEAT COPY.</p>",
            "id": 376,
            "page": 32,
            "text": "Figure 22: Prompt used for REPEAT COPY."
        },
        {
            "bounding_box": [
                {
                    "x": 907,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 190
                },
                {
                    "x": 1548,
                    "y": 235
                },
                {
                    "x": 907,
                    "y": 235
                }
            ],
            "category": "header",
            "html": "<header id='377' style='font-size:20px'>PAL: Program-aided Language Models</header>",
            "id": 377,
            "page": 33,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2215,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 193
                },
                {
                    "x": 2259,
                    "y": 231
                },
                {
                    "x": 2215,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='378' style='font-size:18px'>33</header>",
            "id": 378,
            "page": 33,
            "text": "33"
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 277
                },
                {
                    "x": 1268,
                    "y": 277
                },
                {
                    "x": 1268,
                    "y": 333
                },
                {
                    "x": 225,
                    "y": 333
                }
            ],
            "category": "paragraph",
            "html": "<p id='379' style='font-size:22px'>K. Success and Failure Modes in Symbolic Tasks</p>",
            "id": 379,
            "page": 33,
            "text": "K. Success and Failure Modes in Symbolic Tasks"
        },
        {
            "bounding_box": [
                {
                    "x": 226,
                    "y": 364
                },
                {
                    "x": 608,
                    "y": 364
                },
                {
                    "x": 608,
                    "y": 413
                },
                {
                    "x": 226,
                    "y": 413
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='380' style='font-size:20px'>K.1. Colored Objects</p>",
            "id": 380,
            "page": 33,
            "text": "K.1. Colored Objects"
        },
        {
            "bounding_box": [
                {
                    "x": 278,
                    "y": 463
                },
                {
                    "x": 1855,
                    "y": 463
                },
                {
                    "x": 1855,
                    "y": 550
                },
                {
                    "x": 278,
                    "y": 550
                }
            ],
            "category": "paragraph",
            "html": "<p id='381' style='font-size:16px'># Find non-gold items to the right of the pencil<br>non_gold = [object for object in objects [1+1 : ] if object [1] != gold' ]</p>",
            "id": 381,
            "page": 33,
            "text": "# Find non-gold items to the right of the pencil non_gold = [object for object in objects [1+1 : ] if object  != gold' ]"
        },
        {
            "bounding_box": [
                {
                    "x": 914,
                    "y": 614
                },
                {
                    "x": 1567,
                    "y": 614
                },
                {
                    "x": 1567,
                    "y": 657
                },
                {
                    "x": 914,
                    "y": 657
                }
            ],
            "category": "paragraph",
            "html": "<p id='382' style='font-size:16px'>(a) Snippet of PAL doing a filter operation.</p>",
            "id": 382,
            "page": 33,
            "text": "(a) Snippet of PAL doing a filter operation."
        },
        {
            "bounding_box": [
                {
                    "x": 274,
                    "y": 668
                },
                {
                    "x": 1723,
                    "y": 668
                },
                {
                    "x": 1723,
                    "y": 754
                },
                {
                    "x": 274,
                    "y": 754
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='383' style='font-size:16px'># Remove all pink objects<br>non_pink = [object for object in objects if object [1] != 'pink ' ]</p>",
            "id": 383,
            "page": 33,
            "text": "# Remove all pink objects non_pink = [object for object in objects if object  != 'pink ' ]"
        },
        {
            "bounding_box": [
                {
                    "x": 280,
                    "y": 789
                },
                {
                    "x": 1771,
                    "y": 789
                },
                {
                    "x": 1771,
                    "y": 918
                },
                {
                    "x": 280,
                    "y": 918
                }
            ],
            "category": "paragraph",
            "html": "<p id='384' style='font-size:14px'># Count number of crayons<br>crayons = [object for object in non_pink if object [0] == , crayon ' ]<br>answer = len (crayons)</p>",
            "id": 384,
            "page": 33,
            "text": "# Count number of crayons crayons = [object for object in non_pink if object  == , crayon ' ] answer = len (crayons)"
        },
        {
            "bounding_box": [
                {
                    "x": 853,
                    "y": 982
                },
                {
                    "x": 1630,
                    "y": 982
                },
                {
                    "x": 1630,
                    "y": 1029
                },
                {
                    "x": 853,
                    "y": 1029
                }
            ],
            "category": "paragraph",
            "html": "<p id='385' style='font-size:20px'>(b) Snippet of PAL composing multiple operations.</p>",
            "id": 385,
            "page": 33,
            "text": "(b) Snippet of PAL composing multiple operations."
        },
        {
            "bounding_box": [
                {
                    "x": 557,
                    "y": 1067
                },
                {
                    "x": 1926,
                    "y": 1067
                },
                {
                    "x": 1926,
                    "y": 1119
                },
                {
                    "x": 557,
                    "y": 1119
                }
            ],
            "category": "paragraph",
            "html": "<p id='386' style='font-size:22px'>Figure 23: Example model generation snippets on Reasoning about Color Object.</p>",
            "id": 386,
            "page": 33,
            "text": "Figure 23: Example model generation snippets on Reasoning about Color Object."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 1170
                },
                {
                    "x": 2263,
                    "y": 1170
                },
                {
                    "x": 2263,
                    "y": 1424
                },
                {
                    "x": 225,
                    "y": 1424
                }
            ],
            "category": "paragraph",
            "html": "<p id='387' style='font-size:18px'>By manually examining the the model outputs, we observe that PAL often performs better on questions that involve counting<br>objects that satisfy one or several conditions. For example, CoT fails in the following example: \"On the desk, you see a<br>bunch of items arranged in a row: a gold textbook, a purple puzzle, a teal necklace, and a silver pencil. How many non-gold<br>items do you see to the right of the pencil?\". With pure NL reasoning, a LLM can easily lose track of the objects and output<br>the wrong answer of \"The number of non-gold items to the right of the pencil is two. So the answer is two.\"</p>",
            "id": 387,
            "page": 33,
            "text": "By manually examining the the model outputs, we observe that PAL often performs better on questions that involve counting objects that satisfy one or several conditions. For example, CoT fails in the following example: \"On the desk, you see a bunch of items arranged in a row: a gold textbook, a purple puzzle, a teal necklace, and a silver pencil. How many non-gold items do you see to the right of the pencil?\". With pure NL reasoning, a LLM can easily lose track of the objects and output the wrong answer of \"The number of non-gold items to the right of the pencil is two. So the answer is two.\""
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1445
                },
                {
                    "x": 2264,
                    "y": 1445
                },
                {
                    "x": 2264,
                    "y": 1749
                },
                {
                    "x": 223,
                    "y": 1749
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='388' style='font-size:18px'>In comparison, PAL is able to accurately construct the object lists with correct order and attributes. Further, it can precisely<br>leverage the simple yet complete PL syntax: it composes routines with functional operators from elementary builtin<br>operation/operators. Figure 4 lists the last a few lines of the solution to the question described above generated by PAL,<br>which perform filtering over objects. PAL can further compose such operations across multiple reasoning steps as shown in<br>Figure 23b, where it first filters out all pink objects and then scans the remaining to count crayons. Other reasoning such as<br>\"how many objects are left after filtering\" can be easily tackled precisely with an runtime.</p>",
            "id": 388,
            "page": 33,
            "text": "In comparison, PAL is able to accurately construct the object lists with correct order and attributes. Further, it can precisely leverage the simple yet complete PL syntax: it composes routines with functional operators from elementary builtin operation/operators. Figure 4 lists the last a few lines of the solution to the question described above generated by PAL, which perform filtering over objects. PAL can further compose such operations across multiple reasoning steps as shown in Figure 23b, where it first filters out all pink objects and then scans the remaining to count crayons. Other reasoning such as \"how many objects are left after filtering\" can be easily tackled precisely with an runtime."
        },
        {
            "bounding_box": [
                {
                    "x": 226,
                    "y": 1797
                },
                {
                    "x": 664,
                    "y": 1797
                },
                {
                    "x": 664,
                    "y": 1850
                },
                {
                    "x": 226,
                    "y": 1850
                }
            ],
            "category": "paragraph",
            "html": "<p id='389' style='font-size:18px'>K.2. Penguins in a Table</p>",
            "id": 389,
            "page": 33,
            "text": "K.2. Penguins in a Table"
        },
        {
            "bounding_box": [
                {
                    "x": 284,
                    "y": 1898
                },
                {
                    "x": 2204,
                    "y": 1898
                },
                {
                    "x": 2204,
                    "y": 2110
                },
                {
                    "x": 284,
                    "y": 2110
                }
            ],
            "category": "paragraph",
            "html": "<p id='390' style='font-size:14px'>· · · This question focuses on age · We know the following : Louis is 7 years old, Bernard<br>→ is 5 years old, Vincent is 9 years old, and Gwen is 8 years old. Now, we add James<br>→ to this table : James is 12 years old. We then delete the penguin named Bernard<br>→ from the table · The penguins that are less than 8 years old are Louis and Bernard.<br>→ There are 2 penguins less than 8 years old. So the answer is 2 ·</p>",
            "id": 390,
            "page": 33,
            "text": "· · · This question focuses on age · We know the following : Louis is 7 years old, Bernard → is 5 years old, Vincent is 9 years old, and Gwen is 8 years old. Now, we add James → to this table : James is 12 years old. We then delete the penguin named Bernard → from the table · The penguins that are less than 8 years old are Louis and Bernard. → There are 2 penguins less than 8 years old. So the answer is 2 ·"
        },
        {
            "bounding_box": [
                {
                    "x": 284,
                    "y": 2133
                },
                {
                    "x": 2080,
                    "y": 2133
                },
                {
                    "x": 2080,
                    "y": 2457
                },
                {
                    "x": 284,
                    "y": 2457
                }
            ],
            "category": "paragraph",
            "html": "<p id='391' style='font-size:14px'>· · ·<br># Delete penguin Bernard.<br>penguins = [penguin for penguin in penguins if penguin [0] != 'Bernard' ]<br># Find penguins under 8 years old.<br>penguins_under_8_years_old = [penguin for penguin in penguins if penguin [1] < 8]<br># Count number of perguins under 8.<br>num_penguin_under_8 = 1en (penguins_under_8_years_old)<br>answer = num_penguin_under_8</p>",
            "id": 391,
            "page": 33,
            "text": "· · · # Delete penguin Bernard. penguins = [penguin for penguin in penguins if penguin  != 'Bernard' ] # Find penguins under 8 years old. penguins_under_8_years_old = [penguin for penguin in penguins if penguin  < 8] # Count number of perguins under 8. num_penguin_under_8 = 1en (penguins_under_8_years_old) answer = num_penguin_under_8"
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 2503
                },
                {
                    "x": 2260,
                    "y": 2503
                },
                {
                    "x": 2260,
                    "y": 2606
                },
                {
                    "x": 223,
                    "y": 2606
                }
            ],
            "category": "paragraph",
            "html": "<p id='392' style='font-size:18px'>Figure 24: Generated Snippets for one question (... We then delete the penguin named Bernard from the table. How many<br>penguins are less than 8 years old?) in Penguins in a Table</p>",
            "id": 392,
            "page": 33,
            "text": "Figure 24: Generated Snippets for one question (... We then delete the penguin named Bernard from the table. How many penguins are less than 8 years old?) in Penguins in a Table"
        },
        {
            "bounding_box": [
                {
                    "x": 1224,
                    "y": 2623
                },
                {
                    "x": 1247,
                    "y": 2623
                },
                {
                    "x": 1247,
                    "y": 2650
                },
                {
                    "x": 1224,
                    "y": 2650
                }
            ],
            "category": "paragraph",
            "html": "<p id='393' style='font-size:14px'>·</p>",
            "id": 393,
            "page": 33,
            "text": "·"
        },
        {
            "bounding_box": [
                {
                    "x": 224,
                    "y": 2689
                },
                {
                    "x": 2266,
                    "y": 2689
                },
                {
                    "x": 2266,
                    "y": 2995
                },
                {
                    "x": 224,
                    "y": 2995
                }
            ],
            "category": "paragraph",
            "html": "<p id='394' style='font-size:18px'>In this task, we found a typical failure mode of the language is its inability to stably tracks states in its past generation.<br>Figure 24 lists the generations of CoT and PAL to the question that contains the removal of a penguin (\"... We then delete<br>the penguin named Bernardfrom the table. How many penguins are less than 8 years old?\"). Although CoT picks up the<br>critical information that \"penguins that are less then 8 years old are Louis and Bernard\", and that \"Bernard is deleted\". It<br>still fails to aggregate the information properly and infer that there is one penguin less then 8 left in the end. In comparison,<br>PAL expresses this dynamic through manipulating a penguins list by filtering out the penguin whose name is \"Bernard\",</p>",
            "id": 394,
            "page": 33,
            "text": "In this task, we found a typical failure mode of the language is its inability to stably tracks states in its past generation. Figure 24 lists the generations of CoT and PAL to the question that contains the removal of a penguin (\"... We then delete the penguin named Bernardfrom the table. How many penguins are less than 8 years old?\"). Although CoT picks up the critical information that \"penguins that are less then 8 years old are Louis and Bernard\", and that \"Bernard is deleted\". It still fails to aggregate the information properly and infer that there is one penguin less then 8 left in the end. In comparison, PAL expresses this dynamic through manipulating a penguins list by filtering out the penguin whose name is \"Bernard\","
        },
        {
            "bounding_box": [
                {
                    "x": 908,
                    "y": 190
                },
                {
                    "x": 1547,
                    "y": 190
                },
                {
                    "x": 1547,
                    "y": 236
                },
                {
                    "x": 908,
                    "y": 236
                }
            ],
            "category": "header",
            "html": "<header id='395' style='font-size:22px'>PAL: Program-aided Language Models</header>",
            "id": 395,
            "page": 34,
            "text": "PAL: Program-aided Language Models"
        },
        {
            "bounding_box": [
                {
                    "x": 2215,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 192
                },
                {
                    "x": 2260,
                    "y": 231
                },
                {
                    "x": 2215,
                    "y": 231
                }
            ],
            "category": "header",
            "html": "<br><header id='396' style='font-size:16px'>34</header>",
            "id": 396,
            "page": 34,
            "text": "34"
        },
        {
            "bounding_box": [
                {
                    "x": 221,
                    "y": 285
                },
                {
                    "x": 2262,
                    "y": 285
                },
                {
                    "x": 2262,
                    "y": 384
                },
                {
                    "x": 221,
                    "y": 384
                }
            ],
            "category": "paragraph",
            "html": "<p id='397' style='font-size:18px'>and maintaining apenguins_under18_years_old list. It offloads tracking exact the values (in this case, the length of<br>the list) to the deterministic Python runtime.</p>",
            "id": 397,
            "page": 34,
            "text": "and maintaining apenguins_under18_years_old list. It offloads tracking exact the values (in this case, the length of the list) to the deterministic Python runtime."
        },
        {
            "bounding_box": [
                {
                    "x": 225,
                    "y": 436
                },
                {
                    "x": 680,
                    "y": 436
                },
                {
                    "x": 680,
                    "y": 489
                },
                {
                    "x": 225,
                    "y": 489
                }
            ],
            "category": "paragraph",
            "html": "<p id='398' style='font-size:20px'>K.3. Date Understanding</p>",
            "id": 398,
            "page": 34,
            "text": "K.3. Date Understanding"
        },
        {
            "bounding_box": [
                {
                    "x": 277,
                    "y": 540
                },
                {
                    "x": 2206,
                    "y": 540
                },
                {
                    "x": 2206,
                    "y": 793
                },
                {
                    "x": 277,
                    "y": 793
                }
            ],
            "category": "paragraph",
            "html": "<p id='399' style='font-size:14px'>Q: Jane was born on the last day of Feburary in 2001 · Today is her 16-year-old<br>→ birthday. What is the date 24 hours later in MM/DD/YYYY?<br>A: The last day of February is the 28th, SO Jane was born on 02/28/2001 · Today is her<br>→ 16-year old birthday, SO today is 02/28/2017 · So 24 hours later is 02/29/2017. So<br>→ the answer is 02/29/2017</p>",
            "id": 399,
            "page": 34,
            "text": "Q: Jane was born on the last day of Feburary in 2001 · Today is her 16-year-old → birthday. What is the date 24 hours later in MM/DD/YYYY? A: The last day of February is the 28th, SO Jane was born on 02/28/2001 · Today is her → 16-year old birthday, SO today is 02/28/2017 · So 24 hours later is 02/29/2017. So → the answer is 02/29/2017"
        },
        {
            "bounding_box": [
                {
                    "x": 288,
                    "y": 844
                },
                {
                    "x": 2158,
                    "y": 844
                },
                {
                    "x": 2158,
                    "y": 1214
                },
                {
                    "x": 288,
                    "y": 1214
                }
            ],
            "category": "paragraph",
            "html": "<p id='400' style='font-size:14px'># Q: Jane was born on the last day of Feburary in 2001 · Today is her 16-year-old<br>birthday. What is the date 24 hours later in MM/DD/YYYY?<br># If Jane was born on the last day of Feburary in 2001 and today is her 16-year-old<br>birthday, then today is 16 years later.<br>today = datetime (2001, 2, 28) + relativedelta (years=16)<br># 24 hours later,<br>later = today + relativedelta (hours=24)<br># The answer formatted with 응m/응d/응Y is<br>later strftime ( , 응m/응d/응Y' )</p>",
            "id": 400,
            "page": 34,
            "text": "# Q: Jane was born on the last day of Feburary in 2001 · Today is her 16-year-old birthday. What is the date 24 hours later in MM/DD/YYYY? # If Jane was born on the last day of Feburary in 2001 and today is her 16-year-old birthday, then today is 16 years later. today = datetime (2001, 2, 28) + relativedelta (years=16) # 24 hours later, later = today + relativedelta (hours=24) # The answer formatted with 응m/응d/응Y is later strftime ( , 응m/응d/응Y' )"
        },
        {
            "bounding_box": [
                {
                    "x": 716,
                    "y": 1263
                },
                {
                    "x": 1764,
                    "y": 1263
                },
                {
                    "x": 1764,
                    "y": 1315
                },
                {
                    "x": 716,
                    "y": 1315
                }
            ],
            "category": "paragraph",
            "html": "<p id='401' style='font-size:22px'>Figure 25: Example model generation on Date Understanding.</p>",
            "id": 401,
            "page": 34,
            "text": "Figure 25: Example model generation on Date Understanding."
        },
        {
            "bounding_box": [
                {
                    "x": 223,
                    "y": 1369
                },
                {
                    "x": 2269,
                    "y": 1369
                },
                {
                    "x": 2269,
                    "y": 1520
                },
                {
                    "x": 223,
                    "y": 1520
                }
            ],
            "category": "paragraph",
            "html": "<p id='402' style='font-size:16px'>We found this especially common when the time deltas are across the month boundary. We show an example in Figure 25.<br>Here with CoT prompting, the LLM expresses the knowledge of the 28-day-long February, yet it still outputs 02/29/2017 as<br>the final answer. With PAL, the actual calendar is accurate as a program handles the operation.</p>",
            "id": 402,
            "page": 34,
            "text": "We found this especially common when the time deltas are across the month boundary. We show an example in Figure 25. Here with CoT prompting, the LLM expresses the knowledge of the 28-day-long February, yet it still outputs 02/29/2017 as the final answer. With PAL, the actual calendar is accurate as a program handles the operation."
        }
    ]
}