{
    "id": "32bbe25e-0f94-11ef-8828-426932df3dcf",
    "pdf_path": "/root/data/pdf/2010.02502v4.pdf",
    "elements": [
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 109
                },
                {
                    "x": 1220,
                    "y": 109
                },
                {
                    "x": 1220,
                    "y": 158
                },
                {
                    "x": 445,
                    "y": 158
                }
            ],
            "category": "header",
            "html": "<header id='0' style='font-size:16px'>Published as a conference paper at ICLR 2021</header>",
            "id": 0,
            "page": 1,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 333
                },
                {
                    "x": 1751,
                    "y": 333
                },
                {
                    "x": 1751,
                    "y": 401
                },
                {
                    "x": 445,
                    "y": 401
                }
            ],
            "category": "paragraph",
            "html": "<p id='1' style='font-size:22px'>DENOISING DIFFUSION IMPLICIT MODELS</p>",
            "id": 1,
            "page": 1,
            "text": "DENOISING DIFFUSION IMPLICIT MODELS"
        },
        {
            "bounding_box": [
                {
                    "x": 472,
                    "y": 482
                },
                {
                    "x": 1318,
                    "y": 482
                },
                {
                    "x": 1318,
                    "y": 527
                },
                {
                    "x": 472,
                    "y": 527
                }
            ],
            "category": "paragraph",
            "html": "<p id='2' style='font-size:20px'>Jiaming Song, Chenlin Meng & Stefano Ermon</p>",
            "id": 2,
            "page": 1,
            "text": "Jiaming Song, Chenlin Meng & Stefano Ermon"
        },
        {
            "bounding_box": [
                {
                    "x": 471,
                    "y": 530
                },
                {
                    "x": 803,
                    "y": 530
                },
                {
                    "x": 803,
                    "y": 572
                },
                {
                    "x": 471,
                    "y": 572
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='3' style='font-size:20px'>Stanford University</p>",
            "id": 3,
            "page": 1,
            "text": "Stanford University"
        },
        {
            "bounding_box": [
                {
                    "x": 476,
                    "y": 577
                },
                {
                    "x": 1392,
                    "y": 577
                },
                {
                    "x": 1392,
                    "y": 621
                },
                {
                    "x": 476,
                    "y": 621
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='4' style='font-size:16px'>{tsong, chenlin, ermon }@cs · stanford · edu</p>",
            "id": 4,
            "page": 1,
            "text": "{tsong, chenlin, ermon }@cs · stanford · edu"
        },
        {
            "bounding_box": [
                {
                    "x": 1156,
                    "y": 743
                },
                {
                    "x": 1394,
                    "y": 743
                },
                {
                    "x": 1394,
                    "y": 791
                },
                {
                    "x": 1156,
                    "y": 791
                }
            ],
            "category": "paragraph",
            "html": "<p id='5' style='font-size:22px'>ABSTRACT</p>",
            "id": 5,
            "page": 1,
            "text": "ABSTRACT"
        },
        {
            "bounding_box": [
                {
                    "x": 592,
                    "y": 847
                },
                {
                    "x": 1961,
                    "y": 847
                },
                {
                    "x": 1961,
                    "y": 1494
                },
                {
                    "x": 592,
                    "y": 1494
                }
            ],
            "category": "paragraph",
            "html": "<p id='6' style='font-size:18px'>Denoising diffusion probabilistic models (DDPMs) have achieved high qual-<br>ity image generation without adversarial training, yet they require simulating a<br>Markov chain for many steps in order to produce a sample. To accelerate sam-<br>pling, we present denoising diffusion implicit models (DDIMs), a more efficient<br>class of iterative implicit probabilistic models with the same training procedure as<br>DDPMs. In DDPMs, the generative process is defined as the reverse of a particular<br>Markovian diffusion process. We generalize DDPMs via a class of non-Markovian<br>diffusion processes that lead to the same training objective. These non-Markovian<br>processes can correspond to generative processes that are deterministic, giving rise<br>to implicit models that produce high quality samples much faster. We empirically<br>demonstrate that DDIMs can produce high quality samples 10x to 50x faster in<br>terms of wall-clock time compared to DDPMs, allow us to trade off computation<br>for sample quality, perform semantically meaningful image interpolation directly<br>in the latent space, and reconstruct observations with very low error.</p>",
            "id": 6,
            "page": 1,
            "text": "Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps in order to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a particular Markovian diffusion process. We generalize DDPMs via a class of non-Markovian diffusion processes that lead to the same training objective. These non-Markovian processes can correspond to generative processes that are deterministic, giving rise to implicit models that produce high quality samples much faster. We empirically demonstrate that DDIMs can produce high quality samples 10x to 50x faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, perform semantically meaningful image interpolation directly in the latent space, and reconstruct observations with very low error."
        },
        {
            "bounding_box": [
                {
                    "x": 451,
                    "y": 1591
                },
                {
                    "x": 863,
                    "y": 1591
                },
                {
                    "x": 863,
                    "y": 1641
                },
                {
                    "x": 451,
                    "y": 1641
                }
            ],
            "category": "paragraph",
            "html": "<p id='7' style='font-size:20px'>1 INTRODUCTION</p>",
            "id": 7,
            "page": 1,
            "text": "1 INTRODUCTION"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1695
                },
                {
                    "x": 2108,
                    "y": 1695
                },
                {
                    "x": 2108,
                    "y": 2065
                },
                {
                    "x": 443,
                    "y": 2065
                }
            ],
            "category": "paragraph",
            "html": "<p id='8' style='font-size:18px'>Deep generative models have demonstrated the ability to produce high quality samples in many<br>domains (Karras et al., 2020; van den Oord et al., 2016a). In terms of image generation, genera-<br>tive adversarial networks (GANs, Goodfellow et al. (2014)) currently exhibits higher sample quality<br>than likelihood-based methods such as variational autoencoders (Kingma & Welling, 2013), autore-<br>gressive models (van den Oord et al., 2016b) and normalizing flows (Rezende & Mohamed, 2015;<br>Dinh et al., 2016). However, GANs require very specific choices in optimization and architectures<br>in order to stabilize training (Arjovsky et al., 2017; Gulrajani et al., 2017; Karras et al., 2018; Brock<br>et al., 2018), and could fail to cover modes of the data distribution (Zhao et al., 2018).</p>",
            "id": 8,
            "page": 1,
            "text": "Deep generative models have demonstrated the ability to produce high quality samples in many domains (Karras , 2020; van den Oord , 2016a). In terms of image generation, generative adversarial networks (GANs, Goodfellow  (2014)) currently exhibits higher sample quality than likelihood-based methods such as variational autoencoders (Kingma & Welling, 2013), autoregressive models (van den Oord , 2016b) and normalizing flows (Rezende & Mohamed, 2015; Dinh , 2016). However, GANs require very specific choices in optimization and architectures in order to stabilize training (Arjovsky , 2017; Gulrajani , 2017; Karras , 2018; Brock , 2018), and could fail to cover modes of the data distribution (Zhao , 2018)."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2086
                },
                {
                    "x": 2108,
                    "y": 2086
                },
                {
                    "x": 2108,
                    "y": 2500
                },
                {
                    "x": 443,
                    "y": 2500
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='9' style='font-size:18px'>Recent works on iterative generative models (Bengio et al., 2014), such as denoising diffusion prob-<br>abilistic models (DDPM, Ho et al. (2020)) and noise conditional score networks (NCSN, Song &<br>Ermon (2019)) have demonstrated the ability to produce samples comparable to that of GANs, with-<br>out having to perform adversarial training. To achieve this, many denoising autoencoding models<br>are trained to denoise samples corrupted by various levels of Gaussian noise. Samples are then<br>produced by a Markov chain which, starting from white noise, progressively denoises it into an im-<br>age. This generative Markov Chain process is either based on Langevin dynamics (Song & Ermon,<br>2019) or obtained by reversing a forward diffusion process that progressively turns an image into<br>noise (Sohl-Dickstein et al., 2015).</p>",
            "id": 9,
            "page": 1,
            "text": "Recent works on iterative generative models (Bengio , 2014), such as denoising diffusion probabilistic models (DDPM, Ho  (2020)) and noise conditional score networks (NCSN, Song & Ermon (2019)) have demonstrated the ability to produce samples comparable to that of GANs, without having to perform adversarial training. To achieve this, many denoising autoencoding models are trained to denoise samples corrupted by various levels of Gaussian noise. Samples are then produced by a Markov chain which, starting from white noise, progressively denoises it into an image. This generative Markov Chain process is either based on Langevin dynamics (Song & Ermon, 2019) or obtained by reversing a forward diffusion process that progressively turns an image into noise (Sohl-Dickstein , 2015)."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2523
                },
                {
                    "x": 2109,
                    "y": 2523
                },
                {
                    "x": 2109,
                    "y": 2892
                },
                {
                    "x": 441,
                    "y": 2892
                }
            ],
            "category": "paragraph",
            "html": "<p id='10' style='font-size:18px'>A critical drawback of these models is that they require many iterations to produce a high quality<br>sample. For DDPMs, this is because that the generative process (from noise to data) approximates<br>the reverse of the forward diffusion process (from data to noise), which could have thousands of<br>steps; iterating over all the steps is required to produce a single sample, which is much slower<br>compared to GANs, which only needs one pass through a network. For example, it takes around 20<br>hours to sample 50k images of size 32 x 32 from a DDPM, but less than a minute to do SO from<br>a GAN on a Nvidia 2080 Ti GPU. This becomes more problematic for larger images as sampling<br>50k images of size 256 x 256 could take nearly 1000 hours on the same GPU.</p>",
            "id": 10,
            "page": 1,
            "text": "A critical drawback of these models is that they require many iterations to produce a high quality sample. For DDPMs, this is because that the generative process (from noise to data) approximates the reverse of the forward diffusion process (from data to noise), which could have thousands of steps; iterating over all the steps is required to produce a single sample, which is much slower compared to GANs, which only needs one pass through a network. For example, it takes around 20 hours to sample 50k images of size 32 x 32 from a DDPM, but less than a minute to do SO from a GAN on a Nvidia 2080 Ti GPU. This becomes more problematic for larger images as sampling 50k images of size 256 x 256 could take nearly 1000 hours on the same GPU."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2914
                },
                {
                    "x": 2108,
                    "y": 2914
                },
                {
                    "x": 2108,
                    "y": 3053
                },
                {
                    "x": 442,
                    "y": 3053
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='11' style='font-size:18px'>To close this efficiency gap between DDPMs and GANs, we present denoising diffusion implicit<br>models (DDIMs). DDIMs are implicit probabilistic models (Mohamed & Lakshminarayanan, 2016)<br>and are closely related to DDPMs, in the sense that they are trained with the same objective function.</p>",
            "id": 11,
            "page": 1,
            "text": "To close this efficiency gap between DDPMs and GANs, we present denoising diffusion implicit models (DDIMs). DDIMs are implicit probabilistic models (Mohamed & Lakshminarayanan, 2016) and are closely related to DDPMs, in the sense that they are trained with the same objective function."
        },
        {
            "bounding_box": [
                {
                    "x": 64,
                    "y": 900
                },
                {
                    "x": 148,
                    "y": 900
                },
                {
                    "x": 148,
                    "y": 2317
                },
                {
                    "x": 64,
                    "y": 2317
                }
            ],
            "category": "footer",
            "html": "<br><footer id='12' style='font-size:14px'>2022<br>Oct<br>5<br>[cs.LG]<br>arXiv:2010.02502v4</footer>",
            "id": 12,
            "page": 1,
            "text": "2022 Oct 5 [cs.LG] arXiv:2010.02502v4"
        },
        {
            "bounding_box": [
                {
                    "x": 1261,
                    "y": 3133
                },
                {
                    "x": 1289,
                    "y": 3133
                },
                {
                    "x": 1289,
                    "y": 3172
                },
                {
                    "x": 1261,
                    "y": 3172
                }
            ],
            "category": "footer",
            "html": "<footer id='13' style='font-size:14px'>1</footer>",
            "id": 13,
            "page": 1,
            "text": "1"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='14' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 14,
            "page": 2,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 523,
                    "y": 352
                },
                {
                    "x": 2009,
                    "y": 352
                },
                {
                    "x": 2009,
                    "y": 524
                },
                {
                    "x": 523,
                    "y": 524
                }
            ],
            "category": "figure",
            "html": "<figure><img id='15' style='font-size:14px' alt=\"po po\nX3 X2 X1 X0\nX3 X2 x1 x0\nq(x3|x2, xo) ↑ q(x2]x1, xo)\nq(x2|x1)\" data-coord=\"top-left:(523,352); bottom-right:(2009,524)\" /></figure>",
            "id": 15,
            "page": 2,
            "text": "po po X3 X2 X1 X0 X3 X2 x1 x0 q(x3|x2, xo) ↑ q(x2]x1, xo) q(x2|x1)"
        },
        {
            "bounding_box": [
                {
                    "x": 507,
                    "y": 570
                },
                {
                    "x": 2039,
                    "y": 570
                },
                {
                    "x": 2039,
                    "y": 620
                },
                {
                    "x": 507,
                    "y": 620
                }
            ],
            "category": "caption",
            "html": "<caption id='16' style='font-size:18px'>Figure 1: Graphical models for diffusion (left) and non-Markovian (right) inference models.</caption>",
            "id": 16,
            "page": 2,
            "text": "Figure 1: Graphical models for diffusion (left) and non-Markovian (right) inference models."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 705
                },
                {
                    "x": 2107,
                    "y": 705
                },
                {
                    "x": 2107,
                    "y": 1119
                },
                {
                    "x": 442,
                    "y": 1119
                }
            ],
            "category": "paragraph",
            "html": "<p id='17' style='font-size:16px'>In Section 3, we generalize the forward diffusion process used by DDPMs, which is Markovian,<br>to non-Markovian ones, for which we are still able to design suitable reverse generative Markov<br>chains. We show that the resulting variational training objectives have a shared surrogate objective,<br>which is exactly the objective used to train DDPM. Therefore, we can freely choose from a large<br>family of generative models using the same neural network simply by choosing a different, non-<br>Markovian diffusion process (Section 4.1) and the corresponding reverse generative Markov Chain.<br>In particular, we are able to use non-Markovian diffusion processes which lead to \"short\" generative<br>Markov chains (Section 4.2) that can be simulated in a small number of steps. This can massively<br>increase sample efficiency only at a minor cost in sample quality.</p>",
            "id": 17,
            "page": 2,
            "text": "In Section 3, we generalize the forward diffusion process used by DDPMs, which is Markovian, to non-Markovian ones, for which we are still able to design suitable reverse generative Markov chains. We show that the resulting variational training objectives have a shared surrogate objective, which is exactly the objective used to train DDPM. Therefore, we can freely choose from a large family of generative models using the same neural network simply by choosing a different, nonMarkovian diffusion process (Section 4.1) and the corresponding reverse generative Markov Chain. In particular, we are able to use non-Markovian diffusion processes which lead to \"short\" generative Markov chains (Section 4.2) that can be simulated in a small number of steps. This can massively increase sample efficiency only at a minor cost in sample quality."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1140
                },
                {
                    "x": 2107,
                    "y": 1140
                },
                {
                    "x": 2107,
                    "y": 1508
                },
                {
                    "x": 441,
                    "y": 1508
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='18' style='font-size:16px'>In Section 5, we demonstrate several empirical benefits of DDIMs over DDPMs. First, DDIMs have<br>superior sample generation quality compared to DDPMs, when we accelerate sampling by 10x to<br>100x using our proposed method. Second, DDIM samples have the following \"consistency\" prop-<br>erty, which does not hold for DDPMs: if we start with the same initial latent variable and generate<br>several samples with Markov chains of various lengths, these samples would have similar high-level<br>features. Third, because of \"consistency\" in DDIMs, we can perform semantically meaningful image<br>interpolation by manipulating the initial latent variable in DDIMs, unlike DDPMs which interpolates<br>near the image space due to the stochastic generative process.</p>",
            "id": 18,
            "page": 2,
            "text": "In Section 5, we demonstrate several empirical benefits of DDIMs over DDPMs. First, DDIMs have superior sample generation quality compared to DDPMs, when we accelerate sampling by 10x to 100x using our proposed method. Second, DDIM samples have the following \"consistency\" property, which does not hold for DDPMs: if we start with the same initial latent variable and generate several samples with Markov chains of various lengths, these samples would have similar high-level features. Third, because of \"consistency\" in DDIMs, we can perform semantically meaningful image interpolation by manipulating the initial latent variable in DDIMs, unlike DDPMs which interpolates near the image space due to the stochastic generative process."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1575
                },
                {
                    "x": 838,
                    "y": 1575
                },
                {
                    "x": 838,
                    "y": 1627
                },
                {
                    "x": 445,
                    "y": 1627
                }
            ],
            "category": "paragraph",
            "html": "<p id='19' style='font-size:20px'>2 BACKGROUND</p>",
            "id": 19,
            "page": 2,
            "text": "2 BACKGROUND"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1677
                },
                {
                    "x": 2104,
                    "y": 1677
                },
                {
                    "x": 2104,
                    "y": 1816
                },
                {
                    "x": 442,
                    "y": 1816
                }
            ],
            "category": "paragraph",
            "html": "<p id='20' style='font-size:16px'>Given samples from a data distribution q(xo), we are interested in learning a model distribution<br>po (xo) that approximates q(xo) and is easy to sample from. Denoising diffusion probabilistic mod-<br>els (DDPMs, Sohl-Dickstein et al. (2015); Ho et al. (2020)) are latent variable models of the form</p>",
            "id": 20,
            "page": 2,
            "text": "Given samples from a data distribution q(xo), we are interested in learning a model distribution po (xo) that approximates q(xo) and is easy to sample from. Denoising diffusion probabilistic models (DDPMs, Sohl-Dickstein  (2015); Ho  (2020)) are latent variable models of the form"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1989
                },
                {
                    "x": 2104,
                    "y": 1989
                },
                {
                    "x": 2104,
                    "y": 2082
                },
                {
                    "x": 441,
                    "y": 2082
                }
            ],
            "category": "paragraph",
            "html": "<p id='21' style='font-size:14px'>where X1, · · · , XT are latent variables in the same sample space as X0 (denoted as X). The parame-<br>ters 0 are learned to fit the data distribution q(xo) by maximizing a variational lower bound:</p>",
            "id": 21,
            "page": 2,
            "text": "where X1, · · · , XT are latent variables in the same sample space as X0 (denoted as X). The parameters 0 are learned to fit the data distribution q(xo) by maximizing a variational lower bound:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2193
                },
                {
                    "x": 2106,
                    "y": 2193
                },
                {
                    "x": 2106,
                    "y": 2426
                },
                {
                    "x": 441,
                    "y": 2426
                }
            ],
            "category": "paragraph",
            "html": "<p id='22' style='font-size:16px'>where q(x1:7|x0) is some inference distribution over the latent variables. Unlike typical latent vari-<br>able models (such as the variational autoencoder (Rezende et al., 2014)), DDPMs are learned with a<br>fixed (rather than trainable) inference procedure q(x1:T|x0), and latent variables are relatively high<br>dimensional. For example, Ho et al. (2020) considered the following Markov chain with Gaussian<br>transitions parameterized by a decreasing sequence �1:T E (0, 1]T:</p>",
            "id": 22,
            "page": 2,
            "text": "where q(x1:7|x0) is some inference distribution over the latent variables. Unlike typical latent variable models (such as the variational autoencoder (Rezende , 2014)), DDPMs are learned with a fixed (rather than trainable) inference procedure q(x1:T|x0), and latent variables are relatively high dimensional. For example, Ho  (2020) considered the following Markov chain with Gaussian transitions parameterized by a decreasing sequence �1:T E (0, 1]T:"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 2598
                },
                {
                    "x": 2108,
                    "y": 2598
                },
                {
                    "x": 2108,
                    "y": 2875
                },
                {
                    "x": 440,
                    "y": 2875
                }
            ],
            "category": "paragraph",
            "html": "<p id='23' style='font-size:16px'>where the covariance matrix is ensured to have positive terms on its diagonal. This is called the<br>forward process due to the autoregressive nature of the sampling procedure (from x0 to XT). We<br>call the latent variable model po(xo:T), which is a Markov chain that samples from XT to x0, the<br>generative process, since it approximates the intractable reverse process q(xt-1|xt). Intuitively,<br>the forward process progressively adds noise to the observation x0, whereas the generative process<br>progressively denoises a noisy observation (Figure 1, left).</p>",
            "id": 23,
            "page": 2,
            "text": "where the covariance matrix is ensured to have positive terms on its diagonal. This is called the forward process due to the autoregressive nature of the sampling procedure (from x0 to XT). We call the latent variable model po(xo:T), which is a Markov chain that samples from XT to x0, the generative process, since it approximates the intractable reverse process q(xt-1|xt). Intuitively, the forward process progressively adds noise to the observation x0, whereas the generative process progressively denoises a noisy observation (Figure 1, left)."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2899
                },
                {
                    "x": 1254,
                    "y": 2899
                },
                {
                    "x": 1254,
                    "y": 2944
                },
                {
                    "x": 445,
                    "y": 2944
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='24' style='font-size:16px'>A special property of the forward process is that</p>",
            "id": 24,
            "page": 2,
            "text": "A special property of the forward process is that"
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3171
                },
                {
                    "x": 1259,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='25' style='font-size:16px'>2</footer>",
            "id": 25,
            "page": 2,
            "text": "2"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 112
                },
                {
                    "x": 1220,
                    "y": 112
                },
                {
                    "x": 1220,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='26' style='font-size:16px'>Published as a conference paper at ICLR 2021</header>",
            "id": 26,
            "page": 3,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 352
                },
                {
                    "x": 1680,
                    "y": 352
                },
                {
                    "x": 1680,
                    "y": 392
                },
                {
                    "x": 444,
                    "y": 392
                }
            ],
            "category": "paragraph",
            "html": "<p id='27' style='font-size:14px'>SO we can express Xt as a linear combination of xo and a noise variable e:</p>",
            "id": 27,
            "page": 3,
            "text": "SO we can express Xt as a linear combination of xo and a noise variable e:"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 491
                },
                {
                    "x": 2104,
                    "y": 491
                },
                {
                    "x": 2104,
                    "y": 628
                },
                {
                    "x": 443,
                    "y": 628
                }
            ],
            "category": "paragraph",
            "html": "<p id='28' style='font-size:18px'>When we set aT sufficiently close to 0, q(xT |xo) converges to a standard Gaussian for all x0, SO it<br>is natural to set po(xT) := N(0, I). If all the conditionals are modeled as Gaussians with trainable<br>mean functions and fixed variances, the objective in Eq. (2) can be simplified to1:</p>",
            "id": 28,
            "page": 3,
            "text": "When we set aT sufficiently close to 0, q(xT |xo) converges to a standard Gaussian for all x0, SO it is natural to set po(xT) := N(0, I). If all the conditionals are modeled as Gaussians with trainable mean functions and fixed variances, the objective in Eq. (2) can be simplified to1:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 813
                },
                {
                    "x": 2106,
                    "y": 813
                },
                {
                    "x": 2106,
                    "y": 1154
                },
                {
                    "x": 441,
                    "y": 1154
                }
            ],
            "category": "paragraph",
            "html": "<p id='29' style='font-size:18px'>where EA := {e{t)}t=1 is a set of T functions, each 93 : X → X (indexed by t) is a function with<br>trainable parameters 0(t), and 2 := [Y1, · · · , YT] is a vector of positive coefficients in the objective<br>that depends on �1:T. In Ho et al. (2020), the objective with 2 = 1 is optimized instead to maximize<br>generation performance of the trained model; this is also the same objective used in noise conditional<br>score networks (Song & Ermon, 2019) based on score matching (Hyvarinen, 2005; Vincent, 2011).<br>From a trained model, X0 is sampled by first sampling XT from the prior po (XT), and then sampling<br>Xt-1 from the generative processes iteratively.</p>",
            "id": 29,
            "page": 3,
            "text": "where EA := {e{t)}t=1 is a set of T functions, each 93 : X → X (indexed by t) is a function with trainable parameters 0(t), and 2 := [Y1, · · · , YT] is a vector of positive coefficients in the objective that depends on �1:T. In Ho  (2020), the objective with 2 = 1 is optimized instead to maximize generation performance of the trained model; this is also the same objective used in noise conditional score networks (Song & Ermon, 2019) based on score matching (Hyvarinen, 2005; Vincent, 2011). From a trained model, X0 is sampled by first sampling XT from the prior po (XT), and then sampling Xt-1 from the generative processes iteratively."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1174
                },
                {
                    "x": 2106,
                    "y": 1174
                },
                {
                    "x": 2106,
                    "y": 1500
                },
                {
                    "x": 442,
                    "y": 1500
                }
            ],
            "category": "paragraph",
            "html": "<p id='30' style='font-size:18px'>The length T of the forward process is an important hyperparameter in DDPMs. From a variational<br>perspective, a large T allows the reverse process to be close to a Gaussian (Sohl-Dickstein et al.,<br>2015), SO that the generative process modeled with Gaussian conditional distributions becomes a<br>good approximation; this motivates the choice of large T values, such as T = 1000 in Ho et al.<br>(2020). However, as all T iterations have to be performed sequentially, instead of in parallel, to ob-<br>tain a sample xo, sampling from DDPMs is much slower than sampling from other deep generative<br>models, which makes them impractical for tasks where compute is limited and latency is critical.</p>",
            "id": 30,
            "page": 3,
            "text": "The length T of the forward process is an important hyperparameter in DDPMs. From a variational perspective, a large T allows the reverse process to be close to a Gaussian (Sohl-Dickstein , 2015), SO that the generative process modeled with Gaussian conditional distributions becomes a good approximation; this motivates the choice of large T values, such as T = 1000 in Ho  (2020). However, as all T iterations have to be performed sequentially, instead of in parallel, to obtain a sample xo, sampling from DDPMs is much slower than sampling from other deep generative models, which makes them impractical for tasks where compute is limited and latency is critical."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1561
                },
                {
                    "x": 2067,
                    "y": 1561
                },
                {
                    "x": 2067,
                    "y": 1617
                },
                {
                    "x": 444,
                    "y": 1617
                }
            ],
            "category": "paragraph",
            "html": "<p id='31' style='font-size:20px'>3 VARIATIONAL INFERENCE FOR NON-MARKOVIAN FORWARD PROCESSES</p>",
            "id": 31,
            "page": 3,
            "text": "3 VARIATIONAL INFERENCE FOR NON-MARKOVIAN FORWARD PROCESSES"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1666
                },
                {
                    "x": 2107,
                    "y": 1666
                },
                {
                    "x": 2107,
                    "y": 2036
                },
                {
                    "x": 442,
                    "y": 2036
                }
            ],
            "category": "paragraph",
            "html": "<p id='32' style='font-size:18px'>Because the generative model approximates the reverse of the inference process, we need to rethink<br>the inference process in order to reduce the number of iterations required by the generative model.<br>Our key observation is that the DDPM objective in the form of Ly only depends on the marginals2<br>q(xt|xo), but not directly on the joint q(x1:T |xo). Since there are many inference distributions<br>(joints) with the same marginals, we explore alternative inference processes that are non-Markovian,<br>which leads to new generative processes (Figure 1, right). These non-Markovian inference process<br>lead to the same surrogate objective function as DDPM, as we will show below. In Appendix A, we<br>show that the non-Markovian perspective also applies beyond the Gaussian case.</p>",
            "id": 32,
            "page": 3,
            "text": "Because the generative model approximates the reverse of the inference process, we need to rethink the inference process in order to reduce the number of iterations required by the generative model. Our key observation is that the DDPM objective in the form of Ly only depends on the marginals2 q(xt|xo), but not directly on the joint q(x1:T |xo). Since there are many inference distributions (joints) with the same marginals, we explore alternative inference processes that are non-Markovian, which leads to new generative processes (Figure 1, right). These non-Markovian inference process lead to the same surrogate objective function as DDPM, as we will show below. In Appendix A, we show that the non-Markovian perspective also applies beyond the Gaussian case."
        },
        {
            "bounding_box": [
                {
                    "x": 447,
                    "y": 2087
                },
                {
                    "x": 1277,
                    "y": 2087
                },
                {
                    "x": 1277,
                    "y": 2137
                },
                {
                    "x": 447,
                    "y": 2137
                }
            ],
            "category": "paragraph",
            "html": "<p id='33' style='font-size:16px'>3.1 NON-MARKOVIAN FORWARD PROCESSES</p>",
            "id": 33,
            "page": 3,
            "text": "3.1 NON-MARKOVIAN FORWARD PROCESSES"
        },
        {
            "bounding_box": [
                {
                    "x": 439,
                    "y": 2170
                },
                {
                    "x": 1917,
                    "y": 2170
                },
                {
                    "x": 1917,
                    "y": 2234
                },
                {
                    "x": 439,
                    "y": 2234
                }
            ],
            "category": "paragraph",
            "html": "<p id='34' style='font-size:18px'>Let us consider a family Q of inference distributions, indexed by a real vector 0 E RT0:</p>",
            "id": 34,
            "page": 3,
            "text": "Let us consider a family Q of inference distributions, indexed by a real vector 0 E RT0:"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2411
                },
                {
                    "x": 1506,
                    "y": 2411
                },
                {
                    "x": 1506,
                    "y": 2464
                },
                {
                    "x": 444,
                    "y": 2464
                }
            ],
            "category": "paragraph",
            "html": "<p id='35' style='font-size:18px'>where qo (xT|x0) =N(VaTx0, (1 - �T)I) and for all t > 1,</p>",
            "id": 35,
            "page": 3,
            "text": "where qo (xT|x0) =N(VaTx0, (1 - �T)I) and for all t > 1,"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2616
                },
                {
                    "x": 2106,
                    "y": 2616
                },
                {
                    "x": 2106,
                    "y": 2755
                },
                {
                    "x": 442,
                    "y": 2755
                }
            ],
            "category": "paragraph",
            "html": "<p id='36' style='font-size:18px'>The mean function is chosen to order to ensure that qo(xt|x0) = N(Vatxo, (1 - at)I) for all<br>t (see Lemma 1 of Appendix B), SO that it defines a joint inference distribution that matches the<br>\"marginals\" as desired. The forward process3 can be derived from Bayes' rule:</p>",
            "id": 36,
            "page": 3,
            "text": "The mean function is chosen to order to ensure that qo(xt|x0) = N(Vatxo, (1 - at)I) for all t (see Lemma 1 of Appendix B), SO that it defines a joint inference distribution that matches the \"marginals\" as desired. The forward process3 can be derived from Bayes' rule:"
        },
        {
            "bounding_box": [
                {
                    "x": 491,
                    "y": 2914
                },
                {
                    "x": 1938,
                    "y": 2914
                },
                {
                    "x": 1938,
                    "y": 3053
                },
                {
                    "x": 491,
                    "y": 3053
                }
            ],
            "category": "paragraph",
            "html": "<p id='37' style='font-size:14px'>1Please refer to Appendix C.2 for details.<br>2We slightly abuse this term (as well as joints) when only conditioned on xo.<br>3We overload the term \"forward process\" for cases where the inference model is not a diffusion.</p>",
            "id": 37,
            "page": 3,
            "text": "1Please refer to Appendix C.2 for details. 2We slightly abuse this term (as well as joints) when only conditioned on xo. 3We overload the term \"forward process\" for cases where the inference model is not a diffusion."
        },
        {
            "bounding_box": [
                {
                    "x": 1261,
                    "y": 3133
                },
                {
                    "x": 1288,
                    "y": 3133
                },
                {
                    "x": 1288,
                    "y": 3170
                },
                {
                    "x": 1261,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='38' style='font-size:18px'>3</footer>",
            "id": 38,
            "page": 3,
            "text": "3"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 157
                },
                {
                    "x": 445,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='39' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 39,
            "page": 4,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 348
                },
                {
                    "x": 2107,
                    "y": 348
                },
                {
                    "x": 2107,
                    "y": 577
                },
                {
                    "x": 441,
                    "y": 577
                }
            ],
            "category": "paragraph",
            "html": "<p id='40' style='font-size:16px'>which is also Gaussian (although we do not use this fact for the remainder of this paper). Unlike the<br>diffusion process in Eq. (3), the forward process here is no longer Markovian, since each Xt could<br>depend on both Xt-1 and xo. The magnitude of 0 controls the how stochastic the forward process<br>is; when 0 → 0, we reach an extreme case where as long as we observe x0 and Xt for some t, then<br>Xt-1 become known and fixed.</p>",
            "id": 40,
            "page": 4,
            "text": "which is also Gaussian (although we do not use this fact for the remainder of this paper). Unlike the diffusion process in Eq. (3), the forward process here is no longer Markovian, since each Xt could depend on both Xt-1 and xo. The magnitude of 0 controls the how stochastic the forward process is; when 0 → 0, we reach an extreme case where as long as we observe x0 and Xt for some t, then Xt-1 become known and fixed."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 632
                },
                {
                    "x": 1868,
                    "y": 632
                },
                {
                    "x": 1868,
                    "y": 681
                },
                {
                    "x": 445,
                    "y": 681
                }
            ],
            "category": "paragraph",
            "html": "<p id='41' style='font-size:14px'>3.2 GENERATIVE PROCESS AND UNIFIED VARIATIONAL INFERENCE OBJECTIVE</p>",
            "id": 41,
            "page": 4,
            "text": "3.2 GENERATIVE PROCESS AND UNIFIED VARIATIONAL INFERENCE OBJECTIVE"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 713
                },
                {
                    "x": 2107,
                    "y": 713
                },
                {
                    "x": 2107,
                    "y": 909
                },
                {
                    "x": 440,
                    "y": 909
                }
            ],
            "category": "paragraph",
            "html": "<p id='42' style='font-size:18px'>Next, we define a trainable generative process po (X0:T) where each Ded (xt-1|xt) leverages knowl-<br>edge of 90 (xt-1|xt, xo). Intuitively, given a noisy observation xt, we first make a prediction4<br>of the corresponding xo, and then use it to obtain a sample Xt-1 through the reverse conditional<br>distribution 90 (xt-1|xt, xo), which we have defined.</p>",
            "id": 42,
            "page": 4,
            "text": "Next, we define a trainable generative process po (X0:T) where each Ded (xt-1|xt) leverages knowledge of 90 (xt-1|xt, xo). Intuitively, given a noisy observation xt, we first make a prediction4 of the corresponding xo, and then use it to obtain a sample Xt-1 through the reverse conditional distribution 90 (xt-1|xt, xo), which we have defined."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 943
                },
                {
                    "x": 2107,
                    "y": 943
                },
                {
                    "x": 2107,
                    "y": 1082
                },
                {
                    "x": 442,
                    "y": 1082
                }
            ],
            "category": "paragraph",
            "html": "<p id='43' style='font-size:18px'>For some xo ~ q(xo) and Et ~ N(0,I), Xt can be obtained using Eq. (4). The model 93 (xt) then<br>attempts to predict Et from xt, without knowledge of xo. By rewriting Eq. (4), one can then predict<br>the denoised observation, which is a prediction of X0 given xt:</p>",
            "id": 43,
            "page": 4,
            "text": "For some xo ~ q(xo) and Et ~ N(0,I), Xt can be obtained using Eq. (4). The model 93 (xt) then attempts to predict Et from xt, without knowledge of xo. By rewriting Eq. (4), one can then predict the denoised observation, which is a prediction of X0 given xt:"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1187
                },
                {
                    "x": 1846,
                    "y": 1187
                },
                {
                    "x": 1846,
                    "y": 1235
                },
                {
                    "x": 444,
                    "y": 1235
                }
            ],
            "category": "paragraph",
            "html": "<p id='44' style='font-size:18px'>We can then define the generative process with a fixed prior p0(xT) =N(0,I) and</p>",
            "id": 44,
            "page": 4,
            "text": "We can then define the generative process with a fixed prior p0(xT) =N(0,I) and"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1413
                },
                {
                    "x": 2106,
                    "y": 1413
                },
                {
                    "x": 2106,
                    "y": 1567
                },
                {
                    "x": 441,
                    "y": 1567
                }
            ],
            "category": "paragraph",
            "html": "<p id='45' style='font-size:18px'>where qo (xt-1|xt, f(t) (xt)) is defined as in Eq. (7) with X0 replaced by f(t) (xt). We add some<br>Gaussian noise (with covariance o2I) for the case of t = 1 to ensure that the generative process is<br>supported everywhere.</p>",
            "id": 45,
            "page": 4,
            "text": "where qo (xt-1|xt, f(t) (xt)) is defined as in Eq. (7) with X0 replaced by f(t) (xt). We add some Gaussian noise (with covariance o2I) for the case of t = 1 to ensure that the generative process is supported everywhere."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1590
                },
                {
                    "x": 2026,
                    "y": 1590
                },
                {
                    "x": 2026,
                    "y": 1639
                },
                {
                    "x": 444,
                    "y": 1639
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='46' style='font-size:18px'>We optimize 0 via the following variational inference objective (which is a functional over eA):</p>",
            "id": 46,
            "page": 4,
            "text": "We optimize 0 via the following variational inference objective (which is a functional over eA):"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1881
                },
                {
                    "x": 1914,
                    "y": 1881
                },
                {
                    "x": 1914,
                    "y": 1929
                },
                {
                    "x": 444,
                    "y": 1929
                }
            ],
            "category": "paragraph",
            "html": "<p id='47' style='font-size:20px'>where we factorize qo (X1:T|X0) according to Eq. (6) and pe(xo:T) according to Eq. (1).</p>",
            "id": 47,
            "page": 4,
            "text": "where we factorize qo (X1:T|X0) according to Eq. (6) and pe(xo:T) according to Eq. (1)."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1951
                },
                {
                    "x": 2105,
                    "y": 1951
                },
                {
                    "x": 2105,
                    "y": 2090
                },
                {
                    "x": 441,
                    "y": 2090
                }
            ],
            "category": "paragraph",
            "html": "<p id='48' style='font-size:16px'>From the definition of Jo, it would appear that a different model has to be trained for every choice<br>of �, since it corresponds to a different variational objective (and a different generative process).<br>However, Jo is equivalent to Ly for certain weights 2, as we show below.</p>",
            "id": 48,
            "page": 4,
            "text": "From the definition of Jo, it would appear that a different model has to be trained for every choice of �, since it corresponds to a different variational objective (and a different generative process). However, Jo is equivalent to Ly for certain weights 2, as we show below."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2206
                },
                {
                    "x": 2106,
                    "y": 2206
                },
                {
                    "x": 2106,
                    "y": 2576
                },
                {
                    "x": 442,
                    "y": 2576
                }
            ],
            "category": "paragraph",
            "html": "<p id='49' style='font-size:18px'>The variational objective Ly is special in the sense that if parameters 0 of the models 93 are not<br>shared across different t, then the optimal solution for EA will not depend on the weights 2 (as global<br>optimum is achieved by separately maximizing each term in the sum). This property of Ly has<br>two implications. On the one hand, this justified the use of L1 as a surrogate objective function for<br>the variational lower bound in DDPMs; on the other hand, since Jo is equivalent to some Ly from<br>Theorem 1, the optimal solution of Jo is also the same as that of L1. Therefore, if parameters are<br>not shared across t in the model EA, then the L1 objective used by Ho et al. (2020) can be used as a<br>surrogate objective for the variational objective Jo as well.</p>",
            "id": 49,
            "page": 4,
            "text": "The variational objective Ly is special in the sense that if parameters 0 of the models 93 are not shared across different t, then the optimal solution for EA will not depend on the weights 2 (as global optimum is achieved by separately maximizing each term in the sum). This property of Ly has two implications. On the one hand, this justified the use of L1 as a surrogate objective function for the variational lower bound in DDPMs; on the other hand, since Jo is equivalent to some Ly from Theorem 1, the optimal solution of Jo is also the same as that of L1. Therefore, if parameters are not shared across t in the model EA, then the L1 objective used by Ho  (2020) can be used as a surrogate objective for the variational objective Jo as well."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2642
                },
                {
                    "x": 1764,
                    "y": 2642
                },
                {
                    "x": 1764,
                    "y": 2694
                },
                {
                    "x": 444,
                    "y": 2694
                }
            ],
            "category": "paragraph",
            "html": "<p id='50' style='font-size:20px'>4 S AMPLING FROM GENERALIZED GENERATIVE PROCESSES</p>",
            "id": 50,
            "page": 4,
            "text": "4 S AMPLING FROM GENERALIZED GENERATIVE PROCESSES"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2744
                },
                {
                    "x": 2106,
                    "y": 2744
                },
                {
                    "x": 2106,
                    "y": 2978
                },
                {
                    "x": 443,
                    "y": 2978
                }
            ],
            "category": "paragraph",
            "html": "<p id='51' style='font-size:16px'>With L1 as the objective, we are not only learning a generative process for the Markovian inference<br>process considered in Sohl-Dickstein et al. (2015) and Ho et al. (2020), but also generative processes<br>for many non-Markovian forward processes parametrized by 0 that we have described. Therefore,<br>we can essentially use pretrained DDPM models as the solutions to the new objectives, and focus on<br>finding a generative process that is better at producing samples subject to our needs by changing 0.</p>",
            "id": 51,
            "page": 4,
            "text": "With L1 as the objective, we are not only learning a generative process for the Markovian inference process considered in Sohl-Dickstein  (2015) and Ho  (2020), but also generative processes for many non-Markovian forward processes parametrized by 0 that we have described. Therefore, we can essentially use pretrained DDPM models as the solutions to the new objectives, and focus on finding a generative process that is better at producing samples subject to our needs by changing 0."
        },
        {
            "bounding_box": [
                {
                    "x": 497,
                    "y": 3007
                },
                {
                    "x": 2080,
                    "y": 3007
                },
                {
                    "x": 2080,
                    "y": 3053
                },
                {
                    "x": 497,
                    "y": 3053
                }
            ],
            "category": "paragraph",
            "html": "<p id='52' style='font-size:14px'>4Learning a distribution over the predictions is also possible, but empirically we found little benefits of it.</p>",
            "id": 52,
            "page": 4,
            "text": "4Learning a distribution over the predictions is also possible, but empirically we found little benefits of it."
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 3135
                },
                {
                    "x": 1288,
                    "y": 3135
                },
                {
                    "x": 1288,
                    "y": 3169
                },
                {
                    "x": 1259,
                    "y": 3169
                }
            ],
            "category": "footer",
            "html": "<footer id='53' style='font-size:14px'>4</footer>",
            "id": 53,
            "page": 4,
            "text": "4"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1220,
                    "y": 110
                },
                {
                    "x": 1220,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='54' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 54,
            "page": 5,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 866,
                    "y": 331
                },
                {
                    "x": 1689,
                    "y": 331
                },
                {
                    "x": 1689,
                    "y": 568
                },
                {
                    "x": 866,
                    "y": 568
                }
            ],
            "category": "figure",
            "html": "<figure><img id='55' style='font-size:22px' alt=\"po\n�1\n�3.\nX1 X0\nX3 X2;\n주 q(x2|x0)\nq(x3|x1, xo)\" data-coord=\"top-left:(866,331); bottom-right:(1689,568)\" /></figure>",
            "id": 55,
            "page": 5,
            "text": "po �1 �3. X1 X0 X3 X2; 주 q(x2|x0) q(x3|x1, xo)"
        },
        {
            "bounding_box": [
                {
                    "x": 672,
                    "y": 602
                },
                {
                    "x": 1875,
                    "y": 602
                },
                {
                    "x": 1875,
                    "y": 662
                },
                {
                    "x": 672,
                    "y": 662
                }
            ],
            "category": "caption",
            "html": "<caption id='56' style='font-size:20px'>Figure 2: Graphical model for accelerated generation, where T = [1,3].</caption>",
            "id": 56,
            "page": 5,
            "text": "Figure 2: Graphical model for accelerated generation, where T = ."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 768
                },
                {
                    "x": 1305,
                    "y": 768
                },
                {
                    "x": 1305,
                    "y": 817
                },
                {
                    "x": 444,
                    "y": 817
                }
            ],
            "category": "paragraph",
            "html": "<p id='57' style='font-size:18px'>4.1 DENOISING DIFFUSION IMPLICIT MODELS</p>",
            "id": 57,
            "page": 5,
            "text": "4.1 DENOISING DIFFUSION IMPLICIT MODELS"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 866
                },
                {
                    "x": 1820,
                    "y": 866
                },
                {
                    "x": 1820,
                    "y": 917
                },
                {
                    "x": 444,
                    "y": 917
                }
            ],
            "category": "paragraph",
            "html": "<p id='58' style='font-size:18px'>From po (X1:T) in Eq. (10), one can generate a sample Xt-1 from a sample Xt via:</p>",
            "id": 58,
            "page": 5,
            "text": "From po (X1:T) in Eq. (10), one can generate a sample Xt-1 from a sample Xt via:"
        },
        {
            "bounding_box": [
                {
                    "x": 518,
                    "y": 955
                },
                {
                    "x": 2107,
                    "y": 955
                },
                {
                    "x": 2107,
                    "y": 1162
                },
                {
                    "x": 518,
                    "y": 1162
                }
            ],
            "category": "figure",
            "html": "<figure><img id='59' style='font-size:16px' alt=\"Xt - V1 ate(t) (xt) 93 (xt) + OtEt (12)\nXt-1 = Vat-1 + 1 - at-1 - of ·\nVat\nrandom noise\n'direction pointing to xt\n' predicted x0'\" data-coord=\"top-left:(518,955); bottom-right:(2107,1162)\" /></figure>",
            "id": 59,
            "page": 5,
            "text": "Xt - V1 ate(t) (xt) 93 (xt) + OtEt (12) Xt-1 = Vat-1 + 1 - at-1 - of · Vat random noise \"direction pointing to xt \" predicted x0\""
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1211
                },
                {
                    "x": 2108,
                    "y": 1211
                },
                {
                    "x": 2108,
                    "y": 1404
                },
                {
                    "x": 441,
                    "y": 1404
                }
            ],
            "category": "paragraph",
            "html": "<p id='60' style='font-size:16px'>where Et ~ N(0, I) is standard Gaussian noise independent of xt, and we define ao := 1. Different<br>choices of 0 values results in different generative processes, all while using the same model EA, SO<br>re-training the model is unnecessary. When Ot = V(1 - �t-1)/(1 - at) V 1 - at/at-1 for all t,<br>the forward process becomes Markovian, and the generative process becomes a DDPM.</p>",
            "id": 60,
            "page": 5,
            "text": "where Et ~ N(0, I) is standard Gaussian noise independent of xt, and we define ao := 1. Different choices of 0 values results in different generative processes, all while using the same model EA, SO re-training the model is unnecessary. When Ot = V(1 - �t-1)/(1 - at) V 1 - at/at-1 for all t, the forward process becomes Markovian, and the generative process becomes a DDPM."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1425
                },
                {
                    "x": 2107,
                    "y": 1425
                },
                {
                    "x": 2107,
                    "y": 1749
                },
                {
                    "x": 441,
                    "y": 1749
                }
            ],
            "category": "paragraph",
            "html": "<p id='61' style='font-size:18px'>We note another special case when Ot = 0 for all t5; the forward process becomes deterministic<br>given Xt-1 and x0, except for t = 1; in the generative process, the coefficient before the random<br>noise Et becomes zero. The resulting model becomes an implicit probabilistic model (Mohamed &<br>Lakshminarayanan, 2016), where samples are generated from latent variables with a fixed procedure<br>(from XT to xo). We name this the denoising diffusion implicit model (DDIM, pronounced /d:1m/),<br>because it is an implicit probabilistic model trained with the DDPM objective (despite the forward<br>process no longer being a diffusion).</p>",
            "id": 61,
            "page": 5,
            "text": "We note another special case when Ot = 0 for all t5; the forward process becomes deterministic given Xt-1 and x0, except for t = 1; in the generative process, the coefficient before the random noise Et becomes zero. The resulting model becomes an implicit probabilistic model (Mohamed & Lakshminarayanan, 2016), where samples are generated from latent variables with a fixed procedure (from XT to xo). We name this the denoising diffusion implicit model (DDIM, pronounced /d:1m/), because it is an implicit probabilistic model trained with the DDPM objective (despite the forward process no longer being a diffusion)."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1830
                },
                {
                    "x": 1269,
                    "y": 1830
                },
                {
                    "x": 1269,
                    "y": 1880
                },
                {
                    "x": 442,
                    "y": 1880
                }
            ],
            "category": "paragraph",
            "html": "<p id='62' style='font-size:14px'>4.2 ACCELERATED GENERATION PROCESSES</p>",
            "id": 62,
            "page": 5,
            "text": "4.2 ACCELERATED GENERATION PROCESSES"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1928
                },
                {
                    "x": 2108,
                    "y": 1928
                },
                {
                    "x": 2108,
                    "y": 2162
                },
                {
                    "x": 442,
                    "y": 2162
                }
            ],
            "category": "paragraph",
            "html": "<p id='63' style='font-size:18px'>In the previous sections, the generative process is considered as the approximation to the reverse<br>process; since of the forward process has T steps, the generative process is also forced to sample T<br>steps. However, as the denoising objective L1 does not depend on the specific forward procedure<br>as long as qo(xt |xo) is fixed, we may also consider forward processes with lengths smaller than T,<br>which accelerates the corresponding generative processes without having to train a different model.</p>",
            "id": 63,
            "page": 5,
            "text": "In the previous sections, the generative process is considered as the approximation to the reverse process; since of the forward process has T steps, the generative process is also forced to sample T steps. However, as the denoising objective L1 does not depend on the specific forward procedure as long as qo(xt |xo) is fixed, we may also consider forward processes with lengths smaller than T, which accelerates the corresponding generative processes without having to train a different model."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2183
                },
                {
                    "x": 2106,
                    "y": 2183
                },
                {
                    "x": 2106,
                    "y": 2510
                },
                {
                    "x": 442,
                    "y": 2510
                }
            ],
            "category": "paragraph",
            "html": "<p id='64' style='font-size:14px'>Let us consider the forward process as defined not on all the latent variables X1:T, but on a<br>subset {xT1 , · · · , XTS }, where T is an increasing sub-sequence of [1, · · · , T] of length S. In<br>particular, we define the sequential forward process over XT1 , · · · , XTS such that q(xTi |xo) =<br>N(VaTi xo, (1 - aTi )I) matches the \"marginals\" (see Figure 2 for an illustration). The generative<br>process now samples latent variables according to reversed(�), which we term (sampling) trajec-<br>tory. When the length of the sampling trajectory is much smaller than T, we may achieve significant<br>increases in computational efficiency due to the iterative nature of the sampling process.</p>",
            "id": 64,
            "page": 5,
            "text": "Let us consider the forward process as defined not on all the latent variables X1:T, but on a subset {xT1 , · · · , XTS }, where T is an increasing sub-sequence of [1, · · · , T] of length S. In particular, we define the sequential forward process over XT1 , · · · , XTS such that q(xTi |xo) = N(VaTi xo, (1 - aTi )I) matches the \"marginals\" (see Figure 2 for an illustration). The generative process now samples latent variables according to reversed(�), which we term (sampling) trajectory. When the length of the sampling trajectory is much smaller than T, we may achieve significant increases in computational efficiency due to the iterative nature of the sampling process."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2532
                },
                {
                    "x": 2107,
                    "y": 2532
                },
                {
                    "x": 2107,
                    "y": 2718
                },
                {
                    "x": 442,
                    "y": 2718
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='65' style='font-size:18px'>Using a similar argument as in Section 3, we can justify using the model trained with the L1 ob-<br>jective, SO no changes are needed in training. We show that only slight changes to the updates in<br>Eq. (12) are needed to obtain the new, faster generative processes, which applies to DDPM, DDIM,<br>as well as all generative processes considered in Eq. (10). We include these details in Appendix C.1.</p>",
            "id": 65,
            "page": 5,
            "text": "Using a similar argument as in Section 3, we can justify using the model trained with the L1 objective, SO no changes are needed in training. We show that only slight changes to the updates in Eq. (12) are needed to obtain the new, faster generative processes, which applies to DDPM, DDIM, as well as all generative processes considered in Eq. (10). We include these details in Appendix C.1."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2739
                },
                {
                    "x": 2107,
                    "y": 2739
                },
                {
                    "x": 2107,
                    "y": 2926
                },
                {
                    "x": 442,
                    "y": 2926
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='66' style='font-size:16px'>In principle, this means that we can train a model with an arbitrary number of forward steps but only<br>sample from some of them in the generative process. Therefore, the trained model could consider<br>many more steps than what is considered in (Ho et al., 2020) or even a continuous time variable t<br>(Chen et al., 2020). We leave empirical investigations of this aspect as future work.</p>",
            "id": 66,
            "page": 5,
            "text": "In principle, this means that we can train a model with an arbitrary number of forward steps but only sample from some of them in the generative process. Therefore, the trained model could consider many more steps than what is considered in (Ho , 2020) or even a continuous time variable t (Chen , 2020). We leave empirical investigations of this aspect as future work."
        },
        {
            "bounding_box": [
                {
                    "x": 496,
                    "y": 3005
                },
                {
                    "x": 2076,
                    "y": 3005
                },
                {
                    "x": 2076,
                    "y": 3054
                },
                {
                    "x": 496,
                    "y": 3054
                }
            ],
            "category": "paragraph",
            "html": "<p id='67' style='font-size:14px'>5 Although this case is not covered in Theorem 1, we can always approximate it by making Ot very small.</p>",
            "id": 67,
            "page": 5,
            "text": "5 Although this case is not covered in Theorem 1, we can always approximate it by making Ot very small."
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3132
                },
                {
                    "x": 1290,
                    "y": 3132
                },
                {
                    "x": 1290,
                    "y": 3170
                },
                {
                    "x": 1260,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='68' style='font-size:18px'>5</footer>",
            "id": 68,
            "page": 5,
            "text": "5"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 112
                },
                {
                    "x": 1219,
                    "y": 112
                },
                {
                    "x": 1219,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='69' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 69,
            "page": 6,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 348
                },
                {
                    "x": 1112,
                    "y": 348
                },
                {
                    "x": 1112,
                    "y": 391
                },
                {
                    "x": 445,
                    "y": 391
                }
            ],
            "category": "paragraph",
            "html": "<p id='70' style='font-size:14px'>4.3 RELEVANCE TO NEURAL ODEs</p>",
            "id": 70,
            "page": 6,
            "text": "4.3 RELEVANCE TO NEURAL ODEs"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 434
                },
                {
                    "x": 2103,
                    "y": 434
                },
                {
                    "x": 2103,
                    "y": 524
                },
                {
                    "x": 443,
                    "y": 524
                }
            ],
            "category": "paragraph",
            "html": "<p id='71' style='font-size:16px'>Moreover, we can rewrite the DDIM iterate according to Eq. (12), and its similarity to Euler inte-<br>gration for solving ordinary differential equations (ODEs) becomes more apparent:</p>",
            "id": 71,
            "page": 6,
            "text": "Moreover, we can rewrite the DDIM iterate according to Eq. (12), and its similarity to Euler integration for solving ordinary differential equations (ODEs) becomes more apparent:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 677
                },
                {
                    "x": 2105,
                    "y": 677
                },
                {
                    "x": 2105,
                    "y": 815
                },
                {
                    "x": 441,
                    "y": 815
                }
            ],
            "category": "paragraph",
            "html": "<p id='72' style='font-size:16px'>To derive the corresponding ODE, we can reparameterize (V1 - a Va) with 0 and (x/ Va) with<br>x. In the continuous case, 0 and x are functions oft, where 0 : R≥0 → R≥0 is continous, increasing<br>with �(0) = 0. Equation (13) with can be treated as a Euler method over the following ODE:</p>",
            "id": 72,
            "page": 6,
            "text": "To derive the corresponding ODE, we can reparameterize (V1 - a Va) with 0 and (x/ Va) with x. In the continuous case, 0 and x are functions oft, where 0 : R≥0 → R≥0 is continous, increasing with �(0) = 0. Equation (13) with can be treated as a Euler method over the following ODE:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 938
                },
                {
                    "x": 2105,
                    "y": 938
                },
                {
                    "x": 2105,
                    "y": 1212
                },
                {
                    "x": 442,
                    "y": 1212
                }
            ],
            "category": "paragraph",
            "html": "<p id='73' style='font-size:16px'>where the initial conditions is x(T) ~ N(0, o(T)) for a very large o(T) (which corresponds to the<br>case of a 2 0). This suggests that with enough discretization steps, the we can also reverse the<br>generation process (going from t = 0 to T), which encodes xo to XT and simulates the reverse of<br>the ODE in Eq. (14). This suggests that unlike DDPM, we can use DDIM to obtain encodings of<br>the observations (as the form of XT), which might be useful for other downstream applications that<br>requires latent representations of a model.</p>",
            "id": 73,
            "page": 6,
            "text": "where the initial conditions is x(T) ~ N(0, o(T)) for a very large o(T) (which corresponds to the case of a 2 0). This suggests that with enough discretization steps, the we can also reverse the generation process (going from t = 0 to T), which encodes xo to XT and simulates the reverse of the ODE in Eq. (14). This suggests that unlike DDPM, we can use DDIM to obtain encodings of the observations (as the form of XT), which might be useful for other downstream applications that requires latent representations of a model."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1236
                },
                {
                    "x": 2105,
                    "y": 1236
                },
                {
                    "x": 2105,
                    "y": 1418
                },
                {
                    "x": 442,
                    "y": 1418
                }
            ],
            "category": "paragraph",
            "html": "<p id='74' style='font-size:16px'>In a concurrent work, (Song et al., 2020) proposed a \"probability flow ODE\" that aims to recover the<br>marginal densities of a stochastic differential equation (SDE) based on scores, from which a similar<br>sampling schedule can be obtained. Here, we state that the our ODE is equivalent to a special case<br>of theirs (which corresponds to a continuous-time analog of DDPM).</p>",
            "id": 74,
            "page": 6,
            "text": "In a concurrent work, (Song , 2020) proposed a \"probability flow ODE\" that aims to recover the marginal densities of a stochastic differential equation (SDE) based on scores, from which a similar sampling schedule can be obtained. Here, we state that the our ODE is equivalent to a special case of theirs (which corresponds to a continuous-time analog of DDPM)."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1436
                },
                {
                    "x": 2105,
                    "y": 1436
                },
                {
                    "x": 2105,
                    "y": 1532
                },
                {
                    "x": 442,
                    "y": 1532
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='75' style='font-size:18px'>Proposition 1. The ODE in Eq. (14) with the optimal model e(t) has an equivalent probability flow<br>ODE corresponding to the \"Variance-Exploding\" SDE in Song et al. (2020).</p>",
            "id": 75,
            "page": 6,
            "text": "Proposition 1. The ODE in Eq. (14) with the optimal model e(t) has an equivalent probability flow ODE corresponding to the \"Variance-Exploding\" SDE in Song  (2020)."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1563
                },
                {
                    "x": 2105,
                    "y": 1563
                },
                {
                    "x": 2105,
                    "y": 1655
                },
                {
                    "x": 442,
                    "y": 1655
                }
            ],
            "category": "paragraph",
            "html": "<p id='76' style='font-size:16px'>We include the proof in Appendix B. While the ODEs are equivalent, the sampling procedures are<br>not, since the Euler method for the probability flow ODE will make the following update:</p>",
            "id": 76,
            "page": 6,
            "text": "We include the proof in Appendix B. While the ODEs are equivalent, the sampling procedures are not, since the Euler method for the probability flow ODE will make the following update:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1780
                },
                {
                    "x": 2106,
                    "y": 1780
                },
                {
                    "x": 2106,
                    "y": 1916
                },
                {
                    "x": 442,
                    "y": 1916
                }
            ],
            "category": "paragraph",
            "html": "<p id='77' style='font-size:16px'>which is equivalent to ours if at and �t-△t are close enough. In fewer sampling steps, however,<br>these choices will make a difference; we take Euler steps with respect to do(t) (which depends less<br>directly on the scaling of \"time\" t) whereas Song et al. (2020) take Euler steps with respect to dt.</p>",
            "id": 77,
            "page": 6,
            "text": "which is equivalent to ours if at and �t-△t are close enough. In fewer sampling steps, however, these choices will make a difference; we take Euler steps with respect to do(t) (which depends less directly on the scaling of \"time\" t) whereas Song  (2020) take Euler steps with respect to dt."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 1981
                },
                {
                    "x": 838,
                    "y": 1981
                },
                {
                    "x": 838,
                    "y": 2030
                },
                {
                    "x": 446,
                    "y": 2030
                }
            ],
            "category": "paragraph",
            "html": "<p id='78' style='font-size:20px'>5 EXPERIMENTS</p>",
            "id": 78,
            "page": 6,
            "text": "5 EXPERIMENTS"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2078
                },
                {
                    "x": 2106,
                    "y": 2078
                },
                {
                    "x": 2106,
                    "y": 2356
                },
                {
                    "x": 442,
                    "y": 2356
                }
            ],
            "category": "paragraph",
            "html": "<p id='79' style='font-size:16px'>In this section, we show that DDIMs outperform DDPMs in terms of image generation when fewer<br>iterations are considered, giving speed ups of 10x to 100x over the original DDPM generation<br>process. Moreover, unlike DDPMs, once the initial latent variables XT are fixed, DDIMs retain high-<br>level image features regardless of the generation trajectory, SO they are able to perform interpolation<br>directly from the latent space. DDIMs can also be used to encode samples that reconstruct them<br>from the latent code, which DDPMs cannot do due to the stochastic sampling process.</p>",
            "id": 79,
            "page": 6,
            "text": "In this section, we show that DDIMs outperform DDPMs in terms of image generation when fewer iterations are considered, giving speed ups of 10x to 100x over the original DDPM generation process. Moreover, unlike DDPMs, once the initial latent variables XT are fixed, DDIMs retain highlevel image features regardless of the generation trajectory, SO they are able to perform interpolation directly from the latent space. DDIMs can also be used to encode samples that reconstruct them from the latent code, which DDPMs cannot do due to the stochastic sampling process."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2379
                },
                {
                    "x": 2105,
                    "y": 2379
                },
                {
                    "x": 2105,
                    "y": 2607
                },
                {
                    "x": 442,
                    "y": 2607
                }
            ],
            "category": "paragraph",
            "html": "<p id='80' style='font-size:16px'>For each dataset, we use the same trained model with T = 1000 and the objective being Ly<br>from Eq. (5) with 2 = 1; as we argued in Section 3, no changes are needed with regards to the<br>training procedure. The only changes that we make is how we produce samples from the model;<br>we achieve this by controlling T (which controls how fast the samples are obtained) and 0 (which<br>interpolates between the deterministic DDIM and the stochastic DDPM).</p>",
            "id": 80,
            "page": 6,
            "text": "For each dataset, we use the same trained model with T = 1000 and the objective being Ly from Eq. (5) with 2 = 1; as we argued in Section 3, no changes are needed with regards to the training procedure. The only changes that we make is how we produce samples from the model; we achieve this by controlling T (which controls how fast the samples are obtained) and 0 (which interpolates between the deterministic DDIM and the stochastic DDPM)."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2634
                },
                {
                    "x": 2103,
                    "y": 2634
                },
                {
                    "x": 2103,
                    "y": 2724
                },
                {
                    "x": 443,
                    "y": 2724
                }
            ],
            "category": "paragraph",
            "html": "<p id='81' style='font-size:14px'>We consider different sub-sequences T of [1, · · · , T] and different variance hyperparameters 0 in-<br>dexed by elements of T. To simplify comparisons, we consider 0 with the form:</p>",
            "id": 81,
            "page": 6,
            "text": "We consider different sub-sequences T of [1, · · · , T] and different variance hyperparameters 0 indexed by elements of T. To simplify comparisons, we consider 0 with the form:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2820
                },
                {
                    "x": 2106,
                    "y": 2820
                },
                {
                    "x": 2106,
                    "y": 3053
                },
                {
                    "x": 442,
                    "y": 3053
                }
            ],
            "category": "paragraph",
            "html": "<p id='82' style='font-size:14px'>where 7 E R≥0 is a hyperparameter that we can directly control. This includes an original DDPM<br>generative process when 7 = 1 and DDIM when 7 = 0. We also consider DDPM where the random<br>noise has a larger standard deviation than �(1), which we denote as 8: �Ti = V1 - aTi / aTi-1 ·<br>This is used by the implementation in Ho et al. (2020) only to obtain the CIFAR10 samples, but<br>not samples of the other datasets. We include more details in Appendix D.</p>",
            "id": 82,
            "page": 6,
            "text": "where 7 E R≥0 is a hyperparameter that we can directly control. This includes an original DDPM generative process when 7 = 1 and DDIM when 7 = 0. We also consider DDPM where the random noise has a larger standard deviation than �(1), which we denote as 8: �Ti = V1 - aTi / aTi-1 · This is used by the implementation in Ho  (2020) only to obtain the CIFAR10 samples, but not samples of the other datasets. We include more details in Appendix D."
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3136
                },
                {
                    "x": 1289,
                    "y": 3136
                },
                {
                    "x": 1289,
                    "y": 3170
                },
                {
                    "x": 1260,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='83' style='font-size:14px'>6</footer>",
            "id": 83,
            "page": 6,
            "text": "6"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 157
                },
                {
                    "x": 445,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='84' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 84,
            "page": 7,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 336
                },
                {
                    "x": 2108,
                    "y": 336
                },
                {
                    "x": 2108,
                    "y": 476
                },
                {
                    "x": 442,
                    "y": 476
                }
            ],
            "category": "caption",
            "html": "<caption id='85' style='font-size:16px'>Table 1: CIFAR10 and CelebA image generation measured in FID. 7 = 1.0 and 0 are cases of<br>DDPM (although Ho et al. (2020) only considered T = 1000 steps, and S < T can be seen as<br>simulating DDPMs trained with S steps), and 7 = 0.0 indicates DDIM.</caption>",
            "id": 85,
            "page": 7,
            "text": "Table 1: CIFAR10 and CelebA image generation measured in FID. 7 = 1.0 and 0 are cases of DDPM (although Ho  (2020) only considered T = 1000 steps, and S < T can be seen as simulating DDPMs trained with S steps), and 7 = 0.0 indicates DDIM."
        },
        {
            "bounding_box": [
                {
                    "x": 453,
                    "y": 514
                },
                {
                    "x": 2094,
                    "y": 514
                },
                {
                    "x": 2094,
                    "y": 880
                },
                {
                    "x": 453,
                    "y": 880
                }
            ],
            "category": "table",
            "html": "<table id='86' style='font-size:14px'><tr><td colspan=\"2\"></td><td colspan=\"5\">CIFAR10 (32 x 32)</td><td colspan=\"5\">CelebA (64 x 64)</td></tr><tr><td colspan=\"2\">S</td><td>10</td><td>20</td><td>50</td><td>100</td><td>1000</td><td>10</td><td>20</td><td>50</td><td>100</td><td>1000</td></tr><tr><td colspan=\"2\">0.0</td><td>13.36</td><td>6.84</td><td>4.67</td><td>4.16</td><td>4.04</td><td>17.33</td><td>13.73</td><td>9.17</td><td>6.53</td><td>3.51</td></tr><tr><td rowspan=\"2\">7</td><td>0.2</td><td>14.04</td><td>7.11</td><td>4.77</td><td>4.25</td><td>4.09</td><td>17.66</td><td>14.11</td><td>9.51</td><td>6.79</td><td>3.64</td></tr><tr><td>0.5</td><td>16.66</td><td>8.35</td><td>5.25</td><td>4.46</td><td>4.29</td><td>19.86</td><td>16.06</td><td>11.01</td><td>8.09</td><td>4.28</td></tr><tr><td>1.0</td><td></td><td>41.07</td><td>18.36</td><td>8.01</td><td>5.78</td><td>4.73</td><td>33.12</td><td>26.03</td><td>18.48</td><td>13.93</td><td>5.98</td></tr><tr><td colspan=\"2\">0</td><td>367.43</td><td>133.37</td><td>32.72</td><td>9.99</td><td>3.17</td><td>299.71</td><td>183.83</td><td>71.71</td><td>45.20</td><td>3.26</td></tr></table>",
            "id": 86,
            "page": 7,
            "text": "CIFAR10 (32 x 32) CelebA (64 x 64)  S 10 20 50 100 1000 10 20 50 100 1000  0.0 13.36 6.84 4.67 4.16 4.04 17.33 13.73 9.17 6.53 3.51  7 0.2 14.04 7.11 4.77 4.25 4.09 17.66 14.11 9.51 6.79 3.64  0.5 16.66 8.35 5.25 4.46 4.29 19.86 16.06 11.01 8.09 4.28  1.0  41.07 18.36 8.01 5.78 4.73 33.12 26.03 18.48 13.93 5.98  0 367.43 133.37 32.72 9.99 3.17 299.71 183.83 71.71 45.20"
        },
        {
            "bounding_box": [
                {
                    "x": 472,
                    "y": 927
                },
                {
                    "x": 2085,
                    "y": 927
                },
                {
                    "x": 2085,
                    "y": 1264
                },
                {
                    "x": 472,
                    "y": 1264
                }
            ],
            "category": "figure",
            "html": "<figure><img id='87' style='font-size:14px' alt=\"dim(T) = 10 dim(T) = 100 dim(T) = 10 dim(T) = 100\n0.0 0.0 0.0 0.0\n47\n0.2 0.2 、 0.2 0.2\n<0.5 48 �0.5 ≤0.5 ≤0.5\n1.0 1.0 1.0 1.0\n0 0 0 0\" data-coord=\"top-left:(472,927); bottom-right:(2085,1264)\" /></figure>",
            "id": 87,
            "page": 7,
            "text": "dim(T) = 10 dim(T) = 100 dim(T) = 10 dim(T) = 100 0.0 0.0 0.0 0.0 47 0.2 0.2 、 0.2 0.2 <0.5 48 �0.5 ≤0.5 ≤0.5 1.0 1.0 1.0 1.0 0 0 0 0"
        },
        {
            "bounding_box": [
                {
                    "x": 608,
                    "y": 1304
                },
                {
                    "x": 1938,
                    "y": 1304
                },
                {
                    "x": 1938,
                    "y": 1352
                },
                {
                    "x": 608,
                    "y": 1352
                }
            ],
            "category": "caption",
            "html": "<caption id='88' style='font-size:22px'>Figure 3: CIFAR10 and CelebA samples with dim (T) = 10 and dim (T) = 100.</caption>",
            "id": 88,
            "page": 7,
            "text": "Figure 3: CIFAR10 and CelebA samples with dim (T) = 10 and dim (T) = 100."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1443
                },
                {
                    "x": 1177,
                    "y": 1443
                },
                {
                    "x": 1177,
                    "y": 1490
                },
                {
                    "x": 444,
                    "y": 1490
                }
            ],
            "category": "paragraph",
            "html": "<p id='89' style='font-size:14px'>5.1 S AMPLE QUALITY AND EFFICIENCY</p>",
            "id": 89,
            "page": 7,
            "text": "5.1 S AMPLE QUALITY AND EFFICIENCY"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1530
                },
                {
                    "x": 2107,
                    "y": 1530
                },
                {
                    "x": 2107,
                    "y": 1991
                },
                {
                    "x": 441,
                    "y": 1991
                }
            ],
            "category": "paragraph",
            "html": "<p id='90' style='font-size:20px'>In Table 1, we report the quality of the generated samples with models trained on CIFAR10 and<br>CelebA, as measured by Frechet Inception Distance (FID (Heusel et al., 2017)), where we vary<br>the number of timesteps used to generate a sample (dim(T)) and the stochasticity of the process<br>(7). As expected, the sample quality becomes higher as we increase dim(T), presenting a trade-<br>off between sample quality and computational costs. We observe that DDIM (7 = 0) achieves the<br>best sample quality when dim (T) is small, and DDPM (7 = 1 and 6) typically has worse sample<br>quality compared to its less stochastic counterparts with the same dim (T), except for the case for<br>dim(T) = 1000 and 0 reported by Ho et al. (2020) where DDIM is marginally worse. However, the<br>sample quality of 0 becomes much worse for smaller dim (T), which suggests that it is ill-suited for<br>shorter trajectories. DDIM, on the other hand, achieves high sample quality much more consistently.</p>",
            "id": 90,
            "page": 7,
            "text": "In Table 1, we report the quality of the generated samples with models trained on CIFAR10 and CelebA, as measured by Frechet Inception Distance (FID (Heusel , 2017)), where we vary the number of timesteps used to generate a sample (dim(T)) and the stochasticity of the process (7). As expected, the sample quality becomes higher as we increase dim(T), presenting a tradeoff between sample quality and computational costs. We observe that DDIM (7 = 0) achieves the best sample quality when dim (T) is small, and DDPM (7 = 1 and 6) typically has worse sample quality compared to its less stochastic counterparts with the same dim (T), except for the case for dim(T) = 1000 and 0 reported by Ho  (2020) where DDIM is marginally worse. However, the sample quality of 0 becomes much worse for smaller dim (T), which suggests that it is ill-suited for shorter trajectories. DDIM, on the other hand, achieves high sample quality much more consistently."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2011
                },
                {
                    "x": 2108,
                    "y": 2011
                },
                {
                    "x": 2108,
                    "y": 2242
                },
                {
                    "x": 441,
                    "y": 2242
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='91' style='font-size:20px'>In Figure 3, we show CIFAR10 and CelebA samples with the same number of sampling steps and<br>varying 0. For the DDPM, the sample quality deteriorates rapidly when the sampling trajectory has<br>10 steps. For the case of 0, the generated images seem to have more noisy perturbations under short<br>trajectories; this explains why the FID scores are much worse than other methods, as FID is very<br>sensitive to such perturbations (as discussed in Jolicoeur-Martineau et al. (2020)).</p>",
            "id": 91,
            "page": 7,
            "text": "In Figure 3, we show CIFAR10 and CelebA samples with the same number of sampling steps and varying 0. For the DDPM, the sample quality deteriorates rapidly when the sampling trajectory has 10 steps. For the case of 0, the generated images seem to have more noisy perturbations under short trajectories; this explains why the FID scores are much worse than other methods, as FID is very sensitive to such perturbations (as discussed in Jolicoeur-Martineau  (2020))."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2265
                },
                {
                    "x": 2108,
                    "y": 2265
                },
                {
                    "x": 2108,
                    "y": 2587
                },
                {
                    "x": 441,
                    "y": 2587
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='92' style='font-size:20px'>In Figure 4, we show that the amount of time needed to produce a sample scales linearly with the<br>length of the sample trajectory. This suggests that DDIM is useful for producing samples more<br>efficiently, as samples can be generated in much fewer steps. Notably, DDIM is able to produce<br>samples with quality comparable to 1000 step models within 20 to 100 steps, which is a 10x to<br>50x speed up compared to the original DDPM. Even though DDPM could also achieve reasonable<br>sample quality with 100x steps, DDIM requires much fewer steps to achieve this; on CelebA, the<br>FID score of the 100 step DDPM is similar to that of the 20 step DDIM.</p>",
            "id": 92,
            "page": 7,
            "text": "In Figure 4, we show that the amount of time needed to produce a sample scales linearly with the length of the sample trajectory. This suggests that DDIM is useful for producing samples more efficiently, as samples can be generated in much fewer steps. Notably, DDIM is able to produce samples with quality comparable to 1000 step models within 20 to 100 steps, which is a 10x to 50x speed up compared to the original DDPM. Even though DDPM could also achieve reasonable sample quality with 100x steps, DDIM requires much fewer steps to achieve this; on CelebA, the FID score of the 100 step DDPM is similar to that of the 20 step DDIM."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2644
                },
                {
                    "x": 1162,
                    "y": 2644
                },
                {
                    "x": 1162,
                    "y": 2690
                },
                {
                    "x": 445,
                    "y": 2690
                }
            ],
            "category": "paragraph",
            "html": "<p id='93' style='font-size:14px'>5.2 S AMPLE CONSISTENCY IN DDIMs</p>",
            "id": 93,
            "page": 7,
            "text": "5.2 S AMPLE CONSISTENCY IN DDIMs"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2729
                },
                {
                    "x": 2107,
                    "y": 2729
                },
                {
                    "x": 2107,
                    "y": 3055
                },
                {
                    "x": 442,
                    "y": 3055
                }
            ],
            "category": "paragraph",
            "html": "<p id='94' style='font-size:20px'>For DDIM, the generative process is deterministic, and X0 would depend only on the initial state XT.<br>In Figure 5, we observe the generated images under different generative trajectories (i.e. different T)<br>while starting with the same initial XT. Interestingly, for the generated images with the same initial<br>XT, most high-level features are similar, regardless of the generative trajectory. In many cases,<br>samples generated with only 20 steps are already very similar to ones generated with 1000 steps in<br>terms of high-level features, with only minor differences in details. Therefore, it would appear that<br>XT alone would be an informative latent encoding of the image; and minor details that affects sample</p>",
            "id": 94,
            "page": 7,
            "text": "For DDIM, the generative process is deterministic, and X0 would depend only on the initial state XT. In Figure 5, we observe the generated images under different generative trajectories (i.e. different T) while starting with the same initial XT. Interestingly, for the generated images with the same initial XT, most high-level features are similar, regardless of the generative trajectory. In many cases, samples generated with only 20 steps are already very similar to ones generated with 1000 steps in terms of high-level features, with only minor differences in details. Therefore, it would appear that XT alone would be an informative latent encoding of the image; and minor details that affects sample"
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3171
                },
                {
                    "x": 1260,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='95' style='font-size:18px'>7</footer>",
            "id": 95,
            "page": 7,
            "text": "7"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 157
                },
                {
                    "x": 445,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='96' style='font-size:18px'>Published as a conference paper at ICLR 2021</header>",
            "id": 96,
            "page": 8,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 601,
                    "y": 341
                },
                {
                    "x": 1949,
                    "y": 341
                },
                {
                    "x": 1949,
                    "y": 652
                },
                {
                    "x": 601,
                    "y": 652
                }
            ],
            "category": "figure",
            "html": "<figure><img id='97' style='font-size:14px' alt=\"CIFAR10 Bedroom\n20 1000\n300\n5\nHours\nHours\n2 100\n0.5 30\n0.2 10\n10 30 100 300 1000 10 30 100 300 1000\n# steps # steps\" data-coord=\"top-left:(601,341); bottom-right:(1949,652)\" /></figure>",
            "id": 97,
            "page": 8,
            "text": "CIFAR10 Bedroom 20 1000 300 5 Hours Hours 2 100 0.5 30 0.2 10 10 30 100 300 1000 10 30 100 300 1000 # steps # steps"
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 695
                },
                {
                    "x": 2104,
                    "y": 695
                },
                {
                    "x": 2104,
                    "y": 746
                },
                {
                    "x": 446,
                    "y": 746
                }
            ],
            "category": "caption",
            "html": "<caption id='98' style='font-size:20px'>Figure 4: Hours to sample 50k images with one Nvidia 2080 Ti GPU and samples at different steps.</caption>",
            "id": 98,
            "page": 8,
            "text": "Figure 4: Hours to sample 50k images with one Nvidia 2080 Ti GPU and samples at different steps."
        },
        {
            "bounding_box": [
                {
                    "x": 453,
                    "y": 794
                },
                {
                    "x": 2097,
                    "y": 794
                },
                {
                    "x": 2097,
                    "y": 1723
                },
                {
                    "x": 453,
                    "y": 1723
                }
            ],
            "category": "figure",
            "html": "<figure><img id='99' style='font-size:14px' alt=\"10\ntimesteps\n20\n50\nsample\n100\n1000\ntimesteps\n10\n화폐를\nsample 100\ntimesteps\n10\nsample 100\" data-coord=\"top-left:(453,794); bottom-right:(2097,1723)\" /></figure>",
            "id": 99,
            "page": 8,
            "text": "10 timesteps 20 50 sample 100 1000 timesteps 10 화폐를 sample 100 timesteps 10 sample 100"
        },
        {
            "bounding_box": [
                {
                    "x": 539,
                    "y": 1764
                },
                {
                    "x": 2010,
                    "y": 1764
                },
                {
                    "x": 2010,
                    "y": 1815
                },
                {
                    "x": 539,
                    "y": 1815
                }
            ],
            "category": "caption",
            "html": "<caption id='100' style='font-size:20px'>Figure 5: Samples from DDIM with the same random XT and different number of steps.</caption>",
            "id": 100,
            "page": 8,
            "text": "Figure 5: Samples from DDIM with the same random XT and different number of steps."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1902
                },
                {
                    "x": 2107,
                    "y": 1902
                },
                {
                    "x": 2107,
                    "y": 1999
                },
                {
                    "x": 441,
                    "y": 1999
                }
            ],
            "category": "paragraph",
            "html": "<p id='101' style='font-size:20px'>quality are encoded in the parameters, as longer sample trajectories gives better quality samples but<br>do not significantly affect the high-level features. We show more samples in Appendix D.4.</p>",
            "id": 101,
            "page": 8,
            "text": "quality are encoded in the parameters, as longer sample trajectories gives better quality samples but do not significantly affect the high-level features. We show more samples in Appendix D.4."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2054
                },
                {
                    "x": 1631,
                    "y": 2054
                },
                {
                    "x": 1631,
                    "y": 2102
                },
                {
                    "x": 445,
                    "y": 2102
                }
            ],
            "category": "caption",
            "html": "<caption id='102' style='font-size:16px'>5.3 INTERPOLATION IN DETERMINISTIC GENERATIVE PROCESSES</caption>",
            "id": 102,
            "page": 8,
            "text": "5.3 INTERPOLATION IN DETERMINISTIC GENERATIVE PROCESSES"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2144
                },
                {
                    "x": 2106,
                    "y": 2144
                },
                {
                    "x": 2106,
                    "y": 2819
                },
                {
                    "x": 442,
                    "y": 2819
                }
            ],
            "category": "figure",
            "html": "<figure><img id='103' style='font-size:16px' alt=\"erstock erstoc\nlutterstock.com 122336618\" data-coord=\"top-left:(442,2144); bottom-right:(2106,2819)\" /></figure>",
            "id": 103,
            "page": 8,
            "text": "erstock erstoc lutterstock.com 122336618"
        },
        {
            "bounding_box": [
                {
                    "x": 714,
                    "y": 2849
                },
                {
                    "x": 1832,
                    "y": 2849
                },
                {
                    "x": 1832,
                    "y": 2898
                },
                {
                    "x": 714,
                    "y": 2898
                }
            ],
            "category": "caption",
            "html": "<caption id='104' style='font-size:22px'>Figure 6: Interpolation of samples from DDIM with dim (T) = 50.</caption>",
            "id": 104,
            "page": 8,
            "text": "Figure 6: Interpolation of samples from DDIM with dim (T) = 50."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2960
                },
                {
                    "x": 2107,
                    "y": 2960
                },
                {
                    "x": 2107,
                    "y": 3054
                },
                {
                    "x": 442,
                    "y": 3054
                }
            ],
            "category": "paragraph",
            "html": "<p id='105' style='font-size:20px'>Since the high level features of the DDIM sample is encoded by XT, we are interested to see whether<br>it would exhibit the semantic interpolation effect similar to that observed in other implicit proba-</p>",
            "id": 105,
            "page": 8,
            "text": "Since the high level features of the DDIM sample is encoded by XT, we are interested to see whether it would exhibit the semantic interpolation effect similar to that observed in other implicit proba-"
        },
        {
            "bounding_box": [
                {
                    "x": 1254,
                    "y": 3129
                },
                {
                    "x": 1293,
                    "y": 3129
                },
                {
                    "x": 1293,
                    "y": 3175
                },
                {
                    "x": 1254,
                    "y": 3175
                }
            ],
            "category": "footer",
            "html": "<footer id='106' style='font-size:18px'>8</footer>",
            "id": 106,
            "page": 8,
            "text": "8"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='107' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 107,
            "page": 9,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 588,
                    "y": 338
                },
                {
                    "x": 1956,
                    "y": 338
                },
                {
                    "x": 1956,
                    "y": 384
                },
                {
                    "x": 588,
                    "y": 384
                }
            ],
            "category": "caption",
            "html": "<caption id='108' style='font-size:14px'>Table 2: Reconstruction error with DDIM on CIFAR-10 test set, rounded to 10-4.</caption>",
            "id": 108,
            "page": 9,
            "text": "Table 2: Reconstruction error with DDIM on CIFAR-10 test set, rounded to 10-4."
        },
        {
            "bounding_box": [
                {
                    "x": 631,
                    "y": 424
                },
                {
                    "x": 1909,
                    "y": 424
                },
                {
                    "x": 1909,
                    "y": 571
                },
                {
                    "x": 631,
                    "y": 571
                }
            ],
            "category": "table",
            "html": "<table id='109' style='font-size:18px'><tr><td>S</td><td>10</td><td>20</td><td>50</td><td>100</td><td>200</td><td>500</td><td>1000</td></tr><tr><td>Error</td><td>0.014</td><td>0.0065</td><td>0.0023</td><td>0.0009</td><td>0.0004</td><td>0.0001</td><td>0.0001</td></tr></table>",
            "id": 109,
            "page": 9,
            "text": "S 10 20 50 100 200 500 1000  Error 0.014 0.0065 0.0023 0.0009 0.0004 0.0001"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 652
                },
                {
                    "x": 2108,
                    "y": 652
                },
                {
                    "x": 2108,
                    "y": 930
                },
                {
                    "x": 442,
                    "y": 930
                }
            ],
            "category": "paragraph",
            "html": "<p id='110' style='font-size:18px'>bilistic models, such as GANs (Goodfellow et al., 2014). This is different from the interpolation<br>procedure in Ho et al. (2020), since in DDPM the same XT would lead to highly diverse X0 due to<br>the stochastic generative process 6 In Figure 6, we show that simple interpolations in XT can lead to<br>·<br>semantically meaningful interpolations between two samples. We include more details and samples<br>in Appendix D.5. This allows DDIM to control the generated images on a high level directly through<br>the latent variables, which DDPMs cannot.</p>",
            "id": 110,
            "page": 9,
            "text": "bilistic models, such as GANs (Goodfellow , 2014). This is different from the interpolation procedure in Ho  (2020), since in DDPM the same XT would lead to highly diverse X0 due to the stochastic generative process 6 In Figure 6, we show that simple interpolations in XT can lead to · semantically meaningful interpolations between two samples. We include more details and samples in Appendix D.5. This allows DDIM to control the generated images on a high level directly through the latent variables, which DDPMs cannot."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 986
                },
                {
                    "x": 1276,
                    "y": 986
                },
                {
                    "x": 1276,
                    "y": 1032
                },
                {
                    "x": 445,
                    "y": 1032
                }
            ],
            "category": "paragraph",
            "html": "<p id='111' style='font-size:14px'>5.4 RECONSTRUCTION FROM LATENT SPACE</p>",
            "id": 111,
            "page": 9,
            "text": "5.4 RECONSTRUCTION FROM LATENT SPACE"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1072
                },
                {
                    "x": 2107,
                    "y": 1072
                },
                {
                    "x": 2107,
                    "y": 1393
                },
                {
                    "x": 442,
                    "y": 1393
                }
            ],
            "category": "paragraph",
            "html": "<p id='112' style='font-size:18px'>As DDIM is the Euler integration for a particular ODE, it would be interesting to see whether it<br>can encode from x0 to XT (reverse of Eq. (14)) and reconstruct x0 from the resulting XT (forward<br>of Eq. (14))7. We consider encoding and decoding on the CIFAR-10 test set with the CIFAR-10<br>model with S steps for both encoding and decoding; we report the per-dimension mean squared<br>error (scaled to [0, 1]) in Table 2. Our results show that DDIMs have lower reconstruction error for<br>larger S values and have properties similar to Neural ODEs and normalizing flows. The same cannot<br>be said for DDPMs due to their stochastic nature.</p>",
            "id": 112,
            "page": 9,
            "text": "As DDIM is the Euler integration for a particular ODE, it would be interesting to see whether it can encode from x0 to XT (reverse of Eq. (14)) and reconstruct x0 from the resulting XT (forward of Eq. (14))7. We consider encoding and decoding on the CIFAR-10 test set with the CIFAR-10 model with S steps for both encoding and decoding; we report the per-dimension mean squared error (scaled to ) in Table 2. Our results show that DDIMs have lower reconstruction error for larger S values and have properties similar to Neural ODEs and normalizing flows. The same cannot be said for DDPMs due to their stochastic nature."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1461
                },
                {
                    "x": 885,
                    "y": 1461
                },
                {
                    "x": 885,
                    "y": 1513
                },
                {
                    "x": 445,
                    "y": 1513
                }
            ],
            "category": "paragraph",
            "html": "<p id='113' style='font-size:20px'>6 RELATED W ORK</p>",
            "id": 113,
            "page": 9,
            "text": "6 RELATED W ORK"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1563
                },
                {
                    "x": 2107,
                    "y": 1563
                },
                {
                    "x": 2107,
                    "y": 1932
                },
                {
                    "x": 443,
                    "y": 1932
                }
            ],
            "category": "paragraph",
            "html": "<p id='114' style='font-size:18px'>Our work is based on a large family of existing methods on learning generative models as transi-<br>tion operators of Markov chains (Sohl-Dickstein et al., 2015; Bengio et al., 2014; Salimans et al.,<br>2014; Song et al., 2017; Goyal et al., 2017; Levy et al., 2017). Among them, denoising diffusion<br>probabilistic models (DDPMs, Ho et al. (2020)) and noise conditional score networks (NCSN, Song<br>& Ermon (2019; 2020)) have recently achieved high sample quality comparable to GANs (Brock<br>et al., 2018; Karras et al., 2018). DDPMs optimize a variational lower bound to the log-likelihood,<br>whereas NCSNs optimize the score matching objective (Hyv�rinen, 2005) over a nonparametric<br>Parzen density estimator of the data (Vincent, 2011; Raphan & Simoncelli, 2011).</p>",
            "id": 114,
            "page": 9,
            "text": "Our work is based on a large family of existing methods on learning generative models as transition operators of Markov chains (Sohl-Dickstein , 2015; Bengio , 2014; Salimans , 2014; Song , 2017; Goyal , 2017; Levy , 2017). Among them, denoising diffusion probabilistic models (DDPMs, Ho  (2020)) and noise conditional score networks (NCSN, Song & Ermon (2019; 2020)) have recently achieved high sample quality comparable to GANs (Brock , 2018; Karras , 2018). DDPMs optimize a variational lower bound to the log-likelihood, whereas NCSNs optimize the score matching objective (Hyv�rinen, 2005) over a nonparametric Parzen density estimator of the data (Vincent, 2011; Raphan & Simoncelli, 2011)."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1954
                },
                {
                    "x": 2107,
                    "y": 1954
                },
                {
                    "x": 2107,
                    "y": 2230
                },
                {
                    "x": 441,
                    "y": 2230
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='115' style='font-size:18px'>Despite their different motivations, DDPMs and NCSNs are closely related. Both use a denoising<br>autoencoder objective for many noise levels, and both use a procedure similar to Langevin dynamics<br>to produce samples (Neal et al., 2011). Since Langevin dynamics is a discretization of a gradient<br>flow (Jordan etal., 1998), both DDPM and NCSN require many steps to achieve good sample quality.<br>This aligns with the observation that DDPM and existing NCSN methods have trouble generating<br>high-quality samples in a few iterations.</p>",
            "id": 115,
            "page": 9,
            "text": "Despite their different motivations, DDPMs and NCSNs are closely related. Both use a denoising autoencoder objective for many noise levels, and both use a procedure similar to Langevin dynamics to produce samples (Neal , 2011). Since Langevin dynamics is a discretization of a gradient flow (Jordan etal., 1998), both DDPM and NCSN require many steps to achieve good sample quality. This aligns with the observation that DDPM and existing NCSN methods have trouble generating high-quality samples in a few iterations."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2253
                },
                {
                    "x": 2106,
                    "y": 2253
                },
                {
                    "x": 2106,
                    "y": 2669
                },
                {
                    "x": 442,
                    "y": 2669
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='116' style='font-size:18px'>DDIM, on the other hand, is an implicit generative model (Mohamed & Lakshminarayanan, 2016)<br>where samples are uniquely determined from the latent variables. Hence, DDIM has certain prop-<br>erties that resemble GANs (Goodfellow et al., 2014) and invertible flows (Dinh et al., 2016), such<br>as the ability to produce semantically meaningful interpolations. We derive DDIM from a purely<br>variational perspective, where the restrictions of Langevin dynamics are not relevant; this could par-<br>tially explain why we are able to observe superior sample quality compared to DDPM under fewer<br>iterations. The sampling procedure of DDIM is also reminiscent of neural networks with continuous<br>depth (Chen et al., 2018; Grathwohl et al., 2018), since the samples it produces from the same latent<br>variable have similar high-level visual features, regardless of the specific sample trajectory.</p>",
            "id": 116,
            "page": 9,
            "text": "DDIM, on the other hand, is an implicit generative model (Mohamed & Lakshminarayanan, 2016) where samples are uniquely determined from the latent variables. Hence, DDIM has certain properties that resemble GANs (Goodfellow , 2014) and invertible flows (Dinh , 2016), such as the ability to produce semantically meaningful interpolations. We derive DDIM from a purely variational perspective, where the restrictions of Langevin dynamics are not relevant; this could partially explain why we are able to observe superior sample quality compared to DDPM under fewer iterations. The sampling procedure of DDIM is also reminiscent of neural networks with continuous depth (Chen , 2018; Grathwohl , 2018), since the samples it produces from the same latent variable have similar high-level visual features, regardless of the specific sample trajectory."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 2734
                },
                {
                    "x": 796,
                    "y": 2734
                },
                {
                    "x": 796,
                    "y": 2784
                },
                {
                    "x": 446,
                    "y": 2784
                }
            ],
            "category": "paragraph",
            "html": "<p id='117' style='font-size:22px'>7 DISCUSSION</p>",
            "id": 117,
            "page": 9,
            "text": "7 DISCUSSION"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2835
                },
                {
                    "x": 2106,
                    "y": 2835
                },
                {
                    "x": 2106,
                    "y": 2932
                },
                {
                    "x": 443,
                    "y": 2932
                }
            ],
            "category": "paragraph",
            "html": "<p id='118' style='font-size:16px'>We have presented DDIMs - an implicit generative model trained with denoising auto-encoding /<br>score matching objectives - from a purely variational perspective. DDIM is able to generate high-</p>",
            "id": 118,
            "page": 9,
            "text": "We have presented DDIMs - an implicit generative model trained with denoising auto-encoding / score matching objectives - from a purely variational perspective. DDIM is able to generate high-"
        },
        {
            "bounding_box": [
                {
                    "x": 495,
                    "y": 2962
                },
                {
                    "x": 2097,
                    "y": 2962
                },
                {
                    "x": 2097,
                    "y": 3052
                },
                {
                    "x": 495,
                    "y": 3052
                }
            ],
            "category": "paragraph",
            "html": "<p id='119' style='font-size:14px'>6 Although it might be possible if one interpolates all T noises, like what is done in Song & Ermon (2020).<br>7Since XT and x0 have the same dimensions, their compression qualities are not our immediate concern.</p>",
            "id": 119,
            "page": 9,
            "text": "6 Although it might be possible if one interpolates all T noises, like what is done in Song & Ermon (2020). 7Since XT and x0 have the same dimensions, their compression qualities are not our immediate concern."
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 3133
                },
                {
                    "x": 1289,
                    "y": 3133
                },
                {
                    "x": 1289,
                    "y": 3170
                },
                {
                    "x": 1259,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='120' style='font-size:18px'>9</footer>",
            "id": 120,
            "page": 9,
            "text": "9"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 111
                },
                {
                    "x": 1219,
                    "y": 111
                },
                {
                    "x": 1219,
                    "y": 156
                },
                {
                    "x": 444,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='121' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 121,
            "page": 10,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 347
                },
                {
                    "x": 2107,
                    "y": 347
                },
                {
                    "x": 2107,
                    "y": 623
                },
                {
                    "x": 442,
                    "y": 623
                }
            ],
            "category": "paragraph",
            "html": "<p id='122' style='font-size:14px'>quality samples much more efficiently than existing DDPMs and NCSNs, with the ability to perform<br>meaningful interpolations from the latent space. The non-Markovian forward process presented here<br>seems to suggest continuous forward processes other than Gaussian (which cannot be done in the<br>original diffusion framework, since Gaussian is the only stable distribution with finite variance). We<br>also demonstrated a discrete case with a multinomial forward process in Appendix A, and it would<br>be interesting to investigate similar alternatives for other combinatorial structures.</p>",
            "id": 122,
            "page": 10,
            "text": "quality samples much more efficiently than existing DDPMs and NCSNs, with the ability to perform meaningful interpolations from the latent space. The non-Markovian forward process presented here seems to suggest continuous forward processes other than Gaussian (which cannot be done in the original diffusion framework, since Gaussian is the only stable distribution with finite variance). We also demonstrated a discrete case with a multinomial forward process in Appendix A, and it would be interesting to investigate similar alternatives for other combinatorial structures."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 646
                },
                {
                    "x": 2108,
                    "y": 646
                },
                {
                    "x": 2108,
                    "y": 876
                },
                {
                    "x": 442,
                    "y": 876
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='123' style='font-size:16px'>Moreover, since the sampling procedure of DDIMs is similar to that of an neural ODE, it would<br>be interesting to see if methods that decrease the discretization error in ODEs, including multi-<br>step methods such as Adams-Bashforth (Butcher & Goodwin, 2008), could be helpful for further<br>improving sample quality in fewer steps (Queiruga et al., 2020). It is also relevant to investigate<br>whether DDIMs exhibit other properties of existing implicit models (Bau et al., 2019).</p>",
            "id": 123,
            "page": 10,
            "text": "Moreover, since the sampling procedure of DDIMs is similar to that of an neural ODE, it would be interesting to see if methods that decrease the discretization error in ODEs, including multistep methods such as Adams-Bashforth (Butcher & Goodwin, 2008), could be helpful for further improving sample quality in fewer steps (Queiruga , 2020). It is also relevant to investigate whether DDIMs exhibit other properties of existing implicit models (Bau , 2019)."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 944
                },
                {
                    "x": 942,
                    "y": 944
                },
                {
                    "x": 942,
                    "y": 995
                },
                {
                    "x": 446,
                    "y": 995
                }
            ],
            "category": "paragraph",
            "html": "<p id='124' style='font-size:20px'>ACKNOWLEDGEMENTS</p>",
            "id": 124,
            "page": 10,
            "text": "ACKNOWLEDGEMENTS"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1046
                },
                {
                    "x": 2107,
                    "y": 1046
                },
                {
                    "x": 2107,
                    "y": 1230
                },
                {
                    "x": 443,
                    "y": 1230
                }
            ],
            "category": "paragraph",
            "html": "<p id='125' style='font-size:16px'>The authors would like to thank Yang Song and Shengjia Zhao for helpful discussions over the<br>ideas, Kuno Kim for reviewing an earlier draft of the paper, and Sharvil Nanavati and Sophie Liu<br>for identifying typos. This research was supported by NSF (#1651565, #1522054, #1733686), ONR<br>(N00014-19-1-2145), AFOSR (FA9550-19-1-0024), and Amazon AWS.</p>",
            "id": 125,
            "page": 10,
            "text": "The authors would like to thank Yang Song and Shengjia Zhao for helpful discussions over the ideas, Kuno Kim for reviewing an earlier draft of the paper, and Sharvil Nanavati and Sophie Liu for identifying typos. This research was supported by NSF (#1651565, #1522054, #1733686), ONR (N00014-19-1-2145), AFOSR (FA9550-19-1-0024), and Amazon AWS."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1298
                },
                {
                    "x": 735,
                    "y": 1298
                },
                {
                    "x": 735,
                    "y": 1347
                },
                {
                    "x": 445,
                    "y": 1347
                }
            ],
            "category": "paragraph",
            "html": "<p id='126' style='font-size:22px'>REFERENCES</p>",
            "id": 126,
            "page": 10,
            "text": "REFERENCES"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1376
                },
                {
                    "x": 2105,
                    "y": 1376
                },
                {
                    "x": 2105,
                    "y": 1467
                },
                {
                    "x": 443,
                    "y": 1467
                }
            ],
            "category": "paragraph",
            "html": "<p id='127' style='font-size:16px'>Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein GAN. arXiv preprint<br>arXiv:1701.07875, January 2017.</p>",
            "id": 127,
            "page": 10,
            "text": "Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein GAN. arXiv preprint arXiv:1701.07875, January 2017."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1499
                },
                {
                    "x": 2107,
                    "y": 1499
                },
                {
                    "x": 2107,
                    "y": 1637
                },
                {
                    "x": 443,
                    "y": 1637
                }
            ],
            "category": "paragraph",
            "html": "<p id='128' style='font-size:16px'>David Bau, Jun-Yan Zhu, Jonas Wulff, William Peebles, Hendrik Strobelt, Bolei Zhou, and An-<br>tonio Torralba. Seeing what a gan cannot generate. In Proceedings of the IEEE International<br>Conference on Computer Vision, pp. 4502-4511, 2019.</p>",
            "id": 128,
            "page": 10,
            "text": "David Bau, Jun-Yan Zhu, Jonas Wulff, William Peebles, Hendrik Strobelt, Bolei Zhou, and Antonio Torralba. Seeing what a gan cannot generate. In Proceedings of the IEEE International Conference on Computer Vision, pp. 4502-4511, 2019."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1668
                },
                {
                    "x": 2106,
                    "y": 1668
                },
                {
                    "x": 2106,
                    "y": 1805
                },
                {
                    "x": 443,
                    "y": 1805
                }
            ],
            "category": "paragraph",
            "html": "<p id='129' style='font-size:16px'>Yoshua Bengio, Eric Laufer, Guillaume Alain, and Jason Yosinski. Deep generative stochastic<br>networks trainable by backprop. In International Conference on Machine Learning, pp. 226-234,<br>January 2014.</p>",
            "id": 129,
            "page": 10,
            "text": "Yoshua Bengio, Eric Laufer, Guillaume Alain, and Jason Yosinski. Deep generative stochastic networks trainable by backprop. In International Conference on Machine Learning, pp. 226-234, January 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1838
                },
                {
                    "x": 1818,
                    "y": 1838
                },
                {
                    "x": 1818,
                    "y": 1885
                },
                {
                    "x": 443,
                    "y": 1885
                }
            ],
            "category": "paragraph",
            "html": "<p id='130' style='font-size:18px'>Christopher M Bishop. Pattern recognition and machine learning. springer, 2006.</p>",
            "id": 130,
            "page": 10,
            "text": "Christopher M Bishop. Pattern recognition and machine learning. springer, 2006."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1915
                },
                {
                    "x": 2104,
                    "y": 1915
                },
                {
                    "x": 2104,
                    "y": 2007
                },
                {
                    "x": 444,
                    "y": 2007
                }
            ],
            "category": "paragraph",
            "html": "<p id='131' style='font-size:20px'>Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity<br>natural image synthesis. arXiv preprint arXiv:1809.11096, September 2018.</p>",
            "id": 131,
            "page": 10,
            "text": "Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity natural image synthesis. arXiv preprint arXiv:1809.11096, September 2018."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2038
                },
                {
                    "x": 2104,
                    "y": 2038
                },
                {
                    "x": 2104,
                    "y": 2130
                },
                {
                    "x": 443,
                    "y": 2130
                }
            ],
            "category": "paragraph",
            "html": "<p id='132' style='font-size:16px'>John Charles Butcher and Nicolette Goodwin. Numerical methods for ordinary differential equa-<br>tions, volume 2. Wiley Online Library, 2008.</p>",
            "id": 132,
            "page": 10,
            "text": "John Charles Butcher and Nicolette Goodwin. Numerical methods for ordinary differential equations, volume 2. Wiley Online Library, 2008."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2161
                },
                {
                    "x": 2106,
                    "y": 2161
                },
                {
                    "x": 2106,
                    "y": 2297
                },
                {
                    "x": 443,
                    "y": 2297
                }
            ],
            "category": "paragraph",
            "html": "<p id='133' style='font-size:16px'>Nanxin Chen, Yu Zhang, Heiga Zen, Ron J Weiss, Mohammad Norouzi, and William Chan. WaveG-<br>rad: Estimating gradients for waveform generation. arXiv preprint arXiv:2009.00713, September<br>2020.</p>",
            "id": 133,
            "page": 10,
            "text": "Nanxin Chen, Yu Zhang, Heiga Zen, Ron J Weiss, Mohammad Norouzi, and William Chan. WaveGrad: Estimating gradients for waveform generation. arXiv preprint arXiv:2009.00713, September 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2328
                },
                {
                    "x": 2105,
                    "y": 2328
                },
                {
                    "x": 2105,
                    "y": 2423
                },
                {
                    "x": 442,
                    "y": 2423
                }
            ],
            "category": "paragraph",
            "html": "<p id='134' style='font-size:16px'>Ricky T Q Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural ordinary differ-<br>ential equations. arXiv preprint arXiv:1806.07366, June 2018.</p>",
            "id": 134,
            "page": 10,
            "text": "Ricky T Q Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural ordinary differential equations. arXiv preprint arXiv:1806.07366, June 2018."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2454
                },
                {
                    "x": 2105,
                    "y": 2454
                },
                {
                    "x": 2105,
                    "y": 2544
                },
                {
                    "x": 443,
                    "y": 2544
                }
            ],
            "category": "paragraph",
            "html": "<p id='135' style='font-size:20px'>Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real NVP. arXiv<br>preprint arXiv:1605.08803, May 2016.</p>",
            "id": 135,
            "page": 10,
            "text": "Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real NVP. arXiv preprint arXiv:1605.08803, May 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2576
                },
                {
                    "x": 2105,
                    "y": 2576
                },
                {
                    "x": 2105,
                    "y": 2714
                },
                {
                    "x": 443,
                    "y": 2714
                }
            ],
            "category": "paragraph",
            "html": "<p id='136' style='font-size:16px'>Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,<br>Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-<br>mation processing systems, pp. 2672-2680, 2014.</p>",
            "id": 136,
            "page": 10,
            "text": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pp. 2672-2680, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2746
                },
                {
                    "x": 2106,
                    "y": 2746
                },
                {
                    "x": 2106,
                    "y": 2883
                },
                {
                    "x": 443,
                    "y": 2883
                }
            ],
            "category": "paragraph",
            "html": "<p id='137' style='font-size:16px'>Anirudh Goyal, Nan Rosemary Ke, Surya Ganguli, and Yoshua Bengio. Variational walkback:<br>Learning a transition operator as a stochastic recurrent net. In Advances in Neural Information<br>Processing Systems, pp. 4392-4402, 2017.</p>",
            "id": 137,
            "page": 10,
            "text": "Anirudh Goyal, Nan Rosemary Ke, Surya Ganguli, and Yoshua Bengio. Variational walkback: Learning a transition operator as a stochastic recurrent net. In Advances in Neural Information Processing Systems, pp. 4392-4402, 2017."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2914
                },
                {
                    "x": 2107,
                    "y": 2914
                },
                {
                    "x": 2107,
                    "y": 3053
                },
                {
                    "x": 444,
                    "y": 3053
                }
            ],
            "category": "paragraph",
            "html": "<p id='138' style='font-size:16px'>Will Grathwohl, Ricky TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. FFJORD:<br>Free-form continuous dynamics for scalable reversible generative models. arXiv preprint<br>arXiv:1810.01367, October 2018.</p>",
            "id": 138,
            "page": 10,
            "text": "Will Grathwohl, Ricky TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. FFJORD: Free-form continuous dynamics for scalable reversible generative models. arXiv preprint arXiv:1810.01367, October 2018."
        },
        {
            "bounding_box": [
                {
                    "x": 1253,
                    "y": 3133
                },
                {
                    "x": 1300,
                    "y": 3133
                },
                {
                    "x": 1300,
                    "y": 3172
                },
                {
                    "x": 1253,
                    "y": 3172
                }
            ],
            "category": "footer",
            "html": "<footer id='139' style='font-size:14px'>10</footer>",
            "id": 139,
            "page": 10,
            "text": "10"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 111
                },
                {
                    "x": 1220,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='140' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 140,
            "page": 11,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 346
                },
                {
                    "x": 2108,
                    "y": 346
                },
                {
                    "x": 2108,
                    "y": 482
                },
                {
                    "x": 442,
                    "y": 482
                }
            ],
            "category": "paragraph",
            "html": "<p id='141' style='font-size:18px'>Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Im-<br>proved training of wasserstein gans. In Advances in Neural Information Processing Systems, pp.<br>5769-5779, 2017.</p>",
            "id": 141,
            "page": 11,
            "text": "Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training of wasserstein gans. In Advances in Neural Information Processing Systems, pp. 5769-5779, 2017."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 516
                },
                {
                    "x": 2108,
                    "y": 516
                },
                {
                    "x": 2108,
                    "y": 653
                },
                {
                    "x": 442,
                    "y": 653
                }
            ],
            "category": "paragraph",
            "html": "<p id='142' style='font-size:16px'>Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.<br>GANs trained by a two Time-Scale update rule converge to a local nash equilibrium. arXiv<br>preprint arXiv:1706.08500, June 2017.</p>",
            "id": 142,
            "page": 11,
            "text": "Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs trained by a two Time-Scale update rule converge to a local nash equilibrium. arXiv preprint arXiv:1706.08500, June 2017."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 686
                },
                {
                    "x": 2107,
                    "y": 686
                },
                {
                    "x": 2107,
                    "y": 775
                },
                {
                    "x": 443,
                    "y": 775
                }
            ],
            "category": "paragraph",
            "html": "<p id='143' style='font-size:20px'>Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. arXiv preprint<br>arXiv:2006.11239, June 2020.</p>",
            "id": 143,
            "page": 11,
            "text": "Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. arXiv preprint arXiv:2006.11239, June 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 808
                },
                {
                    "x": 2109,
                    "y": 808
                },
                {
                    "x": 2109,
                    "y": 898
                },
                {
                    "x": 444,
                    "y": 898
                }
            ],
            "category": "paragraph",
            "html": "<p id='144' style='font-size:18px'>Aapo Hyv�rinen. Estimation of Non-Normalized statistical models by score matching. Journal of<br>Machine Learning Researc h, 6:695-709, 2005.</p>",
            "id": 144,
            "page": 11,
            "text": "Aapo Hyv�rinen. Estimation of Non-Normalized statistical models by score matching. Journal of Machine Learning Researc h, 6:695-709, 2005."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 931
                },
                {
                    "x": 2108,
                    "y": 931
                },
                {
                    "x": 2108,
                    "y": 1067
                },
                {
                    "x": 444,
                    "y": 1067
                }
            ],
            "category": "paragraph",
            "html": "<p id='145' style='font-size:20px'>Alexia Jolicoeur-Martineau, Remi Piche-Taillefer, Remi Tachet des Combes, and Ioannis<br>Mitliagkas. Adversarial score matching and improved sampling for image generation. September<br>2020.</p>",
            "id": 145,
            "page": 11,
            "text": "Alexia Jolicoeur-Martineau, Remi Piche-Taillefer, Remi Tachet des Combes, and Ioannis Mitliagkas. Adversarial score matching and improved sampling for image generation. September 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1098
                },
                {
                    "x": 2106,
                    "y": 1098
                },
                {
                    "x": 2106,
                    "y": 1192
                },
                {
                    "x": 442,
                    "y": 1192
                }
            ],
            "category": "paragraph",
            "html": "<p id='146' style='font-size:18px'>Richard Jordan, David Kinderlehrer, and Felix Otto. The variational formulation of the fokker-<br>planck equation. SIAM journal on mathematical analysis, 29(1):1-17, 1998.</p>",
            "id": 146,
            "page": 11,
            "text": "Richard Jordan, David Kinderlehrer, and Felix Otto. The variational formulation of the fokkerplanck equation. SIAM journal on mathematical analysis, 29(1):1-17, 1998."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1222
                },
                {
                    "x": 2108,
                    "y": 1222
                },
                {
                    "x": 2108,
                    "y": 1314
                },
                {
                    "x": 443,
                    "y": 1314
                }
            ],
            "category": "paragraph",
            "html": "<p id='147' style='font-size:16px'>Tero Karras, Samuli Laine, and Timo Aila. A Style-Based generator architecture for generative<br>adversarial networks. arXiv preprint arXiv:1812.04948, December 2018.</p>",
            "id": 147,
            "page": 11,
            "text": "Tero Karras, Samuli Laine, and Timo Aila. A Style-Based generator architecture for generative adversarial networks. arXiv preprint arXiv:1812.04948, December 2018."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1344
                },
                {
                    "x": 2107,
                    "y": 1344
                },
                {
                    "x": 2107,
                    "y": 1484
                },
                {
                    "x": 442,
                    "y": 1484
                }
            ],
            "category": "paragraph",
            "html": "<p id='148' style='font-size:20px'>Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyz-<br>ing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF Conference on<br>Computer Vision and Pattern Recognition, pp. 8110-8119, 2020.</p>",
            "id": 148,
            "page": 11,
            "text": "Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8110-8119, 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1515
                },
                {
                    "x": 2106,
                    "y": 1515
                },
                {
                    "x": 2106,
                    "y": 1606
                },
                {
                    "x": 441,
                    "y": 1606
                }
            ],
            "category": "paragraph",
            "html": "<p id='149' style='font-size:20px'>Diederik P Kingma and Max Welling. Auto-Encoding variational bayes. arXiv preprint<br>arXiv:1312.6114v10, December 2013.</p>",
            "id": 149,
            "page": 11,
            "text": "Diederik P Kingma and Max Welling. Auto-Encoding variational bayes. arXiv preprint arXiv:1312.6114v10, December 2013."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1637
                },
                {
                    "x": 2106,
                    "y": 1637
                },
                {
                    "x": 2106,
                    "y": 1728
                },
                {
                    "x": 442,
                    "y": 1728
                }
            ],
            "category": "paragraph",
            "html": "<p id='150' style='font-size:16px'>Daniel Levy, Matthew D Hoffman, and Jascha Sohl-Dickstein. Generalizing hamiltonian monte<br>carlo with neural networks. arXiv preprint arXiv:1711.09268, 2017.</p>",
            "id": 150,
            "page": 11,
            "text": "Daniel Levy, Matthew D Hoffman, and Jascha Sohl-Dickstein. Generalizing hamiltonian monte carlo with neural networks. arXiv preprint arXiv:1711.09268, 2017."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1761
                },
                {
                    "x": 2106,
                    "y": 1761
                },
                {
                    "x": 2106,
                    "y": 1853
                },
                {
                    "x": 442,
                    "y": 1853
                }
            ],
            "category": "paragraph",
            "html": "<p id='151' style='font-size:20px'>Shakir Mohamed and Balaji Lakshminarayanan. Learning in implicit generative models. arXiv<br>preprint arXiv:1610.03483, October 2016.</p>",
            "id": 151,
            "page": 11,
            "text": "Shakir Mohamed and Balaji Lakshminarayanan. Learning in implicit generative models. arXiv preprint arXiv:1610.03483, October 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1883
                },
                {
                    "x": 2104,
                    "y": 1883
                },
                {
                    "x": 2104,
                    "y": 1974
                },
                {
                    "x": 443,
                    "y": 1974
                }
            ],
            "category": "paragraph",
            "html": "<p id='152' style='font-size:16px'>Radford M Neal et al. Mcmc using hamiltonian dynamics. Handbook of markov chain monte carlo,<br>2(11):2, 2011.</p>",
            "id": 152,
            "page": 11,
            "text": "Radford M Neal  Mcmc using hamiltonian dynamics. Handbook of markov chain monte carlo, 2(11):2, 2011."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2006
                },
                {
                    "x": 2105,
                    "y": 2006
                },
                {
                    "x": 2105,
                    "y": 2099
                },
                {
                    "x": 444,
                    "y": 2099
                }
            ],
            "category": "paragraph",
            "html": "<p id='153' style='font-size:20px'>Alejandro F Queiruga, N Benjamin Erichson, Dane Taylor, and Michael W Mahoney. Continuous-<br>in-depth neural networks. arXiv preprint arXiv:2008.02389, 2020.</p>",
            "id": 153,
            "page": 11,
            "text": "Alejandro F Queiruga, N Benjamin Erichson, Dane Taylor, and Michael W Mahoney. Continuousin-depth neural networks. arXiv preprint arXiv:2008.02389, 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2129
                },
                {
                    "x": 2104,
                    "y": 2129
                },
                {
                    "x": 2104,
                    "y": 2221
                },
                {
                    "x": 441,
                    "y": 2221
                }
            ],
            "category": "paragraph",
            "html": "<p id='154' style='font-size:18px'>Martin Raphan and Eero P Simoncelli. Least squares estimation without priors or supervision.<br>Neural computation, 23(2):374-420, February 2011. ISSN 0899-7667, 1530-888X.</p>",
            "id": 154,
            "page": 11,
            "text": "Martin Raphan and Eero P Simoncelli. Least squares estimation without priors or supervision. Neural computation, 23(2):374-420, February 2011. ISSN 0899-7667, 1530-888X."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2253
                },
                {
                    "x": 2106,
                    "y": 2253
                },
                {
                    "x": 2106,
                    "y": 2344
                },
                {
                    "x": 443,
                    "y": 2344
                }
            ],
            "category": "paragraph",
            "html": "<p id='155' style='font-size:18px'>Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing flows. arXiv<br>preprint arXiv:1505.05770, May 2015.</p>",
            "id": 155,
            "page": 11,
            "text": "Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing flows. arXiv preprint arXiv:1505.05770, May 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2375
                },
                {
                    "x": 2107,
                    "y": 2375
                },
                {
                    "x": 2107,
                    "y": 2468
                },
                {
                    "x": 443,
                    "y": 2468
                }
            ],
            "category": "paragraph",
            "html": "<p id='156' style='font-size:16px'>Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and<br>approximate inference in deep generative models. arXiv preprint arXiv:1401. 4082, 2014.</p>",
            "id": 156,
            "page": 11,
            "text": "Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. arXiv preprint arXiv:1401. 4082, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2500
                },
                {
                    "x": 2106,
                    "y": 2500
                },
                {
                    "x": 2106,
                    "y": 2637
                },
                {
                    "x": 442,
                    "y": 2637
                }
            ],
            "category": "paragraph",
            "html": "<p id='157' style='font-size:18px'>Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedi-<br>cal image segmentation. In International Conference on Medical image computing and computer-<br>assisted intervention, pp. 234-241. Springer, 2015.</p>",
            "id": 157,
            "page": 11,
            "text": "Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computerassisted intervention, pp. 234-241. Springer, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2668
                },
                {
                    "x": 2106,
                    "y": 2668
                },
                {
                    "x": 2106,
                    "y": 2762
                },
                {
                    "x": 442,
                    "y": 2762
                }
            ],
            "category": "paragraph",
            "html": "<p id='158' style='font-size:16px'>Tim Salimans, Diederik P Kingma, and Max Welling. Markov chain monte carlo and variational<br>inference: Bridging the gap. arXiv preprint arXiv:1410.6460, October 2014.</p>",
            "id": 158,
            "page": 11,
            "text": "Tim Salimans, Diederik P Kingma, and Max Welling. Markov chain monte carlo and variational inference: Bridging the gap. arXiv preprint arXiv:1410.6460, October 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2792
                },
                {
                    "x": 2106,
                    "y": 2792
                },
                {
                    "x": 2106,
                    "y": 2883
                },
                {
                    "x": 442,
                    "y": 2883
                }
            ],
            "category": "paragraph",
            "html": "<p id='159' style='font-size:16px'>Ken Shoemake. Animating rotation with quaternion curves. In Proceedings of the 12th annual<br>conference on Computer graphics and interactive techniques, pp. 245-254, 1985.</p>",
            "id": 159,
            "page": 11,
            "text": "Ken Shoemake. Animating rotation with quaternion curves. In Proceedings of the 12th annual conference on Computer graphics and interactive techniques, pp. 245-254, 1985."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2916
                },
                {
                    "x": 2106,
                    "y": 2916
                },
                {
                    "x": 2106,
                    "y": 3050
                },
                {
                    "x": 443,
                    "y": 3050
                }
            ],
            "category": "paragraph",
            "html": "<p id='160' style='font-size:22px'>Jascha Sohl-Dickstein, Eric A Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsuper-<br>vised learning using nonequilibrium thermodynamics. arXiv preprint arXiv:1503.03585, March<br>2015.</p>",
            "id": 160,
            "page": 11,
            "text": "Jascha Sohl-Dickstein, Eric A Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. arXiv preprint arXiv:1503.03585, March 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 3133
                },
                {
                    "x": 1297,
                    "y": 3133
                },
                {
                    "x": 1297,
                    "y": 3172
                },
                {
                    "x": 1252,
                    "y": 3172
                }
            ],
            "category": "footer",
            "html": "<footer id='161' style='font-size:14px'>11</footer>",
            "id": 161,
            "page": 11,
            "text": "11"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 111
                },
                {
                    "x": 1219,
                    "y": 111
                },
                {
                    "x": 1219,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='162' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 162,
            "page": 12,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 346
                },
                {
                    "x": 2105,
                    "y": 346
                },
                {
                    "x": 2105,
                    "y": 438
                },
                {
                    "x": 442,
                    "y": 438
                }
            ],
            "category": "paragraph",
            "html": "<p id='163' style='font-size:20px'>Jiaming Song, Shengjia Zhao, and Stefano Ermon. A-nice-mc: Adversarial training for mcmc. arXiv<br>preprint arXiv:1706.07561, June 2017.</p>",
            "id": 163,
            "page": 12,
            "text": "Jiaming Song, Shengjia Zhao, and Stefano Ermon. A-nice-mc: Adversarial training for mcmc. arXiv preprint arXiv:1706.07561, June 2017."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 471
                },
                {
                    "x": 2106,
                    "y": 471
                },
                {
                    "x": 2106,
                    "y": 564
                },
                {
                    "x": 444,
                    "y": 564
                }
            ],
            "category": "paragraph",
            "html": "<p id='164' style='font-size:22px'>Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution.<br>arXiv preprint arXiv:1907.05600, July 2019.</p>",
            "id": 164,
            "page": 12,
            "text": "Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. arXiv preprint arXiv:1907.05600, July 2019."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 596
                },
                {
                    "x": 2104,
                    "y": 596
                },
                {
                    "x": 2104,
                    "y": 687
                },
                {
                    "x": 443,
                    "y": 687
                }
            ],
            "category": "paragraph",
            "html": "<p id='165' style='font-size:22px'>Yang Song and Stefano Ermon. Improved techniques for training Score-Based generative models.<br>arXiv preprint arXiv:2006.09011, June 2020.</p>",
            "id": 165,
            "page": 12,
            "text": "Yang Song and Stefano Ermon. Improved techniques for training Score-Based generative models. arXiv preprint arXiv:2006.09011, June 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 720
                },
                {
                    "x": 2108,
                    "y": 720
                },
                {
                    "x": 2108,
                    "y": 858
                },
                {
                    "x": 444,
                    "y": 858
                }
            ],
            "category": "paragraph",
            "html": "<p id='166' style='font-size:20px'>Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben<br>Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint<br>arXiv:2011.13456, 2020.</p>",
            "id": 166,
            "page": 12,
            "text": "Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456, 2020."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 890
                },
                {
                    "x": 2107,
                    "y": 890
                },
                {
                    "x": 2107,
                    "y": 1029
                },
                {
                    "x": 443,
                    "y": 1029
                }
            ],
            "category": "paragraph",
            "html": "<p id='167' style='font-size:18px'>Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves,<br>Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. WaveNet: A generative model for<br>raw audio. arXiv preprint arXiv:1609.03499, September 2016a.</p>",
            "id": 167,
            "page": 12,
            "text": "Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. WaveNet: A generative model for raw audio. arXiv preprint arXiv:1609.03499, September 2016a."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1062
                },
                {
                    "x": 2106,
                    "y": 1062
                },
                {
                    "x": 2106,
                    "y": 1152
                },
                {
                    "x": 443,
                    "y": 1152
                }
            ],
            "category": "paragraph",
            "html": "<p id='168' style='font-size:18px'>Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural networks.<br>arXiv preprint arXiv:1601.06759, January 2016b.</p>",
            "id": 168,
            "page": 12,
            "text": "Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural networks. arXiv preprint arXiv:1601.06759, January 2016b."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1184
                },
                {
                    "x": 2106,
                    "y": 1184
                },
                {
                    "x": 2106,
                    "y": 1278
                },
                {
                    "x": 442,
                    "y": 1278
                }
            ],
            "category": "paragraph",
            "html": "<p id='169' style='font-size:16px'>Pascal Vincent. A connection between score matching and denoising autoencoders. Neural compu-<br>tation, 23(7):1661-1674, 2011.</p>",
            "id": 169,
            "page": 12,
            "text": "Pascal Vincent. A connection between score matching and denoising autoencoders. Neural computation, 23(7):1661-1674, 2011."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1308
                },
                {
                    "x": 2105,
                    "y": 1308
                },
                {
                    "x": 2105,
                    "y": 1402
                },
                {
                    "x": 441,
                    "y": 1402
                }
            ],
            "category": "paragraph",
            "html": "<p id='170' style='font-size:20px'>Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint<br>arXiv:1605.07146, May 2016.</p>",
            "id": 170,
            "page": 12,
            "text": "Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint arXiv:1605.07146, May 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1435
                },
                {
                    "x": 2107,
                    "y": 1435
                },
                {
                    "x": 2107,
                    "y": 1575
                },
                {
                    "x": 442,
                    "y": 1575
                }
            ],
            "category": "paragraph",
            "html": "<p id='171' style='font-size:20px'>Shengjia Zhao, Hongyu Ren, Arianna Yuan, Jiaming Song, Noah Goodman, and Stefano Ermon.<br>Bias and generalization in deep generative models: An empirical study. In Advances in Neural<br>Information Processing Systems, pp. 10792-10801, 2018.</p>",
            "id": 171,
            "page": 12,
            "text": "Shengjia Zhao, Hongyu Ren, Arianna Yuan, Jiaming Song, Noah Goodman, and Stefano Ermon. Bias and generalization in deep generative models: An empirical study. In Advances in Neural Information Processing Systems, pp. 10792-10801, 2018."
        },
        {
            "bounding_box": [
                {
                    "x": 1253,
                    "y": 3132
                },
                {
                    "x": 1300,
                    "y": 3132
                },
                {
                    "x": 1300,
                    "y": 3172
                },
                {
                    "x": 1253,
                    "y": 3172
                }
            ],
            "category": "footer",
            "html": "<footer id='172' style='font-size:14px'>12</footer>",
            "id": 172,
            "page": 12,
            "text": "12"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 112
                },
                {
                    "x": 1220,
                    "y": 112
                },
                {
                    "x": 1220,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='173' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 173,
            "page": 13,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 342
                },
                {
                    "x": 1923,
                    "y": 342
                },
                {
                    "x": 1923,
                    "y": 393
                },
                {
                    "x": 445,
                    "y": 393
                }
            ],
            "category": "paragraph",
            "html": "<p id='174' style='font-size:18px'>A NON-MARKOVIAN FORWARD PROCESSES FOR A DISCRETE CASE</p>",
            "id": 174,
            "page": 13,
            "text": "A NON-MARKOVIAN FORWARD PROCESSES FOR A DISCRETE CASE"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 445
                },
                {
                    "x": 2106,
                    "y": 445
                },
                {
                    "x": 2106,
                    "y": 582
                },
                {
                    "x": 442,
                    "y": 582
                }
            ],
            "category": "paragraph",
            "html": "<p id='175' style='font-size:14px'>In this section, we describe a non-Markovian forward processes for discrete data and corresponding<br>variational objectives. Since the focus of this paper is to accelerate reverse models corresponding to<br>the Gaussian diffusion, we leave empirical evaluations as future work.</p>",
            "id": 175,
            "page": 13,
            "text": "In this section, we describe a non-Markovian forward processes for discrete data and corresponding variational objectives. Since the focus of this paper is to accelerate reverse models corresponding to the Gaussian diffusion, we leave empirical evaluations as future work."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 610
                },
                {
                    "x": 2106,
                    "y": 610
                },
                {
                    "x": 2106,
                    "y": 699
                },
                {
                    "x": 443,
                    "y": 699
                }
            ],
            "category": "paragraph",
            "html": "<p id='176' style='font-size:14px'>For a categorical observation x0 that is a one-hot vector with K possible values, we define the<br>forward process as follows. First, we have q(xt|xo) as the following categorical distribution:</p>",
            "id": 176,
            "page": 13,
            "text": "For a categorical observation x0 that is a one-hot vector with K possible values, we define the forward process as follows. First, we have q(xt|xo) as the following categorical distribution:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 801
                },
                {
                    "x": 2104,
                    "y": 801
                },
                {
                    "x": 2104,
                    "y": 894
                },
                {
                    "x": 442,
                    "y": 894
                }
            ],
            "category": "paragraph",
            "html": "<p id='177' style='font-size:14px'>where 1K E RK is a vector with all entries being 1/K, and at decreasing from ao = 1 for t = 0 to<br>aT = 0 for t = T. Then we define q(xt-1|xt, xo) as the following mixture distribution:</p>",
            "id": 177,
            "page": 13,
            "text": "where 1K E RK is a vector with all entries being 1/K, and at decreasing from ao = 1 for t = 0 to aT = 0 for t = T. Then we define q(xt-1|xt, xo) as the following mixture distribution:"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1109
                },
                {
                    "x": 711,
                    "y": 1109
                },
                {
                    "x": 711,
                    "y": 1154
                },
                {
                    "x": 443,
                    "y": 1154
                }
            ],
            "category": "paragraph",
            "html": "<p id='178' style='font-size:16px'>or equivalently:</p>",
            "id": 178,
            "page": 13,
            "text": "or equivalently:"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1251
                },
                {
                    "x": 1385,
                    "y": 1251
                },
                {
                    "x": 1385,
                    "y": 1295
                },
                {
                    "x": 445,
                    "y": 1295
                }
            ],
            "category": "paragraph",
            "html": "<p id='179' style='font-size:14px'>which is consistent with how we have defined q(xt|xo).</p>",
            "id": 179,
            "page": 13,
            "text": "which is consistent with how we have defined q(xt|xo)."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 1319
                },
                {
                    "x": 1459,
                    "y": 1319
                },
                {
                    "x": 1459,
                    "y": 1367
                },
                {
                    "x": 446,
                    "y": 1367
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='180' style='font-size:14px'>Similarly, we can define our reverse process po(xt-1|xt) as:</p>",
            "id": 180,
            "page": 13,
            "text": "Similarly, we can define our reverse process po(xt-1|xt) as:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1496
                },
                {
                    "x": 2105,
                    "y": 1496
                },
                {
                    "x": 2105,
                    "y": 1643
                },
                {
                    "x": 442,
                    "y": 1643
                }
            ],
            "category": "paragraph",
            "html": "<p id='181' style='font-size:16px'>where f(t) (xt) maps Xt to a K-dimensional vector. As (1 - at-1)-(1-at)ot → 0, the sampling<br>process will become less stochastic, in the sense that it will either choose Xt or the predicted x0<br>with high probability. The KL divergence</p>",
            "id": 181,
            "page": 13,
            "text": "where f(t) (xt) maps Xt to a K-dimensional vector. As (1 - at-1)-(1-at)ot → 0, the sampling process will become less stochastic, in the sense that it will either choose Xt or the predicted x0 with high probability. The KL divergence"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1740
                },
                {
                    "x": 2104,
                    "y": 1740
                },
                {
                    "x": 2104,
                    "y": 1875
                },
                {
                    "x": 443,
                    "y": 1875
                }
            ],
            "category": "paragraph",
            "html": "<p id='182' style='font-size:16px'>is well-defined, and is simply the KL divergence between two categoricals. Therefore, the resulting<br>variational objective function should be easy to optimize as well. Moreover, as KL divergence is<br>convex, we have this upper bound (which is tight when the right hand side goes to zero):</p>",
            "id": 182,
            "page": 13,
            "text": "is well-defined, and is simply the KL divergence between two categoricals. Therefore, the resulting variational objective function should be easy to optimize as well. Moreover, as KL divergence is convex, we have this upper bound (which is tight when the right hand side goes to zero):"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1982
                },
                {
                    "x": 2105,
                    "y": 1982
                },
                {
                    "x": 2105,
                    "y": 2076
                },
                {
                    "x": 441,
                    "y": 2076
                }
            ],
            "category": "paragraph",
            "html": "<p id='183' style='font-size:14px'>The right hand side is simply a multi-class classification loss (up to constants), SO we can arrive at<br>similar arguments regarding how changes in Ot do not affect the objective (up to re-weighting).</p>",
            "id": 183,
            "page": 13,
            "text": "The right hand side is simply a multi-class classification loss (up to constants), SO we can arrive at similar arguments regarding how changes in Ot do not affect the objective (up to re-weighting)."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2141
                },
                {
                    "x": 709,
                    "y": 2141
                },
                {
                    "x": 709,
                    "y": 2193
                },
                {
                    "x": 444,
                    "y": 2193
                }
            ],
            "category": "paragraph",
            "html": "<p id='184' style='font-size:18px'>B PROOFS</p>",
            "id": 184,
            "page": 13,
            "text": "B PROOFS"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2243
                },
                {
                    "x": 2054,
                    "y": 2243
                },
                {
                    "x": 2054,
                    "y": 2292
                },
                {
                    "x": 445,
                    "y": 2292
                }
            ],
            "category": "paragraph",
            "html": "<p id='185' style='font-size:18px'>Lemma 1. For qo(x1:T|x0) defined in Eq. (6) and qo(xt-1|xt, xo) defined in Eq. (7), we have:</p>",
            "id": 185,
            "page": 13,
            "text": "Lemma 1. For qo(x1:T|x0) defined in Eq. (6) and qo(xt-1|xt, xo) defined in Eq. (7), we have:"
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 2411
                },
                {
                    "x": 1734,
                    "y": 2411
                },
                {
                    "x": 1734,
                    "y": 2462
                },
                {
                    "x": 446,
                    "y": 2462
                }
            ],
            "category": "paragraph",
            "html": "<p id='186' style='font-size:18px'>Proof. Assume for any t ≤ T,qo(xt|xo) =N(Vatxo, (1 -at)I) holds, if:</p>",
            "id": 186,
            "page": 13,
            "text": "Proof. Assume for any t ≤ T,qo(xt|xo) =N(Vatxo, (1 -at)I) holds, if:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2558
                },
                {
                    "x": 2102,
                    "y": 2558
                },
                {
                    "x": 2102,
                    "y": 2645
                },
                {
                    "x": 441,
                    "y": 2645
                }
            ],
            "category": "paragraph",
            "html": "<p id='187' style='font-size:14px'>then we can prove the statement with an induction argument for t from T to 1, since the base case<br>(t = T) already holds.</p>",
            "id": 187,
            "page": 13,
            "text": "then we can prove the statement with an induction argument for t from T to 1, since the base case (t = T) already holds."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2672
                },
                {
                    "x": 760,
                    "y": 2672
                },
                {
                    "x": 760,
                    "y": 2717
                },
                {
                    "x": 444,
                    "y": 2717
                }
            ],
            "category": "paragraph",
            "html": "<p id='188' style='font-size:14px'>First, we have that</p>",
            "id": 188,
            "page": 13,
            "text": "First, we have that"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2829
                },
                {
                    "x": 514,
                    "y": 2829
                },
                {
                    "x": 514,
                    "y": 2868
                },
                {
                    "x": 443,
                    "y": 2868
                }
            ],
            "category": "paragraph",
            "html": "<p id='189' style='font-size:14px'>and</p>",
            "id": 189,
            "page": 13,
            "text": "and"
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 3133
                },
                {
                    "x": 1299,
                    "y": 3133
                },
                {
                    "x": 1299,
                    "y": 3171
                },
                {
                    "x": 1252,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='190' style='font-size:14px'>13</footer>",
            "id": 190,
            "page": 13,
            "text": "13"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 113
                },
                {
                    "x": 1219,
                    "y": 113
                },
                {
                    "x": 1219,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='191' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 191,
            "page": 14,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 347
                },
                {
                    "x": 2103,
                    "y": 347
                },
                {
                    "x": 2103,
                    "y": 437
                },
                {
                    "x": 440,
                    "y": 437
                }
            ],
            "category": "paragraph",
            "html": "<p id='192' style='font-size:18px'>From Bishop (2006) (2.115), we have that qo (xt-1|x0) is Gaussian, denoted as N(�t-1,�t-1)<br>where</p>",
            "id": 192,
            "page": 14,
            "text": "From Bishop (2006) (2.115), we have that qo (xt-1|x0) is Gaussian, denoted as N(�t-1,�t-1) where"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 639
                },
                {
                    "x": 513,
                    "y": 639
                },
                {
                    "x": 513,
                    "y": 678
                },
                {
                    "x": 443,
                    "y": 678
                }
            ],
            "category": "paragraph",
            "html": "<p id='193' style='font-size:14px'>and</p>",
            "id": 193,
            "page": 14,
            "text": "and"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 817
                },
                {
                    "x": 2107,
                    "y": 817
                },
                {
                    "x": 2107,
                    "y": 910
                },
                {
                    "x": 442,
                    "y": 910
                }
            ],
            "category": "paragraph",
            "html": "<p id='194' style='font-size:16px'>Therefore, qo(xt-1|x0) = N(Vat-1x0, (1 - �t-1)I), which allows us to apply the induction<br>argument.</p>",
            "id": 194,
            "page": 14,
            "text": "Therefore, qo(xt-1|x0) = N(Vat-1x0, (1 - �t-1)I), which allows us to apply the induction argument."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 937
                },
                {
                    "x": 1890,
                    "y": 937
                },
                {
                    "x": 1890,
                    "y": 987
                },
                {
                    "x": 443,
                    "y": 987
                }
            ],
            "category": "paragraph",
            "html": "<p id='195' style='font-size:16px'>Theorem 1. For all 0 > 0, there exists 2 E R T>0 and C E R, such that Jo = Ly + C.</p>",
            "id": 195,
            "page": 14,
            "text": "Theorem 1. For all 0 > 0, there exists 2 E R T>0 and C E R, such that Jo = Ly + C."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1037
                },
                {
                    "x": 1011,
                    "y": 1037
                },
                {
                    "x": 1011,
                    "y": 1085
                },
                {
                    "x": 445,
                    "y": 1085
                }
            ],
            "category": "paragraph",
            "html": "<p id='196' style='font-size:18px'>Proof. From the definition of Jo:</p>",
            "id": 196,
            "page": 14,
            "text": "Proof. From the definition of Jo:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1454
                },
                {
                    "x": 2100,
                    "y": 1454
                },
                {
                    "x": 2100,
                    "y": 1542
                },
                {
                    "x": 441,
                    "y": 1542
                }
            ],
            "category": "paragraph",
            "html": "<p id='197' style='font-size:14px'>where we use to denote \"equal up to a value that does not depend on EA (but may depend on qo)\".<br>For t > 1:</p>",
            "id": 197,
            "page": 14,
            "text": "where we use to denote \"equal up to a value that does not depend on EA (but may depend on qo)\". For t > 1:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2240
                },
                {
                    "x": 1165,
                    "y": 2240
                },
                {
                    "x": 1165,
                    "y": 2288
                },
                {
                    "x": 442,
                    "y": 2288
                }
            ],
            "category": "paragraph",
            "html": "<p id='198' style='font-size:14px'>where dis the dimension of xo. For t = 1:</p>",
            "id": 198,
            "page": 14,
            "text": "where dis the dimension of xo. For t = 1:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2647
                },
                {
                    "x": 1559,
                    "y": 2647
                },
                {
                    "x": 1559,
                    "y": 2702
                },
                {
                    "x": 442,
                    "y": 2702
                }
            ],
            "category": "paragraph",
            "html": "<p id='199' style='font-size:16px'>Therefore, when Yt = 1/(2dotat) for all t E {1, . . ,T}, we have</p>",
            "id": 199,
            "page": 14,
            "text": "Therefore, when Yt = 1/(2dotat) for all t E {1, . . ,T}, we have"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2872
                },
                {
                    "x": 2103,
                    "y": 2872
                },
                {
                    "x": 2103,
                    "y": 2921
                },
                {
                    "x": 445,
                    "y": 2921
                }
            ],
            "category": "paragraph",
            "html": "<p id='200' style='font-size:16px'>for all EA. From the definition of \"=\", we have that Jo = Ly + C. □</p>",
            "id": 200,
            "page": 14,
            "text": "for all EA. From the definition of \"=\", we have that Jo = Ly + C. □"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2958
                },
                {
                    "x": 2107,
                    "y": 2958
                },
                {
                    "x": 2107,
                    "y": 3054
                },
                {
                    "x": 442,
                    "y": 3054
                }
            ],
            "category": "paragraph",
            "html": "<p id='201' style='font-size:18px'>93 has an equivalent probability flow<br>Proposition 1. The ODE in Eq. (14) with the optimal model<br>ODE corresponding to the \"Variance-Exploding\" SDE in Song et al. (2020).</p>",
            "id": 201,
            "page": 14,
            "text": "93 has an equivalent probability flow Proposition 1. The ODE in Eq. (14) with the optimal model ODE corresponding to the \"Variance-Exploding\" SDE in Song  (2020)."
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 3134
                },
                {
                    "x": 1300,
                    "y": 3134
                },
                {
                    "x": 1300,
                    "y": 3171
                },
                {
                    "x": 1252,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='202' style='font-size:16px'>14</footer>",
            "id": 202,
            "page": 14,
            "text": "14"
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 113
                },
                {
                    "x": 1219,
                    "y": 113
                },
                {
                    "x": 1219,
                    "y": 156
                },
                {
                    "x": 446,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='203' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 203,
            "page": 15,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 349
                },
                {
                    "x": 2103,
                    "y": 349
                },
                {
                    "x": 2103,
                    "y": 484
                },
                {
                    "x": 443,
                    "y": 484
                }
            ],
            "category": "paragraph",
            "html": "<p id='204' style='font-size:14px'>Proof. In the context of the proof, we consider t as a continous, independent \"time\" variable and x<br>and a as functions oft. First, let us consider a reparametrization between DDIM and the VE-SDE8<br>by introducing the variables x and 0:</p>",
            "id": 204,
            "page": 15,
            "text": "Proof. In the context of the proof, we consider t as a continous, independent \"time\" variable and x and a as functions oft. First, let us consider a reparametrization between DDIM and the VE-SDE8 by introducing the variables x and 0:"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 602
                },
                {
                    "x": 1896,
                    "y": 602
                },
                {
                    "x": 1896,
                    "y": 647
                },
                {
                    "x": 445,
                    "y": 647
                }
            ],
            "category": "paragraph",
            "html": "<p id='205' style='font-size:16px'>for t E [0, �) and an increasing continuous function 0 : R≥0 → R≥0 where �(0) = 0.</p>",
            "id": 205,
            "page": 15,
            "text": "for t E [0, �) and an increasing continuous function 0 : R≥0 → R≥0 where �(0) = 0."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 674
                },
                {
                    "x": 1555,
                    "y": 674
                },
                {
                    "x": 1555,
                    "y": 716
                },
                {
                    "x": 446,
                    "y": 716
                }
            ],
            "category": "paragraph",
            "html": "<p id='206' style='font-size:16px'>We can then define a(t) and x(t) corresponding to DDIM case as:</p>",
            "id": 206,
            "page": 15,
            "text": "We can then define a(t) and x(t) corresponding to DDIM case as:"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1041
                },
                {
                    "x": 801,
                    "y": 1041
                },
                {
                    "x": 801,
                    "y": 1083
                },
                {
                    "x": 445,
                    "y": 1083
                }
            ],
            "category": "paragraph",
            "html": "<p id='207' style='font-size:14px'>This also means that:</p>",
            "id": 207,
            "page": 15,
            "text": "This also means that:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1366
                },
                {
                    "x": 2104,
                    "y": 1366
                },
                {
                    "x": 2104,
                    "y": 1456
                },
                {
                    "x": 441,
                    "y": 1456
                }
            ],
            "category": "paragraph",
            "html": "<p id='208' style='font-size:18px'>which establishes an bijection between (x, a) and (x,�). From Equation (4) we have (note that<br>a(0) = 1):</p>",
            "id": 208,
            "page": 15,
            "text": "which establishes an bijection between (x, a) and (x,�). From Equation (4) we have (note that a(0) = 1):"
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 1659
                },
                {
                    "x": 1667,
                    "y": 1659
                },
                {
                    "x": 1667,
                    "y": 1701
                },
                {
                    "x": 446,
                    "y": 1701
                }
            ],
            "category": "paragraph",
            "html": "<p id='209' style='font-size:14px'>which can be reparametrized into a form that is consistent with VE-SDE:</p>",
            "id": 209,
            "page": 15,
            "text": "which can be reparametrized into a form that is consistent with VE-SDE:"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1843
                },
                {
                    "x": 2039,
                    "y": 1843
                },
                {
                    "x": 2039,
                    "y": 1888
                },
                {
                    "x": 445,
                    "y": 1888
                }
            ],
            "category": "paragraph",
            "html": "<p id='210' style='font-size:14px'>Now, we derive the ODE forms for both DDIM and VE-SDE and show that they are equivalent.</p>",
            "id": 210,
            "page": 15,
            "text": "Now, we derive the ODE forms for both DDIM and VE-SDE and show that they are equivalent."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1947
                },
                {
                    "x": 1367,
                    "y": 1947
                },
                {
                    "x": 1367,
                    "y": 1996
                },
                {
                    "x": 444,
                    "y": 1996
                }
            ],
            "category": "paragraph",
            "html": "<p id='211' style='font-size:18px'>ODE form for DDIM We repeat Equation (13) here:</p>",
            "id": 211,
            "page": 15,
            "text": "ODE form for DDIM We repeat Equation (13) here:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2196
                },
                {
                    "x": 828,
                    "y": 2196
                },
                {
                    "x": 828,
                    "y": 2239
                },
                {
                    "x": 442,
                    "y": 2239
                }
            ],
            "category": "paragraph",
            "html": "<p id='212' style='font-size:16px'>which is equivalent to:</p>",
            "id": 212,
            "page": 15,
            "text": "which is equivalent to:"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2367
                },
                {
                    "x": 1348,
                    "y": 2367
                },
                {
                    "x": 1348,
                    "y": 2413
                },
                {
                    "x": 444,
                    "y": 2413
                }
            ],
            "category": "paragraph",
            "html": "<p id='213' style='font-size:16px'>Divide both sides by (-△t) and as △t → 0, we have:</p>",
            "id": 213,
            "page": 15,
            "text": "Divide both sides by (-△t) and as △t → 0, we have:"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2611
                },
                {
                    "x": 1249,
                    "y": 2611
                },
                {
                    "x": 1249,
                    "y": 2655
                },
                {
                    "x": 445,
                    "y": 2655
                }
            ],
            "category": "paragraph",
            "html": "<p id='214' style='font-size:16px'>which is exactly what we have in Equation (14).</p>",
            "id": 214,
            "page": 15,
            "text": "which is exactly what we have in Equation (14)."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 2689
                },
                {
                    "x": 1371,
                    "y": 2689
                },
                {
                    "x": 1371,
                    "y": 2738
                },
                {
                    "x": 446,
                    "y": 2738
                }
            ],
            "category": "paragraph",
            "html": "<p id='215' style='font-size:16px'>We note that for the optimal model, e(t) is a minimizer:</p>",
            "id": 215,
            "page": 15,
            "text": "We note that for the optimal model, e(t) is a minimizer:"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2906
                },
                {
                    "x": 1149,
                    "y": 2906
                },
                {
                    "x": 1149,
                    "y": 2961
                },
                {
                    "x": 443,
                    "y": 2961
                }
            ],
            "category": "paragraph",
            "html": "<p id='216' style='font-size:18px'>where x(t) = Va(t)x(t) + V1 - a(t)e.</p>",
            "id": 216,
            "page": 15,
            "text": "where x(t) = Va(t)x(t) + V1 - a(t)e."
        },
        {
            "bounding_box": [
                {
                    "x": 498,
                    "y": 3008
                },
                {
                    "x": 1363,
                    "y": 3008
                },
                {
                    "x": 1363,
                    "y": 3051
                },
                {
                    "x": 498,
                    "y": 3051
                }
            ],
            "category": "paragraph",
            "html": "<p id='217' style='font-size:14px'>8Refer to (Song et al., 2020) for more details of VE-SDE.</p>",
            "id": 217,
            "page": 15,
            "text": "8Refer to (Song , 2020) for more details of VE-SDE."
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 3134
                },
                {
                    "x": 1300,
                    "y": 3134
                },
                {
                    "x": 1300,
                    "y": 3171
                },
                {
                    "x": 1252,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='218' style='font-size:14px'>15</footer>",
            "id": 218,
            "page": 15,
            "text": "15"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 113
                },
                {
                    "x": 1219,
                    "y": 113
                },
                {
                    "x": 1219,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='219' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 219,
            "page": 16,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 348
                },
                {
                    "x": 2104,
                    "y": 348
                },
                {
                    "x": 2104,
                    "y": 437
                },
                {
                    "x": 444,
                    "y": 437
                }
            ],
            "category": "paragraph",
            "html": "<p id='220' style='font-size:14px'>ODE form for VE-SDE Define pt(x) as the data distribution perturbed with �2 (t) variance Gaus-<br>sian noise. The probability flow for VE-SDE is defined as Song et al. (2020):</p>",
            "id": 220,
            "page": 16,
            "text": "ODE form for VE-SDE Define pt(x) as the data distribution perturbed with �2 (t) variance Gaussian noise. The probability flow for VE-SDE is defined as Song  (2020):"
        },
        {
            "bounding_box": [
                {
                    "x": 439,
                    "y": 574
                },
                {
                    "x": 2105,
                    "y": 574
                },
                {
                    "x": 2105,
                    "y": 763
                },
                {
                    "x": 439,
                    "y": 763
                }
            ],
            "category": "paragraph",
            "html": "<p id='221' style='font-size:16px'>do2(t)<br>is the diffusion coefficient, and ▽ x logpt(�) is the score of pt.<br>where g(t) = V dt<br>The �(t)-perturbed score function ▽ x logpt(x) is also a minimizer (from denoising score match-<br>ing (Vincent, 2011)):</p>",
            "id": 221,
            "page": 16,
            "text": "do2(t) is the diffusion coefficient, and ▽ x logpt(�) is the score of pt. where g(t) = V dt The �(t)-perturbed score function ▽ x logpt(x) is also a minimizer (from denoising score matching (Vincent, 2011)):"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 887
                },
                {
                    "x": 916,
                    "y": 887
                },
                {
                    "x": 916,
                    "y": 934
                },
                {
                    "x": 444,
                    "y": 934
                }
            ],
            "category": "paragraph",
            "html": "<p id='222' style='font-size:18px'>where x(t) = x(t) + o(t)e.</p>",
            "id": 222,
            "page": 16,
            "text": "where x(t) = x(t) + o(t)e."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 957
                },
                {
                    "x": 1928,
                    "y": 957
                },
                {
                    "x": 1928,
                    "y": 1003
                },
                {
                    "x": 444,
                    "y": 1003
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='223' style='font-size:16px'>Since there is an equivalence between x(t) and x(t), we have the following relationship:</p>",
            "id": 223,
            "page": 16,
            "text": "Since there is an equivalence between x(t) and x(t), we have the following relationship:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1200
                },
                {
                    "x": 2103,
                    "y": 1200
                },
                {
                    "x": 2103,
                    "y": 1291
                },
                {
                    "x": 442,
                    "y": 1291
                }
            ],
            "category": "paragraph",
            "html": "<p id='224' style='font-size:16px'>from Equation (46) and Equation (48). Plug Equation (49) and definition of g(t) in Equation (47),<br>we have:</p>",
            "id": 224,
            "page": 16,
            "text": "from Equation (46) and Equation (48). Plug Equation (49) and definition of g(t) in Equation (47), we have:"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1481
                },
                {
                    "x": 1258,
                    "y": 1481
                },
                {
                    "x": 1258,
                    "y": 1526
                },
                {
                    "x": 443,
                    "y": 1526
                }
            ],
            "category": "paragraph",
            "html": "<p id='225' style='font-size:16px'>and we have the following by rearranging terms:</p>",
            "id": 225,
            "page": 16,
            "text": "and we have the following by rearranging terms:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1694
                },
                {
                    "x": 2104,
                    "y": 1694
                },
                {
                    "x": 2104,
                    "y": 1787
                },
                {
                    "x": 442,
                    "y": 1787
                }
            ],
            "category": "paragraph",
            "html": "<p id='226' style='font-size:16px'>which is equivalent to Equation (45). In both cases the initial conditions are x (T) ~ N(0,�2(T)I),<br>SO the resulting ODEs are identical.</p>",
            "id": 226,
            "page": 16,
            "text": "which is equivalent to Equation (45). In both cases the initial conditions are x (T) ~ N(0,�2(T)I), SO the resulting ODEs are identical."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1854
                },
                {
                    "x": 1125,
                    "y": 1854
                },
                {
                    "x": 1125,
                    "y": 1904
                },
                {
                    "x": 443,
                    "y": 1904
                }
            ],
            "category": "paragraph",
            "html": "<p id='227' style='font-size:18px'>C ADDITIONAL DERIVATIONS</p>",
            "id": 227,
            "page": 16,
            "text": "C ADDITIONAL DERIVATIONS"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1952
                },
                {
                    "x": 1231,
                    "y": 1952
                },
                {
                    "x": 1231,
                    "y": 2003
                },
                {
                    "x": 442,
                    "y": 2003
                }
            ],
            "category": "paragraph",
            "html": "<p id='228' style='font-size:14px'>C.1 ACCELERATED SAMPLING PROCESSES</p>",
            "id": 228,
            "page": 16,
            "text": "C.1 ACCELERATED SAMPLING PROCESSES"
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 2042
                },
                {
                    "x": 1770,
                    "y": 2042
                },
                {
                    "x": 1770,
                    "y": 2087
                },
                {
                    "x": 446,
                    "y": 2087
                }
            ],
            "category": "paragraph",
            "html": "<p id='229' style='font-size:14px'>In the accelerated case, we can consider the inference process to be factored as:</p>",
            "id": 229,
            "page": 16,
            "text": "In the accelerated case, we can consider the inference process to be factored as:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2258
                },
                {
                    "x": 2105,
                    "y": 2258
                },
                {
                    "x": 2105,
                    "y": 2397
                },
                {
                    "x": 441,
                    "y": 2397
                }
            ],
            "category": "paragraph",
            "html": "<p id='230' style='font-size:14px'>where T is a sub-sequence of [1, . · · , T] of length S with TS = T, and let テ := {1,. . , T} 1 T<br>be its complement. Intuitively, the graphical model of {xTi }i=1 and xo form a chain, whereas the<br>graphical model of {xt}tE� and x0 forms a star graph. We define:</p>",
            "id": 230,
            "page": 16,
            "text": "where T is a sub-sequence of [1, . · · , T] of length S with TS = T, and let テ := {1,. . , T} 1 T be its complement. Intuitively, the graphical model of {xTi }i=1 and xo form a chain, whereas the graphical model of {xt}tE� and x0 forms a star graph. We define:"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2599
                },
                {
                    "x": 1173,
                    "y": 2599
                },
                {
                    "x": 1173,
                    "y": 2644
                },
                {
                    "x": 444,
                    "y": 2644
                }
            ],
            "category": "paragraph",
            "html": "<p id='231' style='font-size:14px'>where the coefficients are chosen such that:</p>",
            "id": 231,
            "page": 16,
            "text": "where the coefficients are chosen such that:"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2730
                },
                {
                    "x": 907,
                    "y": 2730
                },
                {
                    "x": 907,
                    "y": 2774
                },
                {
                    "x": 443,
                    "y": 2774
                }
            ],
            "category": "paragraph",
            "html": "<p id='232' style='font-size:16px'>i.e., the \"marginals\" match.</p>",
            "id": 232,
            "page": 16,
            "text": "i.e., the \"marginals\" match."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2801
                },
                {
                    "x": 1345,
                    "y": 2801
                },
                {
                    "x": 1345,
                    "y": 2846
                },
                {
                    "x": 444,
                    "y": 2846
                }
            ],
            "category": "paragraph",
            "html": "<p id='233' style='font-size:14px'>The corresponding \"generative process\" is defined as:</p>",
            "id": 233,
            "page": 16,
            "text": "The corresponding \"generative process\" is defined as:"
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 3135
                },
                {
                    "x": 1300,
                    "y": 3135
                },
                {
                    "x": 1300,
                    "y": 3172
                },
                {
                    "x": 1252,
                    "y": 3172
                }
            ],
            "category": "footer",
            "html": "<footer id='234' style='font-size:14px'>16</footer>",
            "id": 234,
            "page": 16,
            "text": "16"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 112
                },
                {
                    "x": 1220,
                    "y": 112
                },
                {
                    "x": 1220,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='235' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 235,
            "page": 17,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 349
                },
                {
                    "x": 2044,
                    "y": 349
                },
                {
                    "x": 2044,
                    "y": 394
                },
                {
                    "x": 445,
                    "y": 394
                }
            ],
            "category": "paragraph",
            "html": "<p id='236' style='font-size:16px'>where only part of the models are actually being used to produce samples. The conditionals are:</p>",
            "id": 236,
            "page": 17,
            "text": "where only part of the models are actually being used to produce samples. The conditionals are:"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 586
                },
                {
                    "x": 2105,
                    "y": 586
                },
                {
                    "x": 2105,
                    "y": 679
                },
                {
                    "x": 443,
                    "y": 679
                }
            ],
            "category": "paragraph",
            "html": "<p id='237' style='font-size:18px'>where we leverage qo,T(xTi-1 |xTi, xo) as part of the inference process (similar to what we have done<br>in Section 3). The resulting variational objective becomes (define XTL+1 = ⌀ for conciseness):</p>",
            "id": 237,
            "page": 17,
            "text": "where we leverage qo,T(xTi-1 |xTi, xo) as part of the inference process (similar to what we have done in Section 3). The resulting variational objective becomes (define XTL+1 = ⌀ for conciseness):"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1081
                },
                {
                    "x": 2105,
                    "y": 1081
                },
                {
                    "x": 2105,
                    "y": 1218
                },
                {
                    "x": 441,
                    "y": 1218
                }
            ],
            "category": "paragraph",
            "html": "<p id='238' style='font-size:16px'>where each KL divergence is between two Gaussians with variance independent of 0. A similar<br>argument to the proof used in Theorem 1 can show that the variational objective J can also be<br>converted to an objective of the form Ly.</p>",
            "id": 238,
            "page": 17,
            "text": "where each KL divergence is between two Gaussians with variance independent of 0. A similar argument to the proof used in Theorem 1 can show that the variational objective J can also be converted to an objective of the form Ly."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1275
                },
                {
                    "x": 1515,
                    "y": 1275
                },
                {
                    "x": 1515,
                    "y": 1323
                },
                {
                    "x": 444,
                    "y": 1323
                }
            ],
            "category": "paragraph",
            "html": "<p id='239' style='font-size:14px'>C.2 DERIVATION OF DENOISING OBJECTIVES FOR DDPMs</p>",
            "id": 239,
            "page": 17,
            "text": "C.2 DERIVATION OF DENOISING OBJECTIVES FOR DDPMs"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1362
                },
                {
                    "x": 2106,
                    "y": 1362
                },
                {
                    "x": 2106,
                    "y": 1695
                },
                {
                    "x": 443,
                    "y": 1695
                }
            ],
            "category": "paragraph",
            "html": "<p id='240' style='font-size:16px'>We note that in Ho et al. (2020), a diffusion hyperparameter Bt9 is first introduced, and then relevant<br>variables at := 1 - Bt and �t = IIt=1 at are defined. In this paper, we have used the notation<br>at to represent the variable �t in Ho et al. (2020) for three reasons. First, it makes it more clear<br>that we only need to choose one set of hyperparameters, reducing possible cross-references of the<br>derived variables. Second, it allows us to introduce the generalization as well as the acceleration<br>case easier, because the inference process is no longer motivated by a diffusion. Third, there exists<br>an isomorphism between �1:T and 1, · · · , T, which is not the case for Bt.</p>",
            "id": 240,
            "page": 17,
            "text": "We note that in Ho  (2020), a diffusion hyperparameter Bt9 is first introduced, and then relevant variables at := 1 - Bt and �t = IIt=1 at are defined. In this paper, we have used the notation at to represent the variable �t in Ho  (2020) for three reasons. First, it makes it more clear that we only need to choose one set of hyperparameters, reducing possible cross-references of the derived variables. Second, it allows us to introduce the generalization as well as the acceleration case easier, because the inference process is no longer motivated by a diffusion. Third, there exists an isomorphism between �1:T and 1, · · · , T, which is not the case for Bt."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1716
                },
                {
                    "x": 2102,
                    "y": 1716
                },
                {
                    "x": 2102,
                    "y": 1764
                },
                {
                    "x": 443,
                    "y": 1764
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='241' style='font-size:16px'>In this section, we use Bt and at to be more consistent with the derivation in Ho et al. (2020), where</p>",
            "id": 241,
            "page": 17,
            "text": "In this section, we use Bt and at to be more consistent with the derivation in Ho  (2020), where"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2010
                },
                {
                    "x": 1206,
                    "y": 2010
                },
                {
                    "x": 1206,
                    "y": 2055
                },
                {
                    "x": 443,
                    "y": 2055
                }
            ],
            "category": "paragraph",
            "html": "<p id='242' style='font-size:16px'>can be uniquely determined from at (i.e. �t).</p>",
            "id": 242,
            "page": 17,
            "text": "can be uniquely determined from at (i.e. �t)."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2078
                },
                {
                    "x": 1140,
                    "y": 2078
                },
                {
                    "x": 1140,
                    "y": 2124
                },
                {
                    "x": 444,
                    "y": 2124
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='243' style='font-size:16px'>First, from the diffusion forward process:</p>",
            "id": 243,
            "page": 17,
            "text": "First, from the diffusion forward process:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2389
                },
                {
                    "x": 1456,
                    "y": 2389
                },
                {
                    "x": 1456,
                    "y": 2454
                },
                {
                    "x": 442,
                    "y": 2454
                }
            ],
            "category": "paragraph",
            "html": "<p id='244' style='font-size:18px'>Ho et al. (2020) considered a specific type ofpot)(xt-1|xt):</p>",
            "id": 244,
            "page": 17,
            "text": "Ho  (2020) considered a specific type ofpot)(xt-1|xt):"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2568
                },
                {
                    "x": 1283,
                    "y": 2568
                },
                {
                    "x": 1283,
                    "y": 2615
                },
                {
                    "x": 445,
                    "y": 2615
                }
            ],
            "category": "paragraph",
            "html": "<p id='245' style='font-size:18px'>which leads to the following variational objective:</p>",
            "id": 245,
            "page": 17,
            "text": "which leads to the following variational objective:"
        },
        {
            "bounding_box": [
                {
                    "x": 497,
                    "y": 3007
                },
                {
                    "x": 1546,
                    "y": 3007
                },
                {
                    "x": 1546,
                    "y": 3052
                },
                {
                    "x": 497,
                    "y": 3052
                }
            ],
            "category": "paragraph",
            "html": "<p id='246' style='font-size:14px'>9In this section we use teal to color notations used in Ho et al. (2020).</p>",
            "id": 246,
            "page": 17,
            "text": "9In this section we use teal to color notations used in Ho  (2020)."
        },
        {
            "bounding_box": [
                {
                    "x": 1253,
                    "y": 3134
                },
                {
                    "x": 1299,
                    "y": 3134
                },
                {
                    "x": 1299,
                    "y": 3171
                },
                {
                    "x": 1253,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='247' style='font-size:16px'>17</footer>",
            "id": 247,
            "page": 17,
            "text": "17"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 112
                },
                {
                    "x": 1220,
                    "y": 112
                },
                {
                    "x": 1220,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='248' style='font-size:16px'>Published as a conference paper at ICLR 2021</header>",
            "id": 248,
            "page": 18,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 348
                },
                {
                    "x": 697,
                    "y": 348
                },
                {
                    "x": 697,
                    "y": 392
                },
                {
                    "x": 444,
                    "y": 392
                }
            ],
            "category": "paragraph",
            "html": "<p id='249' style='font-size:14px'>One can write:</p>",
            "id": 249,
            "page": 18,
            "text": "One can write:"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 531
                },
                {
                    "x": 1155,
                    "y": 531
                },
                {
                    "x": 1155,
                    "y": 574
                },
                {
                    "x": 444,
                    "y": 574
                }
            ],
            "category": "paragraph",
            "html": "<p id='250' style='font-size:16px'>Ho et al. (2020) chose the parametrization</p>",
            "id": 250,
            "page": 18,
            "text": "Ho  (2020) chose the parametrization"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 723
                },
                {
                    "x": 902,
                    "y": 723
                },
                {
                    "x": 902,
                    "y": 765
                },
                {
                    "x": 444,
                    "y": 765
                }
            ],
            "category": "paragraph",
            "html": "<p id='251' style='font-size:16px'>which can be simplified to:</p>",
            "id": 251,
            "page": 18,
            "text": "which can be simplified to:"
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 952
                },
                {
                    "x": 1077,
                    "y": 952
                },
                {
                    "x": 1077,
                    "y": 1002
                },
                {
                    "x": 446,
                    "y": 1002
                }
            ],
            "category": "paragraph",
            "html": "<p id='252' style='font-size:20px'>D EXPERIMENTAL DETAILS</p>",
            "id": 252,
            "page": 18,
            "text": "D EXPERIMENTAL DETAILS"
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 1054
                },
                {
                    "x": 1143,
                    "y": 1054
                },
                {
                    "x": 1143,
                    "y": 1099
                },
                {
                    "x": 446,
                    "y": 1099
                }
            ],
            "category": "paragraph",
            "html": "<p id='253' style='font-size:14px'>D.1 DATASETS AND ARCHITECTURES</p>",
            "id": 253,
            "page": 18,
            "text": "D.1 DATASETS AND ARCHITECTURES"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1136
                },
                {
                    "x": 2106,
                    "y": 1136
                },
                {
                    "x": 2106,
                    "y": 1462
                },
                {
                    "x": 442,
                    "y": 1462
                }
            ],
            "category": "paragraph",
            "html": "<p id='254' style='font-size:18px'>We consider 4 image datasets with various resolutions: CIFAR10 (32 x 32, unconditional), CelebA<br>(64 x 64), LSUN Bedroom (256 x 256) and LSUN Church (256 x 256). For all datasets, we<br>set the hyperparameters a according to the heuristic in (Ho et al., 2020) to make the results directly<br>comparable. We use the same model for each dataset, and only compare the performance of different<br>generative processes. For CIFAR10, Bedroom and Church, we obtain the pretrained checkpoints<br>from the original DDPM implementation; for CelebA, we trained our own model using the denoising<br>objective L1.</p>",
            "id": 254,
            "page": 18,
            "text": "We consider 4 image datasets with various resolutions: CIFAR10 (32 x 32, unconditional), CelebA (64 x 64), LSUN Bedroom (256 x 256) and LSUN Church (256 x 256). For all datasets, we set the hyperparameters a according to the heuristic in (Ho , 2020) to make the results directly comparable. We use the same model for each dataset, and only compare the performance of different generative processes. For CIFAR10, Bedroom and Church, we obtain the pretrained checkpoints from the original DDPM implementation; for CelebA, we trained our own model using the denoising objective L1."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1485
                },
                {
                    "x": 2106,
                    "y": 1485
                },
                {
                    "x": 2106,
                    "y": 1772
                },
                {
                    "x": 441,
                    "y": 1772
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='255' style='font-size:18px'>Our architecture for 33 (xt) follows that in Ho et al. (2020), which is a U-Net (Ronneberger et al.,<br>2015) based on a Wide ResNet (Zagoruyko & Komodakis, 2016). We use the pretrained models<br>from Ho et al. (2020) for CIFAR10, Bedroom and Church, and train our own model for the CelebA<br>64 x 64 model (since a pretrained model is not provided). Our CelebA model has five feature map<br>resolutions from 64 x 64 to 4 x 4, and we use the original CelebA dataset (not CelebA-HQ) using<br>the pre-processing technique from the StyleGAN (Karras et al., 2018) repository.</p>",
            "id": 255,
            "page": 18,
            "text": "Our architecture for 33 (xt) follows that in Ho  (2020), which is a U-Net (Ronneberger , 2015) based on a Wide ResNet (Zagoruyko & Komodakis, 2016). We use the pretrained models from Ho  (2020) for CIFAR10, Bedroom and Church, and train our own model for the CelebA 64 x 64 model (since a pretrained model is not provided). Our CelebA model has five feature map resolutions from 64 x 64 to 4 x 4, and we use the original CelebA dataset (not CelebA-HQ) using the pre-processing technique from the StyleGAN (Karras , 2018) repository."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1825
                },
                {
                    "x": 2104,
                    "y": 1825
                },
                {
                    "x": 2104,
                    "y": 1914
                },
                {
                    "x": 444,
                    "y": 1914
                }
            ],
            "category": "paragraph",
            "html": "<p id='256' style='font-size:16px'>Table 3: LSUN Bedroom and Church image generation results, measured in FID. For 1000 steps<br>DDPM, the FIDs are 6.36 for Bedroom and 7.89 for Church.</p>",
            "id": 256,
            "page": 18,
            "text": "Table 3: LSUN Bedroom and Church image generation results, measured in FID. For 1000 steps DDPM, the FIDs are 6.36 for Bedroom and 7.89 for Church."
        },
        {
            "bounding_box": [
                {
                    "x": 465,
                    "y": 1956
                },
                {
                    "x": 2073,
                    "y": 1956
                },
                {
                    "x": 2073,
                    "y": 2190
                },
                {
                    "x": 465,
                    "y": 2190
                }
            ],
            "category": "table",
            "html": "<table id='257' style='font-size:18px'><tr><td></td><td colspan=\"4\">Bedroom (256 x 256)</td><td colspan=\"4\">Church (256 x 256)</td></tr><tr><td>dim (T)</td><td>10</td><td>20</td><td>50</td><td>100</td><td>10</td><td>20</td><td>50</td><td>100</td></tr><tr><td>DDIM (7 = 0.0)</td><td>16.95</td><td>8.89</td><td>6.75</td><td>6.62</td><td>19.45</td><td>12.47</td><td>10.84</td><td>10.58</td></tr><tr><td>DDPM (7 = 1.0)</td><td>42.78</td><td>22.77</td><td>10.81</td><td>6.81</td><td>51.56</td><td>23.37</td><td>11.16</td><td>8.27</td></tr></table>",
            "id": 257,
            "page": 18,
            "text": "Bedroom (256 x 256) Church (256 x 256)  dim (T) 10 20 50 100 10 20 50 100  DDIM (7 = 0.0) 16.95 8.89 6.75 6.62 19.45 12.47 10.84 10.58  DDPM (7 = 1.0) 42.78 22.77 10.81 6.81 51.56 23.37 11.16"
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 2269
                },
                {
                    "x": 1393,
                    "y": 2269
                },
                {
                    "x": 1393,
                    "y": 2316
                },
                {
                    "x": 446,
                    "y": 2316
                }
            ],
            "category": "paragraph",
            "html": "<p id='258' style='font-size:16px'>D.2 REVERSE PROCESS SUB-SEQUENCE SELECTION</p>",
            "id": 258,
            "page": 18,
            "text": "D.2 REVERSE PROCESS SUB-SEQUENCE SELECTION"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2356
                },
                {
                    "x": 1824,
                    "y": 2356
                },
                {
                    "x": 1824,
                    "y": 2404
                },
                {
                    "x": 445,
                    "y": 2404
                }
            ],
            "category": "paragraph",
            "html": "<p id='259' style='font-size:18px'>We consider two types of selection procedure for T given the desired dim (T) <T:</p>",
            "id": 259,
            "page": 18,
            "text": "We consider two types of selection procedure for T given the desired dim (T) <T:"
        },
        {
            "bounding_box": [
                {
                    "x": 557,
                    "y": 2441
                },
                {
                    "x": 1733,
                    "y": 2441
                },
                {
                    "x": 1733,
                    "y": 2552
                },
                {
                    "x": 557,
                    "y": 2552
                }
            ],
            "category": "paragraph",
            "html": "<p id='260' style='font-size:14px'>· Linear: we select the timesteps such that Ti = [ci] for some c;<br>· Quadratic: we select the timesteps such that Ti = Lci2 I for some c.</p>",
            "id": 260,
            "page": 18,
            "text": "· Linear: we select the timesteps such that Ti = [ci] for some c; · Quadratic: we select the timesteps such that Ti = Lci2 I for some c."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2586
                },
                {
                    "x": 2105,
                    "y": 2586
                },
                {
                    "x": 2105,
                    "y": 2723
                },
                {
                    "x": 442,
                    "y": 2723
                }
            ],
            "category": "paragraph",
            "html": "<p id='261' style='font-size:16px'>The constant value c is selected such that T-1 is close to T. We used quadratic for CIFAR10 and<br>linear for the remaining datasets. These choices achieve slightly better FID than their alternatives in<br>the respective datasets.</p>",
            "id": 261,
            "page": 18,
            "text": "The constant value c is selected such that T-1 is close to T. We used quadratic for CIFAR10 and linear for the remaining datasets. These choices achieve slightly better FID than their alternatives in the respective datasets."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2780
                },
                {
                    "x": 1517,
                    "y": 2780
                },
                {
                    "x": 1517,
                    "y": 2825
                },
                {
                    "x": 445,
                    "y": 2825
                }
            ],
            "category": "paragraph",
            "html": "<p id='262' style='font-size:14px'>D.3 CLOSED FORM EQUATIONS FOR EACH SAMPLING STEP</p>",
            "id": 262,
            "page": 18,
            "text": "D.3 CLOSED FORM EQUATIONS FOR EACH SAMPLING STEP"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2867
                },
                {
                    "x": 1914,
                    "y": 2867
                },
                {
                    "x": 1914,
                    "y": 2914
                },
                {
                    "x": 445,
                    "y": 2914
                }
            ],
            "category": "paragraph",
            "html": "<p id='263' style='font-size:20px'>From the general sampling equation in Eq. (12), we have the following update equation:</p>",
            "id": 263,
            "page": 18,
            "text": "From the general sampling equation in Eq. (12), we have the following update equation:"
        },
        {
            "bounding_box": [
                {
                    "x": 1253,
                    "y": 3135
                },
                {
                    "x": 1300,
                    "y": 3135
                },
                {
                    "x": 1300,
                    "y": 3171
                },
                {
                    "x": 1253,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='264' style='font-size:16px'>18</footer>",
            "id": 264,
            "page": 18,
            "text": "18"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 111
                },
                {
                    "x": 1219,
                    "y": 111
                },
                {
                    "x": 1219,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='265' style='font-size:14px'>Published as a conference paper at ICLR 2021</header>",
            "id": 265,
            "page": 19,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 617,
                    "y": 343
                },
                {
                    "x": 1926,
                    "y": 343
                },
                {
                    "x": 1926,
                    "y": 1175
                },
                {
                    "x": 617,
                    "y": 1175
                }
            ],
            "category": "figure",
            "html": "<figure><img id='266' alt=\"\" data-coord=\"top-left:(617,343); bottom-right:(1926,1175)\" /></figure>",
            "id": 266,
            "page": 19,
            "text": ""
        },
        {
            "bounding_box": [
                {
                    "x": 512,
                    "y": 1220
                },
                {
                    "x": 2033,
                    "y": 1220
                },
                {
                    "x": 2033,
                    "y": 1269
                },
                {
                    "x": 512,
                    "y": 1269
                }
            ],
            "category": "caption",
            "html": "<caption id='267' style='font-size:20px'>Figure 7: CIFAR10 samples from 1000 step DDPM, 1000 step DDIM and 100 step DDIM.</caption>",
            "id": 267,
            "page": 19,
            "text": "Figure 7: CIFAR10 samples from 1000 step DDPM, 1000 step DDIM and 100 step DDIM."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1438
                },
                {
                    "x": 556,
                    "y": 1438
                },
                {
                    "x": 556,
                    "y": 1479
                },
                {
                    "x": 443,
                    "y": 1479
                }
            ],
            "category": "paragraph",
            "html": "<p id='268' style='font-size:16px'>where</p>",
            "id": 268,
            "page": 19,
            "text": "where"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1616
                },
                {
                    "x": 1776,
                    "y": 1616
                },
                {
                    "x": 1776,
                    "y": 1665
                },
                {
                    "x": 443,
                    "y": 1665
                }
            ],
            "category": "paragraph",
            "html": "<p id='269' style='font-size:16px'>For the case of 0 (DDPM with a larger variance), the update equation becomes:</p>",
            "id": 269,
            "page": 19,
            "text": "For the case of 0 (DDPM with a larger variance), the update equation becomes:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1845
                },
                {
                    "x": 2107,
                    "y": 1845
                },
                {
                    "x": 2107,
                    "y": 1984
                },
                {
                    "x": 441,
                    "y": 1984
                }
            ],
            "category": "paragraph",
            "html": "<p id='270' style='font-size:16px'>which uses a different coefficient for E compared with the update for 7 = 1, but uses the same<br>coefficient for the non-stochastic parts. This update is more stochastic than the update for 7 = 1,<br>which explains why it achieves worse performance when dim(T) is small.</p>",
            "id": 270,
            "page": 19,
            "text": "which uses a different coefficient for E compared with the update for 7 = 1, but uses the same coefficient for the non-stochastic parts. This update is more stochastic than the update for 7 = 1, which explains why it achieves worse performance when dim(T) is small."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2039
                },
                {
                    "x": 1083,
                    "y": 2039
                },
                {
                    "x": 1083,
                    "y": 2087
                },
                {
                    "x": 444,
                    "y": 2087
                }
            ],
            "category": "paragraph",
            "html": "<p id='271' style='font-size:16px'>D.4 SAMPLES AND CONSISTENCY</p>",
            "id": 271,
            "page": 19,
            "text": "D.4 SAMPLES AND CONSISTENCY"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2123
                },
                {
                    "x": 2103,
                    "y": 2123
                },
                {
                    "x": 2103,
                    "y": 2218
                },
                {
                    "x": 442,
                    "y": 2218
                }
            ],
            "category": "paragraph",
            "html": "<p id='272' style='font-size:20px'>We show more samples in Figure 7 (CIFAR10), Figure 8 (CelebA), Figure 10 (Church) and consis-<br>tency results of DDIM in Figure 9 (CelebA).</p>",
            "id": 272,
            "page": 19,
            "text": "We show more samples in Figure 7 (CIFAR10), Figure 8 (CelebA), Figure 10 (Church) and consistency results of DDIM in Figure 9 (CelebA)."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2274
                },
                {
                    "x": 852,
                    "y": 2274
                },
                {
                    "x": 852,
                    "y": 2321
                },
                {
                    "x": 444,
                    "y": 2321
                }
            ],
            "category": "paragraph",
            "html": "<p id='273' style='font-size:20px'>D.5 INTERPOLATION</p>",
            "id": 273,
            "page": 19,
            "text": "D.5 INTERPOLATION"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2358
                },
                {
                    "x": 2107,
                    "y": 2358
                },
                {
                    "x": 2107,
                    "y": 2498
                },
                {
                    "x": 442,
                    "y": 2498
                }
            ],
            "category": "paragraph",
            "html": "<p id='274' style='font-size:18px'>To generate interpolations on a line, we randomly sample two initial XT values from the standard<br>Gaussian, interpolate them with spherical linear interpolation (Shoemake, 1985), and then use the<br>DDIM to obtain x0 samples.</p>",
            "id": 274,
            "page": 19,
            "text": "To generate interpolations on a line, we randomly sample two initial XT values from the standard Gaussian, interpolate them with spherical linear interpolation (Shoemake, 1985), and then use the DDIM to obtain x0 samples."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2660
                },
                {
                    "x": 1869,
                    "y": 2660
                },
                {
                    "x": 1869,
                    "y": 2763
                },
                {
                    "x": 441,
                    "y": 2763
                }
            ],
            "category": "paragraph",
            "html": "<p id='275' style='font-size:20px'>x(1)<br>(x⌀) T<br>where 0 = arccos ( Ux⌀ 111x((1) II ) These values are used to produce DDIM samples.</p>",
            "id": 275,
            "page": 19,
            "text": "x(1) (x⌀) T where 0 = arccos ( Ux⌀ 111x((1) II ) These values are used to produce DDIM samples."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2781
                },
                {
                    "x": 2109,
                    "y": 2781
                },
                {
                    "x": 2109,
                    "y": 2970
                },
                {
                    "x": 442,
                    "y": 2970
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='276' style='font-size:16px'>To generate interpolations on a grid, we sample four latent variables and separate them in to two<br>pairs; then we use slerp with the pairs under the same a, and use slerp over the interpolated samples<br>across the pairs (under an independently chosen interpolation coefficient). We show more grid<br>interpolation results in Figure 11 (CelebA), Figure 12 (Bedroom), and Figure 13 (Church).</p>",
            "id": 276,
            "page": 19,
            "text": "To generate interpolations on a grid, we sample four latent variables and separate them in to two pairs; then we use slerp with the pairs under the same a, and use slerp over the interpolated samples across the pairs (under an independently chosen interpolation coefficient). We show more grid interpolation results in Figure 11 (CelebA), Figure 12 (Bedroom), and Figure 13 (Church)."
        },
        {
            "bounding_box": [
                {
                    "x": 1253,
                    "y": 3133
                },
                {
                    "x": 1299,
                    "y": 3133
                },
                {
                    "x": 1299,
                    "y": 3171
                },
                {
                    "x": 1253,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='277' style='font-size:16px'>19</footer>",
            "id": 277,
            "page": 19,
            "text": "19"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1219,
                    "y": 110
                },
                {
                    "x": 1219,
                    "y": 158
                },
                {
                    "x": 444,
                    "y": 158
                }
            ],
            "category": "header",
            "html": "<header id='278' style='font-size:18px'>Published as a conference paper at ICLR 2021</header>",
            "id": 278,
            "page": 20,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 618,
                    "y": 377
                },
                {
                    "x": 1926,
                    "y": 377
                },
                {
                    "x": 1926,
                    "y": 1122
                },
                {
                    "x": 618,
                    "y": 1122
                }
            ],
            "category": "figure",
            "html": "<figure><img id='279' style='font-size:16px' alt=\"-\n-\n등\n\" data-coord=\"top-left:(618,377); bottom-right:(1926,1122)\" /></figure>",
            "id": 279,
            "page": 20,
            "text": "등 "
        },
        {
            "bounding_box": [
                {
                    "x": 530,
                    "y": 1169
                },
                {
                    "x": 2018,
                    "y": 1169
                },
                {
                    "x": 2018,
                    "y": 1216
                },
                {
                    "x": 530,
                    "y": 1216
                }
            ],
            "category": "caption",
            "html": "<caption id='280' style='font-size:22px'>Figure 8: CelebA samples from 1000 step DDPM, 1000 step DDIM and 100 step DDIM.</caption>",
            "id": 280,
            "page": 20,
            "text": "Figure 8: CelebA samples from 1000 step DDPM, 1000 step DDIM and 100 step DDIM."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1315
                },
                {
                    "x": 2097,
                    "y": 1315
                },
                {
                    "x": 2097,
                    "y": 1699
                },
                {
                    "x": 443,
                    "y": 1699
                }
            ],
            "category": "figure",
            "html": "<figure><img id='281' style='font-size:14px' alt=\"20 이 す\ntimesteps\n50 것 이 6 ◐\nL ·\nsample\n100 S 양 5 �\nL \n1000 O T\" data-coord=\"top-left:(443,1315); bottom-right:(2097,1699)\" /></figure>",
            "id": 281,
            "page": 20,
            "text": "20 이 す timesteps 50 것 이 6 ◐ L · sample 100 S 양 5 � L  1000 O T"
        },
        {
            "bounding_box": [
                {
                    "x": 473,
                    "y": 1741
                },
                {
                    "x": 2078,
                    "y": 1741
                },
                {
                    "x": 2078,
                    "y": 1791
                },
                {
                    "x": 473,
                    "y": 1791
                }
            ],
            "category": "caption",
            "html": "<caption id='282' style='font-size:20px'>Figure 9: CelebA samples from DDIM with the same random XT and different number of steps.</caption>",
            "id": 282,
            "page": 20,
            "text": "Figure 9: CelebA samples from DDIM with the same random XT and different number of steps."
        },
        {
            "bounding_box": [
                {
                    "x": 622,
                    "y": 1890
                },
                {
                    "x": 1927,
                    "y": 1890
                },
                {
                    "x": 1927,
                    "y": 2914
                },
                {
                    "x": 622,
                    "y": 2914
                }
            ],
            "category": "figure",
            "html": "<figure><img id='283' alt=\"\" data-coord=\"top-left:(622,1890); bottom-right:(1927,2914)\" /></figure>",
            "id": 283,
            "page": 20,
            "text": ""
        },
        {
            "bounding_box": [
                {
                    "x": 683,
                    "y": 2960
                },
                {
                    "x": 1863,
                    "y": 2960
                },
                {
                    "x": 1863,
                    "y": 3009
                },
                {
                    "x": 683,
                    "y": 3009
                }
            ],
            "category": "caption",
            "html": "<caption id='284' style='font-size:20px'>Figure 10: Church samples from 100 step DDPM and 100 step DDIM.</caption>",
            "id": 284,
            "page": 20,
            "text": "Figure 10: Church samples from 100 step DDPM and 100 step DDIM."
        },
        {
            "bounding_box": [
                {
                    "x": 1249,
                    "y": 3131
                },
                {
                    "x": 1299,
                    "y": 3131
                },
                {
                    "x": 1299,
                    "y": 3172
                },
                {
                    "x": 1249,
                    "y": 3172
                }
            ],
            "category": "footer",
            "html": "<footer id='285' style='font-size:20px'>20</footer>",
            "id": 285,
            "page": 20,
            "text": "20"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 109
                },
                {
                    "x": 1221,
                    "y": 109
                },
                {
                    "x": 1221,
                    "y": 158
                },
                {
                    "x": 443,
                    "y": 158
                }
            ],
            "category": "header",
            "html": "<header id='286' style='font-size:16px'>Published as a conference paper at ICLR 2021</header>",
            "id": 286,
            "page": 21,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 769,
                    "y": 463
                },
                {
                    "x": 1775,
                    "y": 463
                },
                {
                    "x": 1775,
                    "y": 1465
                },
                {
                    "x": 769,
                    "y": 1465
                }
            ],
            "category": "figure",
            "html": "<figure><img id='287' alt=\"\" data-coord=\"top-left:(769,463); bottom-right:(1775,1465)\" /></figure>",
            "id": 287,
            "page": 21,
            "text": ""
        },
        {
            "bounding_box": [
                {
                    "x": 642,
                    "y": 1494
                },
                {
                    "x": 1901,
                    "y": 1494
                },
                {
                    "x": 1901,
                    "y": 1551
                },
                {
                    "x": 642,
                    "y": 1551
                }
            ],
            "category": "caption",
            "html": "<caption id='288' style='font-size:20px'>Figure 11: More interpolations from the CelebA DDIM with dim(T) = 50.</caption>",
            "id": 288,
            "page": 21,
            "text": "Figure 11: More interpolations from the CelebA DDIM with dim(T) = 50."
        },
        {
            "bounding_box": [
                {
                    "x": 770,
                    "y": 1827
                },
                {
                    "x": 1771,
                    "y": 1827
                },
                {
                    "x": 1771,
                    "y": 2832
                },
                {
                    "x": 770,
                    "y": 2832
                }
            ],
            "category": "figure",
            "html": "<figure><img id='289' style='font-size:14px' alt=\"되\" data-coord=\"top-left:(770,1827); bottom-right:(1771,2832)\" /></figure>",
            "id": 289,
            "page": 21,
            "text": "되"
        },
        {
            "bounding_box": [
                {
                    "x": 631,
                    "y": 2860
                },
                {
                    "x": 1916,
                    "y": 2860
                },
                {
                    "x": 1916,
                    "y": 2914
                },
                {
                    "x": 631,
                    "y": 2914
                }
            ],
            "category": "caption",
            "html": "<caption id='290' style='font-size:20px'>Figure 12: More interpolations from the Bedroom DDIM with dim (T) = 50.</caption>",
            "id": 290,
            "page": 21,
            "text": "Figure 12: More interpolations from the Bedroom DDIM with dim (T) = 50."
        },
        {
            "bounding_box": [
                {
                    "x": 1249,
                    "y": 3130
                },
                {
                    "x": 1297,
                    "y": 3130
                },
                {
                    "x": 1297,
                    "y": 3172
                },
                {
                    "x": 1249,
                    "y": 3172
                }
            ],
            "category": "footer",
            "html": "<footer id='291' style='font-size:18px'>21</footer>",
            "id": 291,
            "page": 21,
            "text": "21"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 109
                },
                {
                    "x": 1221,
                    "y": 109
                },
                {
                    "x": 1221,
                    "y": 158
                },
                {
                    "x": 443,
                    "y": 158
                }
            ],
            "category": "header",
            "html": "<header id='292' style='font-size:16px'>Published as a conference paper at ICLR 2021</header>",
            "id": 292,
            "page": 22,
            "text": "Published as a conference paper at ICLR 2021"
        },
        {
            "bounding_box": [
                {
                    "x": 771,
                    "y": 1141
                },
                {
                    "x": 1776,
                    "y": 1141
                },
                {
                    "x": 1776,
                    "y": 2148
                },
                {
                    "x": 771,
                    "y": 2148
                }
            ],
            "category": "figure",
            "html": "<figure><img id='293' style='font-size:14px' alt=\"ock.com\nerstoc\" data-coord=\"top-left:(771,1141); bottom-right:(1776,2148)\" /></figure>",
            "id": 293,
            "page": 22,
            "text": "ock.com erstoc"
        },
        {
            "bounding_box": [
                {
                    "x": 641,
                    "y": 2176
                },
                {
                    "x": 1903,
                    "y": 2176
                },
                {
                    "x": 1903,
                    "y": 2233
                },
                {
                    "x": 641,
                    "y": 2233
                }
            ],
            "category": "caption",
            "html": "<caption id='294' style='font-size:20px'>Figure 13: More interpolations from the Church DDIM with dim (T) = 50.</caption>",
            "id": 294,
            "page": 22,
            "text": "Figure 13: More interpolations from the Church DDIM with dim (T) = 50."
        },
        {
            "bounding_box": [
                {
                    "x": 1249,
                    "y": 3130
                },
                {
                    "x": 1300,
                    "y": 3130
                },
                {
                    "x": 1300,
                    "y": 3173
                },
                {
                    "x": 1249,
                    "y": 3173
                }
            ],
            "category": "footer",
            "html": "<footer id='295' style='font-size:20px'>22</footer>",
            "id": 295,
            "page": 22,
            "text": "22"
        }
    ]
}