{
    "id": "32ac776a-0f94-11ef-8828-426932df3dcf",
    "pdf_path": "/root/data/pdf/1609.01704v7.pdf",
    "elements": [
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 109
                },
                {
                    "x": 1223,
                    "y": 109
                },
                {
                    "x": 1223,
                    "y": 158
                },
                {
                    "x": 444,
                    "y": 158
                }
            ],
            "category": "header",
            "html": "<header id='0' style='font-size:16px'>Published as a conference paper at ICLR 2017</header>",
            "id": 0,
            "page": 1,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 330
                },
                {
                    "x": 1496,
                    "y": 330
                },
                {
                    "x": 1496,
                    "y": 485
                },
                {
                    "x": 445,
                    "y": 485
                }
            ],
            "category": "paragraph",
            "html": "<p id='1' style='font-size:22px'>HIERARCHICAL MULTISCALE<br>RECURRENT NEURAL NETWORKS</p>",
            "id": 1,
            "page": 1,
            "text": "HIERARCHICAL MULTISCALE RECURRENT NEURAL NETWORKS"
        },
        {
            "bounding_box": [
                {
                    "x": 469,
                    "y": 564
                },
                {
                    "x": 1371,
                    "y": 564
                },
                {
                    "x": 1371,
                    "y": 612
                },
                {
                    "x": 469,
                    "y": 612
                }
            ],
            "category": "paragraph",
            "html": "<p id='2' style='font-size:20px'>Junyoung Chung, Sungjin Ahn & Yoshua Bengio *</p>",
            "id": 2,
            "page": 1,
            "text": "Junyoung Chung, Sungjin Ahn & Yoshua Bengio *"
        },
        {
            "bounding_box": [
                {
                    "x": 469,
                    "y": 614
                },
                {
                    "x": 1466,
                    "y": 614
                },
                {
                    "x": 1466,
                    "y": 701
                },
                {
                    "x": 469,
                    "y": 701
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='3' style='font-size:20px'>Departement d'informatique et de recherche operationnelle<br>Universite de Montreal</p>",
            "id": 3,
            "page": 1,
            "text": "Departement d'informatique et de recherche operationnelle Universite de Montreal"
        },
        {
            "bounding_box": [
                {
                    "x": 478,
                    "y": 707
                },
                {
                    "x": 1850,
                    "y": 707
                },
                {
                    "x": 1850,
                    "y": 752
                },
                {
                    "x": 478,
                    "y": 752
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='4' style='font-size:16px'>{ junyoung · chung, sungjin · ahn, yoshua · bengio } @umontreal · ca</p>",
            "id": 4,
            "page": 1,
            "text": "{ junyoung · chung, sungjin · ahn, yoshua · bengio } @umontreal · ca"
        },
        {
            "bounding_box": [
                {
                    "x": 1153,
                    "y": 871
                },
                {
                    "x": 1396,
                    "y": 871
                },
                {
                    "x": 1396,
                    "y": 922
                },
                {
                    "x": 1153,
                    "y": 922
                }
            ],
            "category": "paragraph",
            "html": "<p id='5' style='font-size:22px'>ABSTRACT</p>",
            "id": 5,
            "page": 1,
            "text": "ABSTRACT"
        },
        {
            "bounding_box": [
                {
                    "x": 589,
                    "y": 971
                },
                {
                    "x": 1963,
                    "y": 971
                },
                {
                    "x": 1963,
                    "y": 1530
                },
                {
                    "x": 589,
                    "y": 1530
                }
            ],
            "category": "paragraph",
            "html": "<p id='6' style='font-size:18px'>Learning both hierarchical and temporal representation has been among the long-<br>standing challenges of recurrent neural networks. Multiscale recurrent neural<br>networks have been considered as a promising approach to resolve this issue, yet<br>there has been a lack of empirical evidence showing that this type of models can<br>actually capture the temporal dependencies by discovering the latent hierarchical<br>structure of the sequence. In this paper, we propose a novel multiscale approach,<br>called the hierarchical multiscale recurrent neural network, that can capture the<br>latent hierarchical structure in the sequence by encoding the temporal dependencies<br>with different timescales using a novel update mechanism. We show some evidence<br>that the proposed model can discover underlying hierarchical structure in the<br>sequences without using explicit boundary information. We evaluate our proposed<br>model on character-level language modelling and handwriting sequence generation.</p>",
            "id": 6,
            "page": 1,
            "text": "Learning both hierarchical and temporal representation has been among the longstanding challenges of recurrent neural networks. Multiscale recurrent neural networks have been considered as a promising approach to resolve this issue, yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence. In this paper, we propose a novel multiscale approach, called the hierarchical multiscale recurrent neural network, that can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism. We show some evidence that the proposed model can discover underlying hierarchical structure in the sequences without using explicit boundary information. We evaluate our proposed model on character-level language modelling and handwriting sequence generation."
        },
        {
            "bounding_box": [
                {
                    "x": 449,
                    "y": 1614
                },
                {
                    "x": 863,
                    "y": 1614
                },
                {
                    "x": 863,
                    "y": 1668
                },
                {
                    "x": 449,
                    "y": 1668
                }
            ],
            "category": "paragraph",
            "html": "<p id='7' style='font-size:20px'>1 INTRODUCTION</p>",
            "id": 7,
            "page": 1,
            "text": "1 INTRODUCTION"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1717
                },
                {
                    "x": 2110,
                    "y": 1717
                },
                {
                    "x": 2110,
                    "y": 2359
                },
                {
                    "x": 441,
                    "y": 2359
                }
            ],
            "category": "paragraph",
            "html": "<p id='8' style='font-size:18px'>One of the key principles of learning in deep neural networks as well as in the human brain is to obtain<br>a hierarchical representation with increasing levels of abstraction (Bengio, 2009; LeCun et al., 2015;<br>Schmidhuber, 2015). A stack of representation layers, learned from the data in a way to optimize<br>the target task, make deep neural networks entertain advantages such as generalization to unseen<br>examples (Hoffman et al., 2013), sharing learned knowledge among multiple tasks, and discovering<br>disentangling factors of variation (Kingma & Welling, 2013). The remarkable recent successes of<br>the deep convolutional neural networks are particularly based on this ability to learn hierarchical<br>representation for spatial data (Krizhevsky et al., 2012). For modelling temporal data, the recent<br>resurgence of recurrent neural networks (RNN) has led to remarkable advances (Mikolov et al., 2010;<br>Graves, 2013; Cho et al., 2014; Sutskever et al., 2014; Vinyals et al., 2015). However, unlike the<br>spatial data, learning both hierarchical and temporal representation has been among the long-standing<br>challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many<br>temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin et al., 1996; Koutnik<br>et al., 2014).</p>",
            "id": 8,
            "page": 1,
            "text": "One of the key principles of learning in deep neural networks as well as in the human brain is to obtain a hierarchical representation with increasing levels of abstraction (Bengio, 2009; LeCun , 2015; Schmidhuber, 2015). A stack of representation layers, learned from the data in a way to optimize the target task, make deep neural networks entertain advantages such as generalization to unseen examples (Hoffman , 2013), sharing learned knowledge among multiple tasks, and discovering disentangling factors of variation (Kingma & Welling, 2013). The remarkable recent successes of the deep convolutional neural networks are particularly based on this ability to learn hierarchical representation for spatial data (Krizhevsky , 2012). For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Mikolov , 2010; Graves, 2013; Cho , 2014; Sutskever , 2014; Vinyals , 2015). However, unlike the spatial data, learning both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991; Mozer, 1993; El Hihi & Bengio, 1995; Lin , 1996; Koutnik , 2014)."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2381
                },
                {
                    "x": 2109,
                    "y": 2381
                },
                {
                    "x": 2109,
                    "y": 2980
                },
                {
                    "x": 441,
                    "y": 2980
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='9' style='font-size:18px'>A promising approach to model such hierarchical and temporal representation is the multiscale<br>RNNs (Schmidhuber, 1992; El Hihi & Bengio, 1995; Koutnik et al., 2014). Based on the observation<br>that high-level abstraction changes slowly with temporal coherency while low-level abstraction<br>has quickly changing features sensitive to the precise local timing (El Hihi & Bengio, 1995), the<br>multiscale RNNs group hidden units into multiple modules of different timescales. In addition to<br>the fact that the architecture fits naturally to the latent hierarchical structures in many temporal data,<br>the multiscale approach provides the following advantages that resolve some inherent problems<br>of standard RNNs: (a) computational efficiency obtained by updating the high-level layers less<br>frequently, (b) efficiently delivering long-term dependencies with fewer updates at the high-level<br>layers, which mitigates the vanishing gradient problem, (c) flexible resource allocation (e.g., more<br>hidden units to the higher layers that focus on modelling long-term dependencies and less hidden<br>units to the lower layers which are in charge of learning short-term dependencies). In addition, the<br>learned latent hierarchical structures can provide useful information to other downstream tasks such</p>",
            "id": 9,
            "page": 1,
            "text": "A promising approach to model such hierarchical and temporal representation is the multiscale RNNs (Schmidhuber, 1992; El Hihi & Bengio, 1995; Koutnik , 2014). Based on the observation that high-level abstraction changes slowly with temporal coherency while low-level abstraction has quickly changing features sensitive to the precise local timing (El Hihi & Bengio, 1995), the multiscale RNNs group hidden units into multiple modules of different timescales. In addition to the fact that the architecture fits naturally to the latent hierarchical structures in many temporal data, the multiscale approach provides the following advantages that resolve some inherent problems of standard RNNs: (a) computational efficiency obtained by updating the high-level layers less frequently, (b) efficiently delivering long-term dependencies with fewer updates at the high-level layers, which mitigates the vanishing gradient problem, (c) flexible resource allocation (e.g., more hidden units to the higher layers that focus on modelling long-term dependencies and less hidden units to the lower layers which are in charge of learning short-term dependencies). In addition, the learned latent hierarchical structures can provide useful information to other downstream tasks such"
        },
        {
            "bounding_box": [
                {
                    "x": 497,
                    "y": 3007
                },
                {
                    "x": 1122,
                    "y": 3007
                },
                {
                    "x": 1122,
                    "y": 3051
                },
                {
                    "x": 497,
                    "y": 3051
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='10' style='font-size:16px'>*Yoshua Bengio is CIFAR Senior Fellow.</p>",
            "id": 10,
            "page": 1,
            "text": "*Yoshua Bengio is CIFAR Senior Fellow."
        },
        {
            "bounding_box": [
                {
                    "x": 64,
                    "y": 879
                },
                {
                    "x": 149,
                    "y": 879
                },
                {
                    "x": 149,
                    "y": 2319
                },
                {
                    "x": 64,
                    "y": 2319
                }
            ],
            "category": "footer",
            "html": "<br><footer id='11' style='font-size:14px'>2017<br>Mar<br>6<br>[cs.LG]<br>arXiv:1609.01704v7</footer>",
            "id": 11,
            "page": 1,
            "text": "2017 Mar 6 [cs.LG] arXiv:1609.01704v7"
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3133
                },
                {
                    "x": 1287,
                    "y": 3133
                },
                {
                    "x": 1287,
                    "y": 3172
                },
                {
                    "x": 1260,
                    "y": 3172
                }
            ],
            "category": "footer",
            "html": "<footer id='12' style='font-size:14px'>1</footer>",
            "id": 12,
            "page": 1,
            "text": "1"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1224,
                    "y": 110
                },
                {
                    "x": 1224,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='13' style='font-size:14px'>Published as a conference paper at ICLR 2017</header>",
            "id": 13,
            "page": 2,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 348
                },
                {
                    "x": 2106,
                    "y": 348
                },
                {
                    "x": 2106,
                    "y": 440
                },
                {
                    "x": 441,
                    "y": 440
                }
            ],
            "category": "paragraph",
            "html": "<p id='14' style='font-size:20px'>as module structures in computer program learning, sub-task structures in hierarchical reinforcement<br>learning, and story segments in video understanding.</p>",
            "id": 14,
            "page": 2,
            "text": "as module structures in computer program learning, sub-task structures in hierarchical reinforcement learning, and story segments in video understanding."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 463
                },
                {
                    "x": 2108,
                    "y": 463
                },
                {
                    "x": 2108,
                    "y": 877
                },
                {
                    "x": 441,
                    "y": 877
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='15' style='font-size:18px'>There have been various approaches to implementing the multiscale RNNs. The most popular<br>approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutnik et al., 2014;<br>Bahdanau et al., 2016) instead of treating them as dynamic variables that can be learned from the<br>data (Schmidhuber, 1991 ; 1992; Chung et al., 2015; 2016). However, considering the fact that<br>non-stationarity is prevalent in temporal data, and that many entities of abstraction such as words<br>and sentences are in variable length, we claim that it is important for an RNN to dynamically adapt<br>its timescales to the particulars of the input entities of various length. While this is trivial if the<br>hierarchical boundary structure is provided (Sordoni et al., 2015), it has been a challenge for an RNN<br>to discover the latent hierarchical structure in temporal data without explicit boundary information.</p>",
            "id": 15,
            "page": 2,
            "text": "There have been various approaches to implementing the multiscale RNNs. The most popular approach is to set the timescales as hyperparameters (El Hihi & Bengio, 1995; Koutnik , 2014; Bahdanau , 2016) instead of treating them as dynamic variables that can be learned from the data (Schmidhuber, 1991 ; 1992; Chung , 2015; 2016). However, considering the fact that non-stationarity is prevalent in temporal data, and that many entities of abstraction such as words and sentences are in variable length, we claim that it is important for an RNN to dynamically adapt its timescales to the particulars of the input entities of various length. While this is trivial if the hierarchical boundary structure is provided (Sordoni , 2015), it has been a challenge for an RNN to discover the latent hierarchical structure in temporal data without explicit boundary information."
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 899
                },
                {
                    "x": 2109,
                    "y": 899
                },
                {
                    "x": 2109,
                    "y": 1815
                },
                {
                    "x": 440,
                    "y": 1815
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='16' style='font-size:18px'>In this paper, we propose a novel multiscale RNN model, which can learn the hierarchical multiscale<br>structure from temporal data without explicit boundary information. This model, called a hierarchical<br>multiscale recurrent neural network (HM-RNN), does not assign fixed update rates, but adaptively<br>determines proper update times corresponding to different abstraction levels of the layers. We find<br>that this model tends to learn fine timescales for low-level layers and coarse timescales for high-level<br>layers. To do this, we introduce a binary boundary detector at each layer. The boundary detector is<br>turned on only at the time steps where a segment of the corresponding abstraction level is completely<br>processed. Otherwise, i.e., during the within segment processing, it stays turned off. Using the<br>hierarchical boundary states, we implement three operations, UPDATE, COPY and FLUSH, and<br>choose one of them at each time step. The UPDATE operation is similar to the usual update rule of<br>the long short-term memory (LSTM) (Hochreiter & Schmidhuber, 1997), except that it is executed<br>sparsely according to the detected boundaries. The COPY operation simply copies the cell and hidden<br>states of the previous time step. Unlike the leaky integration of the LSTM or the Gated Recurrent<br>Unit (GRU) (Cho et al., 2014), the COPY operation retains the whole states without any loss of<br>information. The FLUSH operation is executed when a boundary is detected, where it first ejects the<br>summarized representation of the current segment to the upper layer and then reinitializes the states<br>to start processing the next segment. Learning to select a proper operation at each time step and to<br>detect the boundaries, the HM-RNN discovers the latent hierarchical structure of the sequences. We<br>find that the straight-through estimator (Hinton, 2012; Bengio et al., 2013; Courbariaux et al., 2016)<br>is efficient for training this model containing discrete variables.</p>",
            "id": 16,
            "page": 2,
            "text": "In this paper, we propose a novel multiscale RNN model, which can learn the hierarchical multiscale structure from temporal data without explicit boundary information. This model, called a hierarchical multiscale recurrent neural network (HM-RNN), does not assign fixed update rates, but adaptively determines proper update times corresponding to different abstraction levels of the layers. We find that this model tends to learn fine timescales for low-level layers and coarse timescales for high-level layers. To do this, we introduce a binary boundary detector at each layer. The boundary detector is turned on only at the time steps where a segment of the corresponding abstraction level is completely processed. Otherwise, i.e., during the within segment processing, it stays turned off. Using the hierarchical boundary states, we implement three operations, UPDATE, COPY and FLUSH, and choose one of them at each time step. The UPDATE operation is similar to the usual update rule of the long short-term memory (LSTM) (Hochreiter & Schmidhuber, 1997), except that it is executed sparsely according to the detected boundaries. The COPY operation simply copies the cell and hidden states of the previous time step. Unlike the leaky integration of the LSTM or the Gated Recurrent Unit (GRU) (Cho , 2014), the COPY operation retains the whole states without any loss of information. The FLUSH operation is executed when a boundary is detected, where it first ejects the summarized representation of the current segment to the upper layer and then reinitializes the states to start processing the next segment. Learning to select a proper operation at each time step and to detect the boundaries, the HM-RNN discovers the latent hierarchical structure of the sequences. We find that the straight-through estimator (Hinton, 2012; Bengio , 2013; Courbariaux , 2016) is efficient for training this model containing discrete variables."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1835
                },
                {
                    "x": 2107,
                    "y": 1835
                },
                {
                    "x": 2107,
                    "y": 2160
                },
                {
                    "x": 441,
                    "y": 2160
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='17' style='font-size:18px'>We evaluate our model on two tasks: character-level language modelling and handwriting sequence<br>generation. For the character-level language modelling, the HM-RNN achieves the state-of-the-art<br>results on the Text8 dataset, and comparable results to the state-of-the-art on the Penn Treebank<br>and Hutter Prize Wikipedia datasets. The HM-RNN also outperforms the standard RNN on the<br>handwriting sequence generation using the IAM-OnDB dataset. In addition, we demonstrate that the<br>hierarchical structure found by the HM-RNN is indeed very similar to the intrinsic structure observed<br>in the data. The contributions of this paper are:</p>",
            "id": 17,
            "page": 2,
            "text": "We evaluate our model on two tasks: character-level language modelling and handwriting sequence generation. For the character-level language modelling, the HM-RNN achieves the state-of-the-art results on the Text8 dataset, and comparable results to the state-of-the-art on the Penn Treebank and Hutter Prize Wikipedia datasets. The HM-RNN also outperforms the standard RNN on the handwriting sequence generation using the IAM-OnDB dataset. In addition, we demonstrate that the hierarchical structure found by the HM-RNN is indeed very similar to the intrinsic structure observed in the data. The contributions of this paper are:"
        },
        {
            "bounding_box": [
                {
                    "x": 553,
                    "y": 2190
                },
                {
                    "x": 2109,
                    "y": 2190
                },
                {
                    "x": 2109,
                    "y": 2567
                },
                {
                    "x": 553,
                    "y": 2567
                }
            ],
            "category": "paragraph",
            "html": "<p id='18' style='font-size:16px'>● We propose for the first time an RNN model that can learn a latent hierarchical structure of<br>a sequence without using explicit boundary information.<br>● We show that it is beneficial to utilize the above structure through empirical evaluation.<br>● We show that the straight-through estimator is an efficient way of training a model containing<br>discrete variables.<br>● We propose the slope annealing trick to improve the training procedure based on the<br>straight-through estimator.</p>",
            "id": 18,
            "page": 2,
            "text": "● We propose for the first time an RNN model that can learn a latent hierarchical structure of a sequence without using explicit boundary information. ● We show that it is beneficial to utilize the above structure through empirical evaluation. ● We show that the straight-through estimator is an efficient way of training a model containing discrete variables. ● We propose the slope annealing trick to improve the training procedure based on the straight-through estimator."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2628
                },
                {
                    "x": 884,
                    "y": 2628
                },
                {
                    "x": 884,
                    "y": 2682
                },
                {
                    "x": 445,
                    "y": 2682
                }
            ],
            "category": "paragraph",
            "html": "<p id='19' style='font-size:22px'>2 RELATED WORK</p>",
            "id": 19,
            "page": 2,
            "text": "2 RELATED WORK"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2729
                },
                {
                    "x": 2109,
                    "y": 2729
                },
                {
                    "x": 2109,
                    "y": 3055
                },
                {
                    "x": 442,
                    "y": 3055
                }
            ],
            "category": "paragraph",
            "html": "<p id='20' style='font-size:20px'>Two notable early attempts inspiring our model are Schmidhuber (1992) and El Hihi & Bengio (1995).<br>In these works, it is advocated to stack multiple layers of RNNs in a decreasing order of update<br>frequency for computational and learning efficiency. In Schmidhuber (1992), the author shows a<br>model that can self-organize a hierarchical multiscale structure. Particularly in El Hihi & Bengio<br>(1995), the advantages of incorporating a priori knowledge, \"temporal dependencies are structured<br>hierarchically\", into the RNN architecture is studied. The authors propose an RNN architecture that<br>updates each layer with a fixed but different rate, called a hierarchical RNN.</p>",
            "id": 20,
            "page": 2,
            "text": "Two notable early attempts inspiring our model are Schmidhuber (1992) and El Hihi & Bengio (1995). In these works, it is advocated to stack multiple layers of RNNs in a decreasing order of update frequency for computational and learning efficiency. In Schmidhuber (1992), the author shows a model that can self-organize a hierarchical multiscale structure. Particularly in El Hihi & Bengio (1995), the advantages of incorporating a priori knowledge, \"temporal dependencies are structured hierarchically\", into the RNN architecture is studied. The authors propose an RNN architecture that updates each layer with a fixed but different rate, called a hierarchical RNN."
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3171
                },
                {
                    "x": 1259,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='21' style='font-size:18px'>2</footer>",
            "id": 21,
            "page": 2,
            "text": "2"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1223,
                    "y": 110
                },
                {
                    "x": 1223,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='22' style='font-size:14px'>Published as a conference paper at ICLR 2017</header>",
            "id": 22,
            "page": 3,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 343
                },
                {
                    "x": 2109,
                    "y": 343
                },
                {
                    "x": 2109,
                    "y": 851
                },
                {
                    "x": 441,
                    "y": 851
                }
            ],
            "category": "paragraph",
            "html": "<p id='23' style='font-size:20px'>LSTMs (Hochreiter & Schmidhuber, 1997) employ the multiscale update concept, where the hidden<br>units have different forget and update rates and thus can operate with different timescales. However,<br>unlike our model, these timescales are not organized hierarchically. Although the LSTM has a self-<br>loop for the gradients that helps to capture the long-term dependencies by mitigating the vanishing<br>gradient problem, in practice, itis still limited to a few hundred time steps due to the leaky integration<br>by which the contents to memorize for a long-term is gradually diluted at every time step. Also, the<br>model remains computationally expensive because it has to perform the update at every time step<br>for each unit. However, our model is less prone to these problems because it learns a hierarchical<br>structure such that, by design, high-level layers learn to perform less frequent updates than low-level<br>layers. We hypothesize that this property mitigates the vanishing gradient problem more efficiently<br>while also being computationally more efficient.</p>",
            "id": 23,
            "page": 3,
            "text": "LSTMs (Hochreiter & Schmidhuber, 1997) employ the multiscale update concept, where the hidden units have different forget and update rates and thus can operate with different timescales. However, unlike our model, these timescales are not organized hierarchically. Although the LSTM has a selfloop for the gradients that helps to capture the long-term dependencies by mitigating the vanishing gradient problem, in practice, itis still limited to a few hundred time steps due to the leaky integration by which the contents to memorize for a long-term is gradually diluted at every time step. Also, the model remains computationally expensive because it has to perform the update at every time step for each unit. However, our model is less prone to these problems because it learns a hierarchical structure such that, by design, high-level layers learn to perform less frequent updates than low-level layers. We hypothesize that this property mitigates the vanishing gradient problem more efficiently while also being computationally more efficient."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 874
                },
                {
                    "x": 2108,
                    "y": 874
                },
                {
                    "x": 2108,
                    "y": 1340
                },
                {
                    "x": 441,
                    "y": 1340
                }
            ],
            "category": "paragraph",
            "html": "<p id='24' style='font-size:16px'>A more recent model, the clockwork RNN (CW-RNN) (Koutnik et al., 2014) extends the hierarchical<br>RNN (El Hihi & Bengio, 1995) and the NARX RNN (Lin et al., 1996)1 The CW-RNN tries to<br>solve the issue of using soft timescales in the LSTM, by explicitly assigning hard timescales. In the<br>CW-RNN, hidden units are partitioned into several modules, and different timescales are assigned to<br>the modules such that a module i updates its hidden units at every 2(i-1) -th time step. The CW-RNN<br>is computationally more efficient than the standard RNN including the LSTM since hidden units<br>are updated only at the assigned clock rates. However, finding proper timescales in the CW-RNN<br>remains as a challenge whereas our model learns the intrinsic timescales from the data. In the biscale<br>RNNs (Chung et al., 2016), the authors proposed to model layer-wise timescales adaptively by having<br>additional gating units, however this approach still relies on the soft gating mechanism like LSTMs.</p>",
            "id": 24,
            "page": 3,
            "text": "A more recent model, the clockwork RNN (CW-RNN) (Koutnik , 2014) extends the hierarchical RNN (El Hihi & Bengio, 1995) and the NARX RNN (Lin , 1996)1 The CW-RNN tries to solve the issue of using soft timescales in the LSTM, by explicitly assigning hard timescales. In the CW-RNN, hidden units are partitioned into several modules, and different timescales are assigned to the modules such that a module i updates its hidden units at every 2(i-1) -th time step. The CW-RNN is computationally more efficient than the standard RNN including the LSTM since hidden units are updated only at the assigned clock rates. However, finding proper timescales in the CW-RNN remains as a challenge whereas our model learns the intrinsic timescales from the data. In the biscale RNNs (Chung , 2016), the authors proposed to model layer-wise timescales adaptively by having additional gating units, however this approach still relies on the soft gating mechanism like LSTMs."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1359
                },
                {
                    "x": 2108,
                    "y": 1359
                },
                {
                    "x": 2108,
                    "y": 1727
                },
                {
                    "x": 441,
                    "y": 1727
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='25' style='font-size:20px'>Other forms of Hierarchical RNN (HRNN) architectures have been proposed in the cases where<br>the explicit hierarchical boundary structure is provided. In Ling et al. (2015), after obtaining the<br>word boundary via tokenization, the HRNN architecture is used for neural machine translation by<br>modelling the characters and words using the first and second RNN layers, respectively. A similar<br>HRNN architecture is also adopted in Sordoni et al. (2015) to model dialogue utterances. However,<br>in many cases, hierarchical boundary information is not explicitly observed or expensive to obtain.<br>Also, it is unclear how to deploy more layers than the number of boundary levels that is explicitly<br>observed in the data.</p>",
            "id": 25,
            "page": 3,
            "text": "Other forms of Hierarchical RNN (HRNN) architectures have been proposed in the cases where the explicit hierarchical boundary structure is provided. In Ling  (2015), after obtaining the word boundary via tokenization, the HRNN architecture is used for neural machine translation by modelling the characters and words using the first and second RNN layers, respectively. A similar HRNN architecture is also adopted in Sordoni  (2015) to model dialogue utterances. However, in many cases, hierarchical boundary information is not explicitly observed or expensive to obtain. Also, it is unclear how to deploy more layers than the number of boundary levels that is explicitly observed in the data."
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 1748
                },
                {
                    "x": 2108,
                    "y": 1748
                },
                {
                    "x": 2108,
                    "y": 2073
                },
                {
                    "x": 440,
                    "y": 2073
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='26' style='font-size:16px'>While the above models focus on online prediction problems, where a prediction needs to be made by<br>using only the past data, in some cases, predictions are made after observing the whole sequence. In<br>this setting, the input sequence can be regarded as 1-D spatial data, convolutional neural networks<br>with 1-D kernels are proposed in Kim (2014) and Kim et al. (2015) for language modelling and<br>sentence classification. Also, in Chan et al. (2016) and Bahdanau et al. (2016), the authors proposed<br>to obtain high-level representation of the sequences of reduced length by repeatedly merging or<br>pooling the lower-level representation of the sequences.</p>",
            "id": 26,
            "page": 3,
            "text": "While the above models focus on online prediction problems, where a prediction needs to be made by using only the past data, in some cases, predictions are made after observing the whole sequence. In this setting, the input sequence can be regarded as 1-D spatial data, convolutional neural networks with 1-D kernels are proposed in Kim (2014) and Kim  (2015) for language modelling and sentence classification. Also, in Chan  (2016) and Bahdanau  (2016), the authors proposed to obtain high-level representation of the sequences of reduced length by repeatedly merging or pooling the lower-level representation of the sequences."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2093
                },
                {
                    "x": 2108,
                    "y": 2093
                },
                {
                    "x": 2108,
                    "y": 2280
                },
                {
                    "x": 441,
                    "y": 2280
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='27' style='font-size:16px'>Hierarchical RNN architectures have also been used to discover the segmentation structure in<br>sequences (Fernandez et al., 2007; Kong et al., 2015). It is however different to our model in the<br>sense that they optimize the objective with explicit labels on the hierarchical segments while our<br>model discovers the intrinsic structure only from the sequences without segment label information.</p>",
            "id": 27,
            "page": 3,
            "text": "Hierarchical RNN architectures have also been used to discover the segmentation structure in sequences (Fernandez , 2007; Kong , 2015). It is however different to our model in the sense that they optimize the objective with explicit labels on the hierarchical segments while our model discovers the intrinsic structure only from the sequences without segment label information."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2301
                },
                {
                    "x": 2108,
                    "y": 2301
                },
                {
                    "x": 2108,
                    "y": 2717
                },
                {
                    "x": 441,
                    "y": 2717
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='28' style='font-size:16px'>The COPY operation used in our model can be related to Zoneout (Krueger et al., 2016) which<br>is a recurrent generalization of stochastic depth (Huang et al., 2016). In Zoneout, an identity<br>transformation is randomly applied to each hidden unit at each time step according to a Bernoulli<br>distribution. This results in occasional copy operations of the previous hidden states. While the focus<br>of Zoneout is to propose a regularization technique similar to dropout (Srivastava et al., 2014) (where<br>the regularization strength is controlled by a hyperparameter), our model learns (a) to dynamically<br>determine when to copy from the context inputs and (b) to discover the hierarchical multiscale<br>structure and representation. Although the main goal of our proposed model is not regularization, we<br>found that our model also shows very good generalization performance.</p>",
            "id": 28,
            "page": 3,
            "text": "The COPY operation used in our model can be related to Zoneout (Krueger , 2016) which is a recurrent generalization of stochastic depth (Huang , 2016). In Zoneout, an identity transformation is randomly applied to each hidden unit at each time step according to a Bernoulli distribution. This results in occasional copy operations of the previous hidden states. While the focus of Zoneout is to propose a regularization technique similar to dropout (Srivastava , 2014) (where the regularization strength is controlled by a hyperparameter), our model learns (a) to dynamically determine when to copy from the context inputs and (b) to discover the hierarchical multiscale structure and representation. Although the main goal of our proposed model is not regularization, we found that our model also shows very good generalization performance."
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3133
                },
                {
                    "x": 1289,
                    "y": 3133
                },
                {
                    "x": 1289,
                    "y": 3171
                },
                {
                    "x": 1260,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='29' style='font-size:14px'>3</footer>",
            "id": 29,
            "page": 3,
            "text": "3"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 109
                },
                {
                    "x": 1224,
                    "y": 109
                },
                {
                    "x": 1224,
                    "y": 158
                },
                {
                    "x": 444,
                    "y": 158
                }
            ],
            "category": "header",
            "html": "<header id='30' style='font-size:16px'>Published as a conference paper at ICLR 2017</header>",
            "id": 30,
            "page": 4,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 438,
                    "y": 266
                },
                {
                    "x": 2112,
                    "y": 266
                },
                {
                    "x": 2112,
                    "y": 784
                },
                {
                    "x": 438,
                    "y": 784
                }
            ],
            "category": "figure",
            "html": "<figure><img id='31' style='font-size:14px' alt=\"h2 h2 h2 h2 h2 h2 h23 h2 h2\n○ ○ ○\nh1 h1 h,2 h1 h14 h1s ht ○ h1 h12 ······ h1 h1 h1\nX1 X2 X3 X4 X5 X1 X2 X3 X4 X5\nword1 word2 word1 word2\nphrase1 phrase1\n(a) (b)\" data-coord=\"top-left:(438,266); bottom-right:(2112,784)\" /></figure>",
            "id": 31,
            "page": 4,
            "text": "h2 h2 h2 h2 h2 h2 h23 h2 h2 ○ ○ ○ h1 h1 h,2 h1 h14 h1s ht ○ h1 h12 ······ h1 h1 h1 X1 X2 X3 X4 X5 X1 X2 X3 X4 X5 word1 word2 word1 word2 phrase1 phrase1 (a) (b)"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 811
                },
                {
                    "x": 2111,
                    "y": 811
                },
                {
                    "x": 2111,
                    "y": 911
                },
                {
                    "x": 441,
                    "y": 911
                }
            ],
            "category": "caption",
            "html": "<br><caption id='32' style='font-size:20px'>Figure 1: (a) The HRNN architecture, which requires the knowledge of the hierarchical boundaries.<br>(b) The HM-RNN architecture that discovers the hierarchical multiscale structure in the data.</caption>",
            "id": 32,
            "page": 4,
            "text": "Figure 1: (a) The HRNN architecture, which requires the knowledge of the hierarchical boundaries. (b) The HM-RNN architecture that discovers the hierarchical multiscale structure in the data."
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 991
                },
                {
                    "x": 1894,
                    "y": 991
                },
                {
                    "x": 1894,
                    "y": 1051
                },
                {
                    "x": 440,
                    "y": 1051
                }
            ],
            "category": "paragraph",
            "html": "<p id='33' style='font-size:22px'>3 HIERARCHICAL MULTISCALE RECURRENT NEURAL NETW ORKS</p>",
            "id": 33,
            "page": 4,
            "text": "3 HIERARCHICAL MULTISCALE RECURRENT NEURAL NETW ORKS"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1101
                },
                {
                    "x": 786,
                    "y": 1101
                },
                {
                    "x": 786,
                    "y": 1151
                },
                {
                    "x": 443,
                    "y": 1151
                }
            ],
            "category": "paragraph",
            "html": "<p id='34' style='font-size:20px'>3.1 MOTIVATION</p>",
            "id": 34,
            "page": 4,
            "text": "3.1 MOTIVATION"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1186
                },
                {
                    "x": 2109,
                    "y": 1186
                },
                {
                    "x": 2109,
                    "y": 1464
                },
                {
                    "x": 441,
                    "y": 1464
                }
            ],
            "category": "paragraph",
            "html": "<p id='35' style='font-size:20px'>To begin with, we provide an example of how a stacked RNN can model temporal data in an ideal<br>setting, i.e., when the hierarchy of segments is provided (Sordoni et al., 2015; Ling et al., 2015). In<br>Figure 1 (a), we depict a hierarchical RNN (HRNN) for language modelling with two layers: the first<br>layer receives characters as inputs and generates word-level representations (C2W-RNN), and the<br>second layer takes the word-level representations as inputs and yields phrase-level representations<br>(W2P-RNN).</p>",
            "id": 35,
            "page": 4,
            "text": "To begin with, we provide an example of how a stacked RNN can model temporal data in an ideal setting, i.e., when the hierarchy of segments is provided (Sordoni , 2015; Ling , 2015). In Figure 1 (a), we depict a hierarchical RNN (HRNN) for language modelling with two layers: the first layer receives characters as inputs and generates word-level representations (C2W-RNN), and the second layer takes the word-level representations as inputs and yields phrase-level representations (W2P-RNN)."
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 1487
                },
                {
                    "x": 2107,
                    "y": 1487
                },
                {
                    "x": 2107,
                    "y": 1810
                },
                {
                    "x": 440,
                    "y": 1810
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='36' style='font-size:18px'>As shown, by means of the provided end-of-word labels, the C2W-RNN obtains word-level represen-<br>tation after processing the last character of each word and passes the word-level representation to the<br>W2P-RNN. Then, the W2P-RNN performs an update of the phrase-level representation. Note that the<br>hidden states of the W2P-RNN remains unchanged while all the characters of a word are processed by<br>the C2W-RNN. When the C2W-RNN starts to process the next word, its hidden states are reinitialized<br>using the latest hidden states of the W2P-RNN, which contain summarized representation of all the<br>words that have been processed by that time step, in that phrase.</p>",
            "id": 36,
            "page": 4,
            "text": "As shown, by means of the provided end-of-word labels, the C2W-RNN obtains word-level representation after processing the last character of each word and passes the word-level representation to the W2P-RNN. Then, the W2P-RNN performs an update of the phrase-level representation. Note that the hidden states of the W2P-RNN remains unchanged while all the characters of a word are processed by the C2W-RNN. When the C2W-RNN starts to process the next word, its hidden states are reinitialized using the latest hidden states of the W2P-RNN, which contain summarized representation of all the words that have been processed by that time step, in that phrase."
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 1833
                },
                {
                    "x": 2108,
                    "y": 1833
                },
                {
                    "x": 2108,
                    "y": 2108
                },
                {
                    "x": 440,
                    "y": 2108
                }
            ],
            "category": "paragraph",
            "html": "<p id='37' style='font-size:18px'>From this simple example, we can see the advantages of having a hierarchical multiscale structure: (1)<br>as the W2P-RNN is updated at a much slower update rate than the C2W-RNN, a considerable amount<br>of computation can be saved, (2) gradients are backpropagated through a much smaller number of<br>time steps, and (3) layer-wise capacity control becomes possible (e.g., use a smaller number of hidden<br>units in the first layer which models short-term dependencies but whose updates are invoked much<br>more often).</p>",
            "id": 37,
            "page": 4,
            "text": "From this simple example, we can see the advantages of having a hierarchical multiscale structure: (1) as the W2P-RNN is updated at a much slower update rate than the C2W-RNN, a considerable amount of computation can be saved, (2) gradients are backpropagated through a much smaller number of time steps, and (3) layer-wise capacity control becomes possible (e.g., use a smaller number of hidden units in the first layer which models short-term dependencies but whose updates are invoked much more often)."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2132
                },
                {
                    "x": 2109,
                    "y": 2132
                },
                {
                    "x": 2109,
                    "y": 2638
                },
                {
                    "x": 441,
                    "y": 2638
                }
            ],
            "category": "paragraph",
            "html": "<p id='38' style='font-size:20px'>Can an RNN discover such hierarchical multiscale structure without explicit hierarchical boundary<br>information? Considering the fact that the boundary information is difficult to obtain (for example,<br>consider languages where words are not always cleanly separated by spaces or punctuation symbols,<br>and imperfect rules are used to separately perform segmentation) or usually not provided at all, this is<br>a legitimate problem. It gets worse when we consider higher-level concepts which we would like<br>the RNN to discover autonomously. In Section 2, we discussed the limitations of the existing RNN<br>models under this setting, which either have to update all units at every time step or use fixed update<br>frequencies (El Hihi & Bengio, 1995; Koutnik et al., 2014). Unfortunately, this kind of approach is<br>not well suited to the case where different segments in the hierarchical decomposition have different<br>lengths: for example, different words have different lengths, SO a fixed hierarchy would not update its<br>upper-level units in synchrony with the natural boundaries in the data.</p>",
            "id": 38,
            "page": 4,
            "text": "Can an RNN discover such hierarchical multiscale structure without explicit hierarchical boundary information? Considering the fact that the boundary information is difficult to obtain (for example, consider languages where words are not always cleanly separated by spaces or punctuation symbols, and imperfect rules are used to separately perform segmentation) or usually not provided at all, this is a legitimate problem. It gets worse when we consider higher-level concepts which we would like the RNN to discover autonomously. In Section 2, we discussed the limitations of the existing RNN models under this setting, which either have to update all units at every time step or use fixed update frequencies (El Hihi & Bengio, 1995; Koutnik , 2014). Unfortunately, this kind of approach is not well suited to the case where different segments in the hierarchical decomposition have different lengths: for example, different words have different lengths, SO a fixed hierarchy would not update its upper-level units in synchrony with the natural boundaries in the data."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2696
                },
                {
                    "x": 975,
                    "y": 2696
                },
                {
                    "x": 975,
                    "y": 2743
                },
                {
                    "x": 445,
                    "y": 2743
                }
            ],
            "category": "paragraph",
            "html": "<p id='39' style='font-size:18px'>3.2 THE PROPOSED MODEL</p>",
            "id": 39,
            "page": 4,
            "text": "3.2 THE PROPOSED MODEL"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2782
                },
                {
                    "x": 2109,
                    "y": 2782
                },
                {
                    "x": 2109,
                    "y": 2971
                },
                {
                    "x": 442,
                    "y": 2971
                }
            ],
            "category": "paragraph",
            "html": "<p id='40' style='font-size:18px'>A key element of our model is the introduction of a parametrized boundary detector, which outputs<br>a binary value, in each layer of a stacked RNN, and learns when a segment should end in such<br>a way to optimize the overall target objective. Whenever the boundary detector is turned on at a<br>time step of layer l (i.e., when the boundary state is 1), the model considers this to be the end of a</p>",
            "id": 40,
            "page": 4,
            "text": "A key element of our model is the introduction of a parametrized boundary detector, which outputs a binary value, in each layer of a stacked RNN, and learns when a segment should end in such a way to optimize the overall target objective. Whenever the boundary detector is turned on at a time step of layer l (i.e., when the boundary state is 1), the model considers this to be the end of a"
        },
        {
            "bounding_box": [
                {
                    "x": 499,
                    "y": 3006
                },
                {
                    "x": 1886,
                    "y": 3006
                },
                {
                    "x": 1886,
                    "y": 3053
                },
                {
                    "x": 499,
                    "y": 3053
                }
            ],
            "category": "paragraph",
            "html": "<p id='41' style='font-size:18px'>1The acronym NARX stands for Non-linear Auto-Regressive model with eXogenous inputs.</p>",
            "id": 41,
            "page": 4,
            "text": "1The acronym NARX stands for Non-linear Auto-Regressive model with eXogenous inputs."
        },
        {
            "bounding_box": [
                {
                    "x": 1258,
                    "y": 3133
                },
                {
                    "x": 1288,
                    "y": 3133
                },
                {
                    "x": 1288,
                    "y": 3171
                },
                {
                    "x": 1258,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='42' style='font-size:16px'>4</footer>",
            "id": 42,
            "page": 4,
            "text": "4"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 112
                },
                {
                    "x": 1223,
                    "y": 112
                },
                {
                    "x": 1223,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='43' style='font-size:14px'>Published as a conference paper at ICLR 2017</header>",
            "id": 43,
            "page": 5,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 349
                },
                {
                    "x": 2105,
                    "y": 349
                },
                {
                    "x": 2105,
                    "y": 584
                },
                {
                    "x": 442,
                    "y": 584
                }
            ],
            "category": "paragraph",
            "html": "<p id='44' style='font-size:16px'>segment corresponding to the latent abstraction level of that layer (e.g., word or phrase) and feeds the<br>summarized representation of the detected segment into the upper layer (l + 1). Using the boundary<br>states, at each time step, each layer selects one of the following operations: UPDATE, COPY or<br>FLUSH. The selection is determined by (1) the boundary state of the current time step in the layer<br>below zt-1 and (2) the boundary state of the previous time step in the same layer zt-1.</p>",
            "id": 44,
            "page": 5,
            "text": "segment corresponding to the latent abstraction level of that layer (e.g., word or phrase) and feeds the summarized representation of the detected segment into the upper layer (l + 1). Using the boundary states, at each time step, each layer selects one of the following operations: UPDATE, COPY or FLUSH. The selection is determined by (1) the boundary state of the current time step in the layer below zt-1 and (2) the boundary state of the previous time step in the same layer zt-1."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 606
                },
                {
                    "x": 2105,
                    "y": 606
                },
                {
                    "x": 2105,
                    "y": 744
                },
                {
                    "x": 442,
                    "y": 744
                }
            ],
            "category": "paragraph",
            "html": "<p id='45' style='font-size:16px'>In the following, we describe an HM-RNN based on the LSTM update rule. We call this model<br>a hierarchical multiscale LSTM (HM-LSTM). Consider an HM-LSTM model of L layers (l =<br>1,... , L) which, at each layer l, performs the following update at time step t:</p>",
            "id": 45,
            "page": 5,
            "text": "In the following, we describe an HM-RNN based on the LSTM update rule. We call this model a hierarchical multiscale LSTM (HM-LSTM). Consider an HM-LSTM model of L layers (l = 1,... , L) which, at each layer l, performs the following update at time step t:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 855
                },
                {
                    "x": 2104,
                    "y": 855
                },
                {
                    "x": 2104,
                    "y": 956
                },
                {
                    "x": 442,
                    "y": 956
                }
            ],
            "category": "paragraph",
            "html": "<p id='46' style='font-size:16px'>Here, h and c denote the hidden and cell states, respectively. The function fHM-LSTM is implemented<br>the cell state is updated by:<br>as follows. First, using the two boundary states zt-1 and zt-1 ,</p>",
            "id": 46,
            "page": 5,
            "text": "Here, h and c denote the hidden and cell states, respectively. The function fHM-LSTM is implemented the cell state is updated by: as follows. First, using the two boundary states zt-1 and zt-1 ,"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1178
                },
                {
                    "x": 1123,
                    "y": 1178
                },
                {
                    "x": 1123,
                    "y": 1223
                },
                {
                    "x": 443,
                    "y": 1223
                }
            ],
            "category": "paragraph",
            "html": "<p id='47' style='font-size:14px'>and then the hidden state is obtained by:</p>",
            "id": 47,
            "page": 5,
            "text": "and then the hidden state is obtained by:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1386
                },
                {
                    "x": 2106,
                    "y": 1386
                },
                {
                    "x": 2106,
                    "y": 1570
                },
                {
                    "x": 442,
                    "y": 1570
                }
            ],
            "category": "paragraph",
            "html": "<p id='48' style='font-size:14px'>Here, (f,i, o) are forget, input, output gates, and g is a cell proposal vector. Note that unlike the<br>LSTM, it is not necessary to compute these gates and cell proposal values at every time step. For<br>example, in the case of the COPY operation, we do not need to compute any of these values and thus<br>can save computations.</p>",
            "id": 48,
            "page": 5,
            "text": "Here, (f,i, o) are forget, input, output gates, and g is a cell proposal vector. Note that unlike the LSTM, it is not necessary to compute these gates and cell proposal values at every time step. For example, in the case of the COPY operation, we do not need to compute any of these values and thus can save computations."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1592
                },
                {
                    "x": 2107,
                    "y": 1592
                },
                {
                    "x": 2107,
                    "y": 2151
                },
                {
                    "x": 441,
                    "y": 2151
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='49' style='font-size:16px'>The COPY operation, which simply performs (cl, hl) ← (ct-1, ht-1), implements the observation<br>that an upper layer should keep its state unchanged until it receives the summarized input from<br>the lower layer. The UPDATE operation is performed to update the summary representation of the<br>layer l if the boundary zt-1 is detected from the layer below but the boundary zt-1 was not found<br>at the previous time step. Hence, the UPDATE operation is executed sparsely unlike the standard<br>RNNs where it is executed at every time step, making it computationally inefficient. If a boundary is<br>detected, the FLUSH operation is executed. The FLUSH operation consists of two sub-operations:<br>(a) EJECT to pass the current state to the upper layer and then (b) RESET to reinitialize the state<br>before starting to read a new segment. This operation implicitly forces the upper layer to absorb the<br>summary information of the lower layer segment, because otherwise it will be lost. Note that the<br>FLUSH operation is a hard reset in the sense that it completely erases all the previous states of the<br>same layer, which is different from the soft reset or soft forget operation in the GRU or LSTM.</p>",
            "id": 49,
            "page": 5,
            "text": "The COPY operation, which simply performs (cl, hl) ← (ct-1, ht-1), implements the observation that an upper layer should keep its state unchanged until it receives the summarized input from the lower layer. The UPDATE operation is performed to update the summary representation of the layer l if the boundary zt-1 is detected from the layer below but the boundary zt-1 was not found at the previous time step. Hence, the UPDATE operation is executed sparsely unlike the standard RNNs where it is executed at every time step, making it computationally inefficient. If a boundary is detected, the FLUSH operation is executed. The FLUSH operation consists of two sub-operations: (a) EJECT to pass the current state to the upper layer and then (b) RESET to reinitialize the state before starting to read a new segment. This operation implicitly forces the upper layer to absorb the summary information of the lower layer segment, because otherwise it will be lost. Note that the FLUSH operation is a hard reset in the sense that it completely erases all the previous states of the same layer, which is different from the soft reset or soft forget operation in the GRU or LSTM."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2174
                },
                {
                    "x": 2103,
                    "y": 2174
                },
                {
                    "x": 2103,
                    "y": 2268
                },
                {
                    "x": 442,
                    "y": 2268
                }
            ],
            "category": "paragraph",
            "html": "<p id='50' style='font-size:18px'>Whenever needed (depending on the chosen operation), the gate values (ft, it, ot), the cell proposal<br>gl, and the pre-activation of the boundary detector �� 2 then obtained by:<br>are</p>",
            "id": 50,
            "page": 5,
            "text": "Whenever needed (depending on the chosen operation), the gate values (ft, it, ot), the cell proposal gl, and the pre-activation of the boundary detector �� 2 then obtained by: are"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2566
                },
                {
                    "x": 555,
                    "y": 2566
                },
                {
                    "x": 555,
                    "y": 2607
                },
                {
                    "x": 443,
                    "y": 2607
                }
            ],
            "category": "paragraph",
            "html": "<p id='51' style='font-size:16px'>where</p>",
            "id": 51,
            "page": 5,
            "text": "where"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2860
                },
                {
                    "x": 2104,
                    "y": 2860
                },
                {
                    "x": 2104,
                    "y": 3054
                },
                {
                    "x": 444,
                    "y": 3054
                }
            ],
            "category": "paragraph",
            "html": "<p id='52' style='font-size:14px'>Here, we use W3 E R(4dim(h2)+1)x dim(hl-1) U골 E R(4dim(h2)+1)xdim(h2) denote state transition<br>to<br>,<br>parameters from layer i to layer j, and b E R4dim(h2)+1 is a bias term. In the last layer L, the<br>2�t can also be implemented as a function of ht, e.g., �� = hard sigm(Uhi).</p>",
            "id": 52,
            "page": 5,
            "text": "Here, we use W3 E R(4dim(h2)+1)x dim(hl-1) U골 E R(4dim(h2)+1)xdim(h2) denote state transition to , parameters from layer i to layer j, and b E R4dim(h2)+1 is a bias term. In the last layer L, the 2�t can also be implemented as a function of ht, e.g., �� = hard sigm(Uhi)."
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3132
                },
                {
                    "x": 1289,
                    "y": 3132
                },
                {
                    "x": 1289,
                    "y": 3170
                },
                {
                    "x": 1260,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='53' style='font-size:14px'>5</footer>",
            "id": 53,
            "page": 5,
            "text": "5"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1224,
                    "y": 110
                },
                {
                    "x": 1224,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='54' style='font-size:14px'>Published as a conference paper at ICLR 2017</header>",
            "id": 54,
            "page": 6,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 703,
                    "y": 287
                },
                {
                    "x": 1922,
                    "y": 287
                },
                {
                    "x": 1922,
                    "y": 729
                },
                {
                    "x": 703,
                    "y": 729
                }
            ],
            "category": "figure",
            "html": "<figure><img id='55' style='font-size:14px' alt=\"l+1 l+1 h 3\nt- 1 t\nzt-1\nUl+1\nWe+1\nl\nzt-1 Zt g3\n1- 2t-1 hlt h2 he x t+1\n1\ng2\nUl\nWe-1\nl-1\n2t gt\nl-1 h 1\nt t\" data-coord=\"top-left:(703,287); bottom-right:(1922,729)\" /></figure>",
            "id": 55,
            "page": 6,
            "text": "l+1 l+1 h 3 t- 1 t zt-1 Ul+1 We+1 l zt-1 Zt g3 1- 2t-1 hlt h2 he x t+1 1 g2 Ul We-1 l-1 2t gt l-1 h 1 t t"
        },
        {
            "bounding_box": [
                {
                    "x": 466,
                    "y": 755
                },
                {
                    "x": 2078,
                    "y": 755
                },
                {
                    "x": 2078,
                    "y": 804
                },
                {
                    "x": 466,
                    "y": 804
                }
            ],
            "category": "caption",
            "html": "<caption id='56' style='font-size:18px'>Figure 2: Left: The gating mechanism of the HM-RNN. Right: The output module when L = 3.</caption>",
            "id": 56,
            "page": 6,
            "text": "Figure 2: Left: The gating mechanism of the HM-RNN. Right: The output module when L = 3."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 889
                },
                {
                    "x": 2108,
                    "y": 889
                },
                {
                    "x": 2108,
                    "y": 1030
                },
                {
                    "x": 441,
                    "y": 1030
                }
            ],
            "category": "paragraph",
            "html": "<p id='57' style='font-size:18px'>top-down connection is ignored, and we use ht = Xt. Since the input should not be omitted, we<br>set zo = 1 for all t. Also, we do not use the boundary detector for the last layer. The hard sigm is<br>defined by hard sigm(x) = max (0, min (1, ax2+1 )) with a being the slope variable.</p>",
            "id": 57,
            "page": 6,
            "text": "top-down connection is ignored, and we use ht = Xt. Since the input should not be omitted, we set zo = 1 for all t. Also, we do not use the boundary detector for the last layer. The hard sigm is defined by hard sigm(x) = max (0, min (1, ax2+1 )) with a being the slope variable."
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 1046
                },
                {
                    "x": 2111,
                    "y": 1046
                },
                {
                    "x": 2111,
                    "y": 1352
                },
                {
                    "x": 440,
                    "y": 1352
                }
            ],
            "category": "paragraph",
            "html": "<p id='58' style='font-size:16px'>Unlike the standard LSTM, the HM-LSTM has a top-down connection from (l + 1) to l, which is<br>allowed to be activated only if a boundary is detected at the previous time step of the layer l (see<br>Eq. 6). This makes the layer l to be initialized with more long-term information after the boundary<br>is detected and execute the FLUSH operation. In addition, the input from the lower layer (l - 1)<br>becomes effective only when a boundary is detected at the current time step in the layer (l - 1) due<br>to the binary gate zl-1 · Figure 2 (left) shows the gating mechanism of the HM-LSTM at time step t.</p>",
            "id": 58,
            "page": 6,
            "text": "Unlike the standard LSTM, the HM-LSTM has a top-down connection from (l + 1) to l, which is allowed to be activated only if a boundary is detected at the previous time step of the layer l (see Eq. 6). This makes the layer l to be initialized with more long-term information after the boundary is detected and execute the FLUSH operation. In addition, the input from the lower layer (l - 1) becomes effective only when a boundary is detected at the current time step in the layer (l - 1) due to the binary gate zl-1 · Figure 2 (left) shows the gating mechanism of the HM-LSTM at time step t."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1355
                },
                {
                    "x": 1315,
                    "y": 1355
                },
                {
                    "x": 1315,
                    "y": 1403
                },
                {
                    "x": 444,
                    "y": 1403
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='59' style='font-size:20px'>Finally, the binary boundary state zt is obtained by:</p>",
            "id": 59,
            "page": 6,
            "text": "Finally, the binary boundary state zt is obtained by:"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1495
                },
                {
                    "x": 2075,
                    "y": 1495
                },
                {
                    "x": 2075,
                    "y": 1550
                },
                {
                    "x": 442,
                    "y": 1550
                }
            ],
            "category": "paragraph",
            "html": "<p id='60' style='font-size:14px'>For the binarization function fbound : R → {0,1}, we can either use a deterministic step function:</p>",
            "id": 60,
            "page": 6,
            "text": "For the binarization function fbound : R → {0,1}, we can either use a deterministic step function:"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 1705
                },
                {
                    "x": 2108,
                    "y": 1705
                },
                {
                    "x": 2108,
                    "y": 1847
                },
                {
                    "x": 440,
                    "y": 1847
                }
            ],
            "category": "paragraph",
            "html": "<p id='61' style='font-size:16px'>or sample from a Bernoulli distribution zl ~ Bernoulli(z). Although this binary decision is a key to<br>our model, it is usually difficult to use stochastic gradient descent to train such model with discrete<br>decisions as it is not differentiable.</p>",
            "id": 61,
            "page": 6,
            "text": "or sample from a Bernoulli distribution zl ~ Bernoulli(z). Although this binary decision is a key to our model, it is usually difficult to use stochastic gradient descent to train such model with discrete decisions as it is not differentiable."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1901
                },
                {
                    "x": 1456,
                    "y": 1901
                },
                {
                    "x": 1456,
                    "y": 1948
                },
                {
                    "x": 443,
                    "y": 1948
                }
            ],
            "category": "paragraph",
            "html": "<p id='62' style='font-size:16px'>3.3 COMPUTING GRADIENT OF BOUNDARY DETECTOR</p>",
            "id": 62,
            "page": 6,
            "text": "3.3 COMPUTING GRADIENT OF BOUNDARY DETECTOR"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1986
                },
                {
                    "x": 2109,
                    "y": 1986
                },
                {
                    "x": 2109,
                    "y": 2447
                },
                {
                    "x": 442,
                    "y": 2447
                }
            ],
            "category": "paragraph",
            "html": "<p id='63' style='font-size:18px'>Training neural networks with discrete variables requires more efforts since the standard backpropa-<br>gation is no longer applicable due to the non-differentiability. Among a few methods for training a<br>neural network with discrete variables such as the REINFORCE (Williams, 1992; Mnih & Gregor,<br>2014) and the straight-through estimator (Hinton, 2012; Bengio et al., 2013), we use the straight-<br>through estimator to train our model. The straight-through estimator is a biased estimator because the<br>non-differentiable function used in the forward pass (i.e., the step function in our case) is replaced by<br>a differentiable function during the backward pass (i.e., the hard sigmoid function in our case). The<br>straight-through estimator, however, is much simpler and often works more efficiently in practice<br>than other unbiased but high-variance estimators such as the REINFORCE. The straight-through<br>estimator has also been used in Courbariaux et al. (2016) and Vezhnevets et al. (2016).</p>",
            "id": 63,
            "page": 6,
            "text": "Training neural networks with discrete variables requires more efforts since the standard backpropagation is no longer applicable due to the non-differentiability. Among a few methods for training a neural network with discrete variables such as the REINFORCE (Williams, 1992; Mnih & Gregor, 2014) and the straight-through estimator (Hinton, 2012; Bengio , 2013), we use the straightthrough estimator to train our model. The straight-through estimator is a biased estimator because the non-differentiable function used in the forward pass (i.e., the step function in our case) is replaced by a differentiable function during the backward pass (i.e., the hard sigmoid function in our case). The straight-through estimator, however, is much simpler and often works more efficiently in practice than other unbiased but high-variance estimators such as the REINFORCE. The straight-through estimator has also been used in Courbariaux  (2016) and Vezhnevets  (2016)."
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 2467
                },
                {
                    "x": 2109,
                    "y": 2467
                },
                {
                    "x": 2109,
                    "y": 2794
                },
                {
                    "x": 440,
                    "y": 2794
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='64' style='font-size:16px'>The Slope Annealing Trick. In our experiment, we use the slope annealing trick to reduce the bias<br>of the straight-through estimator. The idea is to reduce the discrepancy between the two functions<br>used during the forward pass and the backward pass. That is, by gradually increasing the slope a of<br>the hard sigmoid function, we make the hard sigmoid be close to the step function. Note that starting<br>with a high slope value from the beginning can make the training difficult while it is more applicable<br>later when the model parameters become more stable. In our experiments, starting from slope a = 1,<br>we slowly increase the slope until it reaches a threshold with an appropriate scheduling.</p>",
            "id": 64,
            "page": 6,
            "text": "The Slope Annealing Trick. In our experiment, we use the slope annealing trick to reduce the bias of the straight-through estimator. The idea is to reduce the discrepancy between the two functions used during the forward pass and the backward pass. That is, by gradually increasing the slope a of the hard sigmoid function, we make the hard sigmoid be close to the step function. Note that starting with a high slope value from the beginning can make the training difficult while it is more applicable later when the model parameters become more stable. In our experiments, starting from slope a = 1, we slowly increase the slope until it reaches a threshold with an appropriate scheduling."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2858
                },
                {
                    "x": 839,
                    "y": 2858
                },
                {
                    "x": 839,
                    "y": 2909
                },
                {
                    "x": 445,
                    "y": 2909
                }
            ],
            "category": "paragraph",
            "html": "<p id='65' style='font-size:20px'>4 EXPERIMENTS</p>",
            "id": 65,
            "page": 6,
            "text": "4 EXPERIMENTS"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2958
                },
                {
                    "x": 2108,
                    "y": 2958
                },
                {
                    "x": 2108,
                    "y": 3055
                },
                {
                    "x": 442,
                    "y": 3055
                }
            ],
            "category": "paragraph",
            "html": "<p id='66' style='font-size:18px'>We evaluate the proposed model on two tasks, character-level language modelling and handwriting<br>sequence generation. Character-level language modelling is a representative example of discrete</p>",
            "id": 66,
            "page": 6,
            "text": "We evaluate the proposed model on two tasks, character-level language modelling and handwriting sequence generation. Character-level language modelling is a representative example of discrete"
        },
        {
            "bounding_box": [
                {
                    "x": 1261,
                    "y": 3137
                },
                {
                    "x": 1287,
                    "y": 3137
                },
                {
                    "x": 1287,
                    "y": 3170
                },
                {
                    "x": 1261,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='67' style='font-size:16px'>6</footer>",
            "id": 67,
            "page": 6,
            "text": "6"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 111
                },
                {
                    "x": 1223,
                    "y": 111
                },
                {
                    "x": 1223,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='68' style='font-size:14px'>Published as a conference paper at ICLR 2017</header>",
            "id": 68,
            "page": 7,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 307,
                    "y": 272
                },
                {
                    "x": 2303,
                    "y": 272
                },
                {
                    "x": 2303,
                    "y": 1014
                },
                {
                    "x": 307,
                    "y": 1014
                }
            ],
            "category": "table",
            "html": "<table id='69' style='font-size:16px'><tr><td colspan=\"3\">Penn Treebank</td><td colspan=\"2\">Hutter Prize Wikipedia</td></tr><tr><td colspan=\"2\">Model</td><td>BPC</td><td>Model</td><td>BPC</td></tr><tr><td>Norm-stabilized RNN</td><td>(Krueger & Memisevic, 2015)</td><td>1.48</td><td>Stacked LSTM (Graves, 2013)</td><td>1.67</td></tr><tr><td>CW-RNN</td><td>(Koutnik et al., 2014)</td><td>1.46</td><td>MRNN (Sutskever et al., 2011)</td><td>1.60</td></tr><tr><td>HF-MRNN</td><td>(Mikolov et al., 2012)</td><td>1.41</td><td>GF-LSTM (Chung et al., 2015)</td><td>1.58</td></tr><tr><td>MI-RNN</td><td>(Wu et al., 2016)</td><td>1.39</td><td>Grid-LSTM (Kalchbrenner et al., 2015)</td><td>1.47</td></tr><tr><td>ME n-gram</td><td>(Mikolov et al., 2012)</td><td>1.37</td><td>MI-LSTM (Wu et al., 2016)</td><td>1.44</td></tr><tr><td>BatchNorm LSTM</td><td>(Cooijmans et al., 2016)</td><td>1.32</td><td>Recurrent Memory Array Structures (Rocki, 2016a)</td><td>1.40</td></tr><tr><td>Zoneout RNN</td><td>(Krueger et al., 2016)</td><td>1.27</td><td>SF-LSTM (Rocki, 2016b)‡</td><td>1.37</td></tr><tr><td>HyperNetworks</td><td>(Ha et al., 2016)</td><td>1.27</td><td>HyperNetworks (Ha et al., 2016)</td><td>1.35</td></tr><tr><td>LayerNorm HyperNetworks</td><td>(Ha et al., 2016)</td><td>1.23</td><td>LayerNorm HyperNetworks (Ha et al., 2016)</td><td>1.34</td></tr><tr><td colspan=\"2\">LayerNorm CW-RNN�</td><td>1.40</td><td>Recurrent Highway Networks (Zilly et al., 2016)</td><td>1.32</td></tr><tr><td colspan=\"2\">LayerNorm LSTM+</td><td>1.29</td><td>LayerNorm LSTM+</td><td>1.39</td></tr><tr><td>LayerNorm HM-LSTM</td><td>Sampling</td><td>1.27</td><td>HM-LSTM</td><td>1.34</td></tr><tr><td>LayerNorm HM-LSTM</td><td>Soft*</td><td>1.27</td><td>LayerNorm HM-LSTM</td><td>1.32</td></tr><tr><td>LayerNorm HM-LSTM</td><td>Step Fn.</td><td>1.25</td><td>PAQ8hp12 (Mahoney, 2005)</td><td>1.32</td></tr><tr><td>LayerNorm HM-LSTM</td><td>Step Fn. & Slope Annealing</td><td>1.24</td><td>decomp8 (Mahoney, 2009)</td><td>1.28</td></tr></table>",
            "id": 69,
            "page": 7,
            "text": "Penn Treebank Hutter Prize Wikipedia  Model BPC Model BPC  Norm-stabilized RNN (Krueger & Memisevic, 2015) 1.48 Stacked LSTM (Graves, 2013) 1.67  CW-RNN (Koutnik , 2014) 1.46 MRNN (Sutskever , 2011) 1.60  HF-MRNN (Mikolov , 2012) 1.41 GF-LSTM (Chung , 2015) 1.58  MI-RNN (Wu , 2016) 1.39 Grid-LSTM (Kalchbrenner , 2015) 1.47  ME n-gram (Mikolov , 2012) 1.37 MI-LSTM (Wu , 2016) 1.44  BatchNorm LSTM (Cooijmans , 2016) 1.32 Recurrent Memory Array Structures (Rocki, 2016a) 1.40  Zoneout RNN (Krueger , 2016) 1.27 SF-LSTM (Rocki, 2016b)‡ 1.37  HyperNetworks (Ha , 2016) 1.27 HyperNetworks (Ha , 2016) 1.35  LayerNorm HyperNetworks (Ha , 2016) 1.23 LayerNorm HyperNetworks (Ha , 2016) 1.34  LayerNorm CW-RNN� 1.40 Recurrent Highway Networks (Zilly , 2016) 1.32  LayerNorm LSTM+ 1.29 LayerNorm LSTM+ 1.39  LayerNorm HM-LSTM Sampling 1.27 HM-LSTM 1.34  LayerNorm HM-LSTM Soft* 1.27 LayerNorm HM-LSTM 1.32  LayerNorm HM-LSTM Step Fn. 1.25 PAQ8hp12 (Mahoney, 2005) 1.32  LayerNorm HM-LSTM Step Fn. & Slope Annealing 1.24 decomp8 (Mahoney, 2009)"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 1045
                },
                {
                    "x": 2110,
                    "y": 1045
                },
                {
                    "x": 2110,
                    "y": 1278
                },
                {
                    "x": 440,
                    "y": 1278
                }
            ],
            "category": "paragraph",
            "html": "<p id='70' style='font-size:16px'>Table 1: BPC on the Penn Treebank test set (left) and Hutter Prize Wikipedia test set (right). (*) This<br>model is a variant of the HM-LSTM that does not discretize the boundary detector states. (t) These<br>models are implemented by the authors to evaluate the performance using layer normalization (Ba<br>et al., 2016) with the additional output module. (1) This method uses test error signals for predicting<br>the next characters, which makes it not comparable to other methods that do not.</p>",
            "id": 70,
            "page": 7,
            "text": "Table 1: BPC on the Penn Treebank test set (left) and Hutter Prize Wikipedia test set (right). (*) This model is a variant of the HM-LSTM that does not discretize the boundary detector states. (t) These models are implemented by the authors to evaluate the performance using layer normalization (Ba , 2016) with the additional output module. (1) This method uses test error signals for predicting the next characters, which makes it not comparable to other methods that do not."
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 1364
                },
                {
                    "x": 2109,
                    "y": 1364
                },
                {
                    "x": 2109,
                    "y": 1504
                },
                {
                    "x": 440,
                    "y": 1504
                }
            ],
            "category": "paragraph",
            "html": "<p id='71' style='font-size:16px'>sequence modelling, where the discrete symbols form a distinct hierarchical multiscale structure. The<br>performance on real-valued sequences is tested on the handwriting sequence generation in which a<br>relatively clear hierarchical multiscale structure exists compared to other data such as speech signals.</p>",
            "id": 71,
            "page": 7,
            "text": "sequence modelling, where the discrete symbols form a distinct hierarchical multiscale structure. The performance on real-valued sequences is tested on the handwriting sequence generation in which a relatively clear hierarchical multiscale structure exists compared to other data such as speech signals."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1557
                },
                {
                    "x": 1361,
                    "y": 1557
                },
                {
                    "x": 1361,
                    "y": 1604
                },
                {
                    "x": 443,
                    "y": 1604
                }
            ],
            "category": "paragraph",
            "html": "<p id='72' style='font-size:18px'>4.1 CHARACTER-LEVEL LANGUAGE MODELLING</p>",
            "id": 72,
            "page": 7,
            "text": "4.1 CHARACTER-LEVEL LANGUAGE MODELLING"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1645
                },
                {
                    "x": 2106,
                    "y": 1645
                },
                {
                    "x": 2106,
                    "y": 1736
                },
                {
                    "x": 441,
                    "y": 1736
                }
            ],
            "category": "paragraph",
            "html": "<p id='73' style='font-size:20px'>A sequence modelling task aims at learning the probability distribution over sequences by minimizing<br>the negative log-likelihood of the training sequences:</p>",
            "id": 73,
            "page": 7,
            "text": "A sequence modelling task aims at learning the probability distribution over sequences by minimizing the negative log-likelihood of the training sequences:"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 1912
                },
                {
                    "x": 2110,
                    "y": 1912
                },
                {
                    "x": 2110,
                    "y": 2143
                },
                {
                    "x": 440,
                    "y": 2143
                }
            ],
            "category": "paragraph",
            "html": "<p id='74' style='font-size:18px'>where 0 is the model parameter, N is the number of training sequences, and Tn is the length of the<br>n-th sequence. A symbol at time t of sequence n is denoted by xn, and xn<t denotes all previous<br>symbols at time t. We evaluate our model on three benchmark text corpora: (1) Penn Treebank, (2)<br>Text8 and (3) Hutter Prize Wikipedia. We use the bits-per-character (BPC), E[- log2 p(xt+1 I x≤t)],<br>as the evaluation metric.</p>",
            "id": 74,
            "page": 7,
            "text": "where 0 is the model parameter, N is the number of training sequences, and Tn is the length of the n-th sequence. A symbol at time t of sequence n is denoted by xn, and xn<t denotes all previous symbols at time t. We evaluate our model on three benchmark text corpora: (1) Penn Treebank, (2) Text8 and (3) Hutter Prize Wikipedia. We use the bits-per-character (BPC), E[- log2 p(xt+1 I x≤t)], as the evaluation metric."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2189
                },
                {
                    "x": 2107,
                    "y": 2189
                },
                {
                    "x": 2107,
                    "y": 2562
                },
                {
                    "x": 442,
                    "y": 2562
                }
            ],
            "category": "paragraph",
            "html": "<p id='75' style='font-size:18px'>Model We use a model consisting of an input embedding layer, an RNN module and an output<br>module. The input embedding layer maps each input symbol into 128-dimensional continuous<br>vector without using any non-linearity. The RNN module is the HM-LSTM, described in Section 3,<br>with three layers. The output module is a feedforward neural network with two layers, an output<br>embedding layer and a softmax layer. Figure 2 (right) shows a diagram of the output module. At each<br>time step, the output embedding layer receives the hidden states of the three RNN layers as input. In<br>order to adaptively control the importance of each layer at each time step, we also introduce three<br>scalar gating units gl E R to each of the layer outputs:</p>",
            "id": 75,
            "page": 7,
            "text": "Model We use a model consisting of an input embedding layer, an RNN module and an output module. The input embedding layer maps each input symbol into 128-dimensional continuous vector without using any non-linearity. The RNN module is the HM-LSTM, described in Section 3, with three layers. The output module is a feedforward neural network with two layers, an output embedding layer and a softmax layer. Figure 2 (right) shows a diagram of the output module. At each time step, the output embedding layer receives the hidden states of the three RNN layers as input. In order to adaptively control the importance of each layer at each time step, we also introduce three scalar gating units gl E R to each of the layer outputs:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2660
                },
                {
                    "x": 2032,
                    "y": 2660
                },
                {
                    "x": 2032,
                    "y": 2722
                },
                {
                    "x": 441,
                    "y": 2722
                }
            ],
            "category": "paragraph",
            "html": "<p id='76' style='font-size:20px'>where we E R�l=1 dim(hl) is the weight parameter. The output embedding he is computed by:</p>",
            "id": 76,
            "page": 7,
            "text": "where we E R�l=1 dim(hl) is the weight parameter. The output embedding he is computed by:"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 2892
                },
                {
                    "x": 2109,
                    "y": 2892
                },
                {
                    "x": 2109,
                    "y": 3055
                },
                {
                    "x": 440,
                    "y": 3055
                }
            ],
            "category": "paragraph",
            "html": "<p id='77' style='font-size:18px'>where L = 3 and ReLU(x) = max(0, x) (Nair & Hinton, 2010). Finally, the probability distribution<br>exj<br>for the next target character is computed by the softmax function, sof tmax(xj) = where<br>EK=1 exk'<br>each output class is a character.</p>",
            "id": 77,
            "page": 7,
            "text": "where L = 3 and ReLU(x) = max(0, x) (Nair & Hinton, 2010). Finally, the probability distribution exj for the next target character is computed by the softmax function, sof tmax(xj) = where EK=1 exk' each output class is a character."
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3169
                },
                {
                    "x": 1260,
                    "y": 3169
                }
            ],
            "category": "footer",
            "html": "<footer id='78' style='font-size:14px'>7</footer>",
            "id": 78,
            "page": 7,
            "text": "7"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1224,
                    "y": 111
                },
                {
                    "x": 1224,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='79' style='font-size:14px'>Published as a conference paper at ICLR 2017</header>",
            "id": 79,
            "page": 8,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 845,
                    "y": 276
                },
                {
                    "x": 1687,
                    "y": 276
                },
                {
                    "x": 1687,
                    "y": 712
                },
                {
                    "x": 845,
                    "y": 712
                }
            ],
            "category": "table",
            "html": "<table id='80' style='font-size:14px'><tr><td colspan=\"2\">Text8</td></tr><tr><td>Model</td><td>BPC</td></tr><tr><td>td-LSTM (Zhang et al., 2016)</td><td>1.63</td></tr><tr><td>HF-MRNN (Mikolov et al., 2012)</td><td>1.54</td></tr><tr><td>MI-RNN (Wu et al., 2016)</td><td>1.52</td></tr><tr><td>Skipping-RNN (Pachitariu & Sahani, 2013)</td><td>1.48</td></tr><tr><td>MI-LSTM (Wu et al., 2016)</td><td>1.44</td></tr><tr><td>BatchNorm LSTM (Cooijmans et al., 2016)</td><td>1.36</td></tr><tr><td>HM-LSTM</td><td>1.32</td></tr><tr><td>LayerNorm HM-LSTM</td><td>1.29</td></tr></table>",
            "id": 80,
            "page": 8,
            "text": "Text8  Model BPC  td-LSTM (Zhang , 2016) 1.63  HF-MRNN (Mikolov , 2012) 1.54  MI-RNN (Wu , 2016) 1.52  Skipping-RNN (Pachitariu & Sahani, 2013) 1.48  MI-LSTM (Wu , 2016) 1.44  BatchNorm LSTM (Cooijmans , 2016) 1.36  HM-LSTM 1.32  LayerNorm HM-LSTM"
        },
        {
            "bounding_box": [
                {
                    "x": 984,
                    "y": 747
                },
                {
                    "x": 1563,
                    "y": 747
                },
                {
                    "x": 1563,
                    "y": 791
                },
                {
                    "x": 984,
                    "y": 791
                }
            ],
            "category": "caption",
            "html": "<caption id='81' style='font-size:14px'>Table 2: BPC on the Text8 test set.</caption>",
            "id": 81,
            "page": 8,
            "text": "Table 2: BPC on the Text8 test set."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 879
                },
                {
                    "x": 2107,
                    "y": 879
                },
                {
                    "x": 2107,
                    "y": 1386
                },
                {
                    "x": 441,
                    "y": 1386
                }
            ],
            "category": "paragraph",
            "html": "<p id='82' style='font-size:20px'>Penn Treebank We process the Penn Treebank dataset (Marcus et al., 1993) by following the<br>procedure introduced in Mikolov et al. (2012). Each update is done by using a mini-batch of 64<br>examples of length 100 to prevent the memory overflow problem when unfolding the RNN in time<br>for backpropagation. The last hidden state of a sequence is used to initialize the hidden state of the<br>next sequence to approximate the full backpropagation. We train the model using Adam (Kingma &<br>Ba, 2014) with an initial learning rate of 0.002. We divide the learning rate by a factor of 50 when<br>the validation negative log-likelihood stopped decreasing. The norm of the gradient is clipped with a<br>threshold of 1 (Mikolov et al., 2010; Pascanu et al., 2012). We also apply layer normalization (Ba<br>et al., 2016) to our models. For all of the character-level language modelling experiments, we apply<br>the same procedure, but only change the number of hidden units, mini-batch size and the initial<br>learning rate.</p>",
            "id": 82,
            "page": 8,
            "text": "Penn Treebank We process the Penn Treebank dataset (Marcus , 1993) by following the procedure introduced in Mikolov  (2012). Each update is done by using a mini-batch of 64 examples of length 100 to prevent the memory overflow problem when unfolding the RNN in time for backpropagation. The last hidden state of a sequence is used to initialize the hidden state of the next sequence to approximate the full backpropagation. We train the model using Adam (Kingma & Ba, 2014) with an initial learning rate of 0.002. We divide the learning rate by a factor of 50 when the validation negative log-likelihood stopped decreasing. The norm of the gradient is clipped with a threshold of 1 (Mikolov , 2010; Pascanu , 2012). We also apply layer normalization (Ba , 2016) to our models. For all of the character-level language modelling experiments, we apply the same procedure, but only change the number of hidden units, mini-batch size and the initial learning rate."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1407
                },
                {
                    "x": 2107,
                    "y": 1407
                },
                {
                    "x": 2107,
                    "y": 1823
                },
                {
                    "x": 442,
                    "y": 1823
                }
            ],
            "category": "paragraph",
            "html": "<p id='83' style='font-size:20px'>For the Penn Treebank dataset, we use 512 units in each layer of the HM-LSTM and for the output<br>embedding layer. In Table 1 (left), we compare the test BPCs of four variants of our model to other<br>baseline models. Note that the HM-LSTM using the step function for the hard boundary decision<br>outperforms the others using either sampling or soft boundary decision (i.e., hard sigmoid). The test<br>BPC is further improved with the slope annealing trick, which reduces the bias of the straight-through<br>estimator. We increased the slope a with the following schedule a = min (5, 1 + 0.04 · Nepoch), where<br>Nepoch is the maximum number of epochs. The HM-LSTM achieves test BPC score of 1.24. For the<br>remaining tasks, we fixed the hard boundary decision using the step function without slope annealing<br>due to the difficulty of finding a good annealing schedule on large-scale datasets.</p>",
            "id": 83,
            "page": 8,
            "text": "For the Penn Treebank dataset, we use 512 units in each layer of the HM-LSTM and for the output embedding layer. In Table 1 (left), we compare the test BPCs of four variants of our model to other baseline models. Note that the HM-LSTM using the step function for the hard boundary decision outperforms the others using either sampling or soft boundary decision (i.e., hard sigmoid). The test BPC is further improved with the slope annealing trick, which reduces the bias of the straight-through estimator. We increased the slope a with the following schedule a = min (5, 1 + 0.04 · Nepoch), where Nepoch is the maximum number of epochs. The HM-LSTM achieves test BPC score of 1.24. For the remaining tasks, we fixed the hard boundary decision using the step function without slope annealing due to the difficulty of finding a good annealing schedule on large-scale datasets."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1869
                },
                {
                    "x": 2108,
                    "y": 1869
                },
                {
                    "x": 2108,
                    "y": 2148
                },
                {
                    "x": 441,
                    "y": 2148
                }
            ],
            "category": "paragraph",
            "html": "<p id='84' style='font-size:18px'>Text8 The Text8 dataset (Mahoney, 2009) consists of 100M characters extracted from the Wikipedia<br>corpus. Text8 contains only alphabets and spaces, and thus we have total 27 symbols. In order to<br>compare with other previous works, we follow the data splits used in Mikolov et al. (2012). We use<br>1024 units for each HM-LSTM layer and 2048 units for the output embedding layer. The mini-batch<br>size and the initial learning rate are set to 128 and 0.001, respectively. The results are shown in<br>Table 2. The HM-LSTM obtains the state-of-the-art test BPC 1.29.</p>",
            "id": 84,
            "page": 8,
            "text": "Text8 The Text8 dataset (Mahoney, 2009) consists of 100M characters extracted from the Wikipedia corpus. Text8 contains only alphabets and spaces, and thus we have total 27 symbols. In order to compare with other previous works, we follow the data splits used in Mikolov  (2012). We use 1024 units for each HM-LSTM layer and 2048 units for the output embedding layer. The mini-batch size and the initial learning rate are set to 128 and 0.001, respectively. The results are shown in Table 2. The HM-LSTM obtains the state-of-the-art test BPC 1.29."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2193
                },
                {
                    "x": 2107,
                    "y": 2193
                },
                {
                    "x": 2107,
                    "y": 2566
                },
                {
                    "x": 442,
                    "y": 2566
                }
            ],
            "category": "paragraph",
            "html": "<p id='85' style='font-size:18px'>Hutter Prize Wikipedia The Hutter Prize Wikipedia (enwik8) dataset (Hutter, 2012) contains<br>205 symbols including XML markups and special characters. We follow the data splits used in Graves<br>(2013) where the first 90M characters are used to train the model, the next 5M characters for validation,<br>and the remainders for the test set. We use the same model size, mini-batch size and the initial<br>learning rate as in the Text8. In Table 1 (right), we show the HM-LSTM achieving the test BPC 1.32,<br>which is a tie with the state-of-the-art result among the neural models. Although the neural models,<br>show remarkable performances, their compression performance is still behind the best models such<br>as PAQ8hp12 (Mahoney, 2005) and decomp8 (Mahoney, 2009).</p>",
            "id": 85,
            "page": 8,
            "text": "Hutter Prize Wikipedia The Hutter Prize Wikipedia (enwik8) dataset (Hutter, 2012) contains 205 symbols including XML markups and special characters. We follow the data splits used in Graves (2013) where the first 90M characters are used to train the model, the next 5M characters for validation, and the remainders for the test set. We use the same model size, mini-batch size and the initial learning rate as in the Text8. In Table 1 (right), we show the HM-LSTM achieving the test BPC 1.32, which is a tie with the state-of-the-art result among the neural models. Although the neural models, show remarkable performances, their compression performance is still behind the best models such as PAQ8hp12 (Mahoney, 2005) and decomp8 (Mahoney, 2009)."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2613
                },
                {
                    "x": 2108,
                    "y": 2613
                },
                {
                    "x": 2108,
                    "y": 2892
                },
                {
                    "x": 441,
                    "y": 2892
                }
            ],
            "category": "paragraph",
            "html": "<p id='86' style='font-size:18px'>Visualizing Learned Hierarchical Multiscale Structure In Figure 3 and 4, we visualize the<br>boundaries detected by the boundary detectors of the HM-LSTM while reading a character sequence<br>of total length 270 taken from the validation set of either the Penn Treebank or Hutter Prize Wikipedia<br>dataset. Due to the page width limit, the figure contains the sequence partitioned into three segments<br>of length 90. The white blocks indicate boundaries zl = 1 while the black blocks indicate the<br>non-boundaries zl = 0.</p>",
            "id": 86,
            "page": 8,
            "text": "Visualizing Learned Hierarchical Multiscale Structure In Figure 3 and 4, we visualize the boundaries detected by the boundary detectors of the HM-LSTM while reading a character sequence of total length 270 taken from the validation set of either the Penn Treebank or Hutter Prize Wikipedia dataset. Due to the page width limit, the figure contains the sequence partitioned into three segments of length 90. The white blocks indicate boundaries zl = 1 while the black blocks indicate the non-boundaries zl = 0."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2915
                },
                {
                    "x": 2108,
                    "y": 2915
                },
                {
                    "x": 2108,
                    "y": 3054
                },
                {
                    "x": 442,
                    "y": 3054
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='87' style='font-size:16px'>Interestingly in both figures, we can observe that the boundary detector of the first layer, 21, tends<br>to be turned on when it sees a space or after it sees a space, which is a reasonable breakpoint to<br>separate between words. This is somewhat surprising because the model self-organizes this structure</p>",
            "id": 87,
            "page": 8,
            "text": "Interestingly in both figures, we can observe that the boundary detector of the first layer, 21, tends to be turned on when it sees a space or after it sees a space, which is a reasonable breakpoint to separate between words. This is somewhat surprising because the model self-organizes this structure"
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3135
                },
                {
                    "x": 1288,
                    "y": 3135
                },
                {
                    "x": 1288,
                    "y": 3170
                },
                {
                    "x": 1260,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='88' style='font-size:18px'>8</footer>",
            "id": 88,
            "page": 8,
            "text": "8"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1223,
                    "y": 111
                },
                {
                    "x": 1223,
                    "y": 157
                },
                {
                    "x": 445,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='89' style='font-size:16px'>Published as a conference paper at ICLR 2017</header>",
            "id": 89,
            "page": 9,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 279,
                    "y": 306
                },
                {
                    "x": 2286,
                    "y": 306
                },
                {
                    "x": 2286,
                    "y": 682
                },
                {
                    "x": 279,
                    "y": 682
                }
            ],
            "category": "figure",
            "html": "<figure><img id='90' style='font-size:14px' alt=\"Wikipedia Line 1\nz 2\nz\ne r n h I g h I a n d s a n d d o e s n o t p a r t a k e o f a n y o t h e r a r e a s C r o p s T h e m o s t f a m o u s m e m b e r o f t\nWikipedia Line 2\nz 2\nz1\nh i s c r o p s y S t e m s o f f e e ] ] b u t o n e o t h e m o r e u s e f u p I a n t s s s 0 r g h u m 」 a d r y - I a n\nWikipedia Line 3\n2\nz\nZ 1\nd g r a I n · A n C i e n t c u I t u r e s a I s 0 e x i s t e d a I I a / o n g t h e [ [ N I / e ] ] , a n d i n m 0 d e r n - d a y [ [ G h a n a ]\" data-coord=\"top-left:(279,306); bottom-right:(2286,682)\" /></figure>",
            "id": 90,
            "page": 9,
            "text": "Wikipedia Line 1 z 2 z e r n h I g h I a n d s a n d d o e s n o t p a r t a k e o f a n y o t h e r a r e a s C r o p s T h e m o s t f a m o u s m e m b e r o f t Wikipedia Line 2 z 2 z1 h i s c r o p s y S t e m s o f f e e ] ] b u t o n e o t h e m o r e u s e f u p I a n t s s s 0 r g h u m 」 a d r y - I a n Wikipedia Line 3 2 z Z 1 d g r a I n · A n C i e n t c u I t u r e s a I s 0 e x i s t e d a I I a / o n g t h e [ [ N I / e ] ] , a n d i n m 0 d e r n - d a y [ [ G h a n a ]"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 731
                },
                {
                    "x": 2109,
                    "y": 731
                },
                {
                    "x": 2109,
                    "y": 838
                },
                {
                    "x": 442,
                    "y": 838
                }
            ],
            "category": "caption",
            "html": "<caption id='91' style='font-size:20px'>Figure 3: Hierarchical multiscale structure in the Wikipedia dataset captured by the boundary<br>detectors of the HM-LSTM.<br>Penn Treebank Line 1</caption>",
            "id": 91,
            "page": 9,
            "text": "Figure 3: Hierarchical multiscale structure in the Wikipedia dataset captured by the boundary detectors of the HM-LSTM. Penn Treebank Line 1"
        },
        {
            "bounding_box": [
                {
                    "x": 249,
                    "y": 859
                },
                {
                    "x": 2266,
                    "y": 859
                },
                {
                    "x": 2266,
                    "y": 1462
                },
                {
                    "x": 249,
                    "y": 1462
                }
            ],
            "category": "figure",
            "html": "<figure><img id='92' style='font-size:14px' alt=\"|h\nZ\n||h2||\nZ\n||h1||\nC o n s u m e r s m a y W a n t t o m o V e t h e i r t e I e p h 0 n e s a I i t t I e C I o S e r t o t h e t V s e t < u n k > < u n k > W a t C\nPenn Treebank Line 2\n||h3||\nZ\n||h2||\nZ\n||b1||\nh I n g a b C s m 0 n d a y n I g h t f 0 0 t b a I I C a n n 0 W V 0 t e d u r I n g < u n k > f 0 r t h e g r e a t e s t p T a y I n N y e a\nPenn Treebank Line 3\n||h3||\nZ'\n||h2||\nz\n|||||\nr s f r o m a m o n g f 0 u r 0 r f i V e < u n k > < u n k > t W o W e e k s a g o V I e W e r s o f s e V e r a I n b C < u n k > C o n s u m e r\" data-coord=\"top-left:(249,859); bottom-right:(2266,1462)\" /></figure>",
            "id": 92,
            "page": 9,
            "text": "|h Z ||h2|| Z ||h1|| C o n s u m e r s m a y W a n t t o m o V e t h e i r t e I e p h 0 n e s a I i t t I e C I o S e r t o t h e t V s e t < u n k > < u n k > W a t C Penn Treebank Line 2 ||h3|| Z ||h2|| Z ||b1|| h I n g a b C s m 0 n d a y n I g h t f 0 0 t b a I I C a n n 0 W V 0 t e d u r I n g < u n k > f 0 r t h e g r e a t e s t p T a y I n N y e a Penn Treebank Line 3 ||h3|| Z\" ||h2|| z ||||| r s f r o m a m o n g f 0 u r 0 r f i V e < u n k > < u n k > t W o W e e k s a g o V I e W e r s o f s e V e r a I n b C < u n k > C o n s u m e r"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1506
                },
                {
                    "x": 2106,
                    "y": 1506
                },
                {
                    "x": 2106,
                    "y": 1599
                },
                {
                    "x": 441,
                    "y": 1599
                }
            ],
            "category": "caption",
            "html": "<caption id='93' style='font-size:20px'>Figure 4: The l2 -norm of the hidden states shown together with the states of the boundary detectors<br>of the HM-LSTM.</caption>",
            "id": 93,
            "page": 9,
            "text": "Figure 4: The l2 -norm of the hidden states shown together with the states of the boundary detectors of the HM-LSTM."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1689
                },
                {
                    "x": 2108,
                    "y": 1689
                },
                {
                    "x": 2108,
                    "y": 2060
                },
                {
                    "x": 442,
                    "y": 2060
                }
            ],
            "category": "paragraph",
            "html": "<p id='94' style='font-size:18px'>without any explicit boundary information. In Figure 3, we observe that the 21 tends to detect the<br>boundaries of the words but also fires within the words, where the 22 tends to fire when it sees either<br>an end of a word or 2, 3-grams. In Figure 4, we also see flushing in the middle of a word, e.g.,<br>\"tele-FLUSH-phone\". Note that \"tele\" is a prefix after which a various number of postfixes can follow.<br>From these, it seems that the model uses to some extent the concept of surprise to learn the boundary.<br>Although interpretation of the second layer boundaries is not as apparent as the first layer boundaries,<br>it seems to segment at reasonable semantic / syntactic boundaries, e.g., \"consumers may\" - \"want to<br>move their telephones a\" - \"little closer to the tv set <unk>\", and SO on.</p>",
            "id": 94,
            "page": 9,
            "text": "without any explicit boundary information. In Figure 3, we observe that the 21 tends to detect the boundaries of the words but also fires within the words, where the 22 tends to fire when it sees either an end of a word or 2, 3-grams. In Figure 4, we also see flushing in the middle of a word, e.g., \"tele-FLUSH-phone\". Note that \"tele\" is a prefix after which a various number of postfixes can follow. From these, it seems that the model uses to some extent the concept of surprise to learn the boundary. Although interpretation of the second layer boundaries is not as apparent as the first layer boundaries, it seems to segment at reasonable semantic / syntactic boundaries, e.g., \"consumers may\" - \"want to move their telephones a\" - \"little closer to the tv set <unk>\", and SO on."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2083
                },
                {
                    "x": 2107,
                    "y": 2083
                },
                {
                    "x": 2107,
                    "y": 2450
                },
                {
                    "x": 442,
                    "y": 2450
                }
            ],
            "category": "paragraph",
            "html": "<p id='95' style='font-size:18px'>Another remarkable point is the fact that we do not pose any constraint on the number of boundaries<br>that the model can fire up. The model, however, learns that it is more beneficial to delay the<br>information ejection to some extent. This is somewhat counterintuitive because it might look more<br>beneficial to feed the fresh update to the upper layers at every time step without any delay. We<br>conjecture the reason that the model works in this way is due to the FLUSH operation that poses an<br>implicit constraint on the frequency of boundary detection, because it contains both a reward (feeding<br>fresh information to upper layers) and a penalty (erasing accumulated information). The model finds<br>an optimal balance between the reward and the penalty.</p>",
            "id": 95,
            "page": 9,
            "text": "Another remarkable point is the fact that we do not pose any constraint on the number of boundaries that the model can fire up. The model, however, learns that it is more beneficial to delay the information ejection to some extent. This is somewhat counterintuitive because it might look more beneficial to feed the fresh update to the upper layers at every time step without any delay. We conjecture the reason that the model works in this way is due to the FLUSH operation that poses an implicit constraint on the frequency of boundary detection, because it contains both a reward (feeding fresh information to upper layers) and a penalty (erasing accumulated information). The model finds an optimal balance between the reward and the penalty."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2469
                },
                {
                    "x": 2109,
                    "y": 2469
                },
                {
                    "x": 2109,
                    "y": 2756
                },
                {
                    "x": 441,
                    "y": 2756
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='96' style='font-size:22px'>To understand the update mechanism more intuitively, in Figure 4, we also depict the heatmap of the<br>l2-norm of the hidden states along with the states of the boundary detectors. As we expect, we can<br>see that there is no change in the norm value within segments due to the COPY operation. Also, the<br>color of ||h1 II changes quickly (at every time step) because there is no COPY operation in the first<br>layer. The color of ||h2|| changes less frequently based on the states of 21 and zt-1. The color of<br>||h3|| changes even slowly, i.e., only when 22 = 1.</p>",
            "id": 96,
            "page": 9,
            "text": "To understand the update mechanism more intuitively, in Figure 4, we also depict the heatmap of the l2-norm of the hidden states along with the states of the boundary detectors. As we expect, we can see that there is no change in the norm value within segments due to the COPY operation. Also, the color of ||h1 II changes quickly (at every time step) because there is no COPY operation in the first layer. The color of ||h2|| changes less frequently based on the states of 21 and zt-1. The color of ||h3|| changes even slowly, i.e., only when 22 = 1."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2777
                },
                {
                    "x": 2110,
                    "y": 2777
                },
                {
                    "x": 2110,
                    "y": 3056
                },
                {
                    "x": 441,
                    "y": 3056
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='97' style='font-size:20px'>A notable advantage of the proposed architecture is that the internal process of the RNN becomes<br>more interpretable. For example, we can substitute the states of 21 and z2-1 into Eq. 2 and infer<br>which operation among the UPDATE, COPY and FLUSH was applied to the second layer at time step<br>t. We can also inspect the update frequencies of the layers simply by counting how many UPDATE<br>and FLUSH operations were made in each layer. For example in Figure 4, we see that the first layer<br>updates at every time step (which is 270 UPDATE operations), the second layer updates 56 times,</p>",
            "id": 97,
            "page": 9,
            "text": "A notable advantage of the proposed architecture is that the internal process of the RNN becomes more interpretable. For example, we can substitute the states of 21 and z2-1 into Eq. 2 and infer which operation among the UPDATE, COPY and FLUSH was applied to the second layer at time step t. We can also inspect the update frequencies of the layers simply by counting how many UPDATE and FLUSH operations were made in each layer. For example in Figure 4, we see that the first layer updates at every time step (which is 270 UPDATE operations), the second layer updates 56 times,"
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 3132
                },
                {
                    "x": 1290,
                    "y": 3132
                },
                {
                    "x": 1290,
                    "y": 3169
                },
                {
                    "x": 1259,
                    "y": 3169
                }
            ],
            "category": "footer",
            "html": "<footer id='98' style='font-size:16px'>9</footer>",
            "id": 98,
            "page": 9,
            "text": "9"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1224,
                    "y": 110
                },
                {
                    "x": 1224,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='99' style='font-size:14px'>Published as a conference paper at ICLR 2017</header>",
            "id": 99,
            "page": 10,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 784,
                    "y": 273
                },
                {
                    "x": 1752,
                    "y": 273
                },
                {
                    "x": 1752,
                    "y": 503
                },
                {
                    "x": 784,
                    "y": 503
                }
            ],
            "category": "table",
            "html": "<table id='100' style='font-size:14px'><tr><td colspan=\"2\">IAM-OnDB</td></tr><tr><td>Model</td><td>Average Log-Likelihood</td></tr><tr><td>Standard LSTM</td><td>1081</td></tr><tr><td>HM-LSTM</td><td>1137</td></tr><tr><td>HM-LSTM & Slope Annealing</td><td>1167</td></tr></table>",
            "id": 100,
            "page": 10,
            "text": "IAM-OnDB  Model Average Log-Likelihood  Standard LSTM 1081  HM-LSTM 1137  HM-LSTM & Slope Annealing"
        },
        {
            "bounding_box": [
                {
                    "x": 661,
                    "y": 535
                },
                {
                    "x": 1883,
                    "y": 535
                },
                {
                    "x": 1883,
                    "y": 584
                },
                {
                    "x": 661,
                    "y": 584
                }
            ],
            "category": "caption",
            "html": "<caption id='101' style='font-size:16px'>Table 3: Average log-likelihood per sequence on the IAM-OnDB test set.</caption>",
            "id": 101,
            "page": 10,
            "text": "Table 3: Average log-likelihood per sequence on the IAM-OnDB test set."
        },
        {
            "bounding_box": [
                {
                    "x": 485,
                    "y": 601
                },
                {
                    "x": 2028,
                    "y": 601
                },
                {
                    "x": 2028,
                    "y": 829
                },
                {
                    "x": 485,
                    "y": 829
                }
            ],
            "category": "figure",
            "html": "<br><figure><img id='102' style='font-size:20px' alt=\"| Ph ~ om de by him in Ph non\nm a\nm a cle by ん m\nVisualization by segments using Visualization by segments using\nthe ground truth of pen-tip location the states of ~2\" data-coord=\"top-left:(485,601); bottom-right:(2028,829)\" /></figure>",
            "id": 102,
            "page": 10,
            "text": "| Ph ~ om de by him in Ph non m a m a cle by ん m Visualization by segments using Visualization by segments using the ground truth of pen-tip location the states of ~2"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 853
                },
                {
                    "x": 2106,
                    "y": 853
                },
                {
                    "x": 2106,
                    "y": 908
                },
                {
                    "x": 440,
                    "y": 908
                }
            ],
            "category": "paragraph",
            "html": "<p id='103' style='font-size:18px'>Figure 5: The visualization by segments based on either the given pen-tip location or states of the 22.</p>",
            "id": 103,
            "page": 10,
            "text": "Figure 5: The visualization by segments based on either the given pen-tip location or states of the 22."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 992
                },
                {
                    "x": 2108,
                    "y": 992
                },
                {
                    "x": 2108,
                    "y": 1176
                },
                {
                    "x": 442,
                    "y": 1176
                }
            ],
            "category": "paragraph",
            "html": "<p id='104' style='font-size:18px'>and only 9 updates has made in the third layer. Note that, by design, the first layer performs UPDATE<br>operation at every time step and then the number of UPDATE operations decreases as the layer level<br>increases. In this example, the total number of updates is 335 for the HM-LSTM which is 60% of<br>reduction from the 810 updates of the standard RNN architecture.</p>",
            "id": 104,
            "page": 10,
            "text": "and only 9 updates has made in the third layer. Note that, by design, the first layer performs UPDATE operation at every time step and then the number of UPDATE operations decreases as the layer level increases. In this example, the total number of updates is 335 for the HM-LSTM which is 60% of reduction from the 810 updates of the standard RNN architecture."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1230
                },
                {
                    "x": 1273,
                    "y": 1230
                },
                {
                    "x": 1273,
                    "y": 1279
                },
                {
                    "x": 443,
                    "y": 1279
                }
            ],
            "category": "paragraph",
            "html": "<p id='105' style='font-size:18px'>4.2 HANDWRITING SEQUENCE GENERATION</p>",
            "id": 105,
            "page": 10,
            "text": "4.2 HANDWRITING SEQUENCE GENERATION"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1317
                },
                {
                    "x": 2109,
                    "y": 1317
                },
                {
                    "x": 2109,
                    "y": 1821
                },
                {
                    "x": 441,
                    "y": 1821
                }
            ],
            "category": "paragraph",
            "html": "<p id='106' style='font-size:16px'>We extend the evaluation of the HM-LSTM to a real-valued sequence modelling task using IAM-<br>OnDB (Liwicki & Bunke, 2005) dataset. The IAM-OnDB dataset consists of 12, 179 handwriting<br>examples, each of which is a sequence of (x, y) coordinate and a binary indicator p for pen-tip<br>location, giving us (X1:Tn, Y1:Tn , P1:Tn ), where n is an index of a sequence. At each time step,<br>the model receives (xt, Yt, pt), and the goal is to predict (xt+1, yt+1, Pt+1). The pen-up (Pt = 1)<br>indicates an end of a stroke, and the pen-down (Pt = 0) indicates that a stroke is in progress. There<br>is usually a large shift in the (x, y) coordinate to start a new stroke after the pen-up happens. We<br>remove all sequences whose length is shorter than 300. This leaves us 10, 465 sequences for training,<br>581 for validation, 582 for test. The average length of the sequences is 648. We normalize the range<br>of the (x, y) coordinates separately with the mean and standard deviation obtained from the training<br>set. We use the mini-batch size of 32, and the initial learning rate is set to 0.0003.</p>",
            "id": 106,
            "page": 10,
            "text": "We extend the evaluation of the HM-LSTM to a real-valued sequence modelling task using IAMOnDB (Liwicki & Bunke, 2005) dataset. The IAM-OnDB dataset consists of 12, 179 handwriting examples, each of which is a sequence of (x, y) coordinate and a binary indicator p for pen-tip location, giving us (X1:Tn, Y1:Tn , P1:Tn ), where n is an index of a sequence. At each time step, the model receives (xt, Yt, pt), and the goal is to predict (xt+1, yt+1, Pt+1). The pen-up (Pt = 1) indicates an end of a stroke, and the pen-down (Pt = 0) indicates that a stroke is in progress. There is usually a large shift in the (x, y) coordinate to start a new stroke after the pen-up happens. We remove all sequences whose length is shorter than 300. This leaves us 10, 465 sequences for training, 581 for validation, 582 for test. The average length of the sequences is 648. We normalize the range of the (x, y) coordinates separately with the mean and standard deviation obtained from the training set. We use the mini-batch size of 32, and the initial learning rate is set to 0.0003."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1844
                },
                {
                    "x": 2109,
                    "y": 1844
                },
                {
                    "x": 2109,
                    "y": 2302
                },
                {
                    "x": 441,
                    "y": 2302
                }
            ],
            "category": "paragraph",
            "html": "<p id='107' style='font-size:16px'>We use the same model architecture as used in the character-level language model, except that the<br>output layer is modified to predict real-valued outputs. We use the mixture density network as the<br>output layer following Graves (2013), and use 400 units for each HM-LSTM layer and for the output<br>embedding layer. In Table 3, we compare the log-likelihood averaged over the test sequences of the<br>IAM-OnDB dataset. We observe that the HM-LSTM outperforms the standard LSTM. The slope<br>annealing trick further improves the test log-likelihood of the HM-LSTM into 1167 in our setting. In<br>this experiment, we increased the slope a with the following schedule a = min (3, 1 + 0.004 · Nepoch).<br>In Figure 5, we let the HM-LSTM to read a randomly picked validation sequence and present the<br>visualization of handwriting examples by segments based on either the states of �2 or the states of<br>pen-tip location3.</p>",
            "id": 107,
            "page": 10,
            "text": "We use the same model architecture as used in the character-level language model, except that the output layer is modified to predict real-valued outputs. We use the mixture density network as the output layer following Graves (2013), and use 400 units for each HM-LSTM layer and for the output embedding layer. In Table 3, we compare the log-likelihood averaged over the test sequences of the IAM-OnDB dataset. We observe that the HM-LSTM outperforms the standard LSTM. The slope annealing trick further improves the test log-likelihood of the HM-LSTM into 1167 in our setting. In this experiment, we increased the slope a with the following schedule a = min (3, 1 + 0.004 · Nepoch). In Figure 5, we let the HM-LSTM to read a randomly picked validation sequence and present the visualization of handwriting examples by segments based on either the states of �2 or the states of pen-tip location3."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2369
                },
                {
                    "x": 820,
                    "y": 2369
                },
                {
                    "x": 820,
                    "y": 2421
                },
                {
                    "x": 445,
                    "y": 2421
                }
            ],
            "category": "paragraph",
            "html": "<p id='108' style='font-size:22px'>5 CONCLUSION</p>",
            "id": 108,
            "page": 10,
            "text": "5 CONCLUSION"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2469
                },
                {
                    "x": 2108,
                    "y": 2469
                },
                {
                    "x": 2108,
                    "y": 2977
                },
                {
                    "x": 442,
                    "y": 2977
                }
            ],
            "category": "paragraph",
            "html": "<p id='109' style='font-size:16px'>In this paper, we proposed the HM-RNN that can capture the latent hierarchical structure of the<br>sequences. We introduced three types of operations to the RNN, which are the COPY, UPDATE<br>and FLUSH operations. In order to implement these operations, we introduced a set of binary<br>variables and a novel update rule that is dependent on the states of these binary variables. Each binary<br>variable is learned to find segments at its level, therefore, we call this binary variable, a boundary<br>detector. On the character-level language modelling, the HM-LSTM achieved state-of-the-art result<br>on the Text8 dataset and comparable results to the state-of-the-art results on the Penn Treebank<br>and Hutter Prize Wikipedia datasets. Also, the HM-LSTM outperformed the standard LSTM on<br>the handwriting sequence generation. Our results and analysis suggest that the proposed HM-RNN<br>can discover the latent hierarchical structure of the sequences and can learn efficient hierarchical<br>multiscale representation that leads to better generalization performance.</p>",
            "id": 109,
            "page": 10,
            "text": "In this paper, we proposed the HM-RNN that can capture the latent hierarchical structure of the sequences. We introduced three types of operations to the RNN, which are the COPY, UPDATE and FLUSH operations. In order to implement these operations, we introduced a set of binary variables and a novel update rule that is dependent on the states of these binary variables. Each binary variable is learned to find segments at its level, therefore, we call this binary variable, a boundary detector. On the character-level language modelling, the HM-LSTM achieved state-of-the-art result on the Text8 dataset and comparable results to the state-of-the-art results on the Penn Treebank and Hutter Prize Wikipedia datasets. Also, the HM-LSTM outperformed the standard LSTM on the handwriting sequence generation. Our results and analysis suggest that the proposed HM-RNN can discover the latent hierarchical structure of the sequences and can learn efficient hierarchical multiscale representation that leads to better generalization performance."
        },
        {
            "bounding_box": [
                {
                    "x": 500,
                    "y": 3007
                },
                {
                    "x": 2132,
                    "y": 3007
                },
                {
                    "x": 2132,
                    "y": 3055
                },
                {
                    "x": 500,
                    "y": 3055
                }
            ],
            "category": "paragraph",
            "html": "<p id='110' style='font-size:14px'>3The plot function could be found at blog · otoro.net/2015/12/12 /handwriting-generation-denc- in-tensorflow/.</p>",
            "id": 110,
            "page": 10,
            "text": "3The plot function could be found at blog · otoro.net/2015/12/12 /handwriting-generation-denc- in-tensorflow/."
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 3132
                },
                {
                    "x": 1299,
                    "y": 3132
                },
                {
                    "x": 1299,
                    "y": 3172
                },
                {
                    "x": 1252,
                    "y": 3172
                }
            ],
            "category": "footer",
            "html": "<footer id='111' style='font-size:16px'>10</footer>",
            "id": 111,
            "page": 10,
            "text": "10"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1223,
                    "y": 111
                },
                {
                    "x": 1223,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='112' style='font-size:16px'>Published as a conference paper at ICLR 2017</header>",
            "id": 112,
            "page": 11,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 447,
                    "y": 344
                },
                {
                    "x": 915,
                    "y": 344
                },
                {
                    "x": 915,
                    "y": 392
                },
                {
                    "x": 447,
                    "y": 392
                }
            ],
            "category": "paragraph",
            "html": "<p id='113' style='font-size:20px'>ACKNOWLEDGMENTS</p>",
            "id": 113,
            "page": 11,
            "text": "ACKNOWLEDGMENTS"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 444
                },
                {
                    "x": 2108,
                    "y": 444
                },
                {
                    "x": 2108,
                    "y": 768
                },
                {
                    "x": 444,
                    "y": 768
                }
            ],
            "category": "paragraph",
            "html": "<p id='114' style='font-size:18px'>The authors would like to thank Alex Graves, Tom Schaul and Hado van Hasselt for their fruitful<br>comments and discussion. We acknowledge the support of the following agencies for research<br>funding and computing support: Ubisoft, Samsung, IBM, Facebook, Google, Microsoft, NSERC,<br>Calcul Quebec, Compute Canada, the Canada Research Chairs and CIFAR. The authors thank the<br>developers of Theano (Team et al., 2016). JC would like to thank Arnaud Bergenon and Frederic<br>Bastien for their technical support. JC would also like to thank Guillaume Alain, Kyle Kastner and<br>David Ha for providing us useful pieces of code.</p>",
            "id": 114,
            "page": 11,
            "text": "The authors would like to thank Alex Graves, Tom Schaul and Hado van Hasselt for their fruitful comments and discussion. We acknowledge the support of the following agencies for research funding and computing support: Ubisoft, Samsung, IBM, Facebook, Google, Microsoft, NSERC, Calcul Quebec, Compute Canada, the Canada Research Chairs and CIFAR. The authors thank the developers of Theano (Team , 2016). JC would like to thank Arnaud Bergenon and Frederic Bastien for their technical support. JC would also like to thank Guillaume Alain, Kyle Kastner and David Ha for providing us useful pieces of code."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 831
                },
                {
                    "x": 735,
                    "y": 831
                },
                {
                    "x": 735,
                    "y": 881
                },
                {
                    "x": 445,
                    "y": 881
                }
            ],
            "category": "paragraph",
            "html": "<p id='115' style='font-size:22px'>REFERENCES</p>",
            "id": 115,
            "page": 11,
            "text": "REFERENCES"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 905
                },
                {
                    "x": 2107,
                    "y": 905
                },
                {
                    "x": 2107,
                    "y": 987
                },
                {
                    "x": 444,
                    "y": 987
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='116' style='font-size:18px'>Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450,<br>2016.</p>",
            "id": 116,
            "page": 11,
            "text": "Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1021
                },
                {
                    "x": 2108,
                    "y": 1021
                },
                {
                    "x": 2108,
                    "y": 1148
                },
                {
                    "x": 443,
                    "y": 1148
                }
            ],
            "category": "paragraph",
            "html": "<p id='117' style='font-size:18px'>Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Yoshua Bengio, et al. End-to-end attention-based large<br>vocabulary speech recognition. In 2016 IEEE International Conference on Acoustics, Speech and Signal<br>Processing (ICASSP), pp. 4945-4949. IEEE, 2016.</p>",
            "id": 117,
            "page": 11,
            "text": "Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Yoshua Bengio,  End-to-end attention-based large vocabulary speech recognition. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4945-4949. IEEE, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1180
                },
                {
                    "x": 2107,
                    "y": 1180
                },
                {
                    "x": 2107,
                    "y": 1263
                },
                {
                    "x": 445,
                    "y": 1263
                }
            ],
            "category": "paragraph",
            "html": "<p id='118' style='font-size:16px'>Yoshua Bengio. Learning deep architectures for ai. Foundations and trendsⓇ in Machine Learning, 2(1):1-127,<br>2009.</p>",
            "id": 118,
            "page": 11,
            "text": "Yoshua Bengio. Learning deep architectures for ai. Foundations and trendsⓇ in Machine Learning, 2(1):1-127, 2009."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1297
                },
                {
                    "x": 2106,
                    "y": 1297
                },
                {
                    "x": 2106,
                    "y": 1382
                },
                {
                    "x": 444,
                    "y": 1382
                }
            ],
            "category": "paragraph",
            "html": "<p id='119' style='font-size:14px'>Yoshua Bengio, Nicholas Leonard, and Aaron Courville. Estimating or propagating gradients through stochastic<br>neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.</p>",
            "id": 119,
            "page": 11,
            "text": "Yoshua Bengio, Nicholas Leonard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1412
                },
                {
                    "x": 2107,
                    "y": 1412
                },
                {
                    "x": 2107,
                    "y": 1539
                },
                {
                    "x": 443,
                    "y": 1539
                }
            ],
            "category": "paragraph",
            "html": "<p id='120' style='font-size:16px'>William Chan, Navdeep Jaitly, Quoc Le, and Oriol Vinyals. Listen, attend and spell: A neural network for large<br>vocabulary conversational speech recognition. In 2016 IEEE International Conference on Acoustics, Speech<br>and Signal Processing (ICASSP), pp. 4960-4964. IEEE, 2016.</p>",
            "id": 120,
            "page": 11,
            "text": "William Chan, Navdeep Jaitly, Quoc Le, and Oriol Vinyals. Listen, attend and spell: A neural network for large vocabulary conversational speech recognition. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 4960-4964. IEEE, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1569
                },
                {
                    "x": 2107,
                    "y": 1569
                },
                {
                    "x": 2107,
                    "y": 1698
                },
                {
                    "x": 441,
                    "y": 1698
                }
            ],
            "category": "paragraph",
            "html": "<p id='121' style='font-size:18px'>Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua<br>Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In<br>Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014), October 2014.</p>",
            "id": 121,
            "page": 11,
            "text": "Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using RNN encoder-decoder for statistical machine translation. In Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014), October 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1729
                },
                {
                    "x": 2103,
                    "y": 1729
                },
                {
                    "x": 2103,
                    "y": 1814
                },
                {
                    "x": 443,
                    "y": 1814
                }
            ],
            "category": "paragraph",
            "html": "<p id='122' style='font-size:16px'>Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. Gated feedback recurrent neural<br>networks. In Proceedings of the 32nd International Conference on Machine Learning (ICML), 2015.</p>",
            "id": 122,
            "page": 11,
            "text": "Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. Gated feedback recurrent neural networks. In Proceedings of the 32nd International Conference on Machine Learning (ICML), 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1846
                },
                {
                    "x": 2105,
                    "y": 1846
                },
                {
                    "x": 2105,
                    "y": 1928
                },
                {
                    "x": 444,
                    "y": 1928
                }
            ],
            "category": "paragraph",
            "html": "<p id='123' style='font-size:18px'>Junyoung Chung, Kyunghyun Cho, and Yoshua Bengio. A character-level decoder without explicit segmentation<br>for neural machine translation. Association for Computational Linguistics (ACL), 2016.</p>",
            "id": 123,
            "page": 11,
            "text": "Junyoung Chung, Kyunghyun Cho, and Yoshua Bengio. A character-level decoder without explicit segmentation for neural machine translation. Association for Computational Linguistics (ACL), 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1960
                },
                {
                    "x": 2106,
                    "y": 1960
                },
                {
                    "x": 2106,
                    "y": 2046
                },
                {
                    "x": 443,
                    "y": 2046
                }
            ],
            "category": "paragraph",
            "html": "<p id='124' style='font-size:14px'>Tim Cooijmans, Nicolas Ballas, Cesar Laurent, and Aaron Courville. Recurrent batch normalization. arXiv<br>preprint arXiv:1603.09025, 2016.</p>",
            "id": 124,
            "page": 11,
            "text": "Tim Cooijmans, Nicolas Ballas, Cesar Laurent, and Aaron Courville. Recurrent batch normalization. arXiv preprint arXiv:1603.09025, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2076
                },
                {
                    "x": 2106,
                    "y": 2076
                },
                {
                    "x": 2106,
                    "y": 2203
                },
                {
                    "x": 442,
                    "y": 2203
                }
            ],
            "category": "paragraph",
            "html": "<p id='125' style='font-size:14px'>Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized neural<br>networks: Training deep neural networks with weights and activations constrained to+ 1 or-1. arXiv preprint<br>arXiv:1602.02830, 2016.</p>",
            "id": 125,
            "page": 11,
            "text": "Matthieu Courbariaux, Itay Hubara, Daniel Soudry, Ran El-Yaniv, and Yoshua Bengio. Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1. arXiv preprint arXiv:1602.02830, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2235
                },
                {
                    "x": 2106,
                    "y": 2235
                },
                {
                    "x": 2106,
                    "y": 2320
                },
                {
                    "x": 443,
                    "y": 2320
                }
            ],
            "category": "paragraph",
            "html": "<p id='126' style='font-size:14px'>Salah El Hihi and Yoshua Bengio. Hierarchical recurrent neural networks for long-term dependencies. In<br>Advances in Neural Information Processing Systems, pp. 493-499. Citeseer, 1995.</p>",
            "id": 126,
            "page": 11,
            "text": "Salah El Hihi and Yoshua Bengio. Hierarchical recurrent neural networks for long-term dependencies. In Advances in Neural Information Processing Systems, pp. 493-499. Citeseer, 1995."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2352
                },
                {
                    "x": 2107,
                    "y": 2352
                },
                {
                    "x": 2107,
                    "y": 2479
                },
                {
                    "x": 443,
                    "y": 2479
                }
            ],
            "category": "paragraph",
            "html": "<p id='127' style='font-size:16px'>Santiago Fernandez, Alex Graves, and Jurgen Schmidhuber. Sequence labelling in structured domains with<br>hierarchical recurrent neural networks. In Proceedings of the 20th internationaljoint conference on Artifical<br>intelligence, pp. 774-779. Morgan Kaufmann Publishers Inc., 2007.</p>",
            "id": 127,
            "page": 11,
            "text": "Santiago Fernandez, Alex Graves, and Jurgen Schmidhuber. Sequence labelling in structured domains with hierarchical recurrent neural networks. In Proceedings of the 20th internationaljoint conference on Artifical intelligence, pp. 774-779. Morgan Kaufmann Publishers Inc., 2007."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2509
                },
                {
                    "x": 2060,
                    "y": 2509
                },
                {
                    "x": 2060,
                    "y": 2554
                },
                {
                    "x": 443,
                    "y": 2554
                }
            ],
            "category": "paragraph",
            "html": "<p id='128' style='font-size:14px'>Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850, 2013.</p>",
            "id": 128,
            "page": 11,
            "text": "Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850, 2013."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2585
                },
                {
                    "x": 1919,
                    "y": 2585
                },
                {
                    "x": 1919,
                    "y": 2628
                },
                {
                    "x": 444,
                    "y": 2628
                }
            ],
            "category": "paragraph",
            "html": "<p id='129' style='font-size:14px'>David Ha, Andrew Dai, and Quoc V Le. Hypernetworks. arXiv preprint arXiv:1609.09106, 2016.</p>",
            "id": 129,
            "page": 11,
            "text": "David Ha, Andrew Dai, and Quoc V Le. Hypernetworks. arXiv preprint arXiv:1609.09106, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2658
                },
                {
                    "x": 1679,
                    "y": 2658
                },
                {
                    "x": 1679,
                    "y": 2703
                },
                {
                    "x": 443,
                    "y": 2703
                }
            ],
            "category": "paragraph",
            "html": "<p id='130' style='font-size:16px'>G. Hinton. Neural networks for machine learning. Coursera, video lectures, 2012.</p>",
            "id": 130,
            "page": 11,
            "text": "G. Hinton. Neural networks for machine learning. Coursera, video lectures, 2012."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2734
                },
                {
                    "x": 2108,
                    "y": 2734
                },
                {
                    "x": 2108,
                    "y": 2817
                },
                {
                    "x": 443,
                    "y": 2817
                }
            ],
            "category": "paragraph",
            "html": "<p id='131' style='font-size:18px'>Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735-1780,<br>1997.</p>",
            "id": 131,
            "page": 11,
            "text": "Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735-1780, 1997."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2850
                },
                {
                    "x": 2107,
                    "y": 2850
                },
                {
                    "x": 2107,
                    "y": 2935
                },
                {
                    "x": 444,
                    "y": 2935
                }
            ],
            "category": "paragraph",
            "html": "<p id='132' style='font-size:18px'>Judy Hoffman, Eric Tzeng, Jeff Donahue, Yangqing Jia, Kate Saenko, and Trevor Darrell. One-shot adaptation<br>of supervised deep convolutional models. arXiv preprint arXiv:1312.6204, 2013.</p>",
            "id": 132,
            "page": 11,
            "text": "Judy Hoffman, Eric Tzeng, Jeff Donahue, Yangqing Jia, Kate Saenko, and Trevor Darrell. One-shot adaptation of supervised deep convolutional models. arXiv preprint arXiv:1312.6204, 2013."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 2967
                },
                {
                    "x": 2107,
                    "y": 2967
                },
                {
                    "x": 2107,
                    "y": 3051
                },
                {
                    "x": 445,
                    "y": 3051
                }
            ],
            "category": "paragraph",
            "html": "<p id='133' style='font-size:16px'>Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Weinberger. Deep networks with stochastic depth.<br>arXiv preprint arXiv:1603.09382, 2016.</p>",
            "id": 133,
            "page": 11,
            "text": "Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Weinberger. Deep networks with stochastic depth. arXiv preprint arXiv:1603.09382, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 3133
                },
                {
                    "x": 1295,
                    "y": 3133
                },
                {
                    "x": 1295,
                    "y": 3171
                },
                {
                    "x": 1252,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='134' style='font-size:14px'>11</footer>",
            "id": 134,
            "page": 11,
            "text": "11"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1223,
                    "y": 111
                },
                {
                    "x": 1223,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='135' style='font-size:18px'>Published as a conference paper at ICLR 2017</header>",
            "id": 135,
            "page": 12,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 348
                },
                {
                    "x": 2111,
                    "y": 348
                },
                {
                    "x": 2111,
                    "y": 394
                },
                {
                    "x": 444,
                    "y": 394
                }
            ],
            "category": "paragraph",
            "html": "<p id='136' style='font-size:14px'>Marcus Hutter. The human knowledge compression contest. 2012. URL http : / /prize . hutter1 net /.</p>",
            "id": 136,
            "page": 12,
            "text": "Marcus Hutter. The human knowledge compression contest. 2012. URL http : / /prize . hutter1 net /."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 425
                },
                {
                    "x": 2108,
                    "y": 425
                },
                {
                    "x": 2108,
                    "y": 509
                },
                {
                    "x": 443,
                    "y": 509
                }
            ],
            "category": "paragraph",
            "html": "<p id='137' style='font-size:18px'>Nal Kalchbrenner, Ivo Danihelka, and Alex Graves. Grid long short-term memory. arXiv preprint<br>arXiv:1507.01526, 2015.</p>",
            "id": 137,
            "page": 12,
            "text": "Nal Kalchbrenner, Ivo Danihelka, and Alex Graves. Grid long short-term memory. arXiv preprint arXiv:1507.01526, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 447,
                    "y": 542
                },
                {
                    "x": 2090,
                    "y": 542
                },
                {
                    "x": 2090,
                    "y": 586
                },
                {
                    "x": 447,
                    "y": 586
                }
            ],
            "category": "paragraph",
            "html": "<p id='138' style='font-size:16px'>Yoon Kim. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882, 2014.</p>",
            "id": 138,
            "page": 12,
            "text": "Yoon Kim. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 618
                },
                {
                    "x": 2111,
                    "y": 618
                },
                {
                    "x": 2111,
                    "y": 702
                },
                {
                    "x": 446,
                    "y": 702
                }
            ],
            "category": "paragraph",
            "html": "<p id='139' style='font-size:18px'>Yoon Kim, Yacine Jernite, David Sontag, and Alexander M Rush. Character-aware neural language models.<br>arXiv preprint arXiv:1508.06615, 2015.</p>",
            "id": 139,
            "page": 12,
            "text": "Yoon Kim, Yacine Jernite, David Sontag, and Alexander M Rush. Character-aware neural language models. arXiv preprint arXiv:1508.06615, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 737
                },
                {
                    "x": 2107,
                    "y": 737
                },
                {
                    "x": 2107,
                    "y": 821
                },
                {
                    "x": 442,
                    "y": 821
                }
            ],
            "category": "paragraph",
            "html": "<p id='140' style='font-size:18px'>Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980,<br>2014.</p>",
            "id": 140,
            "page": 12,
            "text": "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 853
                },
                {
                    "x": 2107,
                    "y": 853
                },
                {
                    "x": 2107,
                    "y": 899
                },
                {
                    "x": 444,
                    "y": 899
                }
            ],
            "category": "paragraph",
            "html": "<p id='141' style='font-size:20px'>Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.</p>",
            "id": 141,
            "page": 12,
            "text": "Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 931
                },
                {
                    "x": 2106,
                    "y": 931
                },
                {
                    "x": 2106,
                    "y": 1013
                },
                {
                    "x": 443,
                    "y": 1013
                }
            ],
            "category": "paragraph",
            "html": "<p id='142' style='font-size:20px'>Lingpeng Kong, Chris Dyer, and Noah A Smith. Segmental recurrent neural networks. arXiv preprint<br>arXiv:1511.06018, 2015.</p>",
            "id": 142,
            "page": 12,
            "text": "Lingpeng Kong, Chris Dyer, and Noah A Smith. Segmental recurrent neural networks. arXiv preprint arXiv:1511.06018, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1047
                },
                {
                    "x": 2106,
                    "y": 1047
                },
                {
                    "x": 2106,
                    "y": 1132
                },
                {
                    "x": 443,
                    "y": 1132
                }
            ],
            "category": "paragraph",
            "html": "<p id='143' style='font-size:16px'>Jan Koutnik, Klaus Greff, Faustino Gomez, and Jurgen Schmidhuber. A clockwork rnn. In Proceedings of the<br>31st International Conference on Machine Learning (ICML 2014), 2014.</p>",
            "id": 143,
            "page": 12,
            "text": "Jan Koutnik, Klaus Greff, Faustino Gomez, and Jurgen Schmidhuber. A clockwork rnn. In Proceedings of the 31st International Conference on Machine Learning (ICML 2014), 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1164
                },
                {
                    "x": 2107,
                    "y": 1164
                },
                {
                    "x": 2107,
                    "y": 1249
                },
                {
                    "x": 444,
                    "y": 1249
                }
            ],
            "category": "paragraph",
            "html": "<p id='144' style='font-size:20px'>Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural<br>networks. In Advances in Neural Information Processing Systems, pp. 1097-1105, 2012.</p>",
            "id": 144,
            "page": 12,
            "text": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems, pp. 1097-1105, 2012."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1282
                },
                {
                    "x": 2107,
                    "y": 1282
                },
                {
                    "x": 2107,
                    "y": 1365
                },
                {
                    "x": 445,
                    "y": 1365
                }
            ],
            "category": "paragraph",
            "html": "<p id='145' style='font-size:18px'>David Krueger and Roland Memisevic. Regularizing rnns by stabilizing activations. arXiv preprint<br>arXiv:1511.08400, 2015.</p>",
            "id": 145,
            "page": 12,
            "text": "David Krueger and Roland Memisevic. Regularizing rnns by stabilizing activations. arXiv preprint arXiv:1511.08400, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1399
                },
                {
                    "x": 2108,
                    "y": 1399
                },
                {
                    "x": 2108,
                    "y": 1524
                },
                {
                    "x": 443,
                    "y": 1524
                }
            ],
            "category": "paragraph",
            "html": "<p id='146' style='font-size:20px'>David Krueger, Tegan Maharaj, Janos Kramar, Mohammad Pezeshki, Nicolas Ballas, Nan Rosemary Ke, Anirudh<br>Goyal, Yoshua Bengio, Hugo Larochelle, Aaron Courville, et al. Zoneout: Regularizing rnns by randomly<br>preserving hidden activations. arXiv preprint arXiv:1606.01305, 2016.</p>",
            "id": 146,
            "page": 12,
            "text": "David Krueger, Tegan Maharaj, Janos Kramar, Mohammad Pezeshki, Nicolas Ballas, Nan Rosemary Ke, Anirudh Goyal, Yoshua Bengio, Hugo Larochelle, Aaron Courville,  Zoneout: Regularizing rnns by randomly preserving hidden activations. arXiv preprint arXiv:1606.01305, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 1558
                },
                {
                    "x": 1992,
                    "y": 1558
                },
                {
                    "x": 1992,
                    "y": 1602
                },
                {
                    "x": 446,
                    "y": 1602
                }
            ],
            "category": "paragraph",
            "html": "<p id='147' style='font-size:22px'>Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436-444, 2015.</p>",
            "id": 147,
            "page": 12,
            "text": "Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436-444, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1634
                },
                {
                    "x": 2107,
                    "y": 1634
                },
                {
                    "x": 2107,
                    "y": 1718
                },
                {
                    "x": 445,
                    "y": 1718
                }
            ],
            "category": "paragraph",
            "html": "<p id='148' style='font-size:16px'>Tsungnan Lin, Bill G Horne, Peter Tino, and C Lee Giles. Learning long-term dependencies in narx recurrent<br>neural networks. IEEE Transactions on Neural Networks, 7(6):1329-1338, 1996.</p>",
            "id": 148,
            "page": 12,
            "text": "Tsungnan Lin, Bill G Horne, Peter Tino, and C Lee Giles. Learning long-term dependencies in narx recurrent neural networks. IEEE Transactions on Neural Networks, 7(6):1329-1338, 1996."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1751
                },
                {
                    "x": 2106,
                    "y": 1751
                },
                {
                    "x": 2106,
                    "y": 1836
                },
                {
                    "x": 445,
                    "y": 1836
                }
            ],
            "category": "paragraph",
            "html": "<p id='149' style='font-size:18px'>Wang Ling, Isabel Trancoso, Chris Dyer, and Alan W Black. Character-based neural machine translation. arXiv<br>preprint arXiv:1511.04586, 2015.</p>",
            "id": 149,
            "page": 12,
            "text": "Wang Ling, Isabel Trancoso, Chris Dyer, and Alan W Black. Character-based neural machine translation. arXiv preprint arXiv:1511.04586, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1868
                },
                {
                    "x": 2108,
                    "y": 1868
                },
                {
                    "x": 2108,
                    "y": 1996
                },
                {
                    "x": 442,
                    "y": 1996
                }
            ],
            "category": "paragraph",
            "html": "<p id='150' style='font-size:14px'>Marcus Liwicki and Horst Bunke. Iam-ondb-an on-line english sentence database acquired from handwritten<br>text on a whiteboard. In Eighth International Conference on Document Analysis and Recognition (ICDAR'05),<br>pp. 956-961. IEEE, 2005.</p>",
            "id": 150,
            "page": 12,
            "text": "Marcus Liwicki and Horst Bunke. Iam-ondb-an on-line english sentence database acquired from handwritten text on a whiteboard. In Eighth International Conference on Document Analysis and Recognition (ICDAR'05), pp. 956-961. IEEE, 2005."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2027
                },
                {
                    "x": 1907,
                    "y": 2027
                },
                {
                    "x": 1907,
                    "y": 2072
                },
                {
                    "x": 443,
                    "y": 2072
                }
            ],
            "category": "paragraph",
            "html": "<p id='151' style='font-size:16px'>Matthew V Mahoney. Adaptive weighing of context models for lossless data compression. 2005.</p>",
            "id": 151,
            "page": 12,
            "text": "Matthew V Mahoney. Adaptive weighing of context models for lossless data compression. 2005."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2104
                },
                {
                    "x": 2109,
                    "y": 2104
                },
                {
                    "x": 2109,
                    "y": 2185
                },
                {
                    "x": 443,
                    "y": 2185
                }
            ],
            "category": "paragraph",
            "html": "<p id='152' style='font-size:18px'>Matthew V Mahoney. Large text compression benchmark. URL: http://www. mattmahoney. net/text/text. html,<br>2009.</p>",
            "id": 152,
            "page": 12,
            "text": "Matthew V Mahoney. Large text compression benchmark. URL: http://www. mattmahoney. net/text/text. html, 2009."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2221
                },
                {
                    "x": 2106,
                    "y": 2221
                },
                {
                    "x": 2106,
                    "y": 2307
                },
                {
                    "x": 444,
                    "y": 2307
                }
            ],
            "category": "paragraph",
            "html": "<p id='153' style='font-size:18px'>Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of<br>english: The penn treebank. Computational linguistics, 19(2):313-330, 1993.</p>",
            "id": 153,
            "page": 12,
            "text": "Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313-330, 1993."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2338
                },
                {
                    "x": 2106,
                    "y": 2338
                },
                {
                    "x": 2106,
                    "y": 2422
                },
                {
                    "x": 444,
                    "y": 2422
                }
            ],
            "category": "paragraph",
            "html": "<p id='154' style='font-size:18px'>Tomas Mikolov, Martin Karafiat, Lukas Burget, Jan Cernocky, and Sanjeev Khudanpur. Recurrent neural<br>network based language model. In INTERSPEECH, volume 2, pp. 3, 2010.</p>",
            "id": 154,
            "page": 12,
            "text": "Tomas Mikolov, Martin Karafiat, Lukas Burget, Jan Cernocky, and Sanjeev Khudanpur. Recurrent neural network based language model. In INTERSPEECH, volume 2, pp. 3, 2010."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2455
                },
                {
                    "x": 2109,
                    "y": 2455
                },
                {
                    "x": 2109,
                    "y": 2581
                },
                {
                    "x": 444,
                    "y": 2581
                }
            ],
            "category": "paragraph",
            "html": "<p id='155' style='font-size:14px'>Tomas Mikolov, Ilya Sutskever, Anoop Deoras, Hai-Son Le, Stefan Kombrink, and J Cernocky. Sub-<br>word language modeling with neural networks. Preprint, 2012. URL http : / / www · fit · vutbr · CZ /<br>~imikolov / rnnlm/ char · pdf.</p>",
            "id": 155,
            "page": 12,
            "text": "Tomas Mikolov, Ilya Sutskever, Anoop Deoras, Hai-Son Le, Stefan Kombrink, and J Cernocky. Subword language modeling with neural networks. Preprint, 2012. URL http : / / www · fit · vutbr · CZ / ~imikolov / rnnlm/ char · pdf."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2732
                },
                {
                    "x": 2106,
                    "y": 2732
                },
                {
                    "x": 2106,
                    "y": 2817
                },
                {
                    "x": 443,
                    "y": 2817
                }
            ],
            "category": "paragraph",
            "html": "<p id='156' style='font-size:16px'>Michael C Mozer. Induction of multiscale temporal structure. Advances in neural information processing<br>systems, pp. 275-275, 1993.</p>",
            "id": 156,
            "page": 12,
            "text": "Michael C Mozer. Induction of multiscale temporal structure. Advances in neural information processing systems, pp. 275-275, 1993."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2615
                },
                {
                    "x": 2108,
                    "y": 2615
                },
                {
                    "x": 2108,
                    "y": 2698
                },
                {
                    "x": 444,
                    "y": 2698
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='157' style='font-size:16px'>Andriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks. In Proceedings of<br>the 31st International Conference on Machine Learning (ICML-14), pp. 1791-1799, 2014.</p>",
            "id": 157,
            "page": 12,
            "text": "Andriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks. In Proceedings of the 31st International Conference on Machine Learning (ICML-14), pp. 1791-1799, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2968
                },
                {
                    "x": 2107,
                    "y": 2968
                },
                {
                    "x": 2107,
                    "y": 3052
                },
                {
                    "x": 444,
                    "y": 3052
                }
            ],
            "category": "paragraph",
            "html": "<p id='158' style='font-size:16px'>Marius Pachitariu and Maneesh Sahani. Regularization and nonlinearities for neural language models: when are<br>they needed? arXiv preprint arXiv:1301.5650, 2013.</p>",
            "id": 158,
            "page": 12,
            "text": "Marius Pachitariu and Maneesh Sahani. Regularization and nonlinearities for neural language models: when are they needed? arXiv preprint arXiv:1301.5650, 2013."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2849
                },
                {
                    "x": 2104,
                    "y": 2849
                },
                {
                    "x": 2104,
                    "y": 2934
                },
                {
                    "x": 443,
                    "y": 2934
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='159' style='font-size:18px'>Vinod Nair and Geoffrey E Hinton. Rectified linear units improve restricted boltzmann machines. In Proceedings<br>of the 27th International Conference on Machine Learning (ICML-10), pp. 807-814, 2010.</p>",
            "id": 159,
            "page": 12,
            "text": "Vinod Nair and Geoffrey E Hinton. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 807-814, 2010."
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 3133
                },
                {
                    "x": 1298,
                    "y": 3133
                },
                {
                    "x": 1298,
                    "y": 3171
                },
                {
                    "x": 1252,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='160' style='font-size:20px'>12</footer>",
            "id": 160,
            "page": 12,
            "text": "12"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1223,
                    "y": 110
                },
                {
                    "x": 1223,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='161' style='font-size:18px'>Published as a conference paper at ICLR 2017</header>",
            "id": 161,
            "page": 13,
            "text": "Published as a conference paper at ICLR 2017"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 349
                },
                {
                    "x": 2111,
                    "y": 349
                },
                {
                    "x": 2111,
                    "y": 434
                },
                {
                    "x": 442,
                    "y": 434
                }
            ],
            "category": "paragraph",
            "html": "<p id='162' style='font-size:18px'>Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the difficulty of training recurrent neural networks.<br>arXiv preprint arXiv:1211.5063, 2012.</p>",
            "id": 162,
            "page": 13,
            "text": "Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the difficulty of training recurrent neural networks. arXiv preprint arXiv:1211.5063, 2012."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 464
                },
                {
                    "x": 1872,
                    "y": 464
                },
                {
                    "x": 1872,
                    "y": 510
                },
                {
                    "x": 441,
                    "y": 510
                }
            ],
            "category": "paragraph",
            "html": "<p id='163' style='font-size:14px'>Kamil M Rocki. Recurrent memory array structures. arXiv preprint arXiv:1607.03085, 2016a.</p>",
            "id": 163,
            "page": 13,
            "text": "Kamil M Rocki. Recurrent memory array structures. arXiv preprint arXiv:1607.03085, 2016a."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 539
                },
                {
                    "x": 2063,
                    "y": 539
                },
                {
                    "x": 2063,
                    "y": 585
                },
                {
                    "x": 445,
                    "y": 585
                }
            ],
            "category": "paragraph",
            "html": "<p id='164' style='font-size:16px'>Kamil M Rocki. Surprisal-driven feedback in recurrent networks. arXiv preprint arXiv:1608.06027, 2016b.</p>",
            "id": 164,
            "page": 13,
            "text": "Kamil M Rocki. Surprisal-driven feedback in recurrent networks. arXiv preprint arXiv:1608.06027, 2016b."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 614
                },
                {
                    "x": 1277,
                    "y": 614
                },
                {
                    "x": 1277,
                    "y": 659
                },
                {
                    "x": 444,
                    "y": 659
                }
            ],
            "category": "paragraph",
            "html": "<p id='165' style='font-size:16px'>Jurgen Schmidhuber. Neural sequence chunkers. 1991.</p>",
            "id": 165,
            "page": 13,
            "text": "Jurgen Schmidhuber. Neural sequence chunkers. 1991."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 689
                },
                {
                    "x": 2107,
                    "y": 689
                },
                {
                    "x": 2107,
                    "y": 775
                },
                {
                    "x": 443,
                    "y": 775
                }
            ],
            "category": "paragraph",
            "html": "<p id='166' style='font-size:22px'>Jurgen Schmidhuber. Learning complex, extended sequences using the principle of history compression. Neural<br>Computation, 4(2):234-242, 1992.</p>",
            "id": 166,
            "page": 13,
            "text": "Jurgen Schmidhuber. Learning complex, extended sequences using the principle of history compression. Neural Computation, 4(2):234-242, 1992."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 804
                },
                {
                    "x": 2050,
                    "y": 804
                },
                {
                    "x": 2050,
                    "y": 850
                },
                {
                    "x": 444,
                    "y": 850
                }
            ],
            "category": "paragraph",
            "html": "<p id='167' style='font-size:18px'>Jurgen Schmidhuber. Deep learning in neural networks: An overview. Neural Networks, 61:85-117, 2015.</p>",
            "id": 167,
            "page": 13,
            "text": "Jurgen Schmidhuber. Deep learning in neural networks: An overview. Neural Networks, 61:85-117, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 880
                },
                {
                    "x": 2111,
                    "y": 880
                },
                {
                    "x": 2111,
                    "y": 1045
                },
                {
                    "x": 445,
                    "y": 1045
                }
            ],
            "category": "paragraph",
            "html": "<p id='168' style='font-size:16px'>Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob Grue Simonsen, and Jian- Yun Nie.<br>A hierarchical recurrent encoder-decoder for generative context-aware query suggestion. In Proceedings of<br>the 24th ACM International on Conference on Information and Knowledge Management, pp. 553-562. ACM,<br>2015.</p>",
            "id": 168,
            "page": 13,
            "text": "Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma, Jakob Grue Simonsen, and Jian- Yun Nie. A hierarchical recurrent encoder-decoder for generative context-aware query suggestion. In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, pp. 553-562. ACM, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1080
                },
                {
                    "x": 2111,
                    "y": 1080
                },
                {
                    "x": 2111,
                    "y": 1205
                },
                {
                    "x": 441,
                    "y": 1205
                }
            ],
            "category": "paragraph",
            "html": "<p id='169' style='font-size:18px'>Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout:<br>a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):<br>1929-1958, 2014.</p>",
            "id": 169,
            "page": 13,
            "text": "Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1): 1929-1958, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1236
                },
                {
                    "x": 2107,
                    "y": 1236
                },
                {
                    "x": 2107,
                    "y": 1323
                },
                {
                    "x": 442,
                    "y": 1323
                }
            ],
            "category": "paragraph",
            "html": "<p id='170' style='font-size:16px'>Ilya Sutskever, James Martens, and Geoffrey E Hinton. Generating text with recurrent neural networks. In<br>Proceedings of the 28th International Conference on Machine Learning (ICML'11), pp. 1017-1024, 2011.</p>",
            "id": 170,
            "page": 13,
            "text": "Ilya Sutskever, James Martens, and Geoffrey E Hinton. Generating text with recurrent neural networks. In Proceedings of the 28th International Conference on Machine Learning (ICML'11), pp. 1017-1024, 2011."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1352
                },
                {
                    "x": 2107,
                    "y": 1352
                },
                {
                    "x": 2107,
                    "y": 1439
                },
                {
                    "x": 443,
                    "y": 1439
                }
            ],
            "category": "paragraph",
            "html": "<p id='171' style='font-size:18px'>Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances<br>in Neural Information Processing Systems, pp. 3104-3112, 2014.</p>",
            "id": 171,
            "page": 13,
            "text": "Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in Neural Information Processing Systems, pp. 3104-3112, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1468
                },
                {
                    "x": 2107,
                    "y": 1468
                },
                {
                    "x": 2107,
                    "y": 1598
                },
                {
                    "x": 442,
                    "y": 1598
                }
            ],
            "category": "paragraph",
            "html": "<p id='172' style='font-size:18px'>The Theano Development Team, Rami Al-Rfou, Guillaume Alain, Amjad Almahairi, Christof Angermueller,<br>Dzmitry Bahdanau, Nicolas Ballas, Frederic Bastien, Justin Bayer, Anatoly Belikov, et al. Theano: A python<br>framework for fast computation of mathematical expressions. arXiv preprint arXiv:1605.02688, 2016.</p>",
            "id": 172,
            "page": 13,
            "text": "The Theano Development Team, Rami Al-Rfou, Guillaume Alain, Amjad Almahairi, Christof Angermueller, Dzmitry Bahdanau, Nicolas Ballas, Frederic Bastien, Justin Bayer, Anatoly Belikov,  Theano: A python framework for fast computation of mathematical expressions. arXiv preprint arXiv:1605.02688, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1627
                },
                {
                    "x": 2108,
                    "y": 1627
                },
                {
                    "x": 2108,
                    "y": 1752
                },
                {
                    "x": 443,
                    "y": 1752
                }
            ],
            "category": "paragraph",
            "html": "<p id='173' style='font-size:20px'>Alexander Vezhnevets, Volodymyr Mnih, John Agapiou, Simon Osindero, Alex Graves, Oriol Vinyals, Koray<br>Kavukcuoglu, et al. Strategic attentive writer for learning macro-actions. arXiv preprint arXiv:1606.04695,<br>2016.</p>",
            "id": 173,
            "page": 13,
            "text": "Alexander Vezhnevets, Volodymyr Mnih, John Agapiou, Simon Osindero, Alex Graves, Oriol Vinyals, Koray Kavukcuoglu,  Strategic attentive writer for learning macro-actions. arXiv preprint arXiv:1606.04695, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1785
                },
                {
                    "x": 2109,
                    "y": 1785
                },
                {
                    "x": 2109,
                    "y": 1911
                },
                {
                    "x": 442,
                    "y": 1911
                }
            ],
            "category": "paragraph",
            "html": "<p id='174' style='font-size:18px'>Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. Show and tell: A neural image caption<br>generator. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3156-<br>3164, 2015.</p>",
            "id": 174,
            "page": 13,
            "text": "Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. Show and tell: A neural image caption generator. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 31563164, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1944
                },
                {
                    "x": 2110,
                    "y": 1944
                },
                {
                    "x": 2110,
                    "y": 2028
                },
                {
                    "x": 442,
                    "y": 2028
                }
            ],
            "category": "paragraph",
            "html": "<p id='175' style='font-size:20px'>Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning.<br>Machine learning, 8(3-4):229-256, 1992.</p>",
            "id": 175,
            "page": 13,
            "text": "Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4):229-256, 1992."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2058
                },
                {
                    "x": 2108,
                    "y": 2058
                },
                {
                    "x": 2108,
                    "y": 2146
                },
                {
                    "x": 443,
                    "y": 2146
                }
            ],
            "category": "paragraph",
            "html": "<p id='176' style='font-size:18px'>Yuhuai Wu, Saizheng Zhang, Ying Zhang, Yoshua Bengio, and Ruslan Salakhutdinov. On multiplicative<br>integration with recurrent neural networks. arXiv preprint arXiv:1606.06630, 2016.</p>",
            "id": 176,
            "page": 13,
            "text": "Yuhuai Wu, Saizheng Zhang, Ying Zhang, Yoshua Bengio, and Ruslan Salakhutdinov. On multiplicative integration with recurrent neural networks. arXiv preprint arXiv:1606.06630, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2174
                },
                {
                    "x": 2109,
                    "y": 2174
                },
                {
                    "x": 2109,
                    "y": 2300
                },
                {
                    "x": 443,
                    "y": 2300
                }
            ],
            "category": "paragraph",
            "html": "<p id='177' style='font-size:18px'>Saizheng Zhang, Yuhuai Wu, Tong Che, Zhouhan Lin, Roland Memisevic, Ruslan Salakhutdinov, and Yoshua<br>Bengio. Architectural complexity measures of recurrent neural networks. arXiv preprint arXiv: 1602.08210,<br>2016.</p>",
            "id": 177,
            "page": 13,
            "text": "Saizheng Zhang, Yuhuai Wu, Tong Che, Zhouhan Lin, Roland Memisevic, Ruslan Salakhutdinov, and Yoshua Bengio. Architectural complexity measures of recurrent neural networks. arXiv preprint arXiv: 1602.08210, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2333
                },
                {
                    "x": 2106,
                    "y": 2333
                },
                {
                    "x": 2106,
                    "y": 2421
                },
                {
                    "x": 442,
                    "y": 2421
                }
            ],
            "category": "paragraph",
            "html": "<p id='178' style='font-size:20px'>Julian Georg Zilly, Rupesh Kumar Srivastava, Jan Koutnik, and Jurgen Schmidhuber. Recurrent highway<br>networks. arXiv preprint arXiv:1607.03474, 2016.</p>",
            "id": 178,
            "page": 13,
            "text": "Julian Georg Zilly, Rupesh Kumar Srivastava, Jan Koutnik, and Jurgen Schmidhuber. Recurrent highway networks. arXiv preprint arXiv:1607.03474, 2016."
        },
        {
            "bounding_box": [
                {
                    "x": 1252,
                    "y": 3132
                },
                {
                    "x": 1297,
                    "y": 3132
                },
                {
                    "x": 1297,
                    "y": 3171
                },
                {
                    "x": 1252,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='179' style='font-size:18px'>13</footer>",
            "id": 179,
            "page": 13,
            "text": "13"
        }
    ]
}