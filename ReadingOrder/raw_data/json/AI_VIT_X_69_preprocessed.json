{
    "id": "329782e2-0f94-11ef-8828-426932df3dcf",
    "pdf_path": "./pdf/AI_VIT_X/1511.06018v2.pdf",
    "elements": [
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 110
                },
                {
                    "x": 1225,
                    "y": 110
                },
                {
                    "x": 1225,
                    "y": 157
                },
                {
                    "x": 445,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='0' style='font-size:16px'>Published as a conference paper at ICLR 2016</header>",
            "id": 0,
            "page": 1,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 333
                },
                {
                    "x": 1890,
                    "y": 333
                },
                {
                    "x": 1890,
                    "y": 402
                },
                {
                    "x": 446,
                    "y": 402
                }
            ],
            "category": "paragraph",
            "html": "<p id='1' style='font-size:22px'>SEGMENTAL RECURRENT NEURAL NETWORKS</p>",
            "id": 1,
            "page": 1,
            "text": "SEGMENTAL RECURRENT NEURAL NETWORKS"
        },
        {
            "bounding_box": [
                {
                    "x": 469,
                    "y": 485
                },
                {
                    "x": 969,
                    "y": 485
                },
                {
                    "x": 969,
                    "y": 529
                },
                {
                    "x": 469,
                    "y": 529
                }
            ],
            "category": "paragraph",
            "html": "<p id='2' style='font-size:20px'>Lingpeng Kong, Chris Dyer</p>",
            "id": 2,
            "page": 1,
            "text": "Lingpeng Kong, Chris Dyer"
        },
        {
            "bounding_box": [
                {
                    "x": 475,
                    "y": 532
                },
                {
                    "x": 995,
                    "y": 532
                },
                {
                    "x": 995,
                    "y": 669
                },
                {
                    "x": 475,
                    "y": 669
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='3' style='font-size:20px'>School of Computer Science<br>Carnegie Mellon University<br>Pittsburgh, PA 15213, USA</p>",
            "id": 3,
            "page": 1,
            "text": "School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213, USA"
        },
        {
            "bounding_box": [
                {
                    "x": 478,
                    "y": 670
                },
                {
                    "x": 1168,
                    "y": 670
                },
                {
                    "x": 1168,
                    "y": 713
                },
                {
                    "x": 478,
                    "y": 713
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='4' style='font-size:14px'>{lingpenk, cdyer}@cs · cmu · edu</p>",
            "id": 4,
            "page": 1,
            "text": "{lingpenk, cdyer}@cs · cmu · edu"
        },
        {
            "bounding_box": [
                {
                    "x": 470,
                    "y": 784
                },
                {
                    "x": 739,
                    "y": 784
                },
                {
                    "x": 739,
                    "y": 826
                },
                {
                    "x": 470,
                    "y": 826
                }
            ],
            "category": "paragraph",
            "html": "<p id='5' style='font-size:18px'>Noah A. Smith</p>",
            "id": 5,
            "page": 1,
            "text": "Noah A. Smith"
        },
        {
            "bounding_box": [
                {
                    "x": 471,
                    "y": 833
                },
                {
                    "x": 1103,
                    "y": 833
                },
                {
                    "x": 1103,
                    "y": 1011
                },
                {
                    "x": 471,
                    "y": 1011
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='6' style='font-size:16px'>Computer Science & Engineering<br>University of Washington<br>Seattle, WA 98195, USA<br>nasmi th@cs · washington · edu</p>",
            "id": 6,
            "page": 1,
            "text": "Computer Science & Engineering University of Washington Seattle, WA 98195, USA nasmi th@cs · washington · edu"
        },
        {
            "bounding_box": [
                {
                    "x": 1155,
                    "y": 1138
                },
                {
                    "x": 1395,
                    "y": 1138
                },
                {
                    "x": 1395,
                    "y": 1181
                },
                {
                    "x": 1155,
                    "y": 1181
                }
            ],
            "category": "paragraph",
            "html": "<p id='7' style='font-size:22px'>ABSTRACT</p>",
            "id": 7,
            "page": 1,
            "text": "ABSTRACT"
        },
        {
            "bounding_box": [
                {
                    "x": 590,
                    "y": 1261
                },
                {
                    "x": 1960,
                    "y": 1261
                },
                {
                    "x": 1960,
                    "y": 1904
                },
                {
                    "x": 590,
                    "y": 1904
                }
            ],
            "category": "paragraph",
            "html": "<p id='8' style='font-size:18px'>We introduce segmental recurrent neural networks (SRNNs) which define,<br>given an input sequence, a joint probability distribution over segmentations of<br>the input and labelings of the segments. Representations of the input segments<br>(i.e., contiguous subsequences of the input) are computed by encoding their con-<br>stituent tokens using bidirectional recurrent neural nets, and these \"segment em-<br>beddings\" are used to define compatibility scores with output labels. These lo-<br>cal compatibility scores are integrated using a global semi-Markov conditional<br>random field. Both fully supervised training-in which segment boundaries and<br>labels are observed -as well as partially supervised training-in which segment<br>boundaries are latent-are straightforward. Experiments on handwriting recog-<br>nition and joint Chinese word segmentation/POS tagging show that, compared to<br>models that do not explicitly represent segments such as BIO tagging schemes and<br>connectionist temporal classification (CTC), SRNNs obtain substantially higher<br>accuracies.</p>",
            "id": 8,
            "page": 1,
            "text": "We introduce segmental recurrent neural networks (SRNNs) which define, given an input sequence, a joint probability distribution over segmentations of the input and labelings of the segments. Representations of the input segments (i.e., contiguous subsequences of the input) are computed by encoding their constituent tokens using bidirectional recurrent neural nets, and these \"segment embeddings\" are used to define compatibility scores with output labels. These local compatibility scores are integrated using a global semi-Markov conditional random field. Both fully supervised training-in which segment boundaries and labels are observed -as well as partially supervised training-in which segment boundaries are latent-are straightforward. Experiments on handwriting recognition and joint Chinese word segmentation/POS tagging show that, compared to models that do not explicitly represent segments such as BIO tagging schemes and connectionist temporal classification (CTC), SRNNs obtain substantially higher accuracies."
        },
        {
            "bounding_box": [
                {
                    "x": 452,
                    "y": 2054
                },
                {
                    "x": 862,
                    "y": 2054
                },
                {
                    "x": 862,
                    "y": 2105
                },
                {
                    "x": 452,
                    "y": 2105
                }
            ],
            "category": "paragraph",
            "html": "<p id='9' style='font-size:18px'>1 INTRODUCTION</p>",
            "id": 9,
            "page": 1,
            "text": "1 INTRODUCTION"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2177
                },
                {
                    "x": 2107,
                    "y": 2177
                },
                {
                    "x": 2107,
                    "y": 2319
                },
                {
                    "x": 443,
                    "y": 2319
                }
            ],
            "category": "paragraph",
            "html": "<p id='10' style='font-size:18px'>For sequential data like speech, handwriting, and DNA, segmentation and segment-labeling are<br>abstractions that capture many common data analysis challenges. We consider the joint task of<br>breaking an input sequence into contiguous, arbitrary-length segments while labeling each segment.</p>",
            "id": 10,
            "page": 1,
            "text": "For sequential data like speech, handwriting, and DNA, segmentation and segment-labeling are abstractions that capture many common data analysis challenges. We consider the joint task of breaking an input sequence into contiguous, arbitrary-length segments while labeling each segment."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2341
                },
                {
                    "x": 2108,
                    "y": 2341
                },
                {
                    "x": 2108,
                    "y": 2710
                },
                {
                    "x": 442,
                    "y": 2710
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='11' style='font-size:16px'>Our new approach to this problem is the segmental recursive neural network (SRNN). SRNNs com-<br>bine two powerful machine learning tools: representation learning and structured prediction. First,<br>bidirectional recurrent neural networks (RNNs) embed every feasible segment of the input in a con-<br>tinuous space, and these embeddings are then used to calculate the compatibility of each candidate<br>segment with a label. Unlike past RNN-based approaches (e.g., connectionist temporal classification<br>or CTC; Graves et al., 2006) each candidate segment is represented explicitly, allowing application<br>in settings where an alignment between segments and labels is desired as part of the output (e.g.,<br>protein secondary structure prediction or information extraction from text).</p>",
            "id": 11,
            "page": 1,
            "text": "Our new approach to this problem is the segmental recursive neural network (SRNN). SRNNs combine two powerful machine learning tools: representation learning and structured prediction. First, bidirectional recurrent neural networks (RNNs) embed every feasible segment of the input in a continuous space, and these embeddings are then used to calculate the compatibility of each candidate segment with a label. Unlike past RNN-based approaches (e.g., connectionist temporal classification or CTC; Graves , 2006) each candidate segment is represented explicitly, allowing application in settings where an alignment between segments and labels is desired as part of the output (e.g., protein secondary structure prediction or information extraction from text)."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2731
                },
                {
                    "x": 2109,
                    "y": 2731
                },
                {
                    "x": 2109,
                    "y": 3054
                },
                {
                    "x": 441,
                    "y": 3054
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='12' style='font-size:18px'>At the same time, SRNNs are a variant of semi-Markov conditional random fields (Sarawagi & Co-<br>hen, 2004), in that they define a conditional probability distribution over the output space (segmen-<br>tation and labeling) given the input sequence (§2). This allows explicit modeling of statistical de-<br>pendencies, such as those between adjacent labels, and also of segment lengths (unlike widely used<br>symbolic approaches based on \"BIO\" tagging; Ramshaw & Marcus, 1995). Because the probability<br>score decomposes into chain-structured clique potentials, polynomial-time dynamic programming<br>algorithms exist for prediction and parameter estimation (§3).</p>",
            "id": 12,
            "page": 1,
            "text": "At the same time, SRNNs are a variant of semi-Markov conditional random fields (Sarawagi & Cohen, 2004), in that they define a conditional probability distribution over the output space (segmentation and labeling) given the input sequence (§2). This allows explicit modeling of statistical dependencies, such as those between adjacent labels, and also of segment lengths (unlike widely used symbolic approaches based on \"BIO\" tagging; Ramshaw & Marcus, 1995). Because the probability score decomposes into chain-structured clique potentials, polynomial-time dynamic programming algorithms exist for prediction and parameter estimation (§3)."
        },
        {
            "bounding_box": [
                {
                    "x": 65,
                    "y": 883
                },
                {
                    "x": 148,
                    "y": 883
                },
                {
                    "x": 148,
                    "y": 2320
                },
                {
                    "x": 65,
                    "y": 2320
                }
            ],
            "category": "footer",
            "html": "<br><footer id='13' style='font-size:14px'>2016<br>Mar<br>1<br>[cs.CL]<br>arXiv:1511.06018v2</footer>",
            "id": 13,
            "page": 1,
            "text": "2016 Mar 1 [cs.CL] arXiv:1511.06018v2"
        },
        {
            "bounding_box": [
                {
                    "x": 1261,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3173
                },
                {
                    "x": 1261,
                    "y": 3173
                }
            ],
            "category": "footer",
            "html": "<footer id='14' style='font-size:14px'>1</footer>",
            "id": 14,
            "page": 1,
            "text": "1"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 112
                },
                {
                    "x": 1225,
                    "y": 112
                },
                {
                    "x": 1225,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='15' style='font-size:14px'>Published as a conference paper at ICLR 2016</header>",
            "id": 15,
            "page": 2,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 347
                },
                {
                    "x": 2107,
                    "y": 347
                },
                {
                    "x": 2107,
                    "y": 485
                },
                {
                    "x": 442,
                    "y": 485
                }
            ],
            "category": "paragraph",
            "html": "<p id='16' style='font-size:18px'>Parameters can be learned with either a fully supervised objective-where both segment boundaries<br>and segment labels are provided at training time-and partially supervised training objectives-<br>where segment boundaries are latent (§4).</p>",
            "id": 16,
            "page": 2,
            "text": "Parameters can be learned with either a fully supervised objective-where both segment boundaries and segment labels are provided at training time-and partially supervised training objectiveswhere segment boundaries are latent (§4)."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 510
                },
                {
                    "x": 2105,
                    "y": 510
                },
                {
                    "x": 2105,
                    "y": 694
                },
                {
                    "x": 442,
                    "y": 694
                }
            ],
            "category": "paragraph",
            "html": "<p id='17' style='font-size:18px'>We compare SRNNs to strong models that do not explicitly represent segments on handwriting<br>recognition and joint word segmentation and part-of-speech tagging for Chinese text, showing sig-<br>nificant accuracy improvements in both, demonstrating the value of models that explicitly model<br>segmentation even when segmentation is not necessary for downstream tasks (§5).</p>",
            "id": 17,
            "page": 2,
            "text": "We compare SRNNs to strong models that do not explicitly represent segments on handwriting recognition and joint word segmentation and part-of-speech tagging for Chinese text, showing significant accuracy improvements in both, demonstrating the value of models that explicitly model segmentation even when segmentation is not necessary for downstream tasks (§5)."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 762
                },
                {
                    "x": 692,
                    "y": 762
                },
                {
                    "x": 692,
                    "y": 812
                },
                {
                    "x": 444,
                    "y": 812
                }
            ],
            "category": "paragraph",
            "html": "<p id='18' style='font-size:22px'>2 MODEL</p>",
            "id": 18,
            "page": 2,
            "text": "2 MODEL"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 866
                },
                {
                    "x": 2107,
                    "y": 866
                },
                {
                    "x": 2107,
                    "y": 1164
                },
                {
                    "x": 442,
                    "y": 1164
                }
            ],
            "category": "paragraph",
            "html": "<p id='19' style='font-size:18px'>Given a sequence of input observations x = <x1, X2, · · · , x|x|〉 with length |�|, a segmental recur-<br>rent neural network (SRNN) defines a joint distribution p(y, z I x) over a sequence of labeled<br>segments each of which is characterized by a duration (zi E Z+) and label (Yi E Y). The segment<br>durations constrained such that �1 Zi = |x|. The length of the output sequence 비 = 121 is<br>a random variable, and 비 ≤ � with probability 1. We write the starting time of segment i as<br>Si = 1 + Ej<i zj.</p>",
            "id": 19,
            "page": 2,
            "text": "Given a sequence of input observations x = <x1, X2, · · · , x|x|〉 with length |�|, a segmental recurrent neural network (SRNN) defines a joint distribution p(y, z I x) over a sequence of labeled segments each of which is characterized by a duration (zi E Z+) and label (Yi E Y). The segment durations constrained such that �1 Zi = |x|. The length of the output sequence 비 = 121 is a random variable, and 비 ≤ � with probability 1. We write the starting time of segment i as Si = 1 + Ej<i zj."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1187
                },
                {
                    "x": 2106,
                    "y": 1187
                },
                {
                    "x": 2106,
                    "y": 1279
                },
                {
                    "x": 442,
                    "y": 1279
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='20' style='font-size:16px'>To motivate our model form, we state several desiderata. First, we are interested in the following<br>prediction problem,</p>",
            "id": 20,
            "page": 2,
            "text": "To motivate our model form, we state several desiderata. First, we are interested in the following prediction problem,"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1432
                },
                {
                    "x": 2104,
                    "y": 1432
                },
                {
                    "x": 2104,
                    "y": 1524
                },
                {
                    "x": 442,
                    "y": 1524
                }
            ],
            "category": "paragraph",
            "html": "<p id='21' style='font-size:16px'>Note the use of joint maximization over y and z as a computationally tractable substitute for<br>marginalizing out z; this is commonly done in natural language processing.</p>",
            "id": 21,
            "page": 2,
            "text": "Note the use of joint maximization over y and z as a computationally tractable substitute for marginalizing out z; this is commonly done in natural language processing."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1549
                },
                {
                    "x": 2105,
                    "y": 1549
                },
                {
                    "x": 2105,
                    "y": 1639
                },
                {
                    "x": 443,
                    "y": 1639
                }
            ],
            "category": "paragraph",
            "html": "<p id='22' style='font-size:16px'>Second, for problems where the explicit durations observations are unavailable at training time and<br>are inferred as a latent variable, we must be able to use a marginal likelihood training criterion,</p>",
            "id": 22,
            "page": 2,
            "text": "Second, for problems where the explicit durations observations are unavailable at training time and are inferred as a latent variable, we must be able to use a marginal likelihood training criterion,"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1796
                },
                {
                    "x": 2104,
                    "y": 1796
                },
                {
                    "x": 2104,
                    "y": 1889
                },
                {
                    "x": 442,
                    "y": 1889
                }
            ],
            "category": "paragraph",
            "html": "<p id='23' style='font-size:18px'>In Eqs. 1 and 2, the conditional probability of the labeled segment sequence is (assuming kth order<br>dependencies on y):</p>",
            "id": 23,
            "page": 2,
            "text": "In Eqs. 1 and 2, the conditional probability of the labeled segment sequence is (assuming kth order dependencies on y):"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2082
                },
                {
                    "x": 2104,
                    "y": 2082
                },
                {
                    "x": 2104,
                    "y": 2222
                },
                {
                    "x": 442,
                    "y": 2222
                }
            ],
            "category": "paragraph",
            "html": "<p id='24' style='font-size:18px'>where Z(x) is an appropriate normalization function. To ensure the expressiveness of f and the<br>computational efficiency of the maximization and marginalization problems in Eqs. 1 and 2, we use<br>the following definition of f,</p>",
            "id": 24,
            "page": 2,
            "text": "where Z(x) is an appropriate normalization function. To ensure the expressiveness of f and the computational efficiency of the maximization and marginalization problems in Eqs. 1 and 2, we use the following definition of f,"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2402
                },
                {
                    "x": 2107,
                    "y": 2402
                },
                {
                    "x": 2107,
                    "y": 2893
                },
                {
                    "x": 441,
                    "y": 2893
                }
            ],
            "category": "paragraph",
            "html": "<p id='25' style='font-size:18px'>where RNN (Csi:si+zi-1) is a recurrent neural network that computes the forward segment em-<br>1 and RNN computes<br>bedding by \"encoding\" the zi-length subsequence of x starting at index Si,<br>the reverse segment embedding (i.e., traversing the sequence in reverse order), and gy and gz are<br>functions which map the label candidate y and segmentation duration z into a vector representation.<br>The notation [a; b; c] denotes vector concatenation. Finally, the concatenated segment duration,<br>label candidates and segment embedding are passed through a affine transformation layer param-<br>eterized by V and a and a nonlinear activation function ○ (e.g., tanh), and a dot product with a<br>vector w and addition by scalar 6 computes the log potential for the clique. Our proposed model<br>is equivalent to a semi-Markov conditional random field with local features computed using neural<br>networks. Figure 1 shows the model graphically.</p>",
            "id": 25,
            "page": 2,
            "text": "where RNN (Csi:si+zi-1) is a recurrent neural network that computes the forward segment em1 and RNN computes bedding by \"encoding\" the zi-length subsequence of x starting at index Si, the reverse segment embedding (i.e., traversing the sequence in reverse order), and gy and gz are functions which map the label candidate y and segmentation duration z into a vector representation. The notation [a; b; c] denotes vector concatenation. Finally, the concatenated segment duration, label candidates and segment embedding are passed through a affine transformation layer parameterized by V and a and a nonlinear activation function ○ (e.g., tanh), and a dot product with a vector w and addition by scalar 6 computes the log potential for the clique. Our proposed model is equivalent to a semi-Markov conditional random field with local features computed using neural networks. Figure 1 shows the model graphically."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2926
                },
                {
                    "x": 2106,
                    "y": 2926
                },
                {
                    "x": 2106,
                    "y": 3053
                },
                {
                    "x": 442,
                    "y": 3053
                }
            ],
            "category": "paragraph",
            "html": "<p id='26' style='font-size:14px'>1Rather than directly reading the xi's, each token is represented as the concatenation, Ci, of a forward and<br>backward over the sequence of raw inputs. This permits tokens to be sensitive to the contexts they occur in, and<br>this is standardly used with neural net sequence labeling models (Graves et al., 2006).</p>",
            "id": 26,
            "page": 2,
            "text": "1Rather than directly reading the xi's, each token is represented as the concatenation, Ci, of a forward and backward over the sequence of raw inputs. This permits tokens to be sensitive to the contexts they occur in, and this is standardly used with neural net sequence labeling models (Graves , 2006)."
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3135
                },
                {
                    "x": 1289,
                    "y": 3135
                },
                {
                    "x": 1289,
                    "y": 3170
                },
                {
                    "x": 1260,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='27' style='font-size:16px'>2</footer>",
            "id": 27,
            "page": 2,
            "text": "2"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1226,
                    "y": 110
                },
                {
                    "x": 1226,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='28' style='font-size:14px'>Published as a conference paper at ICLR 2016</header>",
            "id": 28,
            "page": 3,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 344
                },
                {
                    "x": 2110,
                    "y": 344
                },
                {
                    "x": 2110,
                    "y": 622
                },
                {
                    "x": 440,
                    "y": 622
                }
            ],
            "category": "paragraph",
            "html": "<p id='29' style='font-size:18px'>We chose bidirectional LSTMs (Graves & Schmidhuber, 2005) as the implementation of the RNNs<br>in Eq. 4. LSTMs (Hochreiter & Schmidhuber, 1997) are a popular variant of RNNs which have<br>been seen successful in many representation learning problems (Graves & Jaitly, 2014; Karpathy &<br>Fei-Fei, 2015). Bidirectional LSTMs enable effective computation for embedings in both directions<br>and are known to be good at preserving long distance dependencies, and hence are well-suited for<br>our task.</p>",
            "id": 29,
            "page": 3,
            "text": "We chose bidirectional LSTMs (Graves & Schmidhuber, 2005) as the implementation of the RNNs in Eq. 4. LSTMs (Hochreiter & Schmidhuber, 1997) are a popular variant of RNNs which have been seen successful in many representation learning problems (Graves & Jaitly, 2014; Karpathy & Fei-Fei, 2015). Bidirectional LSTMs enable effective computation for embedings in both directions and are known to be good at preserving long distance dependencies, and hence are well-suited for our task."
        },
        {
            "bounding_box": [
                {
                    "x": 828,
                    "y": 705
                },
                {
                    "x": 1742,
                    "y": 705
                },
                {
                    "x": 1742,
                    "y": 1698
                },
                {
                    "x": 828,
                    "y": 1698
                }
            ],
            "category": "figure",
            "html": "<figure><img id='30' style='font-size:14px' alt=\"Model\nY1 Y2 Y3\nSegmentation/Labeling\nZ1 Z2 Z3\n1 3 4.5 6.6\n1 3 4 6 6.6\nC1 C2 C3 C4 C5 C6\nBiRNN\nEncoder\nx 1 X2 X3 X4 X5 X6\" data-coord=\"top-left:(828,705); bottom-right:(1742,1698)\" /></figure>",
            "id": 30,
            "page": 3,
            "text": "Model Y1 Y2 Y3 Segmentation/Labeling Z1 Z2 Z3 1 3 4.5 6.6 1 3 4 6 6.6 C1 C2 C3 C4 C5 C6 BiRNN Encoder x 1 X2 X3 X4 X5 X6"
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 1769
                },
                {
                    "x": 2110,
                    "y": 1769
                },
                {
                    "x": 2110,
                    "y": 2098
                },
                {
                    "x": 440,
                    "y": 2098
                }
            ],
            "category": "caption",
            "html": "<caption id='31' style='font-size:16px'>Figure 1: Graphical model showing a six-frame input and three output segments with durations<br>z = <3, 2, 1> (this particular setting of z is shown only to simplify the layout of this figure; the model<br>assigns probabilities to all valid settings of z). Circles represent random variables. Shaded nodes are<br>observed in training; open nodes are latent random variables; diamonds are deterministic functions<br>of their parents; dashed lines indicate optional statistical dependencies that can be included at the<br>cost of increased inference complexity. The graphical notation we use here draws on conventions<br>used to illustrate neural networks and graphical models.</caption>",
            "id": 31,
            "page": 3,
            "text": "Figure 1: Graphical model showing a six-frame input and three output segments with durations z = <3, 2, 1> (this particular setting of z is shown only to simplify the layout of this figure; the model assigns probabilities to all valid settings of z). Circles represent random variables. Shaded nodes are observed in training; open nodes are latent random variables; diamonds are deterministic functions of their parents; dashed lines indicate optional statistical dependencies that can be included at the cost of increased inference complexity. The graphical notation we use here draws on conventions used to illustrate neural networks and graphical models."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2235
                },
                {
                    "x": 1473,
                    "y": 2235
                },
                {
                    "x": 1473,
                    "y": 2292
                },
                {
                    "x": 441,
                    "y": 2292
                }
            ],
            "category": "paragraph",
            "html": "<p id='32' style='font-size:22px'>3 INFERENCE WITH DYNAMIC PROGRAMMING</p>",
            "id": 32,
            "page": 3,
            "text": "3 INFERENCE WITH DYNAMIC PROGRAMMING"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2351
                },
                {
                    "x": 2108,
                    "y": 2351
                },
                {
                    "x": 2108,
                    "y": 2723
                },
                {
                    "x": 441,
                    "y": 2723
                }
            ],
            "category": "paragraph",
            "html": "<p id='33' style='font-size:18px'>We are interested in three inference problems: (i) finding the most probable segmentation/labeling<br>for a model given a sequence x; (ii) evaluating the partition function Z(x); and (iii) computing<br>the posterior marginal Z(x, y), which sums over all segmentations compatible with a reference se-<br>quence y. These can all be solved using dynamic programming. For simplicity, we will assume<br>zeroth order Markov dependencies between the yis. Extensions to the kth order Markov dependen-<br>cies should be straightforward. Since each of these algorithms relies on the forward and reverse<br>segment embeddings, we first discuss how these can be computed before going on to the inference<br>algorithms.</p>",
            "id": 33,
            "page": 3,
            "text": "We are interested in three inference problems: (i) finding the most probable segmentation/labeling for a model given a sequence x; (ii) evaluating the partition function Z(x); and (iii) computing the posterior marginal Z(x, y), which sums over all segmentations compatible with a reference sequence y. These can all be solved using dynamic programming. For simplicity, we will assume zeroth order Markov dependencies between the yis. Extensions to the kth order Markov dependencies should be straightforward. Since each of these algorithms relies on the forward and reverse segment embeddings, we first discuss how these can be computed before going on to the inference algorithms."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2798
                },
                {
                    "x": 1216,
                    "y": 2798
                },
                {
                    "x": 1216,
                    "y": 2847
                },
                {
                    "x": 444,
                    "y": 2847
                }
            ],
            "category": "paragraph",
            "html": "<p id='34' style='font-size:16px'>3.1 COMPUTING SEGMENT EMBEDDINGS</p>",
            "id": 34,
            "page": 3,
            "text": "3.1 COMPUTING SEGMENT EMBEDDINGS"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2886
                },
                {
                    "x": 2109,
                    "y": 2886
                },
                {
                    "x": 2109,
                    "y": 3056
                },
                {
                    "x": 441,
                    "y": 3056
                }
            ],
            "category": "paragraph",
            "html": "<p id='35' style='font-size:20px'>Let the hi,j designate the RNN encoding of the input span (i,j), traversing from left to right, and<br>let h i,j designate the reverse direction encoding using RNN. There are thus O(|x|2) vectors that<br>must be computed, each of length O(|x|). Naively this can be computed in time O(|x|3), but the</p>",
            "id": 35,
            "page": 3,
            "text": "Let the hi,j designate the RNN encoding of the input span (i,j), traversing from left to right, and let h i,j designate the reverse direction encoding using RNN. There are thus O(|x|2) vectors that must be computed, each of length O(|x|). Naively this can be computed in time O(|x|3), but the"
        },
        {
            "bounding_box": [
                {
                    "x": 1261,
                    "y": 3132
                },
                {
                    "x": 1288,
                    "y": 3132
                },
                {
                    "x": 1288,
                    "y": 3171
                },
                {
                    "x": 1261,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='36' style='font-size:16px'>3</footer>",
            "id": 36,
            "page": 3,
            "text": "3"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1226,
                    "y": 110
                },
                {
                    "x": 1226,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='37' style='font-size:14px'>Published as a conference paper at ICLR 2016</header>",
            "id": 37,
            "page": 4,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 344
                },
                {
                    "x": 1329,
                    "y": 344
                },
                {
                    "x": 1329,
                    "y": 395
                },
                {
                    "x": 442,
                    "y": 395
                }
            ],
            "category": "paragraph",
            "html": "<p id='38' style='font-size:18px'>following dynamic program reduces this to O(|x|2):</p>",
            "id": 38,
            "page": 4,
            "text": "following dynamic program reduces this to O(|x|2):"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 725
                },
                {
                    "x": 2109,
                    "y": 725
                },
                {
                    "x": 2109,
                    "y": 913
                },
                {
                    "x": 441,
                    "y": 913
                }
            ],
            "category": "paragraph",
            "html": "<p id='39' style='font-size:18px'>The algorithm is executed by initializing in the values on the diagonal (representing segments of<br>length 1) and then inductively filling out the rest of the matrix. In practice, we often can put a upper<br>bound for the length of a eligible segment thus reducing the complexity of runtime to O(|x|). This<br>savings can be substantial for very long sequences (e.g., those encountered in speech recognition).</p>",
            "id": 39,
            "page": 4,
            "text": "The algorithm is executed by initializing in the values on the diagonal (representing segments of length 1) and then inductively filling out the rest of the matrix. In practice, we often can put a upper bound for the length of a eligible segment thus reducing the complexity of runtime to O(|x|). This savings can be substantial for very long sequences (e.g., those encountered in speech recognition)."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 964
                },
                {
                    "x": 1837,
                    "y": 964
                },
                {
                    "x": 1837,
                    "y": 1014
                },
                {
                    "x": 445,
                    "y": 1014
                }
            ],
            "category": "paragraph",
            "html": "<p id='40' style='font-size:16px'>3.2 COMPUTING THE MOST PROBABLE SEGMENTATION/LABELING AND Z(x)</p>",
            "id": 40,
            "page": 4,
            "text": "3.2 COMPUTING THE MOST PROBABLE SEGMENTATION/LABELING AND Z(x)"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1055
                },
                {
                    "x": 2107,
                    "y": 1055
                },
                {
                    "x": 2107,
                    "y": 1198
                },
                {
                    "x": 441,
                    "y": 1198
                }
            ],
            "category": "paragraph",
            "html": "<p id='41' style='font-size:18px'>For the input sequence x, there are 2|x|-1 possible segmentations and O(||||�|) different labelings<br>of these segments, making exhaustive computation entirely infeasible. Fortunately, the partition<br>function Z(x) may be computed in polynomial time with the following dynamic program:</p>",
            "id": 41,
            "page": 4,
            "text": "For the input sequence x, there are 2|x|-1 possible segmentations and O(||||�|) different labelings of these segments, making exhaustive computation entirely infeasible. Fortunately, the partition function Z(x) may be computed in polynomial time with the following dynamic program:"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1539
                },
                {
                    "x": 2107,
                    "y": 1539
                },
                {
                    "x": 2107,
                    "y": 1677
                },
                {
                    "x": 441,
                    "y": 1677
                }
            ],
            "category": "paragraph",
            "html": "<p id='42' style='font-size:16px'>After computing these values, Z(x) = a|x|. By changing the summations to a max operators (and<br>storing the corresponding arg max values), the maximal a posteriori segmentation/labeling can be<br>computed.</p>",
            "id": 42,
            "page": 4,
            "text": "After computing these values, Z(x) = a|x|. By changing the summations to a max operators (and storing the corresponding arg max values), the maximal a posteriori segmentation/labeling can be computed."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1699
                },
                {
                    "x": 2106,
                    "y": 1699
                },
                {
                    "x": 2106,
                    "y": 1886
                },
                {
                    "x": 441,
                    "y": 1886
                }
            ],
            "category": "paragraph",
            "html": "<p id='43' style='font-size:16px'>Both the partition function evaluation and the search for the MAP outputs run in time O(|x|2 · |Y|<br>with this dynamic program. Adding nth order Markov dependencies between the yis adds requires<br>additional information in each state and increases the time and space requirements by a factor of<br>O(|Y|n). However, this may be tractable for small V and n.</p>",
            "id": 43,
            "page": 4,
            "text": "Both the partition function evaluation and the search for the MAP outputs run in time O(|x|2 · |Y| with this dynamic program. Adding nth order Markov dependencies between the yis adds requires additional information in each state and increases the time and space requirements by a factor of O(|Y|n). However, this may be tractable for small V and n."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1936
                },
                {
                    "x": 2108,
                    "y": 1936
                },
                {
                    "x": 2108,
                    "y": 2076
                },
                {
                    "x": 442,
                    "y": 2076
                }
            ],
            "category": "paragraph",
            "html": "<p id='44' style='font-size:18px'>Avoiding overflow. Since this dynamic program sums over exponentially many segmentations<br>and labelings, the values in the ai chart can become very large. Thus, to avoid issues with overflow,<br>computations of the ai's must be carried out in log space. 2</p>",
            "id": 44,
            "page": 4,
            "text": "Avoiding overflow. Since this dynamic program sums over exponentially many segmentations and labelings, the values in the ai chart can become very large. Thus, to avoid issues with overflow, computations of the ai's must be carried out in log space. 2"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2127
                },
                {
                    "x": 919,
                    "y": 2127
                },
                {
                    "x": 919,
                    "y": 2180
                },
                {
                    "x": 443,
                    "y": 2180
                }
            ],
            "category": "paragraph",
            "html": "<p id='45' style='font-size:20px'>3.3 COMPUTING Z(x,y)</p>",
            "id": 45,
            "page": 4,
            "text": "3.3 COMPUTING Z(x,y)"
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 2215
                },
                {
                    "x": 2108,
                    "y": 2215
                },
                {
                    "x": 2108,
                    "y": 2445
                },
                {
                    "x": 441,
                    "y": 2445
                }
            ],
            "category": "paragraph",
            "html": "<p id='46' style='font-size:16px'>To compute the posterior marginal Z(x, y), it is necessary to sum over all segmentations that are<br>compatible with a label sequence y given an input sequence x. To do SO requires only a minor<br>modification of the previous dynamic program to track how much of the reference label sequence y<br>has been consumed. We introduce the variable m as the index into y for this purpose. The modified<br>recurrences are:</p>",
            "id": 46,
            "page": 4,
            "text": "To compute the posterior marginal Z(x, y), it is necessary to sum over all segmentations that are compatible with a label sequence y given an input sequence x. To do SO requires only a minor modification of the previous dynamic program to track how much of the reference label sequence y has been consumed. We introduce the variable m as the index into y for this purpose. The modified recurrences are:"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2750
                },
                {
                    "x": 967,
                    "y": 2750
                },
                {
                    "x": 967,
                    "y": 2811
                },
                {
                    "x": 443,
                    "y": 2811
                }
            ],
            "category": "paragraph",
            "html": "<p id='47' style='font-size:20px'>The value Z(x, y) is Vlacl (ly|).</p>",
            "id": 47,
            "page": 4,
            "text": "The value Z(x, y) is Vlacl (ly|)."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2840
                },
                {
                    "x": 2108,
                    "y": 2840
                },
                {
                    "x": 2108,
                    "y": 3054
                },
                {
                    "x": 442,
                    "y": 3054
                }
            ],
            "category": "paragraph",
            "html": "<p id='48' style='font-size:14px'>2An alternative strategy for avoiding overflow in similar dynamic programs is to rescale the forward sum-<br>mations at each time step (Rabiner, 1989; Graves et al., 2006). Unfortunately, in a semi-Markov architecture<br>each term in ai sums over different segmentations (e.g., the summation for �2 will have contain some terms<br>that include �1 and some terms that include only ao), which means there are no common factors, making this<br>strategy inapplicable.</p>",
            "id": 48,
            "page": 4,
            "text": "2An alternative strategy for avoiding overflow in similar dynamic programs is to rescale the forward summations at each time step (Rabiner, 1989; Graves , 2006). Unfortunately, in a semi-Markov architecture each term in ai sums over different segmentations (e.g., the summation for �2 will have contain some terms that include �1 and some terms that include only ao), which means there are no common factors, making this strategy inapplicable."
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3170
                },
                {
                    "x": 1259,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='49' style='font-size:16px'>4</footer>",
            "id": 49,
            "page": 4,
            "text": "4"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1226,
                    "y": 110
                },
                {
                    "x": 1226,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='50' style='font-size:16px'>Published as a conference paper at ICLR 2016</header>",
            "id": 50,
            "page": 5,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 341
                },
                {
                    "x": 1038,
                    "y": 341
                },
                {
                    "x": 1038,
                    "y": 393
                },
                {
                    "x": 443,
                    "y": 393
                }
            ],
            "category": "paragraph",
            "html": "<p id='51' style='font-size:20px'>4 PARAMETER LEARNING</p>",
            "id": 51,
            "page": 5,
            "text": "4 PARAMETER LEARNING"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 441
                },
                {
                    "x": 1218,
                    "y": 441
                },
                {
                    "x": 1218,
                    "y": 490
                },
                {
                    "x": 443,
                    "y": 490
                }
            ],
            "category": "paragraph",
            "html": "<p id='52' style='font-size:20px'>We consider two different learning objectives.</p>",
            "id": 52,
            "page": 5,
            "text": "We consider two different learning objectives."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 543
                },
                {
                    "x": 974,
                    "y": 543
                },
                {
                    "x": 974,
                    "y": 590
                },
                {
                    "x": 444,
                    "y": 590
                }
            ],
            "category": "paragraph",
            "html": "<p id='53' style='font-size:16px'>4.1 SUPERVISED LEARNING</p>",
            "id": 53,
            "page": 5,
            "text": "4.1 SUPERVISED LEARNING"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 628
                },
                {
                    "x": 1908,
                    "y": 628
                },
                {
                    "x": 1908,
                    "y": 676
                },
                {
                    "x": 444,
                    "y": 676
                }
            ],
            "category": "paragraph",
            "html": "<p id='54' style='font-size:16px'>In the supervised case, both the segment durations (2) and their labels (y) are observed.</p>",
            "id": 54,
            "page": 5,
            "text": "In the supervised case, both the segment durations (2) and their labels (y) are observed."
        },
        {
            "bounding_box": [
                {
                    "x": 440,
                    "y": 925
                },
                {
                    "x": 2107,
                    "y": 925
                },
                {
                    "x": 2107,
                    "y": 1019
                },
                {
                    "x": 440,
                    "y": 1019
                }
            ],
            "category": "paragraph",
            "html": "<p id='55' style='font-size:18px'>In this expression, the unnormalized conditional probability of the reference segmentation/labeling,<br>given the input x is written as Z(x,y,z).</p>",
            "id": 55,
            "page": 5,
            "text": "In this expression, the unnormalized conditional probability of the reference segmentation/labeling, given the input x is written as Z(x,y,z)."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1070
                },
                {
                    "x": 1177,
                    "y": 1070
                },
                {
                    "x": 1177,
                    "y": 1118
                },
                {
                    "x": 444,
                    "y": 1118
                }
            ],
            "category": "paragraph",
            "html": "<p id='56' style='font-size:14px'>4.2 PARTIALLY SUPERVISED LEARNING</p>",
            "id": 56,
            "page": 5,
            "text": "4.2 PARTIALLY SUPERVISED LEARNING"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1154
                },
                {
                    "x": 2106,
                    "y": 1154
                },
                {
                    "x": 2106,
                    "y": 1247
                },
                {
                    "x": 442,
                    "y": 1247
                }
            ],
            "category": "paragraph",
            "html": "<p id='57' style='font-size:16px'>In the partially supervised case, only the labels are observed and the segments (the z) are unobserved<br>and marginalized.</p>",
            "id": 57,
            "page": 5,
            "text": "In the partially supervised case, only the labels are observed and the segments (the z) are unobserved and marginalized."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1621
                },
                {
                    "x": 2108,
                    "y": 1621
                },
                {
                    "x": 2108,
                    "y": 1762
                },
                {
                    "x": 441,
                    "y": 1762
                }
            ],
            "category": "paragraph",
            "html": "<p id='58' style='font-size:18px'>For both the fully and partially supervised scenarios, the necessary derivatives can be computed<br>using automatic differentiation or (equivalently) with backward variants of the above dynamic pro-<br>grams (Sarawagi & Cohen, 2004).</p>",
            "id": 58,
            "page": 5,
            "text": "For both the fully and partially supervised scenarios, the necessary derivatives can be computed using automatic differentiation or (equivalently) with backward variants of the above dynamic programs (Sarawagi & Cohen, 2004)."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 1825
                },
                {
                    "x": 839,
                    "y": 1825
                },
                {
                    "x": 839,
                    "y": 1877
                },
                {
                    "x": 446,
                    "y": 1877
                }
            ],
            "category": "paragraph",
            "html": "<p id='59' style='font-size:22px'>5 EXPERIMENTS</p>",
            "id": 59,
            "page": 5,
            "text": "5 EXPERIMENTS"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1924
                },
                {
                    "x": 2109,
                    "y": 1924
                },
                {
                    "x": 2109,
                    "y": 2156
                },
                {
                    "x": 442,
                    "y": 2156
                }
            ],
            "category": "paragraph",
            "html": "<p id='60' style='font-size:16px'>We present two sets of experiments to compare segmental recurrent neural networks against mod-<br>els that do not include explicit representations of segmentation. For the handwriting recognition<br>task, we consider connectionist temporal classification (CTC) (Graves et al., 2006); for Chinese<br>word segmentation, we consider BIO tagging. In these experiments, we do not include Markovian<br>dependencies between adjacent labels for our models or the baselines.</p>",
            "id": 60,
            "page": 5,
            "text": "We present two sets of experiments to compare segmental recurrent neural networks against models that do not include explicit representations of segmentation. For the handwriting recognition task, we consider connectionist temporal classification (CTC) (Graves , 2006); for Chinese word segmentation, we consider BIO tagging. In these experiments, we do not include Markovian dependencies between adjacent labels for our models or the baselines."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2207
                },
                {
                    "x": 1240,
                    "y": 2207
                },
                {
                    "x": 1240,
                    "y": 2255
                },
                {
                    "x": 443,
                    "y": 2255
                }
            ],
            "category": "paragraph",
            "html": "<p id='61' style='font-size:16px'>5.1 ONLINE HANDWRITING RECOGNITION</p>",
            "id": 61,
            "page": 5,
            "text": "5.1 ONLINE HANDWRITING RECOGNITION"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2294
                },
                {
                    "x": 2108,
                    "y": 2294
                },
                {
                    "x": 2108,
                    "y": 2479
                },
                {
                    "x": 442,
                    "y": 2479
                }
            ],
            "category": "paragraph",
            "html": "<p id='62' style='font-size:16px'>Dataset We use the handwriting dataset from Kassel (1995). This dataset is an online collection of<br>hand-written words from 150 writers. It is recorded as the coordinates (x, y) at time t plus special<br>pen-down/pen-up notations. We break the coordinates into strokes using the pen-down and pen-up<br>notations. One character typically consists one or more contiguous strokes. 3</p>",
            "id": 62,
            "page": 5,
            "text": "Dataset We use the handwriting dataset from Kassel (1995). This dataset is an online collection of hand-written words from 150 writers. It is recorded as the coordinates (x, y) at time t plus special pen-down/pen-up notations. We break the coordinates into strokes using the pen-down and pen-up notations. One character typically consists one or more contiguous strokes. 3"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2503
                },
                {
                    "x": 2105,
                    "y": 2503
                },
                {
                    "x": 2105,
                    "y": 2593
                },
                {
                    "x": 443,
                    "y": 2593
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='63' style='font-size:18px'>The dataset is split into train, development and test set following Kassel (1995). Table 1 presents the<br>statistics for the dataset.</p>",
            "id": 63,
            "page": 5,
            "text": "The dataset is split into train, development and test set following Kassel (1995). Table 1 presents the statistics for the dataset."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2616
                },
                {
                    "x": 2108,
                    "y": 2616
                },
                {
                    "x": 2108,
                    "y": 2939
                },
                {
                    "x": 442,
                    "y": 2939
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='64' style='font-size:16px'>A well-know variant of this dataset was introduced by Taskar et al. (2004). Taskar et al. (2004)<br>selected a \"clean\" subset of about 6,100 words and rasterized and normalized the images of each<br>letter. Then, the uppercased letters (since they are usually the first character in a word) are removed<br>and only the lowercase letters are used. The main difference between our dataset and theirs is that<br>their datasetis \"offline\" Taskar et al. (2004) mapped each character into a bitmap and treated the<br>segmentation of characters as a preprocessing step. We use the richer representation of the sequence<br>of strokes as input.</p>",
            "id": 64,
            "page": 5,
            "text": "A well-know variant of this dataset was introduced by Taskar  (2004). Taskar  (2004) selected a \"clean\" subset of about 6,100 words and rasterized and normalized the images of each letter. Then, the uppercased letters (since they are usually the first character in a word) are removed and only the lowercase letters are used. The main difference between our dataset and theirs is that their datasetis \"offline\" Taskar  (2004) mapped each character into a bitmap and treated the segmentation of characters as a preprocessing step. We use the richer representation of the sequence of strokes as input."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2965
                },
                {
                    "x": 2108,
                    "y": 2965
                },
                {
                    "x": 2108,
                    "y": 3052
                },
                {
                    "x": 442,
                    "y": 3052
                }
            ],
            "category": "paragraph",
            "html": "<p id='65' style='font-size:14px'>3There are infrequent cases where one stroke can go across multiple characters or the strokes which form<br>the character can be not contiguous. We leave those cases for future work.</p>",
            "id": 65,
            "page": 5,
            "text": "3There are infrequent cases where one stroke can go across multiple characters or the strokes which form the character can be not contiguous. We leave those cases for future work."
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3171
                },
                {
                    "x": 1260,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='66' style='font-size:16px'>5</footer>",
            "id": 66,
            "page": 5,
            "text": "5"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1225,
                    "y": 111
                },
                {
                    "x": 1225,
                    "y": 157
                },
                {
                    "x": 445,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='67' style='font-size:14px'>Published as a conference paper at ICLR 2016</header>",
            "id": 67,
            "page": 6,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 993,
                    "y": 339
                },
                {
                    "x": 1550,
                    "y": 339
                },
                {
                    "x": 1550,
                    "y": 638
                },
                {
                    "x": 993,
                    "y": 638
                }
            ],
            "category": "table",
            "html": "<table id='68' style='font-size:22px'><tr><td></td><td>#words</td><td>#characters</td></tr><tr><td>Train</td><td>4,368</td><td>37,247</td></tr><tr><td>Dev</td><td>1,269</td><td>10,905</td></tr><tr><td>Test</td><td>637</td><td>5,516</td></tr><tr><td>Total</td><td>6,274</td><td>53,668</td></tr></table>",
            "id": 68,
            "page": 6,
            "text": "#words #characters  Train 4,368 37,247  Dev 1,269 10,905  Test 637 5,516  Total 6,274"
        },
        {
            "bounding_box": [
                {
                    "x": 726,
                    "y": 674
                },
                {
                    "x": 1826,
                    "y": 674
                },
                {
                    "x": 1826,
                    "y": 722
                },
                {
                    "x": 726,
                    "y": 722
                }
            ],
            "category": "caption",
            "html": "<caption id='69' style='font-size:20px'>Table 1: Statistics of the Online Handwriting Recognition Dataset</caption>",
            "id": 69,
            "page": 6,
            "text": "Table 1: Statistics of the Online Handwriting Recognition Dataset"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 817
                },
                {
                    "x": 2108,
                    "y": 817
                },
                {
                    "x": 2108,
                    "y": 1185
                },
                {
                    "x": 443,
                    "y": 1185
                }
            ],
            "category": "paragraph",
            "html": "<p id='70' style='font-size:20px'>Implementation We trained two versions of our model on this dataset, namely, the fully supervised<br>model (§4.1), which takes advantage of the gold segmentations on training data, and the partially<br>supervised model (§4.2) in which the gold segmentations are only used in the evaluation. A CTC<br>model reimplemented on the top of our Encoder BiRNNs layer (Figure 1) is used as a baseline SO<br>For the decoding of the<br>that we can see the effect of explicitly representing the segmentation. 4<br>CTC model, we simply use the best path decoding, where we assume that the most probable path<br>will correspond to the most probable labeling, although it is known that prefix search decoding can<br>slightly improve the results (Graves et al., 2006).</p>",
            "id": 70,
            "page": 6,
            "text": "Implementation We trained two versions of our model on this dataset, namely, the fully supervised model (§4.1), which takes advantage of the gold segmentations on training data, and the partially supervised model (§4.2) in which the gold segmentations are only used in the evaluation. A CTC model reimplemented on the top of our Encoder BiRNNs layer (Figure 1) is used as a baseline SO For the decoding of the that we can see the effect of explicitly representing the segmentation. 4 CTC model, we simply use the best path decoding, where we assume that the most probable path will correspond to the most probable labeling, although it is known that prefix search decoding can slightly improve the results (Graves , 2006)."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 1207
                },
                {
                    "x": 2107,
                    "y": 1207
                },
                {
                    "x": 2107,
                    "y": 1483
                },
                {
                    "x": 441,
                    "y": 1483
                }
            ],
            "category": "paragraph",
            "html": "<p id='71' style='font-size:18px'>As a preprocessing step, we first represented each point in the dataset using a 4 dimensional vector,<br>p = (Px, Py, △px, △py), where Px and Py are the normalized coordinates of the point and △px<br>and △py are the corresponding changes in the coordinates with respect to the previous point. △px<br>and △py are meant to capture basic direction information. Then we map the points inside one<br>stroke into a fixed-length vector using a bi-direction LSTM. Specifically, we concatenated the last<br>position's hidden states in both directions and use it as the input vector x for the stroke.</p>",
            "id": 71,
            "page": 6,
            "text": "As a preprocessing step, we first represented each point in the dataset using a 4 dimensional vector, p = (Px, Py, △px, △py), where Px and Py are the normalized coordinates of the point and △px and △py are the corresponding changes in the coordinates with respect to the previous point. △px and △py are meant to capture basic direction information. Then we map the points inside one stroke into a fixed-length vector using a bi-direction LSTM. Specifically, we concatenated the last position's hidden states in both directions and use it as the input vector x for the stroke."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1507
                },
                {
                    "x": 2107,
                    "y": 1507
                },
                {
                    "x": 2107,
                    "y": 1645
                },
                {
                    "x": 442,
                    "y": 1645
                }
            ],
            "category": "paragraph",
            "html": "<p id='72' style='font-size:16px'>In all the experiments, we use Adam (Kingma & Ba, 2014) with 入 = 1 x 10-6 to optimize the<br>parameters in the models. We train these models until convergence and picked the best model over<br>the iterations based on development set performance then report performance on the test set.</p>",
            "id": 72,
            "page": 6,
            "text": "In all the experiments, we use Adam (Kingma & Ba, 2014) with 入 = 1 x 10-6 to optimize the parameters in the models. We train these models until convergence and picked the best model over the iterations based on development set performance then report performance on the test set."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1667
                },
                {
                    "x": 2107,
                    "y": 1667
                },
                {
                    "x": 2107,
                    "y": 1945
                },
                {
                    "x": 442,
                    "y": 1945
                }
            ],
            "category": "paragraph",
            "html": "<p id='73' style='font-size:18px'>We used 5 as the hidden state dimension in the bidirectional RNNs, which map the points into fixed-<br>length stroke embeddings (hence the input vector size 5x2 = 10). We set the hidden dimensions of c<br>in our model and CTC model to 24 and segment embedding h in our model as 18. These dimensions<br>were chosen based on intuitively reasonable values, and it was confirmed on development data<br>that they performed well. We tried to experiment with larger hidden dimensions and we found the<br>performance did not vary much. Future work might more carefully optimize these parameters.</p>",
            "id": 73,
            "page": 6,
            "text": "We used 5 as the hidden state dimension in the bidirectional RNNs, which map the points into fixedlength stroke embeddings (hence the input vector size 5x2 = 10). We set the hidden dimensions of c in our model and CTC model to 24 and segment embedding h in our model as 18. These dimensions were chosen based on intuitively reasonable values, and it was confirmed on development data that they performed well. We tried to experiment with larger hidden dimensions and we found the performance did not vary much. Future work might more carefully optimize these parameters."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1967
                },
                {
                    "x": 2104,
                    "y": 1967
                },
                {
                    "x": 2104,
                    "y": 2059
                },
                {
                    "x": 443,
                    "y": 2059
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='74' style='font-size:18px'>As for speed, the partially supervised SRNNs run at ~40 instances per second and the fully super-<br>vised SRNNs run at ~53 instances during training using a single CPU.</p>",
            "id": 74,
            "page": 6,
            "text": "As for speed, the partially supervised SRNNs run at ~40 instances per second and the fully supervised SRNNs run at ~53 instances during training using a single CPU."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2082
                },
                {
                    "x": 2107,
                    "y": 2082
                },
                {
                    "x": 2107,
                    "y": 2407
                },
                {
                    "x": 443,
                    "y": 2407
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='75' style='font-size:20px'>Results The results of the online handwriting recognition task are presented in Table 2. We see that<br>both of our models outperform the baseline CTC model, which does not carry an explicit represen-<br>tation for the segments being labeled, by a significant margin. An interesting finding is, although the<br>partially supervised model performs slightly worse in the development set, it actually outperforms<br>the fully supervised model in the test set. Because the test set is written by different people from the<br>train and development set, they exhibit different styles in their handwriting; our results suggest that<br>the partially supervised model may generalize better across different writing styles.</p>",
            "id": 75,
            "page": 6,
            "text": "Results The results of the online handwriting recognition task are presented in Table 2. We see that both of our models outperform the baseline CTC model, which does not carry an explicit representation for the segments being labeled, by a significant margin. An interesting finding is, although the partially supervised model performs slightly worse in the development set, it actually outperforms the fully supervised model in the test set. Because the test set is written by different people from the train and development set, they exhibit different styles in their handwriting; our results suggest that the partially supervised model may generalize better across different writing styles."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2470
                },
                {
                    "x": 1603,
                    "y": 2470
                },
                {
                    "x": 1603,
                    "y": 2518
                },
                {
                    "x": 444,
                    "y": 2518
                }
            ],
            "category": "paragraph",
            "html": "<p id='76' style='font-size:16px'>5.2 JOINT CHINESE WORD SEGMENTATION AND POS TAGGING</p>",
            "id": 76,
            "page": 6,
            "text": "5.2 JOINT CHINESE WORD SEGMENTATION AND POS TAGGING"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2559
                },
                {
                    "x": 2107,
                    "y": 2559
                },
                {
                    "x": 2107,
                    "y": 2792
                },
                {
                    "x": 442,
                    "y": 2792
                }
            ],
            "category": "paragraph",
            "html": "<p id='77' style='font-size:16px'>In this section, we will look into two related tasks. The first task is joint Chinese word segmentation<br>and POS tagging, where the z variables will group the Chinese characters into words and the y<br>variables assign POS tags as labels to these words. We also tested our model on pure Chinese word<br>segmentation task, where the assignments of z is the only thing we care about (simulated using a<br>single label for all segments).</p>",
            "id": 77,
            "page": 6,
            "text": "In this section, we will look into two related tasks. The first task is joint Chinese word segmentation and POS tagging, where the z variables will group the Chinese characters into words and the y variables assign POS tags as labels to these words. We also tested our model on pure Chinese word segmentation task, where the assignments of z is the only thing we care about (simulated using a single label for all segments)."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2840
                },
                {
                    "x": 2107,
                    "y": 2840
                },
                {
                    "x": 2107,
                    "y": 3051
                },
                {
                    "x": 442,
                    "y": 3051
                }
            ],
            "category": "paragraph",
            "html": "<p id='78' style='font-size:14px'>4The CTC interpretation rules specify that repeated symbols, e.g. aa will be interpreted as a single token<br>of a. However since the segments in the handwriting recognition problem are extremely short, we use different<br>rules and interpret this as aa. That is, only the blank symbol may be used to represent extended durations. Our<br>experiments indicate this has little effect, and Graves (p.c.) reports that this change does not harm performance<br>in general.</p>",
            "id": 78,
            "page": 6,
            "text": "4The CTC interpretation rules specify that repeated symbols, e.g. aa will be interpreted as a single token of a. However since the segments in the handwriting recognition problem are extremely short, we use different rules and interpret this as aa. That is, only the blank symbol may be used to represent extended durations. Our experiments indicate this has little effect, and Graves (p.c.) reports that this change does not harm performance in general."
        },
        {
            "bounding_box": [
                {
                    "x": 1261,
                    "y": 3136
                },
                {
                    "x": 1287,
                    "y": 3136
                },
                {
                    "x": 1287,
                    "y": 3170
                },
                {
                    "x": 1261,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='79' style='font-size:14px'>6</footer>",
            "id": 79,
            "page": 6,
            "text": "6"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 110
                },
                {
                    "x": 1225,
                    "y": 110
                },
                {
                    "x": 1225,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='80' style='font-size:14px'>Published as a conference paper at ICLR 2016</header>",
            "id": 80,
            "page": 7,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 476,
                    "y": 337
                },
                {
                    "x": 2070,
                    "y": 337
                },
                {
                    "x": 2070,
                    "y": 619
                },
                {
                    "x": 476,
                    "y": 619
                }
            ],
            "category": "table",
            "html": "<table id='81' style='font-size:16px'><tr><td rowspan=\"2\"></td><td colspan=\"4\">Dev</td><td colspan=\"4\">Test</td></tr><tr><td>Pseg</td><td>Rseg</td><td>Fseg</td><td>Error</td><td>Pseg</td><td>Rseg</td><td>Fseg</td><td>Error</td></tr><tr><td>SRNNs (Partial)</td><td>98.7%</td><td>98.4%</td><td>98.6%</td><td>4.2%</td><td>99.2%</td><td>99.1%</td><td>99.2%</td><td>2.7%</td></tr><tr><td>SRNNs (Full)</td><td>98.9%</td><td>98.6%</td><td>98.8%</td><td>4.3%</td><td>98.8%</td><td>98.6%</td><td>98.6%</td><td>5.4%</td></tr><tr><td>CTC</td><td>-</td><td>-</td><td>-</td><td>15.2%</td><td>-</td><td>-</td><td>-</td><td>13.8%</td></tr></table>",
            "id": 81,
            "page": 7,
            "text": "Dev Test  Pseg Rseg Fseg Error Pseg Rseg Fseg Error  SRNNs (Partial) 98.7% 98.4% 98.6% 4.2% 99.2% 99.1% 99.2% 2.7%  SRNNs (Full) 98.9% 98.6% 98.8% 4.3% 98.8% 98.6% 98.6% 5.4%  CTC - - - 15.2% - - -"
        },
        {
            "bounding_box": [
                {
                    "x": 937,
                    "y": 654
                },
                {
                    "x": 1614,
                    "y": 654
                },
                {
                    "x": 1614,
                    "y": 701
                },
                {
                    "x": 937,
                    "y": 701
                }
            ],
            "category": "caption",
            "html": "<caption id='82' style='font-size:20px'>Table 2: Hand-writing Recognition Task</caption>",
            "id": 82,
            "page": 7,
            "text": "Table 2: Hand-writing Recognition Task"
        },
        {
            "bounding_box": [
                {
                    "x": 701,
                    "y": 753
                },
                {
                    "x": 1848,
                    "y": 753
                },
                {
                    "x": 1848,
                    "y": 1168
                },
                {
                    "x": 701,
                    "y": 1168
                }
            ],
            "category": "table",
            "html": "<table id='83' style='font-size:22px'><tr><td rowspan=\"2\"></td><td colspan=\"3\">Dev</td><td colspan=\"3\">Test</td></tr><tr><td>Pseg</td><td>Rseg</td><td>F seg</td><td>Pseg</td><td>Rseg</td><td>Fseg</td></tr><tr><td>BiRNNs</td><td>93.2%</td><td>92.9%</td><td>93.0%</td><td>94.7%</td><td>95.2%</td><td>95.0%</td></tr><tr><td>SRNNs</td><td>93.8%</td><td>93.8%</td><td>93.8%</td><td>95.3%</td><td>95.8%</td><td>95.5%</td></tr><tr><td></td><td>Ptag</td><td>Rtag</td><td>Ftag</td><td>Ptag</td><td>Rtag</td><td>Ftag</td></tr><tr><td>BiRNNs</td><td>87.1%</td><td>86.9%</td><td>87.0%</td><td>88.1%</td><td>88.5%</td><td>88.3%</td></tr><tr><td>SRNNs</td><td>89.0%</td><td>89.1%</td><td>89.0%</td><td>89.8%</td><td>90.3%</td><td>90.0%</td></tr></table>",
            "id": 83,
            "page": 7,
            "text": "Dev Test  Pseg Rseg F seg Pseg Rseg Fseg  BiRNNs 93.2% 92.9% 93.0% 94.7% 95.2% 95.0%  SRNNs 93.8% 93.8% 93.8% 95.3% 95.8% 95.5%   Ptag Rtag Ftag Ptag Rtag Ftag  BiRNNs 87.1% 86.9% 87.0% 88.1% 88.5% 88.3%  SRNNs 89.0% 89.1% 89.0% 89.8% 90.3%"
        },
        {
            "bounding_box": [
                {
                    "x": 758,
                    "y": 1204
                },
                {
                    "x": 1781,
                    "y": 1204
                },
                {
                    "x": 1781,
                    "y": 1252
                },
                {
                    "x": 758,
                    "y": 1252
                }
            ],
            "category": "caption",
            "html": "<caption id='84' style='font-size:20px'>Table 3: Joint Chinese Word Segmentation and POS Tagging</caption>",
            "id": 84,
            "page": 7,
            "text": "Table 3: Joint Chinese Word Segmentation and POS Tagging"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1346
                },
                {
                    "x": 2108,
                    "y": 1346
                },
                {
                    "x": 2108,
                    "y": 1715
                },
                {
                    "x": 442,
                    "y": 1715
                }
            ],
            "category": "paragraph",
            "html": "<p id='85' style='font-size:16px'>Dataset We used standard benchmark datasets for these two tasks. For the joint Chinese word<br>segmentation and POS tagging task, we use the Penn Chinese Treebank 5 (Xue et al., 2005), fol-<br>lowing the standard train/dev/test splits. For the pure Chinese word segmentation task, we used the<br>SIGHAN 2005 dataset5. This dataset contains four portions, covering both simplified and traditional<br>Chinese. Since there is no pre-assigned dev set in this dataset (only train and test set are provided),<br>we manually split the original train set into two, one of which (roughly the same size as the test<br>set) is used as the dev set. For both tasks, we use Wang2Vec (Ling et al., 2015) to generate the<br>pre-trained character embeddings from the Chinese Gigaword (Graff & Chen, 2005).</p>",
            "id": 85,
            "page": 7,
            "text": "Dataset We used standard benchmark datasets for these two tasks. For the joint Chinese word segmentation and POS tagging task, we use the Penn Chinese Treebank 5 (Xue , 2005), following the standard train/dev/test splits. For the pure Chinese word segmentation task, we used the SIGHAN 2005 dataset5. This dataset contains four portions, covering both simplified and traditional Chinese. Since there is no pre-assigned dev set in this dataset (only train and test set are provided), we manually split the original train set into two, one of which (roughly the same size as the test set) is used as the dev set. For both tasks, we use Wang2Vec (Ling , 2015) to generate the pre-trained character embeddings from the Chinese Gigaword (Graff & Chen, 2005)."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1738
                },
                {
                    "x": 2107,
                    "y": 1738
                },
                {
                    "x": 2107,
                    "y": 2015
                },
                {
                    "x": 442,
                    "y": 2015
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='86' style='font-size:16px'>Implementation Only supervised version SRNNs (§4.1) is tested in these tasks. The baseline model<br>is a bi-directional LSTM tagger (basically the same structure as our Encoder BiRNNs in Figure 1). It<br>takes the c at each time step and pushes it through an element-wise non-linear transformation (tanh)<br>followed by an affine transformation to map it to the same dimension as the number of labels. The<br>total loss is therefore the sum of negative log probabilities over the sequence. Greedy decoding is<br>applied in the baseline model, making it a zeroth order model like our SRNNs.</p>",
            "id": 86,
            "page": 7,
            "text": "Implementation Only supervised version SRNNs (§4.1) is tested in these tasks. The baseline model is a bi-directional LSTM tagger (basically the same structure as our Encoder BiRNNs in Figure 1). It takes the c at each time step and pushes it through an element-wise non-linear transformation (tanh) followed by an affine transformation to map it to the same dimension as the number of labels. The total loss is therefore the sum of negative log probabilities over the sequence. Greedy decoding is applied in the baseline model, making it a zeroth order model like our SRNNs."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2038
                },
                {
                    "x": 2107,
                    "y": 2038
                },
                {
                    "x": 2107,
                    "y": 2220
                },
                {
                    "x": 442,
                    "y": 2220
                }
            ],
            "category": "paragraph",
            "html": "<p id='87' style='font-size:16px'>In order to perform segmentation and POS tagging jointly, we composed the POS tags with \"B\" or<br>\"I\" to represent the segmentation point. For the segmentation-only task, in the SRNNs we simply<br>used same dummy tag for all y and only care about the 2 assignments. In the BiRNN case, we used<br>\"B\" and \"T\" tags.</p>",
            "id": 87,
            "page": 7,
            "text": "In order to perform segmentation and POS tagging jointly, we composed the POS tags with \"B\" or \"I\" to represent the segmentation point. For the segmentation-only task, in the SRNNs we simply used same dummy tag for all y and only care about the 2 assignments. In the BiRNN case, we used \"B\" and \"T\" tags."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2245
                },
                {
                    "x": 2107,
                    "y": 2245
                },
                {
                    "x": 2107,
                    "y": 2521
                },
                {
                    "x": 442,
                    "y": 2521
                }
            ],
            "category": "paragraph",
            "html": "<p id='88' style='font-size:16px'>For both tasks, the dimension for the input character embedding is 64. For our model, the dimension<br>for c and the segment embedding h is set to 24. For the baseline bi-directional LSTM tagger, we set<br>the hidden dimension (the c equivalent) size to 128. Here we deliberately chose a larger size than<br>in our model hoping to make the number of parameters in the bi-directional LSTM tagger roughly<br>the same as our model. We trained these models until convergence and picked the best model over<br>iterations based on its performance on the development set.</p>",
            "id": 88,
            "page": 7,
            "text": "For both tasks, the dimension for the input character embedding is 64. For our model, the dimension for c and the segment embedding h is set to 24. For the baseline bi-directional LSTM tagger, we set the hidden dimension (the c equivalent) size to 128. Here we deliberately chose a larger size than in our model hoping to make the number of parameters in the bi-directional LSTM tagger roughly the same as our model. We trained these models until convergence and picked the best model over iterations based on its performance on the development set."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2545
                },
                {
                    "x": 2104,
                    "y": 2545
                },
                {
                    "x": 2104,
                    "y": 2636
                },
                {
                    "x": 442,
                    "y": 2636
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='89' style='font-size:16px'>As for speed, the SRNNs run at ~3.7 sentence per second during training on the CTB dataset using<br>a single CPU.</p>",
            "id": 89,
            "page": 7,
            "text": "As for speed, the SRNNs run at ~3.7 sentence per second during training on the CTB dataset using a single CPU."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2660
                },
                {
                    "x": 2106,
                    "y": 2660
                },
                {
                    "x": 2106,
                    "y": 2754
                },
                {
                    "x": 442,
                    "y": 2754
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='90' style='font-size:18px'>Results Table 3 presents the results for the joint Chinese word segmentation task. We can see that<br>in both segmentation and POS tagging, the SRNNs achieve higher F-scores than the BiRNNs.</p>",
            "id": 90,
            "page": 7,
            "text": "Results Table 3 presents the results for the joint Chinese word segmentation task. We can see that in both segmentation and POS tagging, the SRNNs achieve higher F-scores than the BiRNNs."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2775
                },
                {
                    "x": 2108,
                    "y": 2775
                },
                {
                    "x": 2108,
                    "y": 2961
                },
                {
                    "x": 442,
                    "y": 2961
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='91' style='font-size:16px'>Table 4 presents the results for the pure Chinese word segmentation task. The SRNNs perform<br>better than the BiRNNs with the exception of the PKU portion of the dataset. The reason for this is<br>probably because the training set in this portion is the smallest among the four. Thus leads to high<br>variance in the test results.</p>",
            "id": 91,
            "page": 7,
            "text": "Table 4 presents the results for the pure Chinese word segmentation task. The SRNNs perform better than the BiRNNs with the exception of the PKU portion of the dataset. The reason for this is probably because the training set in this portion is the smallest among the four. Thus leads to high variance in the test results."
        },
        {
            "bounding_box": [
                {
                    "x": 498,
                    "y": 3007
                },
                {
                    "x": 1280,
                    "y": 3007
                },
                {
                    "x": 1280,
                    "y": 3053
                },
                {
                    "x": 498,
                    "y": 3053
                }
            ],
            "category": "paragraph",
            "html": "<p id='92' style='font-size:16px'>5http : / /www . sighan · org/bakeoff2005/</p>",
            "id": 92,
            "page": 7,
            "text": "5http : / /www . sighan · org/bakeoff2005/"
        },
        {
            "bounding_box": [
                {
                    "x": 1260,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3170
                },
                {
                    "x": 1260,
                    "y": 3170
                }
            ],
            "category": "footer",
            "html": "<footer id='93' style='font-size:14px'>7</footer>",
            "id": 93,
            "page": 7,
            "text": "7"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 111
                },
                {
                    "x": 1226,
                    "y": 111
                },
                {
                    "x": 1226,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='94' style='font-size:14px'>Published as a conference paper at ICLR 2016</header>",
            "id": 94,
            "page": 8,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 726,
                    "y": 336
                },
                {
                    "x": 1817,
                    "y": 336
                },
                {
                    "x": 1817,
                    "y": 662
                },
                {
                    "x": 726,
                    "y": 662
                }
            ],
            "category": "table",
            "html": "<table id='95' style='font-size:20px'><tr><td rowspan=\"2\"></td><td colspan=\"3\">BiRNNs</td><td colspan=\"3\">SRNNs</td></tr><tr><td>Pseg</td><td>Rseg</td><td>Fseg</td><td>Pseg</td><td>Rseg</td><td>F seg</td></tr><tr><td>CU</td><td>92.7%</td><td>93.1%</td><td>92.9%</td><td>93.3%</td><td>93.7%</td><td>93.5%</td></tr><tr><td>AS</td><td>92.8%</td><td>93.5%</td><td>93.1%</td><td>93.2%</td><td>94.2%</td><td>93.7%</td></tr><tr><td>MSR</td><td>89.9%</td><td>90.1%</td><td>90.0%</td><td>90.9%</td><td>90.4%</td><td>90.7%</td></tr><tr><td>PKU</td><td>91.5%</td><td>91.2%</td><td>91.3%</td><td>90.6%</td><td>90.6%</td><td>90.6%</td></tr></table>",
            "id": 95,
            "page": 8,
            "text": "BiRNNs SRNNs  Pseg Rseg Fseg Pseg Rseg F seg  CU 92.7% 93.1% 92.9% 93.3% 93.7% 93.5%  AS 92.8% 93.5% 93.1% 93.2% 94.2% 93.7%  MSR 89.9% 90.1% 90.0% 90.9% 90.4% 90.7%  PKU 91.5% 91.2% 91.3% 90.6% 90.6%"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 697
                },
                {
                    "x": 2108,
                    "y": 697
                },
                {
                    "x": 2108,
                    "y": 885
                },
                {
                    "x": 442,
                    "y": 885
                }
            ],
            "category": "caption",
            "html": "<caption id='96' style='font-size:18px'>Table 4: Chinese Word Segmentation Results on SIGHAN 2005 dataset. There are four portions of<br>the dataset from City University of Hong Kong (CU), Academia Sinica (AS), Microsoft Research<br>(MSR) and Peking University (PKU). The former two are in traditional Chinese and the latter two<br>are in simplified Chinese.</caption>",
            "id": 96,
            "page": 8,
            "text": "Table 4: Chinese Word Segmentation Results on SIGHAN 2005 dataset. There are four portions of the dataset from City University of Hong Kong (CU), Academia Sinica (AS), Microsoft Research (MSR) and Peking University (PKU). The former two are in traditional Chinese and the latter two are in simplified Chinese."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1107
                },
                {
                    "x": 884,
                    "y": 1107
                },
                {
                    "x": 884,
                    "y": 1158
                },
                {
                    "x": 445,
                    "y": 1158
                }
            ],
            "category": "paragraph",
            "html": "<p id='97' style='font-size:22px'>6 RELATED WORK</p>",
            "id": 97,
            "page": 8,
            "text": "6 RELATED WORK"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1305
                },
                {
                    "x": 2107,
                    "y": 1305
                },
                {
                    "x": 2107,
                    "y": 1765
                },
                {
                    "x": 442,
                    "y": 1765
                }
            ],
            "category": "paragraph",
            "html": "<p id='98' style='font-size:18px'>Segmental labeling problems have been widely studied. A widely used approach to a segmental<br>labeling problems with neural networks is the connectionist temporal classification (CTC) objective<br>and decoding rule of Graves et al. (2006). CTC reduces the \"segmental\" sequence label problem to<br>a classical sequence labeling problem in which every position in an input sequence x is explicitly<br>labeled by interpreting repetitions of input labels-or input labels followed by a special \"blank\" out-<br>put symbol-as being a single label with a longer duration. During training, the marginal likelihood<br>of the set of labelings compatible (according to the CTC interpretation rules) with the reference label<br>y is maximized. CTC has demonstrated impressive success in various fully discriminative end-to-<br>end speech recognition models (Graves & Jaitly, 2014; Maas et al., 2015; Hannun et al., 2014, inter<br>alia).</p>",
            "id": 98,
            "page": 8,
            "text": "Segmental labeling problems have been widely studied. A widely used approach to a segmental labeling problems with neural networks is the connectionist temporal classification (CTC) objective and decoding rule of Graves  (2006). CTC reduces the \"segmental\" sequence label problem to a classical sequence labeling problem in which every position in an input sequence x is explicitly labeled by interpreting repetitions of input labels-or input labels followed by a special \"blank\" output symbol-as being a single label with a longer duration. During training, the marginal likelihood of the set of labelings compatible (according to the CTC interpretation rules) with the reference label y is maximized. CTC has demonstrated impressive success in various fully discriminative end-toend speech recognition models (Graves & Jaitly, 2014; Maas , 2015; Hannun , 2014, inter alia)."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1789
                },
                {
                    "x": 2107,
                    "y": 1789
                },
                {
                    "x": 2107,
                    "y": 2294
                },
                {
                    "x": 442,
                    "y": 2294
                }
            ],
            "category": "paragraph",
            "html": "<p id='99' style='font-size:18px'>Although CTC has been used successfully and its reuse of conventional sequence labeling architec-<br>tures is appealing, it has several potentially serious limitations. First, itis not possible to model inter-<br>label dependencies explicitly-these must instead be captured indirectly by the underlying RNNs.<br>Second, CTC has no explicit segmentation model. Although this is most serious in applications<br>where segmentation is a necessary/desired output (e.g., information extraction, protein secondary<br>structure prediction), we argue that explicit segmentation is potentially valuable even when the seg-<br>mentation is not required. To illustrate the value of explicit segments, consider the problem of phone<br>recognition. For this task, segmental duration is strongly correlated with label identity (e.g., while<br>an [o] phone token might last 300ms, it is unlikely that a [t] would) and thus modeling it explicitly<br>may be useful. Finally, making an explicit labeling decision for every position (and introducing a<br>special blank symbol) in an input sequence is conceptually unappealing.</p>",
            "id": 99,
            "page": 8,
            "text": "Although CTC has been used successfully and its reuse of conventional sequence labeling architectures is appealing, it has several potentially serious limitations. First, itis not possible to model interlabel dependencies explicitly-these must instead be captured indirectly by the underlying RNNs. Second, CTC has no explicit segmentation model. Although this is most serious in applications where segmentation is a necessary/desired output (e.g., information extraction, protein secondary structure prediction), we argue that explicit segmentation is potentially valuable even when the segmentation is not required. To illustrate the value of explicit segments, consider the problem of phone recognition. For this task, segmental duration is strongly correlated with label identity (e.g., while an [o] phone token might last 300ms, it is unlikely that a [t] would) and thus modeling it explicitly may be useful. Finally, making an explicit labeling decision for every position (and introducing a special blank symbol) in an input sequence is conceptually unappealing."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2315
                },
                {
                    "x": 2107,
                    "y": 2315
                },
                {
                    "x": 2107,
                    "y": 2639
                },
                {
                    "x": 442,
                    "y": 2639
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='100' style='font-size:14px'>Several alternatives to CTC have been approached, such as using various attention mechanisms in<br>place of marginalization (Chan et al., 2015; Bahdanau et al., 2015). These have been applied to end-<br>to-end discriminative speech recognition problem. A more direct alternative to our method-indeed<br>it was proposed to solve several of the same problems we identified-is due to Graves (2012).<br>However, a crucial difference is that our model explicitly constructs representations of segments<br>which are used to label the segment while that model relies on a marginalized frame-level labeling<br>with a null symbol.</p>",
            "id": 100,
            "page": 8,
            "text": "Several alternatives to CTC have been approached, such as using various attention mechanisms in place of marginalization (Chan , 2015; Bahdanau , 2015). These have been applied to endto-end discriminative speech recognition problem. A more direct alternative to our method-indeed it was proposed to solve several of the same problems we identified-is due to Graves (2012). However, a crucial difference is that our model explicitly constructs representations of segments which are used to label the segment while that model relies on a marginalized frame-level labeling with a null symbol."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2660
                },
                {
                    "x": 2107,
                    "y": 2660
                },
                {
                    "x": 2107,
                    "y": 2891
                },
                {
                    "x": 443,
                    "y": 2891
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='101' style='font-size:16px'>The work of Abdel-Hamid (2013) also seeks to construct embeddings of multi-frame segments.<br>Their approach is quite different than the one taken here. First, they compute representations of<br>variable-sized segments by uniformly sampling a fixed number of frames and using these to con-<br>struct a representation of the segment with a simple feedforward network. Second, they do not<br>consider them problem of latent segmentation.</p>",
            "id": 101,
            "page": 8,
            "text": "The work of Abdel-Hamid (2013) also seeks to construct embeddings of multi-frame segments. Their approach is quite different than the one taken here. First, they compute representations of variable-sized segments by uniformly sampling a fixed number of frames and using these to construct a representation of the segment with a simple feedforward network. Second, they do not consider them problem of latent segmentation."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2915
                },
                {
                    "x": 2108,
                    "y": 2915
                },
                {
                    "x": 2108,
                    "y": 3053
                },
                {
                    "x": 442,
                    "y": 3053
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='102' style='font-size:18px'>Finally, using neural networks to provide local features in conditional random field models has also<br>been proposed for sequential models (Peng et al., 2009) and tree-structured models (Durrett & Klein,<br>2015). To our knowledge, this is the first application to semi-Markov structures.</p>",
            "id": 102,
            "page": 8,
            "text": "Finally, using neural networks to provide local features in conditional random field models has also been proposed for sequential models (Peng , 2009) and tree-structured models (Durrett & Klein, 2015). To our knowledge, this is the first application to semi-Markov structures."
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3171
                },
                {
                    "x": 1259,
                    "y": 3171
                }
            ],
            "category": "footer",
            "html": "<footer id='103' style='font-size:16px'>8</footer>",
            "id": 103,
            "page": 8,
            "text": "8"
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 112
                },
                {
                    "x": 1225,
                    "y": 112
                },
                {
                    "x": 1225,
                    "y": 156
                },
                {
                    "x": 445,
                    "y": 156
                }
            ],
            "category": "header",
            "html": "<header id='104' style='font-size:14px'>Published as a conference paper at ICLR 2016</header>",
            "id": 104,
            "page": 9,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 448,
                    "y": 342
                },
                {
                    "x": 818,
                    "y": 342
                },
                {
                    "x": 818,
                    "y": 392
                },
                {
                    "x": 448,
                    "y": 392
                }
            ],
            "category": "paragraph",
            "html": "<p id='105' style='font-size:22px'>7 CONCLUSION</p>",
            "id": 105,
            "page": 9,
            "text": "7 CONCLUSION"
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 443
                },
                {
                    "x": 2107,
                    "y": 443
                },
                {
                    "x": 2107,
                    "y": 720
                },
                {
                    "x": 442,
                    "y": 720
                }
            ],
            "category": "paragraph",
            "html": "<p id='106' style='font-size:14px'>We have proposed a new model for segment labeling problems that learns representations of seg-<br>ments of an input sequence and then labels these. We outperform existing alternatives both when<br>segmental information should be recovered and when it is only latent. We have not trained the seg-<br>mental representations to be of any use beyond making good labeling (or segmentation) decisions,<br>but an intriguing avenue for future work would be to construct representations that are useful for<br>other tasks.</p>",
            "id": 106,
            "page": 9,
            "text": "We have proposed a new model for segment labeling problems that learns representations of segments of an input sequence and then labels these. We outperform existing alternatives both when segmental information should be recovered and when it is only latent. We have not trained the segmental representations to be of any use beyond making good labeling (or segmentation) decisions, but an intriguing avenue for future work would be to construct representations that are useful for other tasks."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 773
                },
                {
                    "x": 838,
                    "y": 773
                },
                {
                    "x": 838,
                    "y": 816
                },
                {
                    "x": 446,
                    "y": 816
                }
            ],
            "category": "paragraph",
            "html": "<p id='107' style='font-size:16px'>ACKNOWLEDGMENTS</p>",
            "id": 107,
            "page": 9,
            "text": "ACKNOWLEDGMENTS"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 850
                },
                {
                    "x": 2106,
                    "y": 850
                },
                {
                    "x": 2106,
                    "y": 1035
                },
                {
                    "x": 443,
                    "y": 1035
                }
            ],
            "category": "paragraph",
            "html": "<p id='108' style='font-size:16px'>The authors thank the anonymous reviewers, Yanchuan Sim, and Hao Tang for their helpful feed-<br>back. This work was sponsored in part by the Defense Advanced Research Projects Agency<br>(DARPA) Information Innovation Office (I2O) under the Low Resource Languages for Emergent<br>Incidents (LORELEI) program issued by DARPA/I2O under Contract No. HR0011-15-C-0114.</p>",
            "id": 108,
            "page": 9,
            "text": "The authors thank the anonymous reviewers, Yanchuan Sim, and Hao Tang for their helpful feedback. This work was sponsored in part by the Defense Advanced Research Projects Agency (DARPA) Information Innovation Office (I2O) under the Low Resource Languages for Emergent Incidents (LORELEI) program issued by DARPA/I2O under Contract No. HR0011-15-C-0114."
        },
        {
            "bounding_box": [
                {
                    "x": 446,
                    "y": 1102
                },
                {
                    "x": 735,
                    "y": 1102
                },
                {
                    "x": 735,
                    "y": 1151
                },
                {
                    "x": 446,
                    "y": 1151
                }
            ],
            "category": "paragraph",
            "html": "<p id='109' style='font-size:20px'>REFERENCES</p>",
            "id": 109,
            "page": 9,
            "text": "REFERENCES"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1178
                },
                {
                    "x": 2104,
                    "y": 1178
                },
                {
                    "x": 2104,
                    "y": 1269
                },
                {
                    "x": 444,
                    "y": 1269
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='110' style='font-size:16px'>Abdel-Hamid, Huda. Structural-Functional Analysis of Plant Cyclic Nucleotide Gated Ion Chan-<br>nels. PhD thesis, University of Toronto, 2013.</p>",
            "id": 110,
            "page": 9,
            "text": "Abdel-Hamid, Huda. Structural-Functional Analysis of Plant Cyclic Nucleotide Gated Ion Channels. PhD thesis, University of Toronto, 2013."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1300
                },
                {
                    "x": 2102,
                    "y": 1300
                },
                {
                    "x": 2102,
                    "y": 1394
                },
                {
                    "x": 443,
                    "y": 1394
                }
            ],
            "category": "paragraph",
            "html": "<p id='111' style='font-size:20px'>Bahdanau, Dzmitry, Chorowski, Jan, Serdyuk, Dmitriy, Brakel, Philemon, and Bengio, Yoshua.<br>End-to-end attention-based large vocabulary speech recognition. CoRR, abs/1508.04395, 2015.</p>",
            "id": 111,
            "page": 9,
            "text": "Bahdanau, Dzmitry, Chorowski, Jan, Serdyuk, Dmitriy, Brakel, Philemon, and Bengio, Yoshua. End-to-end attention-based large vocabulary speech recognition. CoRR, abs/1508.04395, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 1422
                },
                {
                    "x": 2106,
                    "y": 1422
                },
                {
                    "x": 2106,
                    "y": 1513
                },
                {
                    "x": 442,
                    "y": 1513
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='112' style='font-size:20px'>Chan, William, Jaitly, Navdeep, Le, Quoc V., and Vinyals, Oriol. Listen, attend, and spell. CoRR,<br>abs/1508.01211, 2015.</p>",
            "id": 112,
            "page": 9,
            "text": "Chan, William, Jaitly, Navdeep, Le, Quoc V., and Vinyals, Oriol. Listen, attend, and spell. CoRR, abs/1508.01211, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 445,
                    "y": 1545
                },
                {
                    "x": 1658,
                    "y": 1545
                },
                {
                    "x": 1658,
                    "y": 1591
                },
                {
                    "x": 445,
                    "y": 1591
                }
            ],
            "category": "paragraph",
            "html": "<p id='113' style='font-size:16px'>Durrett, Greg and Klein, Dan. Neural CRF parsing. In Proc. ACL, 2015.</p>",
            "id": 113,
            "page": 9,
            "text": "Durrett, Greg and Klein, Dan. Neural CRF parsing. In Proc. ACL, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1620
                },
                {
                    "x": 1955,
                    "y": 1620
                },
                {
                    "x": 1955,
                    "y": 1667
                },
                {
                    "x": 444,
                    "y": 1667
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='114' style='font-size:16px'>Graff, David and Chen, Ke. Chinese gigaword. LDC Catalog No.: LDC2003T09, 1, 2005.</p>",
            "id": 114,
            "page": 9,
            "text": "Graff, David and Chen, Ke. Chinese gigaword. LDC Catalog No.: LDC2003T09, 1, 2005."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 1696
                },
                {
                    "x": 1973,
                    "y": 1696
                },
                {
                    "x": 1973,
                    "y": 1743
                },
                {
                    "x": 444,
                    "y": 1743
                }
            ],
            "category": "paragraph",
            "html": "<p id='115' style='font-size:14px'>Graves, Alex. Sequence transduction with recurrent neural networks. In Proc. ICML, 2012.</p>",
            "id": 115,
            "page": 9,
            "text": "Graves, Alex. Sequence transduction with recurrent neural networks. In Proc. ICML, 2012."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1773
                },
                {
                    "x": 2104,
                    "y": 1773
                },
                {
                    "x": 2104,
                    "y": 1863
                },
                {
                    "x": 443,
                    "y": 1863
                }
            ],
            "category": "paragraph",
            "html": "<p id='116' style='font-size:16px'>Graves, Alex and Jaitly, Navdeep. Towards end-to-end speech recognition with recurrent neural<br>networks. In Proc. ICML, 2014.</p>",
            "id": 116,
            "page": 9,
            "text": "Graves, Alex and Jaitly, Navdeep. Towards end-to-end speech recognition with recurrent neural networks. In Proc. ICML, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 1895
                },
                {
                    "x": 2106,
                    "y": 1895
                },
                {
                    "x": 2106,
                    "y": 1986
                },
                {
                    "x": 443,
                    "y": 1986
                }
            ],
            "category": "paragraph",
            "html": "<p id='117' style='font-size:16px'>Graves, Alex and Schmidhuber, Jurgen. Framewise phoneme classification with bidirectional LSTM<br>and other neural network architectures. Neural Networks, 18(5):602-610, 2005.</p>",
            "id": 117,
            "page": 9,
            "text": "Graves, Alex and Schmidhuber, Jurgen. Framewise phoneme classification with bidirectional LSTM and other neural network architectures. Neural Networks, 18(5):602-610, 2005."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2016
                },
                {
                    "x": 2107,
                    "y": 2016
                },
                {
                    "x": 2107,
                    "y": 2151
                },
                {
                    "x": 442,
                    "y": 2151
                }
            ],
            "category": "paragraph",
            "html": "<p id='118' style='font-size:16px'>Graves, Alex, Fernandez, Santiago, Gomez, Faustino, and Schmidhuber, Jurgen. Connectionist<br>temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In<br>Proc. ICML, 2006.</p>",
            "id": 118,
            "page": 9,
            "text": "Graves, Alex, Fernandez, Santiago, Gomez, Faustino, and Schmidhuber, Jurgen. Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In Proc. ICML, 2006."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 2183
                },
                {
                    "x": 2106,
                    "y": 2183
                },
                {
                    "x": 2106,
                    "y": 2321
                },
                {
                    "x": 442,
                    "y": 2321
                }
            ],
            "category": "paragraph",
            "html": "<p id='119' style='font-size:20px'>Hannun, Awni Y., Case, Carl, Casper, Jared, Catanzaro, Bryan C., Diamos, Greg, Elsen, Erich,<br>Prenger, Ryan, Satheesh, Sanjeev, Sengupta, Shubho, Coates, Adam, and Ng, Andrew Y. Deep<br>speech: Scaling up end-to-end speech recognition. CoRR, abs/1412.5567, 2014.</p>",
            "id": 119,
            "page": 9,
            "text": "Hannun, Awni Y., Case, Carl, Casper, Jared, Catanzaro, Bryan C., Diamos, Greg, Elsen, Erich, Prenger, Ryan, Satheesh, Sanjeev, Sengupta, Shubho, Coates, Adam, and Ng, Andrew Y. Deep speech: Scaling up end-to-end speech recognition. CoRR, abs/1412.5567, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2349
                },
                {
                    "x": 2106,
                    "y": 2349
                },
                {
                    "x": 2106,
                    "y": 2440
                },
                {
                    "x": 443,
                    "y": 2440
                }
            ],
            "category": "paragraph",
            "html": "<br><p id='120' style='font-size:20px'>Hochreiter, Sepp and Schmidhuber, Jurgen. Long short-term memory. Neural computation, 9(8):<br>1735-1780, 1997.</p>",
            "id": 120,
            "page": 9,
            "text": "Hochreiter, Sepp and Schmidhuber, Jurgen. Long short-term memory. Neural computation, 9(8): 1735-1780, 1997."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2473
                },
                {
                    "x": 2103,
                    "y": 2473
                },
                {
                    "x": 2103,
                    "y": 2563
                },
                {
                    "x": 444,
                    "y": 2563
                }
            ],
            "category": "paragraph",
            "html": "<p id='121' style='font-size:18px'>Karpathy, Andrej and Fei-Fei, Li. Deep visual-semantic alignments for generating image descrip-<br>tions. In Proc. CVPR, 2015.</p>",
            "id": 121,
            "page": 9,
            "text": "Karpathy, Andrej and Fei-Fei, Li. Deep visual-semantic alignments for generating image descriptions. In Proc. CVPR, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2596
                },
                {
                    "x": 2105,
                    "y": 2596
                },
                {
                    "x": 2105,
                    "y": 2685
                },
                {
                    "x": 444,
                    "y": 2685
                }
            ],
            "category": "paragraph",
            "html": "<p id='122' style='font-size:16px'>Kassel, Robert H. A comparison of approaches to on-line handwritten character recognition. PhD<br>thesis, Massachusetts Institute of Technology, 1995.</p>",
            "id": 122,
            "page": 9,
            "text": "Kassel, Robert H. A comparison of approaches to on-line handwritten character recognition. PhD thesis, Massachusetts Institute of Technology, 1995."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2718
                },
                {
                    "x": 2106,
                    "y": 2718
                },
                {
                    "x": 2106,
                    "y": 2806
                },
                {
                    "x": 444,
                    "y": 2806
                }
            ],
            "category": "paragraph",
            "html": "<p id='123' style='font-size:16px'>Kingma, Diederik and Ba, Jimmy. Adam: A method for stochastic optimization. arXiv preprint<br>arXiv:1412.6980, 2014.</p>",
            "id": 123,
            "page": 9,
            "text": "Kingma, Diederik and Ba, Jimmy. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 2839
                },
                {
                    "x": 2106,
                    "y": 2839
                },
                {
                    "x": 2106,
                    "y": 2929
                },
                {
                    "x": 443,
                    "y": 2929
                }
            ],
            "category": "paragraph",
            "html": "<p id='124' style='font-size:18px'>Ling, Wang, Dyer, Chris, Black, Alan W, and Trancoso, Isabel. Two/too simple adaptations of<br>word2vec for syntax problems. In Proc. NAACL, 2015.</p>",
            "id": 124,
            "page": 9,
            "text": "Ling, Wang, Dyer, Chris, Black, Alan W, and Trancoso, Isabel. Two/too simple adaptations of word2vec for syntax problems. In Proc. NAACL, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 2961
                },
                {
                    "x": 2107,
                    "y": 2961
                },
                {
                    "x": 2107,
                    "y": 3052
                },
                {
                    "x": 444,
                    "y": 3052
                }
            ],
            "category": "paragraph",
            "html": "<p id='125' style='font-size:18px'>Maas, Andrew L., Xie, Ziang, Jurafsky, Dan, and Ng, Andrew Y. Lexicon-free conversational speech<br>recognition with neural networks. In Proc. NAACL, 2015.</p>",
            "id": 125,
            "page": 9,
            "text": "Maas, Andrew L., Xie, Ziang, Jurafsky, Dan, and Ng, Andrew Y. Lexicon-free conversational speech recognition with neural networks. In Proc. NAACL, 2015."
        },
        {
            "bounding_box": [
                {
                    "x": 1259,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3134
                },
                {
                    "x": 1289,
                    "y": 3169
                },
                {
                    "x": 1259,
                    "y": 3169
                }
            ],
            "category": "footer",
            "html": "<footer id='126' style='font-size:14px'>9</footer>",
            "id": 126,
            "page": 9,
            "text": "9"
        },
        {
            "bounding_box": [
                {
                    "x": 444,
                    "y": 111
                },
                {
                    "x": 1225,
                    "y": 111
                },
                {
                    "x": 1225,
                    "y": 157
                },
                {
                    "x": 444,
                    "y": 157
                }
            ],
            "category": "header",
            "html": "<header id='127' style='font-size:14px'>Published as a conference paper at ICLR 2016</header>",
            "id": 127,
            "page": 10,
            "text": "Published as a conference paper at ICLR 2016"
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 346
                },
                {
                    "x": 1904,
                    "y": 346
                },
                {
                    "x": 1904,
                    "y": 393
                },
                {
                    "x": 443,
                    "y": 393
                }
            ],
            "category": "paragraph",
            "html": "<p id='128' style='font-size:20px'>Peng, Jian, Bo, Liefeng, and Xu, Jinbo. Conditional neural fields. In Proc. NIPS, 2009.</p>",
            "id": 128,
            "page": 10,
            "text": "Peng, Jian, Bo, Liefeng, and Xu, Jinbo. Conditional neural fields. In Proc. NIPS, 2009."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 425
                },
                {
                    "x": 2108,
                    "y": 425
                },
                {
                    "x": 2108,
                    "y": 519
                },
                {
                    "x": 443,
                    "y": 519
                }
            ],
            "category": "paragraph",
            "html": "<p id='129' style='font-size:18px'>Rabiner, Lawrence R. A tutorion on hidden Markov models and selected applications in speech<br>recognition. Proc. IEEE, 77(2), 1989.</p>",
            "id": 129,
            "page": 10,
            "text": "Rabiner, Lawrence R. A tutorion on hidden Markov models and selected applications in speech recognition. Proc. IEEE, 77(2), 1989."
        },
        {
            "bounding_box": [
                {
                    "x": 441,
                    "y": 550
                },
                {
                    "x": 2106,
                    "y": 550
                },
                {
                    "x": 2106,
                    "y": 643
                },
                {
                    "x": 441,
                    "y": 643
                }
            ],
            "category": "paragraph",
            "html": "<p id='130' style='font-size:20px'>Ramshaw, Lance A. and Marcus, Mitchell P. Text chunking using transformation-based learning. In<br>Proceedings of the Workshop on Very Large Corpora, 1995.</p>",
            "id": 130,
            "page": 10,
            "text": "Ramshaw, Lance A. and Marcus, Mitchell P. Text chunking using transformation-based learning. In Proceedings of the Workshop on Very Large Corpora, 1995."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 676
                },
                {
                    "x": 2109,
                    "y": 676
                },
                {
                    "x": 2109,
                    "y": 766
                },
                {
                    "x": 442,
                    "y": 766
                }
            ],
            "category": "paragraph",
            "html": "<p id='131' style='font-size:18px'>Sarawagi, Sunita and Cohen, William W. Semi-Markov conditional random fields for information<br>extraction. In Proc. NIPS, 2004.</p>",
            "id": 131,
            "page": 10,
            "text": "Sarawagi, Sunita and Cohen, William W. Semi-Markov conditional random fields for information extraction. In Proc. NIPS, 2004."
        },
        {
            "bounding_box": [
                {
                    "x": 443,
                    "y": 798
                },
                {
                    "x": 2106,
                    "y": 798
                },
                {
                    "x": 2106,
                    "y": 888
                },
                {
                    "x": 443,
                    "y": 888
                }
            ],
            "category": "paragraph",
            "html": "<p id='132' style='font-size:22px'>Taskar, Ben, Guestrin, Carlos, and Koller, Daphne. Max-margin Markov networks. NIPS, 16:25,<br>2004.</p>",
            "id": 132,
            "page": 10,
            "text": "Taskar, Ben, Guestrin, Carlos, and Koller, Daphne. Max-margin Markov networks. NIPS, 16:25, 2004."
        },
        {
            "bounding_box": [
                {
                    "x": 442,
                    "y": 923
                },
                {
                    "x": 2108,
                    "y": 923
                },
                {
                    "x": 2108,
                    "y": 1020
                },
                {
                    "x": 442,
                    "y": 1020
                }
            ],
            "category": "paragraph",
            "html": "<p id='133' style='font-size:20px'>Xue, Naiwen, Xia, Fei, Chiou, Fu-Dong, and Palmer, Martha. The Penn Chinese TreeBank: Phrase<br>structure annotation of a large corpus. Natural Language Engineering, 11(2):207-238, 2005.</p>",
            "id": 133,
            "page": 10,
            "text": "Xue, Naiwen, Xia, Fei, Chiou, Fu-Dong, and Palmer, Martha. The Penn Chinese TreeBank: Phrase structure annotation of a large corpus. Natural Language Engineering, 11(2):207-238, 2005."
        },
        {
            "bounding_box": [
                {
                    "x": 1253,
                    "y": 3131
                },
                {
                    "x": 1301,
                    "y": 3131
                },
                {
                    "x": 1301,
                    "y": 3173
                },
                {
                    "x": 1253,
                    "y": 3173
                }
            ],
            "category": "footer",
            "html": "<footer id='134' style='font-size:16px'>10</footer>",
            "id": 134,
            "page": 10,
            "text": "10"
        }
    ]
}